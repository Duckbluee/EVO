{"references":[{"paperId":"093f9b0cd66a2356f18ecac15cf4209edae1ca4c","externalIds":{"DBLP":"conf/acl/ChatterjeeTD024","ArXiv":"2405.10548","DOI":"10.48550/arXiv.2405.10548","CorpusId":269899641},"title":"Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks"},{"paperId":"e88a6a1b385d4ce14e0eea162bd821ae8320291f","externalIds":{"ArXiv":"2405.10738","DBLP":"conf/acl/Li0ZJM24","DOI":"10.48550/arXiv.2405.10738","CorpusId":269899527},"title":"Feature-Adaptive and Data-Scalable In-Context Learning"},{"paperId":"8cfb990489950eb5734198ef163410a387081c20","externalIds":{"DBLP":"journals/corr/abs-2405-00200","ArXiv":"2405.00200","DOI":"10.48550/arXiv.2405.00200","CorpusId":269484643},"title":"In-Context Learning with Long-Context Models: An In-Depth Exploration"},{"paperId":"2717e5c7384ec12cfd6cf9c34897c6adad3230ed","externalIds":{"DBLP":"journals/tmlr/Li0DYC25","ArXiv":"2404.02060","DOI":"10.48550/arXiv.2404.02060","CorpusId":268857023},"title":"Long-context LLMs Struggle with Long In-context Learning"},{"paperId":"63914b58bb944edbccba8304fd3e5bccb232a964","externalIds":{"DBLP":"conf/iclr/0001MLLLG24","ArXiv":"2403.06914","DOI":"10.48550/arXiv.2403.06914","CorpusId":268363458},"title":"MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning"},{"paperId":"29eadc8a20594dcf62d505cf478149c4d4ec647e","externalIds":{"ArXiv":"2402.10738","DBLP":"journals/corr/abs-2402-10738","DOI":"10.48550/arXiv.2402.10738","CorpusId":267740729},"title":"Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning"},{"paperId":"b2f4d22fddf3619a38a1754d9497935aa0848426","externalIds":{"DBLP":"journals/tmlr/0003XLPK24","ArXiv":"2401.11624","DOI":"10.48550/arXiv.2401.11624","CorpusId":267069067},"title":"In-context Learning with Retrieved Demonstrations for Language Models: A Survey"},{"paperId":"1eddc4e36632342309885131a63ebd0bac1d837f","externalIds":{"ArXiv":"2312.07405","DBLP":"journals/corr/abs-2312-07405","DOI":"10.48550/arXiv.2312.07405","CorpusId":266174713},"title":"ICL Markup: Structuring In-Context Learning using Soft-Token Tags"},{"paperId":"600c842b141a4c92b4e1306ff1cdba04ab61e2ff","externalIds":{"DBLP":"journals/corr/abs-2311-09263","ArXiv":"2311.09263","DOI":"10.48550/arXiv.2311.09263","CorpusId":265221442},"title":"Auto-ICL: In-Context Learning without Human Supervision"},{"paperId":"267ef391ebaa4fc3c8ec62cb92107e8efe82a5db","externalIds":{"ArXiv":"2311.06668","DBLP":"conf/icml/LiuY0Z24","DOI":"10.48550/arXiv.2311.06668","CorpusId":265149781},"title":"In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering"},{"paperId":"419a7e9df13a3a03234aba0f05f48291261b8e59","externalIds":{"ArXiv":"2311.00871","DBLP":"journals/corr/abs-2311-00871","DOI":"10.48550/arXiv.2311.00871","CorpusId":264935329},"title":"Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models"},{"paperId":"03613effe356d2a8815f899027d6a5868822fd93","externalIds":{"DBLP":"journals/corr/abs-2310-20046","ArXiv":"2310.20046","DOI":"10.48550/arXiv.2310.20046","CorpusId":264829036},"title":"Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection"},{"paperId":"fff81378762c5cbf7de9a56c9c8ab1092644b33e","externalIds":{"DBLP":"conf/nips/FuCJS24","ArXiv":"2310.17086","DOI":"10.52202/079017-3132","CorpusId":264490768},"title":"Transformers Learn to Achieve Second-Order Convergence Rates for In-Context Linear Regression"},{"paperId":"95240dda409e28acccdc5cf619ad0c036cf4292d","externalIds":{"DBLP":"conf/icml/LiuWDZY0S0TRC23","ArXiv":"2310.17157","DOI":"10.48550/arXiv.2310.17157","CorpusId":260815690},"title":"Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"},{"paperId":"d395c771f6537259610497ba218cce5b9bfc2c50","externalIds":{"DBLP":"journals/corr/abs-2310-10638","ArXiv":"2310.10638","DOI":"10.48550/arXiv.2310.10638","CorpusId":264172290},"title":"In-Context Pretraining: Language Modeling Beyond Document Boundaries"},{"paperId":"b217b6bc340af9a10bebbf8acc36ea30871769bd","externalIds":{"ArXiv":"2310.09881","DBLP":"journals/corr/abs-2310-09881","DOI":"10.48550/arXiv.2310.09881","CorpusId":264146526},"title":"In-Context Learning with Iterative Demonstration Selection"},{"paperId":"380ba3def262f92e44c95ea9ff0eac755db34c59","externalIds":{"ArXiv":"2310.08309","DBLP":"journals/corr/abs-2310-08309","DOI":"10.48550/arXiv.2310.08309","CorpusId":263909494},"title":"Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning"},{"paperId":"f30ddf0c7455f89f016c540564e235b191c503db","externalIds":{"ArXiv":"2310.08540","CorpusId":263909464},"title":"Do pretrained Transformers Learn In-Context by Gradient Descent?"},{"paperId":"0a9030dd6cc2d438509f7568c1081d58c2523d5c","externalIds":{"ArXiv":"2310.03331","DBLP":"journals/corr/abs-2310-03331","DOI":"10.48550/arXiv.2310.03331","CorpusId":263672156},"title":"Fine-tune Language Models to Approximate Unbiased In-context Learning"},{"paperId":"cd7d770eabb4dab6894d9f91d2c3bc337e94a4e1","externalIds":{"ArXiv":"2309.13205","DBLP":"conf/ranlp/Li23","ACL":"2023.ranlp-1.69","DOI":"10.26615/978-954-452-092-2_069","CorpusId":262460726},"title":"A Practical Survey on Zero-Shot Prompt Design for In-Context Learning"},{"paperId":"2ccac575a4899144a875a817b46e4423192a7ac5","externalIds":{"ArXiv":"2308.08780","DBLP":"journals/corr/abs-2308-08780","DOI":"10.48550/arXiv.2308.08780","CorpusId":261030492},"title":"Exploring Demonstration Ensembling for In-context Learning"},{"paperId":"3c8444cc4e96bdbe6853b886caf032afd1ee1d20","externalIds":{"ArXiv":"2308.06912","DBLP":"conf/iclr/0002LWGS24","CorpusId":260887420},"title":"CausalLM is not optimal for in-context learning"},{"paperId":"104b0bb1da562d53cbda87aec79ef6a2827d191a","externalIds":{"ArXiv":"2307.09288","DBLP":"journals/corr/abs-2307-09288","CorpusId":259950998},"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models"},{"paperId":"cbec8bf16a459b0ae38856f604a6a14cd1343477","externalIds":{"DBLP":"conf/iclr/MahankaliH024","ArXiv":"2307.03576","DOI":"10.48550/arXiv.2307.03576","CorpusId":259375820},"title":"One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention"},{"paperId":"1733eb7792f7a43dd21f51f4d1017a1bffd217b5","externalIds":{"DBLP":"journals/tacl/LiuLHPBPL24","ArXiv":"2307.03172","ACL":"2024.tacl-1.9","DOI":"10.1162/tacl_a_00638","CorpusId":259360665},"title":"Lost in the Middle: How Language Models Use Long Contexts"},{"paperId":"602cea8acd2a25dee3c2970d4f05174cd6f91982","externalIds":{"DBLP":"journals/corr/abs-2307-02419","ArXiv":"2307.02419","DOI":"10.48550/arXiv.2307.02419","CorpusId":259342611},"title":"In-Context Learning for Attention Scheme: from Single Softmax Regression to Multiple Softmax Regression via a Tensor Trick"},{"paperId":"4c60ce3e5116037390b3b92866f43df83f3e9c6f","externalIds":{"DBLP":"conf/nips/RaventosPCG23","ArXiv":"2306.15063","DOI":"10.48550/arXiv.2306.15063","CorpusId":259261789},"title":"Pretraining task diversity and the emergence of non-Bayesian in-context learning for regression"},{"paperId":"f4d543ff431359947bf41152ac01233b8062221f","externalIds":{"DBLP":"journals/corr/abs-2306-04891","ArXiv":"2306.04891","DOI":"10.48550/arXiv.2306.04891","CorpusId":259108565},"title":"In-Context Learning through the Bayesian Prism"},{"paperId":"f5e9337477d7a9eb6267d0310549fdefafbb7fe2","externalIds":{"ArXiv":"2306.00297","DBLP":"conf/nips/AhnCDS23","DOI":"10.48550/arXiv.2306.00297","CorpusId":258999480},"title":"Transformers learn to implement preconditioned gradient descent for in-context learning"},{"paperId":"11ae58636a5daf0ea1297f1c4ee94042fcebefa8","externalIds":{"DBLP":"conf/nips/BiettiCBJB23","ArXiv":"2306.00802","DOI":"10.48550/arXiv.2306.00802","CorpusId":258999187},"title":"Birth of a Transformer: A Memory Viewpoint"},{"paperId":"4487bdcf1eb42bdec83709ba0df5b32dcf388976","externalIds":{"DBLP":"journals/corr/abs-2305-19420","ArXiv":"2305.19420","DOI":"10.48550/arXiv.2305.19420","CorpusId":258987402},"title":"What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization"},{"paperId":"8f936af93fb2b52b9678ff8f17c1ebe8de236a88","externalIds":{"DBLP":"journals/corr/abs-2305-17256","ArXiv":"2305.17256","DOI":"10.18653/v1/2023.findings-acl.284","CorpusId":258959244},"title":"Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning"},{"paperId":"7bd4ca8706a79983d31ab74e6c79bfdfd949602e","externalIds":{"ArXiv":"2305.14160","DBLP":"journals/corr/abs-2305-14160","DOI":"10.48550/arXiv.2305.14160","CorpusId":258841117},"title":"Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning"},{"paperId":"3706bdb607a83a558e38b62dacfed7bc9e114310","externalIds":{"DBLP":"journals/tmlr/HanWZJ25","ArXiv":"2305.12766","CorpusId":258833197},"title":"Understanding Emergent In-Context Learning from a Kernel Regression Perspective"},{"paperId":"43ffae1c1c6a7371dfe89ac84ae45f3456fdc5a0","externalIds":{"ArXiv":"2305.13016","DBLP":"conf/acl/YangH0WLL0L24","DOI":"10.48550/arXiv.2305.13016","CorpusId":258832340},"title":"Iterative Forward Tuning Boosts In-context Learning in Language Models"},{"paperId":"ff2a0fb125e7f03428420230c6ecbeafd4cf07a8","externalIds":{"DBLP":"journals/corr/abs-2305-12740","ArXiv":"2305.12740","DOI":"10.48550/arXiv.2305.12740","CorpusId":258832407},"title":"Can We Edit Factual Knowledge by In-Context Learning?"},{"paperId":"dd889342b0de45f7434cdfa7543e3bd46ec824cb","externalIds":{"DBLP":"conf/acl/SiFJFC023","ArXiv":"2305.13299","ACL":"2023.acl-long.632","DOI":"10.48550/arXiv.2305.13299","CorpusId":258833064},"title":"Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations"},{"paperId":"0088c9f4d50706c7ab71efa13bcb4b42cf2058e2","externalIds":{"DBLP":"journals/corr/abs-2305-12600","ArXiv":"2305.12600","DOI":"10.48550/arXiv.2305.12600","CorpusId":258832444},"title":"PRODIGY: Enabling In-context Learning Over Graphs"},{"paperId":"8ce6ad6d8a73757309d3b9f525cf15cb68e32397","externalIds":{"DBLP":"journals/corr/abs-2305-11170","ArXiv":"2305.11170","DOI":"10.48550/arXiv.2305.11170","CorpusId":258762345},"title":"Efficient Prompting via Dynamic In-Context Learning"},{"paperId":"3fb0731538c59f8520a309996a0567b58965f0fe","externalIds":{"ArXiv":"2305.09137","DBLP":"conf/acl/Gu0WH23","ACL":"2023.acl-long.267","DOI":"10.48550/arXiv.2305.09137","CorpusId":258715048},"title":"Pre-Training to Learn in Context"},{"paperId":"7fa85f9c0fe44f1bf9e58a55f0f009296578c2f0","externalIds":{"DBLP":"journals/corr/abs-2305-09731","ArXiv":"2305.09731","DOI":"10.48550/arXiv.2305.09731","CorpusId":258740972},"title":"What In-Context Learning \"Learns\" In-Context: Disentangling Task Recognition and Task Learning"},{"paperId":"dd7f28d93dc2ec3cbc1cc66c3443c1c17105f1b3","externalIds":{"DBLP":"conf/acl/XuXWLZM24","ArXiv":"2305.08848","DOI":"10.48550/arXiv.2305.08848","CorpusId":258685778},"title":"Small Models are Valuable Plug-ins for Large Language Models"},{"paperId":"ca0c955699f552e1c2fbda747bd41faf8a2513ce","externalIds":{"DBLP":"journals/corr/abs-2305-08804","ArXiv":"2305.08804","CorpusId":258686689},"title":"Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text"},{"paperId":"3db1219429c3f04e88347d41269bdc83c457fbf9","externalIds":{"ArXiv":"2305.08298","DBLP":"conf/emnlp/WeiHLCHTCLZ0L23","DOI":"10.48550/arXiv.2305.08298","CorpusId":258686712},"title":"Symbol tuning improves in-context learning in language models"},{"paperId":"8bd6a2a89503be083176f2cc26fabedb79238cbd","externalIds":{"ArXiv":"2305.06500","DBLP":"journals/corr/abs-2305-06500","DOI":"10.48550/arXiv.2305.06500","CorpusId":258615266},"title":"InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"},{"paperId":"1fb5a5298747b8c7d60f98640a543f20d42ab053","externalIds":{"ACL":"2023.acl-long.346","DBLP":"journals/corr/abs-2305-05940","ArXiv":"2305.05940","DOI":"10.48550/arXiv.2305.05940","CorpusId":258588286},"title":"Multilingual LLMs are Better Cross-lingual In-context Learners with Alignment"},{"paperId":"500cfab9345de174644d7534bb39695f17920601","externalIds":{"DBLP":"journals/corr/abs-2305-04835","ACL":"2023.acl-long.618","ArXiv":"2305.04835","DOI":"10.48550/arXiv.2305.04835","CorpusId":258558112},"title":"How Do In-Context Examples Affect Compositional Generalization?"},{"paperId":"6a2d96d2a7adde6349f15c1e680b67d114e7b67c","externalIds":{"DBLP":"journals/corr/abs-2305-04320","ACL":"2023.acl-long.256","ArXiv":"2305.04320","DOI":"10.48550/arXiv.2305.04320","CorpusId":258557751},"title":"Unified Demonstration Retriever for In-Context Learning"},{"paperId":"d6d3604f369bb0415cbe814e43ca3131323b03e2","externalIds":{"DBLP":"journals/pami/LiZCWPCYLL25","ArXiv":"2305.03726","DOI":"10.1109/TPAMI.2025.3571946","CorpusId":258547300,"PubMed":"40392642"},"title":"Otter: A Multi-Modal Model With In-Context Instruction Tuning"},{"paperId":"f2cd02c03d0169374442d9bc227c9aed178f4b20","externalIds":{"ArXiv":"2305.02105","DBLP":"conf/emnlp/WanCMLSLK23","DOI":"10.48550/arXiv.2305.02105","CorpusId":258461040},"title":"GPT-RE: In-context Learning for Relation Extraction using Large Language Models"},{"paperId":"57be0448d168e8d6d0b6e0d1a4405fb5fbaa1b56","externalIds":{"DBLP":"journals/corr/abs-2305-01115","ArXiv":"2305.01115","DOI":"10.48550/arXiv.2305.01115","CorpusId":258437037},"title":"In-Context Learning Unlocked for Diffusion Models"},{"paperId":"a569b9daa3606952dbcfdaa310ddfe6ad4eb95f3","externalIds":{"DBLP":"journals/corr/abs-2304-13276","ArXiv":"2304.13276","DOI":"10.48550/arXiv.2304.13276","CorpusId":258331729},"title":"The Closeness of In-Context Learning and Weight Shifting for Softmax Regression"},{"paperId":"cc0f0cb09a73f82ed44d900f5ca710bec784acc1","externalIds":{"DBLP":"conf/nips/PourrezaR23","ArXiv":"2304.11015","DOI":"10.48550/arXiv.2304.11015","CorpusId":258291425},"title":"DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction"},{"paperId":"ca6a2bc279be5a3349a22bfd6866ed633d18734b","externalIds":{"ArXiv":"2304.10592","DBLP":"conf/iclr/Zhu0SLE24","DOI":"10.48550/arXiv.2304.10592","CorpusId":258291930},"title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"},{"paperId":"a5036f31f0e629dc661f120b8c3b1f374d479ab8","externalIds":{"DBLP":"journals/corr/abs-2304-08485","ArXiv":"2304.08485","DOI":"10.48550/arXiv.2304.08485","CorpusId":258179774},"title":"Visual Instruction Tuning"},{"paperId":"9cef5a098486aeab6ed3700c5e3d29488488d16f","externalIds":{"DBLP":"journals/tip/SunCWWL25","ArXiv":"2304.04748","DOI":"10.1109/TIP.2025.3554410","CorpusId":258048653,"PubMed":"40168207"},"title":"Exploring Effective Factors for Improving Visual In-Context Learning"},{"paperId":"dfd8944d39b378489b878d6e105d040fa0e524db","externalIds":{"DBLP":"conf/naacl/ZhuLDXHKCL24","ArXiv":"2304.04675","DOI":"10.48550/arXiv.2304.04675","CorpusId":258048937},"title":"Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis"},{"paperId":"90af7c6cdf4b3359f6d275afb436f54f60082364","externalIds":{"ArXiv":"2304.03284","DBLP":"journals/corr/abs-2304-03284","DOI":"10.48550/arXiv.2304.03284","CorpusId":257985532},"title":"SegGPT: Segmenting Everything In Context"},{"paperId":"0ea7fc93d4947d9024ccaa202987a2070683bc1f","externalIds":{"DBLP":"journals/corr/abs-2303-07971","ArXiv":"2303.07971","DOI":"10.48550/arXiv.2303.07971","CorpusId":257505037},"title":"A Theory of Emergent In-Context Learning as Implicit Structure Induction"},{"paperId":"da3aca9d7b50da823f669c983edeb60445720fe0","externalIds":{"DBLP":"conf/nips/WiesLS23","ArXiv":"2303.07895","DOI":"10.48550/arXiv.2303.07895","CorpusId":257505009},"title":"The Learnability of In-Context Learning"},{"paperId":"197022486b2e2584302bd9b6442e44d15bf3e351","externalIds":{"DBLP":"journals/corr/abs-2303-05063","ArXiv":"2303.05063","DOI":"10.1109/ICCV51070.2023.01785","CorpusId":257427632},"title":"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction"},{"paperId":"154493f69d7db3d49da0e51df0192c6ad5f1724a","externalIds":{"DBLP":"journals/corr/abs-2303-03846","ArXiv":"2303.03846","DOI":"10.48550/arXiv.2303.03846","CorpusId":257378479},"title":"Larger language models do in-context learning differently"},{"paperId":"c40ec51ddd4145402bd95eeb3ce6977778d87881","externalIds":{"ArXiv":"2303.03926","DBLP":"journals/corr/abs-2303-03926","DOI":"10.48550/arXiv.2303.03926","CorpusId":257378493},"title":"Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling"},{"paperId":"a55dfc1482c9fa32859d1e8e8c5813f5a22982cc","externalIds":{"DBLP":"journals/corr/abs-2303-02913","ACL":"2023.acl-demo.47","ArXiv":"2303.02913","DOI":"10.48550/arXiv.2303.02913","CorpusId":257365525},"title":"OpenICL: An Open-Source Framework for In-context Learning"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"dc385646887a3669ae0ee506a263d592f4f7c7a6","externalIds":{"DBLP":"conf/emnlp/LiQ23a","ArXiv":"2302.13539","DOI":"10.18653/v1/2023.findings-emnlp.411","CorpusId":257219778},"title":"Finding Support Examples for In-Context Learning"},{"paperId":"fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c","externalIds":{"ArXiv":"2302.14045","DBLP":"conf/nips/Huang0WHSML0MPL23","DOI":"10.48550/arXiv.2302.14045","CorpusId":257219775},"title":"Language Is Not All You Need: Aligning Perception with Language Models"},{"paperId":"b6207fe49e29c77402f8dbab052e949990949609","externalIds":{"DBLP":"journals/corr/abs-2302-11042","ArXiv":"2302.11042","DOI":"10.48550/arXiv.2302.11042","CorpusId":257078624},"title":"In-context Example Selection with Influences"},{"paperId":"48abfc41a0abf023d2037ebb2f274835e0d322d0","externalIds":{"DBLP":"journals/corr/abs-2302-05698","ArXiv":"2302.05698","DOI":"10.48550/arXiv.2302.05698","CorpusId":256826793},"title":"Compositional Exemplars for In-context Learning"},{"paperId":"2e6fa3095df1d1ed041dfb4f5a18e31d4b7bd7bb","externalIds":{"DBLP":"journals/corr/abs-2302-04931","ArXiv":"2302.04931","DOI":"10.48550/arXiv.2302.04931","CorpusId":256808462},"title":"In-Context Learning with Many Demonstration Examples"},{"paperId":"1d75f8de31bf47ec46fa5586056420ec8bc97e86","externalIds":{"ArXiv":"2302.00871","DBLP":"journals/corr/abs-2302-00871","DOI":"10.48550/arXiv.2302.00871","CorpusId":256503647},"title":"Using In-Context Learning to Improve Dialogue Safety"},{"paperId":"465471bb5bf1a945549d6291c2d23367966b4957","externalIds":{"ArXiv":"2302.00083","DBLP":"journals/corr/abs-2302-00083","DOI":"10.1162/tacl_a_00605","CorpusId":256459451},"title":"In-Context Retrieval-Augmented Language Models"},{"paperId":"5f61ddc37476acf3741b0bfe5fcb59639cadbb86","externalIds":{"ArXiv":"2301.13670","DBLP":"conf/nips/ZhangZ023","DOI":"10.48550/arXiv.2301.13670","CorpusId":256416477},"title":"What Makes Good Examples for Visual In-Context Learning?"},{"paperId":"3f5b31c4f7350dc88002c121aecbdc82f86eb5bb","externalIds":{"DBLP":"journals/corr/abs-2301-12597","ArXiv":"2301.12597","DOI":"10.48550/arXiv.2301.12597","CorpusId":256390509},"title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"},{"paperId":"c2f91f35df893714418cc29096083dce0b441229","externalIds":{"ArXiv":"2301.02111","DBLP":"journals/corr/abs-2301-02111","DOI":"10.1109/TASLPRO.2025.3530270","CorpusId":255440307},"title":"Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers"},{"paperId":"e965e93e76a9e6c4e4863d145b5c007b540d575d","externalIds":{"ArXiv":"2212.12017","DBLP":"journals/corr/abs-2212-12017","CorpusId":255096269},"title":"OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"},{"paperId":"79f47aaef765d3452327588c37ad37826da760c7","externalIds":{"DBLP":"conf/aaai/ChoKKLLYK23","ArXiv":"2212.10873","DOI":"10.48550/arXiv.2212.10873","CorpusId":254926458},"title":"Prompt-Augmented Linear Probing: Scaling Beyond The Limit of Few-shot In-Context Learners"},{"paperId":"0c0300f53c01ae609c97395c98de4c9d85d92876","externalIds":{"DBLP":"conf/acl/XuSH23","ACL":"2023.acl-long.641","ArXiv":"2212.10773","DOI":"10.48550/arXiv.2212.10773","CorpusId":254926784},"title":"MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning"},{"paperId":"e65b346d442e9962a4276dc1c1af2956d9d5f1eb","externalIds":{"DBLP":"journals/corr/abs-2212-10560","ArXiv":"2212.10560","ACL":"2023.acl-long.754","DOI":"10.48550/arXiv.2212.10560","CorpusId":254877310},"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions"},{"paperId":"70b98d90767345b15e0569082c0e4ac661279b5d","externalIds":{"ArXiv":"2212.10450","DBLP":"conf/acl/DingQLCLJB23","ACL":"2023.acl-long.626","DOI":"10.48550/arXiv.2212.10450","CorpusId":254877171},"title":"Is GPT-3 a Good Data Annotator?"},{"paperId":"3d5922d71a370f32b7f232a596def914f67eebd1","externalIds":{"ACL":"2023.acl-long.79","DBLP":"journals/corr/abs-2212-10375","ArXiv":"2212.10375","DOI":"10.48550/arXiv.2212.10375","CorpusId":254877590},"title":"Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering"},{"paperId":"6845bea94b2fb17d4377b3bb2bd10f73a959f9cc","externalIds":{"DBLP":"journals/corr/abs-2212-09597","ArXiv":"2212.09597","ACL":"2023.acl-long.294","DOI":"10.48550/arXiv.2212.09597","CorpusId":254854219},"title":"Reasoning with Language Model Prompting: A Survey"},{"paperId":"126a4776ff8315fd506766cb8f3c722cf746ad9e","externalIds":{"DBLP":"journals/corr/abs-2212-08410","ACL":"2023.acl-short.151","ArXiv":"2212.08410","DOI":"10.48550/arXiv.2212.08410","CorpusId":254823156},"title":"Teaching Small Language Models to Reason"},{"paperId":"525d93a382f6e7873b5d8a2e0713eb3dff7fb250","externalIds":{"DBLP":"conf/icml/OswaldNRSMZV23","ArXiv":"2212.07677","DOI":"10.48550/arXiv.2212.07677","CorpusId":254685643},"title":"Transformers learn in-context by gradient descent"},{"paperId":"34ff1da13770908ef0bf389365cdde743d3c9db1","externalIds":{"DBLP":"journals/corr/abs-2212-06800","ACL":"2023.acl-long.78","ArXiv":"2212.06800","DOI":"10.48550/arXiv.2212.06800","CorpusId":254591242},"title":"Diverse Demonstrations Improve In-context Compositional Generalization"},{"paperId":"eecb45aa040064cbc0b37fd100706c02e7dc880e","externalIds":{"DBLP":"journals/corr/abs-2212-06713","ArXiv":"2212.06713","DOI":"10.48550/arXiv.2212.06713","CorpusId":254591686},"title":"Structured Prompting: Scaling In-Context Learning to 1, 000 Examples"},{"paperId":"d03a9b2a0e090cc9fd2ba0a457ecea35372f1018","externalIds":{"ArXiv":"2212.04037","DBLP":"journals/corr/abs-2212-04037","DOI":"10.48550/arXiv.2212.04037","CorpusId":254408772},"title":"Demystifying Prompts in Language Models via Perplexity Estimation"},{"paperId":"9ceaeff7117965832f4c05fd6355d021862d0a82","externalIds":{"DBLP":"conf/cvpr/WangWCS023","ArXiv":"2212.02499","DOI":"10.1109/CVPR52729.2023.00660","CorpusId":254246343},"title":"Images Speak in Images: A Generalist Painter for In-Context Visual Learning"},{"paperId":"7aa801b907b59b8ee4cfb1296d9dac22c5164c5d","externalIds":{"DBLP":"journals/corr/abs-2211-15661","ArXiv":"2211.15661","DOI":"10.48550/arXiv.2211.15661","CorpusId":254043800},"title":"What learning algorithm is in-context learning? Investigations with linear models"},{"paperId":"4d17732d90440682b0500f4e209c6cc4fac20e0e","externalIds":{"ArXiv":"2211.09066","DBLP":"journals/corr/abs-2211-09066","DOI":"10.48550/arXiv.2211.09066","CorpusId":253553151},"title":"Teaching Algorithmic Reasoning via In-context Learning"},{"paperId":"b8bd29a6104d26a16687400049a4e7e026ae6258","externalIds":{"DBLP":"conf/emnlp/ZhangFT22","ACL":"2022.emnlp-main.622","ArXiv":"2211.04486","DOI":"10.48550/arXiv.2211.04486","CorpusId":253420743},"title":"Active Example Selection for In-Context Learning"},{"paperId":"4610ffb1b016acaa82a2065ffd1a3adbae1ce722","externalIds":{"DBLP":"journals/corr/abs-2211-01910","ArXiv":"2211.01910","DOI":"10.48550/arXiv.2211.01910","CorpusId":253265328},"title":"Large Language Models Are Human-Level Prompt Engineers"},{"paperId":"c8d594f09413b1555970f43e68847c211235d60f","externalIds":{"DBLP":"journals/corr/abs-2210-09150","ArXiv":"2210.09150","DOI":"10.48550/arXiv.2210.09150","CorpusId":252917981},"title":"Prompting GPT-3 To Be Reliable"},{"paperId":"663a41c866d49ce052801fbc88947d39764cad29","externalIds":{"DBLP":"conf/acl/SuzgunSSGTCCLCZ23","ArXiv":"2210.09261","DOI":"10.48550/arXiv.2210.09261","CorpusId":252917648},"title":"Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them"},{"paperId":"90350aa626bed47b02d0c162462e5b0ca82be6b2","externalIds":{"DBLP":"journals/corr/abs-2210-03493","ArXiv":"2210.03493","CorpusId":252762275},"title":"Automatic Chain of Thought Prompting in Large Language Models"},{"paperId":"e070ff286709db28312e08b52b05539debe88146","externalIds":{"DBLP":"conf/emnlp/PressZMSSL23","ArXiv":"2210.03350","DOI":"10.48550/arXiv.2210.03350","CorpusId":252762102},"title":"Measuring and Narrowing the Compositionality Gap in Language Models"},{"paperId":"62f0db3a5ad5c795ec18fc7a6e7b01836809df57","externalIds":{"DBLP":"conf/iclr/ShiSF0SVCTRZ0W23","ArXiv":"2210.03057","DOI":"10.48550/arXiv.2210.03057","CorpusId":252735112},"title":"Language Models are Multilingual Chain-of-Thought Reasoners"},{"paperId":"c88cafa3e980765a64febe369ceb7c2aa7261d2a","externalIds":{"DBLP":"journals/corr/abs-2210-00720","ArXiv":"2210.00720","DOI":"10.48550/arXiv.2210.00720","CorpusId":252683303},"title":"Complexity-Based Prompting for Multi-Step Reasoning"},{"paperId":"e7028cd7ea838ab8294ecf26d5a2c0dbb8cfa81a","externalIds":{"DBLP":"journals/corr/abs-2210-01240","ArXiv":"2210.01240","DOI":"10.48550/arXiv.2210.01240","CorpusId":252693237},"title":"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought"},{"paperId":"c90a99eeb57019732a6cc996bb9eaf13faedf00f","externalIds":{"ArXiv":"2209.11895","DBLP":"journals/corr/abs-2209-11895","DOI":"10.48550/arXiv.2209.11895","CorpusId":252532078},"title":"In-context Learning and Induction Heads"},{"paperId":"46d64d0c1dd240f5035b1af57e738b3f70850ca2","externalIds":{"DBLP":"journals/corr/abs-2209-07661","ArXiv":"2209.07661","DOI":"10.48550/arXiv.2209.07661","CorpusId":252355503},"title":"On the Relation between Sensitivity and Accuracy in In-context Learning"},{"paperId":"86d0d3855f94105e25d81cab9f3d269c6062a9c4","externalIds":{"DBLP":"conf/iclr/SuKWSWX0OZS023","ArXiv":"2209.01975","DOI":"10.48550/arXiv.2209.01975","CorpusId":252089424},"title":"Selective Annotation Makes Language Models Better Few-Shot Learners"},{"paperId":"0a25c137edc7c9752aa6d99ae4084683c3fe6b56","externalIds":{"DBLP":"conf/nips/BarGDGE22","ArXiv":"2209.00647","DOI":"10.48550/arXiv.2209.00647","CorpusId":251979350},"title":"Visual Prompting via Image Inpainting"},{"paperId":"de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9","externalIds":{"DBLP":"journals/corr/abs-2208-01066","ArXiv":"2208.01066","DOI":"10.48550/arXiv.2208.01066","CorpusId":251253368},"title":"What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"},{"paperId":"dcbf62f17dad0f4554f91c822d141fb92f78429a","externalIds":{"ArXiv":"2206.08082","DBLP":"journals/corr/abs-2206-08082","DOI":"10.48550/arXiv.2206.08082","CorpusId":249712501},"title":"Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator"},{"paperId":"a8fd9c1625011741f74401ff9bdc1c584e25c86d","externalIds":{"ArXiv":"2206.06336","DBLP":"journals/corr/abs-2206-06336","DOI":"10.48550/arXiv.2206.06336","CorpusId":249626024},"title":"Language Models are General-Purpose Interfaces"},{"paperId":"bd1331b233e84bab7eba503abc60b31ac08e7881","externalIds":{"ArXiv":"2206.04615","DBLP":"journals/corr/abs-2206-04615","CorpusId":263625818},"title":"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"},{"paperId":"316206a2f89eb94ce02a81fba1dc304586f21b39","externalIds":{"ArXiv":"2205.12685","DBLP":"conf/emnlp/YooKKCJLLK22","ACL":"2022.emnlp-main.155","DOI":"10.48550/arXiv.2205.12685","CorpusId":249062718},"title":"Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations"},{"paperId":"4e5f7cd537a1bbcd090f9887b1b59f39a3715dba","externalIds":{"DBLP":"journals/corr/abs-2205-10782","ACL":"2023.acl-long.108","ArXiv":"2205.10782","DOI":"10.48550/arXiv.2205.10782","CorpusId":248986755},"title":"Instruction Induction: From Few Examples to Natural Language Task Descriptions"},{"paperId":"5437e8adab596d7294124c0e798708e050e25321","externalIds":{"ArXiv":"2205.10625","DBLP":"conf/iclr/ZhouSHWS0SCBLC23","DOI":"10.48550/arXiv.2205.10625","CorpusId":248986239},"title":"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"},{"paperId":"81986b8a3d3fe6c5be06fc4527953fb514ad12e8","externalIds":{"DBLP":"conf/naacl/ChenDPMISK22","ACL":"2022.naacl-main.260","ArXiv":"2205.01703","DOI":"10.48550/arXiv.2205.01703","CorpusId":248512524},"title":"Improving In-Context Few-Shot Learning via Self-Supervised Training"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","externalIds":{"DBLP":"journals/corr/abs-2204-14198","ArXiv":"2204.14198","CorpusId":248476411},"title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"1fafaccebc4a74898a74c606f846318c4c2c7536","externalIds":{"DBLP":"journals/corr/abs-2204-13509","ACL":"2022.naacl-main.380","ArXiv":"2204.13509","DOI":"10.48550/arXiv.2204.13509","CorpusId":248427215},"title":"On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model"},{"paperId":"146e9e1238ff6caf18f0bd936ffcfbe1e65d2afd","externalIds":{"DBLP":"conf/nips/ChanSLWSRMH22","ArXiv":"2205.05055","DOI":"10.48550/arXiv.2205.05055","CorpusId":248665718},"title":"Data Distributional Properties Drive Emergent In-Context Learning in Transformers"},{"paperId":"06d7cb8c8816360feb33c3367073e0ef66d7d0b0","externalIds":{"ACL":"2022.emnlp-main.340","ArXiv":"2204.07705","DBLP":"conf/emnlp/WangMAKMNADASPK22","DOI":"10.18653/v1/2022.emnlp-main.340","CorpusId":253098274},"title":"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"d53e70d834243d3d8d4b621c0c52dfec26081155","externalIds":{"ArXiv":"2203.11364","DBLP":"conf/acl/SorensenRRSRDKF22","ACL":"2022.acl-long.60","DOI":"10.18653/v1/2022.acl-long.60","CorpusId":282736019},"title":"An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels"},{"paperId":"3f4d11971f2c64be9125a7fe99c019588bbebf16","externalIds":{"DBLP":"conf/emnlp/Wang0S22","ArXiv":"2203.08383","ACL":"2022.emnlp-main.174","DOI":"10.18653/v1/2022.emnlp-main.174","CorpusId":253098851},"title":"Iteratively Prompt Pre-trained Language Models for Chain of Thought"},{"paperId":"f4df78183261538e718066331898ee5cad7cad05","externalIds":{"DBLP":"journals/corr/abs-2202-12837","ArXiv":"2202.12837","ACL":"2022.emnlp-main.759","DOI":"10.18653/v1/2022.emnlp-main.759","CorpusId":247155069},"title":"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"},{"paperId":"663662fbd9be73f99c764a7b85982bf825acfe8a","externalIds":{"DBLP":"journals/corr/abs-2202-05798","ArXiv":"2202.05798","CorpusId":246823378},"title":"The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"b3848d32f7294ec708627897833c4097eb4d8778","externalIds":{"DBLP":"journals/corr/abs-2201-08239","ArXiv":"2201.08239","CorpusId":246063428},"title":"LaMDA: Language Models for Dialog Applications"},{"paperId":"002c58077a1f1b296468b117230a1199e91f35c2","externalIds":{"ArXiv":"2201.03514","DBLP":"conf/icml/SunSQHQ22","CorpusId":245836882},"title":"Black-Box Tuning for Language-Model-as-a-Service"},{"paperId":"f9838a3be5c94bb2674a0e224de349b50e18f3c4","externalIds":{"DBLP":"journals/corr/abs-2112-08633","ACL":"2022.naacl-main.191","ArXiv":"2112.08633","DOI":"10.18653/v1/2022.naacl-main.191","CorpusId":245218561},"title":"Learning To Retrieve Prompts for In-Context Learning"},{"paperId":"10bd4160b44803ada6a3d2e366c44b7e2a4ffe90","externalIds":{"DBLP":"journals/corr/abs-2111-02080","ArXiv":"2111.02080","CorpusId":241035330},"title":"An Explanation of In-context Learning as Implicit Bayesian Inference"},{"paperId":"47df3fd32d00220c85c2c51a571254fd99b2ecc7","externalIds":{"ArXiv":"2110.15943","ACL":"2022.naacl-main.201","DBLP":"journals/corr/abs-2110-15943","DOI":"10.18653/v1/2022.naacl-main.201","CorpusId":240288835},"title":"MetaICL: Learning to Learn In Context"},{"paperId":"6bd91a3183ddb844641acb9f3fe9faec6a9ff617","externalIds":{"ArXiv":"2110.07814","DBLP":"conf/acl/ChenZZK022","ACL":"2022.acl-long.53","DOI":"10.18653/v1/2022.acl-long.53","CorpusId":239009828},"title":"Meta-learning via Language Model In-context Tuning"},{"paperId":"ff0b2681d7b05e16c46dfb71d980cc2f605907cd","externalIds":{"DBLP":"journals/corr/abs-2109-01652","ArXiv":"2109.01652","CorpusId":237416585},"title":"Finetuned Language Models Are Zero-Shot Learners"},{"paperId":"4e263b4cd6998bff2501dd143e685f413179b12d","externalIds":{"DBLP":"conf/emnlp/WangLXZZ21","ArXiv":"2108.13487","DOI":"10.18653/v1/2021.findings-emnlp.354","CorpusId":237363383},"title":"Want To Reduce Labeling Cost? GPT-3 Can Help"},{"paperId":"76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2","externalIds":{"DBLP":"journals/corr/abs-2108-07258","ArXiv":"2108.07258","CorpusId":237091588},"title":"On the Opportunities and Risks of Foundation Models"},{"paperId":"eea7bca03bda3ee2448cd012bbcb2b33822861d8","externalIds":{"DBLP":"conf/acl/MinLHZ22","ArXiv":"2108.04106","ACL":"2022.acl-long.365","DOI":"10.18653/v1/2022.acl-long.365","CorpusId":236956577},"title":"Noisy Channel Language Model Prompting for Few-Shot Text Classification"},{"paperId":"28692beece311a90f5fa1ca2ec9d0c2ce293d069","externalIds":{"DBLP":"journals/csur/LiuYFJHN23","ArXiv":"2107.13586","DOI":"10.1145/3560815","CorpusId":236493269},"title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"},{"paperId":"01b5412f3d17e90e09226d7c40ad4d4468a1414d","externalIds":{"ArXiv":"2106.13884","DBLP":"journals/corr/abs-2106-13884","CorpusId":235658331},"title":"Multimodal Few-Shot Learning with Frozen Language Models"},{"paperId":"0adec918885dff698acf359988ed79a543157f80","externalIds":{"DBLP":"journals/corr/abs-2104-08786","ArXiv":"2104.08786","ACL":"2022.acl-long.556","DOI":"10.18653/v1/2022.acl-long.556","CorpusId":233296494},"title":"Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"},{"paperId":"cbdb45fc16b0885905b91d84281c310e6cb49e9c","externalIds":{"ArXiv":"2104.08773","ACL":"2022.acl-long.244","DBLP":"conf/acl/MishraKBH22","DOI":"10.18653/v1/2022.acl-long.244","CorpusId":237421373},"title":"Cross-Task Generalization via Natural Language Crowdsourcing Instructions"},{"paperId":"240b0caabb415578bdea4da7d0a32bdff2e8163f","externalIds":{"DBLP":"journals/corr/abs-2104-08164","ArXiv":"2104.08164","ACL":"2021.emnlp-main.522","DOI":"10.18653/v1/2021.emnlp-main.522","CorpusId":233289412},"title":"Editing Factual Knowledge in Language Models"},{"paperId":"d7ac65d335b5d847f4f5826313a8732bc7abc7a8","externalIds":{"MAG":"3132736064","ArXiv":"2102.09690","DBLP":"journals/corr/abs-2102-09690","CorpusId":231979430},"title":"Calibrate Before Use: Improving Few-Shot Performance of Language Models"},{"paperId":"59641c10ed7431a3cf841f308367dc2dc0281b74","externalIds":{"DBLP":"conf/acl-deelio/LiuSZDCC22","ArXiv":"2101.06804","ACL":"2022.deelio-1.10","DOI":"10.18653/v1/2022.deelio-1.10","CorpusId":231632658},"title":"What Makes Good In-Context Examples for GPT-3?"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"4f03e69963b9649950ba29ae864a0de8c14f1f86","externalIds":{"DBLP":"conf/acl/WangTDWHJCJZ21","ArXiv":"2002.01808","MAG":"3005441132","ACL":"2021.findings-acl.121","DOI":"10.18653/v1/2021.findings-acl.121","CorpusId":211031933},"title":"K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters"},{"paperId":"bfeb827d06c1a3583b5cc6d25241203a81f6af09","externalIds":{"MAG":"2970986510","DBLP":"conf/emnlp/PetersNLSJSS19","ACL":"D19-1005","ArXiv":"1909.04164","DOI":"10.18653/v1/D19-1005","CorpusId":202542757},"title":"Knowledge Enhanced Contextual Word Representations"},{"paperId":"5f994dc8cae24ca9d1ed629e517fcc652660ddde","externalIds":{"MAG":"2953356739","DBLP":"conf/acl/ZhangHLJSL19","ArXiv":"1905.07129","ACL":"P19-1139","DOI":"10.18653/v1/P19-1139","CorpusId":158046772},"title":"ERNIE: Enhanced Language Representation with Informative Entities"},{"paperId":"d9f6ada77448664b71128bb19df15765336974a6","externalIds":{"MAG":"2943552823","ArXiv":"1905.00537","DBLP":"conf/nips/WangPNSMHLB19","CorpusId":143424870},"title":"SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"},{"paperId":"cf4aa38ae31b43fd07abe13b4ffdb265babb7be1","externalIds":{"DBLP":"journals/corr/abs-1904-09751","MAG":"2938704169","ArXiv":"1904.09751","CorpusId":127986954},"title":"The Curious Case of Neural Text Degeneration"},{"paperId":"3b5505eaec8583a2dd98d72a84d95b9eff475a81","externalIds":{"MAG":"2937153231","DBLP":"journals/corr/abs-1904-05046","CorpusId":131773911},"title":"Few-shot Learning: A Survey"},{"paperId":"4d1c856275744c0284312a3a50efb6ca9dc4cd4c","externalIds":{"MAG":"2963323070","ACL":"P18-2124","ArXiv":"1806.03822","DBLP":"journals/corr/abs-1806-03822","DOI":"10.18653/v1/P18-2124","CorpusId":47018994},"title":"Know What You Donâ€™t Know: Unanswerable Questions for SQuAD"},{"paperId":"51a55df1f023571a7e07e338ee45a3e3d66ef73e","externalIds":{"DBLP":"journals/corr/ZhangZL15","MAG":"2963012544","ArXiv":"1509.01626","CorpusId":368182},"title":"Character-level Convolutional Networks for Text Classification"},{"paperId":"f04df4e20a18358ea2f689b4c129781628ef7fc1","externalIds":{"MAG":"2953084091","ACL":"D15-1075","DBLP":"conf/emnlp/BowmanAPM15","ArXiv":"1508.05326","DOI":"10.18653/v1/D15-1075","CorpusId":14604520},"title":"A large annotated corpus for learning natural language inference"},{"paperId":"b7fc1c390c9c6d22ac4bf7dce589af3174ac13fc","externalIds":{"MAG":"1984377166","DOI":"10.1016/S0262-4079(14)62389-7","CorpusId":119946829},"title":"Beyond the imitation game"},{"paperId":"687bac2d3320083eb4530bf18bb8f8f721477600","externalIds":{"ACL":"D13-1170","DBLP":"conf/emnlp/SocherPWCMNP13","MAG":"2251939518","DOI":"10.18653/v1/d13-1170","CorpusId":990233},"title":"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"},{"paperId":"7066d011f1eaa7b0ab3e97f683d2bda9d978131f","externalIds":{"MAG":"2094848746","DBLP":"journals/cacm/Winston80","DOI":"10.1145/359038.359042","CorpusId":9814700},"title":"Learning and reasoning by analogy"},{"paperId":"bff20fb30adad8d1c173963089df5fc9664304f0","externalIds":{"MAG":"2076337359","DOI":"10.1512/IUMJ.1957.6.56038","CorpusId":123329493},"title":"A Markovian Decision Process"},{"paperId":"9070c05c70c3b16b2405b04255d12d2b0584014b","externalIds":{"DOI":"10.1136/bmj.2.4578.662-a","CorpusId":56727608},"title":"Empirical Methods"},{"paperId":"3b01b5b497e1f359b11da45af029281ee6f64c2c","externalIds":{"DBLP":"journals/corr/abs-2303-17780","DOI":"10.48550/arXiv.2303.17780","CorpusId":263897368},"title":"Towards Enhancing In-Context Learning for Code Generation"},{"paperId":"ab4467bd55ddfe7b575aad37df11720ec93965d6","externalIds":{"DBLP":"journals/corr/abs-2301-11916","DOI":"10.48550/arXiv.2301.11916","CorpusId":270973586},"title":"Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning"},{"paperId":"d86ca0894cb4d165eb5ef45b73526ca8b4cdd725","externalIds":{"DBLP":"journals/corr/abs-2212-10559","DOI":"10.48550/arXiv.2212.10559","CorpusId":254877715},"title":"Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers"},{"paperId":"a131c44951b7ace0892dd830dd0a040b99ed0803","externalIds":{"DBLP":"journals/corr/abs-2301-07067","DOI":"10.48550/arXiv.2301.07067","CorpusId":255942113},"title":"Transformers as Algorithms: Generalization and Implicit Model Selection in In-context Learning"},{"paperId":"227dcfb8f289b9629997da8572cfa84a3a016e2e","externalIds":{"DBLP":"journals/corr/abs-2305-01639","DOI":"10.48550/arXiv.2305.01639","CorpusId":263872623},"title":"Differentially Private In-Context Learning"},{"paperId":"ca0dcc09e69732b7fc582d8a610488f86ad07e36","externalIds":{"DBLP":"journals/corr/abs-2307-12375","DOI":"10.48550/arXiv.2307.12375","CorpusId":263867991},"title":"In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"c21a4d70d83e0f6eb2a9e1c41d034842dd561e47","externalIds":{"MAG":"2952331680","ACL":"N19-1421","DBLP":"journals/corr/abs-1811-00937","ArXiv":"1811.00937","DOI":"10.18653/v1/N19-1421","CorpusId":53296520},"title":"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"},{"paperId":"ed47fd8aecae53fb7fa01f1668d9a16f0d19221c","externalIds":{"MAG":"2991044292","CorpusId":213282269},"title":"Conference on Neural Information Processing Systems"},{"paperId":"5e537c4d988d55f74d0bd5bb5015208977fc52e6","externalIds":{"CorpusId":126210996},"title":"FWDselect : Variable selection algorithm in regression models"},{"paperId":"8eb180e37164d43029f627b1388279bdac47acce","externalIds":{"MAG":"2165549065","DBLP":"books/sp/09/Bontcheva0FLW09","DOI":"10.1007/978-3-540-88845-1_4","CorpusId":17232200},"title":"Human Language Technologies"},{"paperId":"b2dfc53e172160b1d9e4174dea1f997b522ce145","externalIds":{"CorpusId":280921971},"title":"Language Models are Zero-Shot Text to Speech Synthesizers"}]}