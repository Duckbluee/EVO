{"abstract":"Keyphrase generation is a crucial task that can effectively provide underlying support for numerous downstream natural language processing (NLP) tasks, e.g., information retrieval and document summarization. However, the existing generative or extractive methods neglect the fact that the sentences are not equally important to generate the keyphrases of the articles. Intuitively, some sentences are more representative than others to catch an article's central idea. To better select the representative sentences, we apply a BERT-based sentence scorer to estimate the importance of each sentence. Then, we design two strategies to more accurately generate the keyphrases by employing the learned importance score. In addition, to alleviate the inconsistency problem between the training and testing modes, we introduce a fine-grained token-level reinforcement learning (RL) reward based on prefix-matching to enhance the training procedure to boost the performance of our model. Empirical results on five datasets demonstrate that our model brings substantial improvements over the state-of-the-art methods."}