{"references":[{"paperId":"40e8af970329135ec95057d73e239dab805ad128","externalIds":{"ArXiv":"2407.21783","CorpusId":271571434},"title":"The Llama 3 Herd of Models"},{"paperId":"58200b9596c1ae759ecec7623d491ce9b1967881","externalIds":{"ArXiv":"2407.19638","DBLP":"conf/acl/0013QT0KH25","DOI":"10.18653/v1/2025.acl-long.471","CorpusId":271534539},"title":"On the Reliability of Large Language Models for Causal Discovery"},{"paperId":"a8a2a15b5d51b51c62eeed6045ab1e67130e0867","externalIds":{"DBLP":"journals/corr/abs-2406-12158","ArXiv":"2406.12158","ACL":"2024.emnlp-main.590","DOI":"10.48550/arXiv.2406.12158","CorpusId":270562831},"title":"LLMs Are Prone to Fallacies in Causal Inference"},{"paperId":"c5e9d810dcadf83d75e0121c99747859a7759326","externalIds":{"DBLP":"journals/corr/abs-2405-05363","ArXiv":"2405.05363","DOI":"10.48550/arXiv.2405.05363","CorpusId":269635354},"title":"LOC-ZSON: Language-driven Object-Centric Zero-Shot Object Retrieval and Navigation"},{"paperId":"96b3c4d0afb5ccee486e2a99f52426a5c565cd74","externalIds":{"ACL":"2024.naacl-long.246","DBLP":"conf/naacl/XuLJC024","ArXiv":"2404.02444","DOI":"10.18653/v1/2024.naacl-long.246","CorpusId":268876181},"title":"The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education"},{"paperId":"0a39a9d3d884501ae103ec47d48608b6b642203a","externalIds":{"DBLP":"journals/corr/abs-2403-18346","ArXiv":"2403.18346","DOI":"10.48550/arXiv.2403.18346","CorpusId":268723751},"title":"Quantifying and Mitigating Unimodal Biases in Multimodal Large Language Models: A Causal Perspective"},{"paperId":"e0702a22e0841c54ab865b4996d7b07af192a3e1","externalIds":{"DBLP":"journals/corr/abs-2401-10529","ArXiv":"2401.10529","DOI":"10.48550/arXiv.2401.10529","CorpusId":267061347},"title":"Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences"},{"paperId":"e9273e5c14343c0b34010bbf2e2aada57d5f6bcf","externalIds":{"DBLP":"journals/corr/abs-2312-14670","ArXiv":"2312.14670","DOI":"10.48550/arXiv.2312.14670","CorpusId":266521610},"title":"Zero-shot Causal Graph Extrapolation from Text via LLMs"},{"paperId":"d99f91a811512ecd1c9f1d80dcdd712d5c5abc88","externalIds":{"ArXiv":"2312.07132","DBLP":"journals/corr/abs-2312-07132","DOI":"10.48550/arXiv.2312.07132","CorpusId":266174326},"title":"Image Content Generation with Causal Reasoning"},{"paperId":"7e1a823a3ee88e0964a18b89015614d8cc82d560","externalIds":{"DBLP":"journals/corr/abs-2312-06820","ArXiv":"2312.06820","DOI":"10.48550/arXiv.2312.06820","CorpusId":266174756},"title":"Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning"},{"paperId":"4923e93f043091da51ac41b039be1698a1158d80","externalIds":{"ArXiv":"2312.06685","DBLP":"journals/corr/abs-2312-06685","DOI":"10.1109/CVPR52733.2024.01267","CorpusId":266174299},"title":"Causal-CoG: A Causal-Effect Look at Context Generation for Boosting Multi-Modal Language Models"},{"paperId":"01efb3fd2d3ae4b5f4389c916c94f2c6d9c11b81","externalIds":{"DBLP":"journals/corr/abs-2311-08648","ArXiv":"2311.08648","DOI":"10.48550/arXiv.2311.08648","CorpusId":265213076},"title":"Explore Spurious Correlations at the Concept Level in Language Models for Text Classification"},{"paperId":"00147fc393e1f66dbdc8efb2347ae2445a81e9cd","externalIds":{"DBLP":"journals/corr/abs-2311-04284","ArXiv":"2311.04284","DOI":"10.48550/arXiv.2311.04284","CorpusId":265050972},"title":"CRAB: Assessing the Strength of Causal Relationships Between Real-world Events"},{"paperId":"578887182fcf49cfd4d99fa3b1de200e8ebb2c45","externalIds":{"DBLP":"journals/corr/abs-2311-01270","ArXiv":"2311.01270","DOI":"10.48550/arXiv.2311.01270","CorpusId":264935274},"title":"People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection"},{"paperId":"708450b22ed062da7fa577e10088f25023b1437c","externalIds":{"DBLP":"journals/corr/abs-2310-19677","ArXiv":"2310.19677","DOI":"10.48550/arXiv.2310.19677","CorpusId":264802129},"title":"MoCa: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks"},{"paperId":"e92b2df1bc4b348b47707eb0bb8718de2ff34dfc","externalIds":{"DBLP":"conf/iclr/VashishthaR0BB025","ArXiv":"2310.15117","CorpusId":264591509},"title":"Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference"},{"paperId":"70ca99ac3c21f353b3db948004510a09fdebc4f2","externalIds":{"DBLP":"journals/corr/abs-2310-14491","ArXiv":"2310.14491","DOI":"10.48550/arXiv.2310.14491","CorpusId":264426404},"title":"Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models"},{"paperId":"961f0a7fe7dc399c6881ac0ef2fa51af879333ce","externalIds":{"DBLP":"conf/cikm/BettiABK23","DOI":"10.1145/3583780.3615029","CorpusId":264350705},"title":"Relevance-based Infilling for Natural Language Counterfactuals"},{"paperId":"42d8d84083bb766b0d22906794eb2c659121525a","externalIds":{"DBLP":"journals/corr/abs-2310-06680","ArXiv":"2310.06680","DOI":"10.48550/arXiv.2310.06680","CorpusId":263828962},"title":"Benchmarking and Explaining Large Language Model-based Code Generation: A Causality-Centric Approach"},{"paperId":"894df6e5d0f34014e6a67b2d5f43e2bde91f63e3","externalIds":{"DBLP":"conf/iclr/GatCFCSR24","ArXiv":"2310.00603","DOI":"10.48550/arXiv.2310.00603","CorpusId":263334113},"title":"Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals"},{"paperId":"4aca327bf18bf35acb65689b30e8d2d647b5c3ee","externalIds":{"ArXiv":"2310.00809","DBLP":"journals/corr/abs-2310-00809","DOI":"10.48550/arXiv.2310.00809","CorpusId":263605897},"title":"Towards Causal Foundation Model: on Duality between Causal Inference and Attention"},{"paperId":"5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0","externalIds":{"DBLP":"journals/corr/abs-2309-16609","ArXiv":"2309.16609","DOI":"10.48550/arXiv.2309.16609","CorpusId":263134555},"title":"Qwen Technical Report"},{"paperId":"26089bdfdbca1e6eaaceca71e3116b715bec6d47","externalIds":{"DBLP":"journals/corr/abs-2309-01029","ArXiv":"2309.01029","DOI":"10.1145/3639372","CorpusId":261530292},"title":"Explainability for Large Language Models: A Survey"},{"paperId":"bcfa73aedf1b2d1ee4f168e21298a37ac55a37f7","externalIds":{"DBLP":"journals/coling/GallegosRBTKDYZA24","ArXiv":"2309.00770","DOI":"10.1162/coli_a_00524","CorpusId":261530629},"title":"Bias and Fairness in Large Language Models: A Survey"},{"paperId":"b9672ac98913c43fcb996b3def314789d1cc0cf4","externalIds":{"DBLP":"journals/corr/abs-2308-13067","ArXiv":"2308.13067","DOI":"10.48550/arXiv.2308.13067","CorpusId":261214555},"title":"Causal Parrots: Large Language Models May Talk Causality But Are Not Causal"},{"paperId":"1fd31b74f5e1eeb67341982fd35a613c6fad10e0","externalIds":{"DBLP":"journals/corr/abs-2308-07891","ArXiv":"2308.07891","DOI":"10.1109/CVPR52733.2024.02566","CorpusId":260899869},"title":"Link-Context Learning for Multimodal LLMs"},{"paperId":"104b0bb1da562d53cbda87aec79ef6a2827d191a","externalIds":{"ArXiv":"2307.09288","DBLP":"journals/corr/abs-2307-09288","CorpusId":259950998},"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models"},{"paperId":"69f2ba0f33a54e01de32c616b64e85d5d7194067","externalIds":{"DBLP":"journals/corr/abs-2307-08678","ArXiv":"2307.08678","DOI":"10.48550/arXiv.2307.08678","CorpusId":259937644},"title":"Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations"},{"paperId":"37a25ec621139e98498252874b142c6ef3730e2a","externalIds":{"ArXiv":"2306.16902","DBLP":"journals/tai/BanCLWZTC25","DOI":"10.1109/TAI.2025.3560927","CorpusId":259287331},"title":"Integrating Large Language Model for Improved Causal Discovery"},{"paperId":"dcb43c2b28f8991a97f391e6b79d267b411cccfd","externalIds":{"DBLP":"journals/corr/abs-2306-10790","ArXiv":"2306.10790","ACL":"2023.acl-long.509","DOI":"10.48550/arXiv.2306.10790","CorpusId":259203213},"title":"Preserving Commonsense Knowledge from Pre-trained Language Models via Causal Inference"},{"paperId":"0a94fbb5e1c93513523f00e75d672ef4553861f9","externalIds":{"ArXiv":"2306.05836","DBLP":"conf/iclr/Jin0LPSMDS24","DOI":"10.48550/arXiv.2306.05836","CorpusId":259129342},"title":"Can Large Language Models Infer Causation from Correlation?"},{"paperId":"d011b9cc8bad2d29595f1ef5cff344abd2c5c5ab","externalIds":{"ArXiv":"2306.00374","DBLP":"journals/corr/abs-2306-00374","DOI":"10.18653/v1/2023.findings-acl.720","CorpusId":258999496},"title":"CFL: Causally Fair Language Models Through Token-level Attribute Controlled Generation"},{"paperId":"498d1406fc4cddb05cd46477793f2e726a6fe238","externalIds":{"ArXiv":"2305.19213","DBLP":"journals/corr/abs-2305-19213","DOI":"10.48550/arXiv.2305.19213","CorpusId":258968140},"title":"The Magic of IF: Investigating Causal Reasoning Abilities in Large Language Models of Code"},{"paperId":"0457c6c4f3512beb0237e62292d905e962b391a9","externalIds":{"DBLP":"journals/corr/abs-2305-17727","ArXiv":"2305.17727","DOI":"10.1109/TKDE.2024.3352575","CorpusId":258959446},"title":"Learning a Structural Causal Model for Intuition Reasoning in Conversation"},{"paperId":"62b322b0bead56d6a252a2e24de499ea8385ad7f","externalIds":{"DBLP":"journals/corr/abs-2305-13669","DOI":"10.48550/arXiv.2305.13669","CorpusId":258840979},"title":"Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment"},{"paperId":"138a78320301b6a3500f7752146d1a560de3aa32","externalIds":{"DBLP":"conf/emnlp/00020CS23","ArXiv":"2305.14010","DOI":"10.48550/arXiv.2305.14010","CorpusId":258841172},"title":"IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions"},{"paperId":"744a98cc2736fa71d3984602e10b68319a47c65e","externalIds":{"DBLP":"conf/sigsoft/WanWHGBL23","ArXiv":"2305.12434","DOI":"10.1145/3611643.3616310","CorpusId":258833296},"title":"BiasAsker: Measuring the Bias in Conversational AI System"},{"paperId":"3f7fa58806614a1f38ae760c25c1305e3a87d4ce","externalIds":{"DBLP":"journals/corr/abs-2305-08809","ArXiv":"2305.08809","DOI":"10.48550/arXiv.2305.08809","CorpusId":258685390},"title":"Interpretability at Scale: Identifying Causal Mechanisms in Alpaca"},{"paperId":"1b9fc8268b392742ea43c2c017a767cf62386139","externalIds":{"DBLP":"conf/emnlp/GaoD0023","ArXiv":"2305.07375","DOI":"10.48550/arXiv.2305.07375","CorpusId":258676401},"title":"Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation"},{"paperId":"12910786da7a34c9ee26798fd81b0ed7b0e38789","externalIds":{"DBLP":"journals/tmlr/GurneeNPHTB23","ArXiv":"2305.01610","DOI":"10.48550/arXiv.2305.01610","CorpusId":258437237},"title":"Finding Neurons in a Haystack: Case Studies with Sparse Probing"},{"paperId":"10632e0a667cbc3c52cc8f11a46d8e8e9c7739e3","externalIds":{"DBLP":"journals/corr/abs-2305-00050","ArXiv":"2305.00050","DOI":"10.48550/arXiv.2305.00050","CorpusId":258426662},"title":"Causal Reasoning and Large Language Models: Opening a New Frontier for Causality"},{"paperId":"8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c","externalIds":{"ArXiv":"2303.12712","DBLP":"journals/corr/abs-2303-12712","CorpusId":257663729},"title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"762ca2711eb167f19b79e39c175708ca15e1f5d7","externalIds":{"ArXiv":"2303.08112","DBLP":"journals/corr/abs-2303-08112","DOI":"10.48550/arXiv.2303.08112","CorpusId":257504984},"title":"Eliciting Latent Predictions from Transformers with the Tuned Lens"},{"paperId":"0606bb9a541ce7e57bd78ac680a7df0225ece30c","externalIds":{"DBLP":"journals/corr/abs-2303-05279","ArXiv":"2303.05279","DOI":"10.48550/arXiv.2303.05279","CorpusId":253065120},"title":"Can large language models build causal graphs?"},{"paperId":"cb1b5d949a1d711b1bd3a2924e045ad3f893252c","externalIds":{"ArXiv":"2303.02536","DBLP":"journals/corr/abs-2303-02536","DOI":"10.48550/arXiv.2303.02536","CorpusId":257365438},"title":"Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations"},{"paperId":"886499f0ab825a266f953f952dccda4b721e80f7","externalIds":{"ArXiv":"2302.09236","ACL":"2023.findings-eacl.58","DBLP":"journals/corr/abs-2302-09236","DOI":"10.48550/arXiv.2302.09236","CorpusId":257038347},"title":"Scalable Prompt Generation for Semi-supervised Learning with Language Models"},{"paperId":"c43a4a7b7ea4f4889de051321cb0073fd577f843","externalIds":{"DBLP":"conf/eacl/ZhangXYZYAC23","ACL":"2023.findings-eacl.31","ArXiv":"2301.10896","DOI":"10.48550/arXiv.2301.10896","CorpusId":256274941},"title":"Causal Reasoning of Entities and Events in Procedural Texts"},{"paperId":"8d43f788a863258dc0a34e05f4a0c9f434be7829","externalIds":{"DBLP":"journals/corr/abs-2301-13819","ArXiv":"2301.13819","DOI":"10.48550/arXiv.2301.13819","CorpusId":256416013},"title":"Causal-Discovery Performance of ChatGPT in the context of Neuropathic Pain Diagnosis"},{"paperId":"6a38a5a85d8405a11171876126eb9c7633005b03","externalIds":{"ArXiv":"2210.04692","DBLP":"journals/corr/abs-2210-04692","DOI":"10.48550/arXiv.2210.04692","CorpusId":252780087},"title":"Language Prior Is Not the Only Shortcut: A Benchmark for Shortcut Learning in VQA"},{"paperId":"59fd003eac336b799da8e42f920b0f29558d0990","externalIds":{"ArXiv":"2209.00869","CorpusId":252070639},"title":"A Survey of Causal Inference Frameworks"},{"paperId":"418085c9726669bf53f3d66e0018f2b08ffc4ce6","externalIds":{"DBLP":"conf/iclr/LuFZXWEW23","ArXiv":"2206.02928","CorpusId":252681067},"title":"Neuro-Symbolic Procedural Planning with Commonsense Prompting"},{"paperId":"27faee1141f69cb909b86635c718f7f409dd099c","externalIds":{"ArXiv":"2205.12331","DBLP":"journals/corr/abs-2205-12331","DOI":"10.48550/arXiv.2205.12331","CorpusId":249062932},"title":"Certified Robustness Against Natural Language Attacks by Causal Intervention"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"c4e991c0c5c21608a5a21d31fd478ce7b7fb527d","externalIds":{"ACL":"2022.acl-long.398","DBLP":"journals/corr/abs-2203-12258","ArXiv":"2203.12258","DOI":"10.48550/arXiv.2203.12258","CorpusId":247619066},"title":"Can Prompt Probe Pretrained Language Models? Understanding the Invisible Risks from a Causal View"},{"paperId":"706dfab036ebe310a1af0344f8481868c8bedbed","externalIds":{"DBLP":"journals/corr/abs-2202-00436","ArXiv":"2202.00436","CorpusId":246442301},"title":"Causal Inference Principles for Reasoning about Commonsense Causality"},{"paperId":"b3848d32f7294ec708627897833c4097eb4d8778","externalIds":{"DBLP":"journals/corr/abs-2201-08239","ArXiv":"2201.08239","CorpusId":246063428},"title":"LaMDA: Language Models for Dialog Applications"},{"paperId":"1847784333aab5a3f3aa718b755eae4996765021","externalIds":{"DBLP":"conf/aaai/DingYXGHLKDBJ22","ArXiv":"2112.05194","DOI":"10.1609/aaai.v36i11.21443","CorpusId":245117373},"title":"Word Embeddings via Causal Inference: Gender Bias Reducing and Semantic Information Preserving"},{"paperId":"de6807676d8171472ed6cf421c4e4ed3cbb47699","externalIds":{"ArXiv":"2110.08527","ACL":"2022.acl-long.132","DBLP":"journals/corr/abs-2110-08527","DOI":"10.18653/v1/2022.acl-long.132","CorpusId":239015827},"title":"An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models"},{"paperId":"130d432ccbc836380a212bea618f84ff094a6a52","externalIds":{"DBLP":"journals/corr/abs-2109-00725","ArXiv":"2109.00725","DOI":"10.1162/tacl_a_00511","CorpusId":237386009},"title":"Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond"},{"paperId":"7f07e3a5c26c3993a590988bd9daeab00d8e7a54","externalIds":{"ArXiv":"2107.07610","DBLP":"conf/naacl/MengDSW22","DOI":"10.18653/v1/2022.findings-naacl.8","CorpusId":249018208},"title":"Self-Supervised Contrastive Learning with Adversarial Perturbations for Defending Word Substitution-based Attacks"},{"paperId":"1c2e60e0e31d06c909ddffbb2387987b449aceb0","externalIds":{"DBLP":"journals/corr/abs-2105-14553","ACL":"2021.findings-acl.287","ArXiv":"2105.14553","DOI":"10.18653/v1/2021.findings-acl.287","CorpusId":235254289},"title":"Defending Pre-trained Language Models from Adversarial Word Substitution Without Performance Sacrifice"},{"paperId":"e24b84322e232a1f25f345a08bfd9440469decbe","externalIds":{"MAG":"3115151495","ACL":"2020.coling-main.133","DBLP":"conf/coling/XuZLZ20","DOI":"10.18653/V1/2020.COLING-MAIN.133","CorpusId":227230406},"title":"A Review of Dataset and Labeling Methods for Causality Extraction"},{"paperId":"3e3f55cb25b919c4e8158195fd3ce2f23cfa7723","externalIds":{"ArXiv":"2006.04315","DBLP":"journals/corr/abs-2006-04315","MAG":"3033665206","DOI":"10.1109/CVPR46437.2021.01251","CorpusId":219530451},"title":"Counterfactual VQA: A Cause-Effect Look at Language Bias"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"e6c561d02500b2596a230b341a8eb8b921ca5bf2","externalIds":{"MAG":"3001279689","ArXiv":"2001.08361","DBLP":"journals/corr/abs-2001-08361","CorpusId":210861095},"title":"Scaling Laws for Neural Language Models"},{"paperId":"8ae9a17c87a4518b513e860683a0ef7824be994d","externalIds":{"MAG":"3002104146","ArXiv":"2001.07676","ACL":"2021.eacl-main.20","DBLP":"journals/corr/abs-2001-07676","DOI":"10.18653/v1/2021.eacl-main.20","CorpusId":210838924},"title":"Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"},{"paperId":"4136cbc5f7f1fa34b91bf7bd335b173afaaf68d6","externalIds":{"DBLP":"journals/corr/abs-2001-02378","MAG":"2999152968","ArXiv":"2001.02378","CorpusId":210064343},"title":"MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"4690190d6c110f7525f7250e1acf4a4eab42519f","externalIds":{"ACL":"D19-1423","DBLP":"journals/corr/abs-1909-00986","MAG":"2971789279","ArXiv":"1909.00986","DOI":"10.18653/v1/D19-1423","CorpusId":202538141},"title":"Certified Robustness to Adversarial Word Substitutions"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"1670a07b70f90cc4ddba71343e6a7ee4b5198595","externalIds":{"ACL":"P19-1164","MAG":"2947599143","DBLP":"conf/acl/StanovskySZ19","ArXiv":"1906.00591","DOI":"10.18653/v1/P19-1164","CorpusId":173991101},"title":"Evaluating Gender Bias in Machine Translation"},{"paperId":"f6e6c948a2074e38e0a4e9099c0f63773c6013dd","externalIds":{"DOI":"10.7551/mitpress/11578.003.0012","CorpusId":4709500},"title":"Causality"},{"paperId":"b1832b749528755dfcbe462717f4f5afc07243b8","externalIds":{"DBLP":"journals/corr/abs-1904-01172","MAG":"2928107702","CorpusId":91184338},"title":"Commonsense Reasoning for Natural Language Understanding: A Survey of Benchmarks, Resources, and Approaches"},{"paperId":"f7325d232c7ac7d2daaf6605377058db5b5b83cc","externalIds":{"MAG":"2951278035","DBLP":"journals/csur/GuidottiMRTGP19","ArXiv":"1802.01933","DOI":"10.1145/3236009","CorpusId":3342225},"title":"A Survey of Methods for Explaining Black Box Models"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"2bf2c3598f1ee3a2fa22185cb2aaeb425de004ad","externalIds":{"MAG":"2073302931","DBLP":"journals/cacm/DavisM15","DOI":"10.1145/2701413","CorpusId":13583137},"title":"Commonsense reasoning and commonsense knowledge in artificial intelligence"},{"paperId":"19dabe9fdbe82d74a584f5ece882f5825e4effdb","externalIds":{"MAG":"2121756366","DOI":"10.1093/BIOMET/AST066","CorpusId":16482102},"title":"Measurement bias and effect restoration in causal inference"},{"paperId":"545122e2990590524459ec9b59ccac6ce71e3b6a","externalIds":{"MAG":"2132917208","DOI":"10.1037/H0037350","CorpusId":52832751},"title":"Estimating causal effects of treatments in randomized and nonrandomized studies."},{"paperId":"f6d9ba13cb2f6354787e1c8fe4ee30cbd5f6addb","externalIds":{"MAG":"2055509010","DOI":"10.1214/AOMS/1177732676","CorpusId":121382684},"title":"The Method of Path Coefficients"},{"paperId":"0425c47e19b5f1fcc680967ebd6c6e7cebc0b768","externalIds":{"DBLP":"conf/naacl/Xia0HZM024","ACL":"2024.naacl-long.262","DOI":"10.18653/v1/2024.naacl-long.262","CorpusId":270514540},"title":"Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback"},{"paperId":"fed3376de52d70ba83050182e79466dddde45746","externalIds":{"DBLP":"journals/corr/abs-2402-10340","DOI":"10.48550/arXiv.2402.10340","CorpusId":270802839},"title":"On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities"},{"paperId":"ebda8d187f83876e37922c4105b171e6d7f99b05","externalIds":{"DBLP":"conf/acl/Wu0CWRKRM24","DOI":"10.18653/v1/2024.acl-long.758","CorpusId":268290124},"title":"DeCoT: Debiasing Chain-of-Thought for Knowledge-Intensive Tasks in Large Language Models via Causal Intervention"},{"paperId":"f30b720e34d405f200270a6ef2d09e98585fb4d1","externalIds":{"DBLP":"conf/nips/JinCLGKLBAKSS23","DOI":"10.48550/arXiv.2312.04350","CorpusId":268042280},"title":"CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models"},{"paperId":"55e67fb0bf20606af9bb931118c155383fc80c20","externalIds":{"DBLP":"conf/emnlp/Miao0Q23","DOI":"10.18653/v1/2023.emnlp-main.344","CorpusId":266163908},"title":"Generating Commonsense Counterfactuals for Stable Relation Extraction"},{"paperId":"3ca2296b4e9f33316e574cf14c166d2804198676","externalIds":{"DBLP":"journals/corr/abs-2310-17512","DOI":"10.48550/arXiv.2310.17512","CorpusId":264490541},"title":"CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents"},{"paperId":"dce7db550d6edda246d7848a37f777ba3b9bbf2f","externalIds":{"DBLP":"conf/nips/FederWSSB23","DOI":"10.48550/arXiv.2310.12803","CorpusId":268064142},"title":"Causal-structure Driven Augmentations for Text OOD Generalization"},{"paperId":"a5d5b918033ee0b97886515e3812f4cacd763a80","externalIds":{"DBLP":"journals/corr/abs-2307-16387","DOI":"10.48550/arXiv.2307.16387","CorpusId":260333963},"title":"Relation-Oriented: Toward Knowledge-Aligned Causal AI"},{"paperId":"60999ddb99aea5a93bd2ba16fb7671dc76bf3ba5","externalIds":{"ACL":"2023.acl-long.232","DBLP":"conf/acl/ZhouMYYZ23","DOI":"10.18653/v1/2023.acl-long.232","CorpusId":259370743},"title":"Causal-Debias: Unifying Debiasing in Pretrained Language Models and Fine-tuning via Causal Invariant Learning"},{"paperId":"13b8060acc3db1fc555f6e55368f6d02899a1698","externalIds":{"DBLP":"conf/acl/FleisigAABDOSVW23","ACL":"2023.acl-long.343","DOI":"10.18653/v1/2023.acl-long.343","CorpusId":259092939},"title":"FairPrism: Evaluating Fairness-Related Harms in Text Generation"},{"paperId":"16af44cd417766bab61e4ec9ebd4566cfa2a3b93","externalIds":{"DBLP":"conf/emnlp/MadaanHY23","DOI":"10.18653/v1/2023.findings-emnlp.101","CorpusId":266176622},"title":"What Makes Chain-of-Thought Prompting Effective? A Counterfactual Study"},{"paperId":"27d80545d142ced9b921290b5b2798cabd55468b","externalIds":{"ACL":"2023.wassa-1.33","DBLP":"conf/wassa/KimGYL23","DOI":"10.18653/v1/2023.wassa-1.33","CorpusId":260063124},"title":"Can ChatGPT Understand Causal Language in Science Claims?"},{"paperId":"84dc889beff9d51fe429cff8c92735e7410ee3c2","externalIds":{"DBLP":"journals/corr/abs-2306-14565","DOI":"10.48550/arXiv.2306.14565","CorpusId":263860779},"title":"Aligning Large Multi-Modal Model with Robust Instruction Tuning"},{"paperId":"65d5728ea17f016382870aa27aac1e78d590b50c","externalIds":{"DBLP":"journals/corr/abs-2310-14566","DOI":"10.48550/arXiv.2310.14566","CorpusId":264426657},"title":"HallusionBench: You See What You Think? Or You Think What You See? An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5, and Other Multi-modality Models"},{"paperId":"f0359e993b444e002479a3f2a7177c11e4e432ba","externalIds":{"DBLP":"conf/blackboxnlp/Tan23","ACL":"2023.blackboxnlp-1.12","DOI":"10.18653/v1/2023.blackboxnlp-1.12","CorpusId":266052360},"title":"Causal Abstraction for Chain-of-Thought Reasoning in Arithmetic Word Problems"},{"paperId":"04dd492b506e48b7dd91ecb1e1fdb80c1ce30e34","externalIds":{"DBLP":"journals/corr/abs-2308-11914","DOI":"10.48550/arXiv.2308.11914","CorpusId":261076364},"title":"Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs"},{"paperId":"ca483f42d70047fe4fb5c1abe9a2a6cd734329ae","externalIds":{"DBLP":"journals/corr/abs-2311-08605","DOI":"10.48550/arXiv.2311.08605","CorpusId":273994240},"title":"Navigating the Ocean of Biases: Political Bias Attribution in Language Models via Causal Structures"},{"paperId":"29c7f009df21d0112c48dec254ff80cc45fac3af","externalIds":{"DBLP":"conf/nips/SchaefferMK23","ArXiv":"2304.15004","DOI":"10.48550/arXiv.2304.15004","CorpusId":258418299},"title":"Are Emergent Abilities of Large Language Models a Mirage?"},{"paperId":"fe0825f9ddb1cccb545f4249da55b6b55e577bbd","externalIds":{"DBLP":"conf/iclr/SanhWRBSACSRDBX22","CorpusId":276421109},"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization"},{"paperId":"78d08b8ab4132defffe98ec7f80a51452203f70d","externalIds":{"DBLP":"conf/nips/VigGBQNSS20","MAG":"3104142662","CorpusId":227275068},"title":"Investigating Gender Bias in Language Models Using Causal Mediation Analysis"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":"09260da50abc7a39b3f00281c5fce6fa604de88b","externalIds":{"MAG":"2397449569","DBLP":"books/crc/tucker97/Pearl97","DOI":"10.1007/978-94-017-1735-9_12","CorpusId":2506646},"title":"Graphical Models for Probabilistic and Causal Reasoning"},{"paperId":"8ad550872eac4d53f07cb2ffe9dc9e0ce9a0fdc8","externalIds":{"MAG":"637373685","CorpusId":166526704},"title":"Mexico City : MÃ©xico"}]}