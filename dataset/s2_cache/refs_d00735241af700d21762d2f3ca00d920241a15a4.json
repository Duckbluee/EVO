{"references":[{"paperId":"988a9394967d300e461155a9384c0a3f8ab17d12","externalIds":{"DBLP":"journals/corr/abs-2503-06868","ArXiv":"2503.06868","DOI":"10.48550/arXiv.2503.06868","CorpusId":276902780},"title":"Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset, Evaluation Framework, and Mitigation"},{"paperId":"06796ca506bb28419a734f777f069ea2f42c1eb9","externalIds":{"ArXiv":"2412.15204","DBLP":"journals/corr/abs-2412-15204","DOI":"10.48550/arXiv.2412.15204","CorpusId":274859535},"title":"LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks"},{"paperId":"3707939a856655fcabf0acd5cba1a1009987b439","externalIds":{"DBLP":"journals/corr/abs-2408-15240","ArXiv":"2408.15240","DOI":"10.48550/arXiv.2408.15240","CorpusId":271963324},"title":"Generative Verifiers: Reward Modeling as Next-Token Prediction"},{"paperId":"9de9fa60a786ca23f924f5521326b2a264c22228","externalIds":{"ArXiv":"2407.08488","DBLP":"journals/corr/abs-2407-08488","DOI":"10.48550/arXiv.2407.08488","CorpusId":271097527},"title":"Lynx: An Open Source Hallucination Evaluation Model"},{"paperId":"b76e865e070cb353b52a3cb1e50c86ec460da79e","externalIds":{"DBLP":"journals/corr/abs-2405-20362","ArXiv":"2405.20362","DOI":"10.48550/arXiv.2405.20362","CorpusId":269976547},"title":"Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools"},{"paperId":"54972b2e4304d2164a61036ae947df2503c07009","externalIds":{"DBLP":"conf/emnlp/GekhmanYAEFRH24","ACL":"2024.emnlp-main.444","ArXiv":"2405.05904","DOI":"10.48550/arXiv.2405.05904","CorpusId":269635770},"title":"Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"},{"paperId":"1544f956492b613b47efd9ac79c3987df373fb81","externalIds":{"ArXiv":"2404.11972","ACL":"2024.emnlp-main.119","DBLP":"journals/corr/abs-2404-11972","DOI":"10.48550/arXiv.2404.11972","CorpusId":269214521},"title":"Aligning Language Models to Explicitly Handle Ambiguity"},{"paperId":"c19ea4c61ad94644f7e315d4bb547f6c610fc93d","externalIds":{"DBLP":"conf/acl/ZhangY024","ArXiv":"2402.17811","DOI":"10.48550/arXiv.2402.17811","CorpusId":268041726},"title":"TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space"},{"paperId":"0247c8299c1ead8fb2d4e5b82aeb9f1058048c87","externalIds":{"DBLP":"conf/emnlp/ShiY0ZWYL24","ACL":"2024.emnlp-main.489","ArXiv":"2402.06925","DOI":"10.48550/arXiv.2402.06925","CorpusId":267627384},"title":"A Thorough Examination of Decoding Methods in the Era of LLMs"},{"paperId":"fcee1c19e12f3b7e3595aeba702416d055bdbc3f","externalIds":{"DBLP":"conf/emnlp/WanHCQB024","ArXiv":"2401.10768","ACL":"2024.emnlp-main.152","DOI":"10.18653/v1/2024.emnlp-main.152","CorpusId":267060796},"title":"Knowledge Verification to Nip Hallucination in the Bud"},{"paperId":"3f915aab835cbfe69e7b2ea1c73b74ac8a2d384e","externalIds":{"DBLP":"conf/naacl/ZhangCBS25","ArXiv":"2312.15710","DOI":"10.48550/arXiv.2312.15710","CorpusId":266551298},"title":"Alleviating Hallucinations of Large Language Models through Induced Hallucinations"},{"paperId":"97e98215bed061bceb1a121ae9b0ef814acf8c6a","externalIds":{"DBLP":"journals/corr/abs-2311-09469","ArXiv":"2311.09469","DOI":"10.48550/arXiv.2311.09469","CorpusId":265221465},"title":"Clarify When Necessary: Resolving Ambiguity Through Interaction with LMs"},{"paperId":"b3474a0bfddd48d46abe2214f42e660b569cc4aa","externalIds":{"DBLP":"journals/corr/abs-2310-12086","ArXiv":"2310.12086","DOI":"10.48550/arXiv.2310.12086","CorpusId":264289140},"title":"FactCHD: Benchmarking Fact-Conflicting Hallucination Detection"},{"paperId":"58fdf550600fc3873729d466601c5d08a51ba8a0","externalIds":{"DBLP":"journals/corr/abs-2310-01405","ArXiv":"2310.01405","DOI":"10.48550/arXiv.2310.01405","CorpusId":263605618},"title":"Representation Engineering: A Top-Down Approach to AI Transparency"},{"paperId":"4b0b56be0ae9479d2bd5c2f0943db1906343c10f","externalIds":{"DBLP":"journals/corr/abs-2309-11495","ArXiv":"2309.11495","DOI":"10.48550/arXiv.2309.11495","CorpusId":262062565},"title":"Chain-of-Verification Reduces Hallucination in Large Language Models"},{"paperId":"e9f0b498dd964fae320a7fc145d385298a78ed36","externalIds":{"DBLP":"journals/corr/abs-2309-11064","ArXiv":"2309.11064","DOI":"10.48550/arXiv.2309.11064","CorpusId":262065814},"title":"Exploring the Relationship between LLM Hallucinations and Prompt Linguistic Nuances: Readability, Formality, and Concreteness"},{"paperId":"aa0b3306f7dd827a6fb8487aeb39d832fdcb97a0","externalIds":{"DBLP":"journals/corr/abs-2309-09558","ArXiv":"2309.09558","DOI":"10.48550/arXiv.2309.09558","CorpusId":262044218},"title":"Summarization is (Almost) Dead"},{"paperId":"7bf607c643a1f7f4607db84dfc0f4b63ff0bde70","externalIds":{"DBLP":"journals/corr/abs-2309-08594","ArXiv":"2309.08594","DOI":"10.48550/arXiv.2309.08594","CorpusId":261875641},"title":"\"Merge Conflicts!\" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs"},{"paperId":"6414281e2efb42601aa7bb5eac8759a774896968","externalIds":{"DBLP":"journals/corr/abs-2309-05936","ACL":"2023.acl-long.173","ArXiv":"2309.05936","DOI":"10.18653/v1/2023.acl-long.173","CorpusId":259370557},"title":"Do PLMs Know and Understand Ontological Knowledge?"},{"paperId":"e26888285436bc7998e5c95102a9beb60144be5e","externalIds":{"DBLP":"journals/corr/abs-2309-05463","ArXiv":"2309.05463","DOI":"10.48550/arXiv.2309.05463","CorpusId":261696657},"title":"Textbooks Are All You Need II: phi-1.5 technical report"},{"paperId":"ed5020eeda1fbe8c29b1282d654b34abee22d90f","externalIds":{"DBLP":"conf/iclr/ChuangXLKGH24","ArXiv":"2309.03883","DOI":"10.48550/arXiv.2309.03883","CorpusId":261582463},"title":"DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models"},{"paperId":"705ffeccfde95c3b0723f197c4565f7d3f0451a1","externalIds":{"DBLP":"conf/emnlp/0001XM24","ArXiv":"2309.02654","DOI":"10.48550/arXiv.2309.02654","CorpusId":261557193},"title":"Zero-Resource Hallucination Prevention for Large Language Models"},{"paperId":"d60bc65862c9aca2b4c18595cc1d0f34cadaf4cf","externalIds":{"DBLP":"journals/corr/abs-2309-03118","ArXiv":"2309.03118","DOI":"10.48550/arXiv.2309.03118","CorpusId":261557137},"title":"Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs"},{"paperId":"eee548fbd0b9dd954c692fbd8880e80d5f077bd7","externalIds":{"ArXiv":"2308.11764","DBLP":"journals/corr/abs-2308-11764","DOI":"10.48550/arXiv.2308.11764","CorpusId":261076218},"title":"Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models"},{"paperId":"f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f","externalIds":{"ArXiv":"2308.10792","DBLP":"journals/corr/abs-2308-10792","DOI":"10.1145/3777411","CorpusId":261049152},"title":"Instruction Tuning for Large Language Models: A Survey"},{"paperId":"96f6ad72733599db609332987ec6b65e30f11d07","externalIds":{"ArXiv":"2308.07317","DBLP":"journals/corr/abs-2308-07317","DOI":"10.48550/arXiv.2308.07317","CorpusId":260886870},"title":"Platypus: Quick, Cheap, and Powerful Refinement of LLMs"},{"paperId":"658cd67a91da86cf451e6f1b015f762b56015172","externalIds":{"DBLP":"conf/aaai/GunjalYB24","ArXiv":"2308.06394","DOI":"10.48550/arXiv.2308.06394","CorpusId":260887222},"title":"Detecting and Preventing Hallucinations in Large Vision Language Models"},{"paperId":"a37d5620210276e47cf0c9dd2898c2a82c9d0422","externalIds":{"DBLP":"journals/corr/abs-2308-03958","ArXiv":"2308.03958","DOI":"10.48550/arXiv.2308.03958","CorpusId":260704246},"title":"Simple synthetic data reduces sycophancy in large language models"},{"paperId":"76513f54fcecf7a380f77ad785f05c3bc869db4a","externalIds":{"DBLP":"journals/tacl/AdlakhaBLMR24a","ACL":"2024.tacl-1.38","ArXiv":"2307.16877","DOI":"10.1162/tacl_a_00667","CorpusId":260334056},"title":"Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering"},{"paperId":"47030369e97cc44d4b2e3cf1be85da0fd134904a","externalIds":{"DBLP":"journals/corr/abs-2307-15043","ArXiv":"2307.15043","CorpusId":260202961},"title":"Universal and Transferable Adversarial Attacks on Aligned Language Models"},{"paperId":"7a5b44ea10a51708e18786595c8d70b18950da11","externalIds":{"DBLP":"journals/corr/abs-2307-13528","ArXiv":"2307.13528","DOI":"10.48550/arXiv.2307.13528","CorpusId":260154834},"title":"FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios"},{"paperId":"84b77180228051040286423cec82b62c323a8fda","externalIds":{"ArXiv":"2307.11019","DBLP":"journals/corr/abs-2307-11019","DOI":"10.48550/arXiv.2307.11019","CorpusId":259991467},"title":"Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation"},{"paperId":"e01ab53663e5df5961a021506a9cb09f4efc3788","externalIds":{"DBLP":"journals/corr/abs-2307-10169","ArXiv":"2307.10169","DOI":"10.48550/arXiv.2307.10169","CorpusId":259982665},"title":"Challenges and Applications of Large Language Models"},{"paperId":"104b0bb1da562d53cbda87aec79ef6a2827d191a","externalIds":{"ArXiv":"2307.09288","DBLP":"journals/corr/abs-2307-09288","CorpusId":259950998},"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models"},{"paperId":"827afa7dd36e4afbb1a49c735bfbb2c69749756e","externalIds":{"DBLP":"journals/corr/abs-2307-13702","ArXiv":"2307.13702","DOI":"10.48550/arXiv.2307.13702","CorpusId":259953372},"title":"Measuring Faithfulness in Chain-of-Thought Reasoning"},{"paperId":"8154fb1d828cdc390dc1fa442d84034948679c47","externalIds":{"DBLP":"journals/corr/abs-2307-11768","ArXiv":"2307.11768","DOI":"10.48550/arXiv.2307.11768","CorpusId":259980634},"title":"Question Decomposition Improves the Faithfulness of Model-Generated Reasoning"},{"paperId":"a72975eb88eb31f193e9587e7415cb04e7bcdbee","externalIds":{"ACL":"2024.eacl-long.4","DBLP":"conf/eacl/MuhlgayRMLRBALSS24","ArXiv":"2307.06908","DOI":"10.48550/arXiv.2307.06908","CorpusId":259847758},"title":"Generating Benchmarks for Factuality Evaluation of Language Models"},{"paperId":"434b9f9bc71c935e4a46a1aff36a8cc4c22d9afa","externalIds":{"ACL":"2024.naacl-long.15","ArXiv":"2307.05300","DBLP":"conf/naacl/WangMW0WJ24","DOI":"10.18653/v1/2024.naacl-long.15","CorpusId":259765919},"title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration"},{"paperId":"548278897d46a54958909bb23bcaecf63e24fadf","externalIds":{"DBLP":"journals/corr/abs-2307-04964","ArXiv":"2307.04964","DOI":"10.48550/arXiv.2307.04964","CorpusId":259766568},"title":"Secrets of RLHF in Large Language Models Part I: PPO"},{"paperId":"d62c4d00b277e948956b6610ce2644e88fe1577b","externalIds":{"DBLP":"journals/cacm/Cerf23c","ArXiv":"2307.05782","DOI":"10.1007/978-981-96-6259-3","CorpusId":259837466,"PubMed":"38320147"},"title":"Large Language Models"},{"paperId":"8e1868f84091272544cb4209c4ccaad7cc88af27","externalIds":{"ArXiv":"2307.03917","DBLP":"journals/corr/abs-2307-03917","DOI":"10.1109/ASRU57964.2023.10389705","CorpusId":259501685},"title":"On Decoder-Only Architecture For Speech-to-Text and Large Language Model Integration"},{"paperId":"1827dd28ef866eaeb929ddf4bcfa492880aba4c7","externalIds":{"DBLP":"journals/corr/abs-2307-03987","ArXiv":"2307.03987","DOI":"10.48550/arXiv.2307.03987","CorpusId":263699899},"title":"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation"},{"paperId":"1733eb7792f7a43dd21f51f4d1017a1bffd217b5","externalIds":{"DBLP":"journals/tacl/LiuLHPBPL24","ArXiv":"2307.03172","ACL":"2024.tacl-1.9","DOI":"10.1162/tacl_a_00638","CorpusId":259360665},"title":"Lost in the Middle: How Language Models Use Long Contexts"},{"paperId":"888728745dbb769e29ed475d4f7661eebe1a71cf","externalIds":{"DBLP":"journals/tist/ChangWWWYZCYWWYZCYYX24","ArXiv":"2307.03109","DOI":"10.1145/3641289","CorpusId":259360395},"title":"A Survey on Evaluation of Large Language Models"},{"paperId":"929305892d4ddae575a0fc23227a8139f7681632","externalIds":{"DBLP":"journals/corr/abs-2307-02483","ArXiv":"2307.02483","DOI":"10.48550/arXiv.2307.02483","CorpusId":259342528},"title":"Jailbroken: How Does LLM Safety Training Fail?"},{"paperId":"ad022cd5da75637ac3e0a8f8cc4f0d394ba5ff7a","externalIds":{"DBLP":"conf/iclr/AlemohammadCLHB24","ArXiv":"2307.01850","DOI":"10.52591/lxai202312101","CorpusId":259341801},"title":"Self-Consuming Generative Models Go MAD"},{"paperId":"1b173d9b8b0a2529259b6fa16376aff11c1ac08f","externalIds":{"DBLP":"journals/corr/abs-2307-00360","ArXiv":"2307.00360","DOI":"10.48550/arXiv.2307.00360","CorpusId":259317198},"title":"BatGPT: A Bidirectional Autoregessive Talker from Generative Pre-trained Transformer"},{"paperId":"8f7297454d7f44365b9bcda5ebb9439a43daf5e6","externalIds":{"DBLP":"journals/corr/abs-2306-13063","ArXiv":"2306.13063","DOI":"10.48550/arXiv.2306.13063","CorpusId":259224389},"title":"Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"},{"paperId":"3e826e52754d0876611c8cf2fa7a781a701c39e6","externalIds":{"ArXiv":"2306.09296","DBLP":"journals/corr/abs-2306-09296","DOI":"10.48550/arXiv.2306.09296","CorpusId":259165244},"title":"KoLA: Carefully Benchmarking World Knowledge of Large Language Models"},{"paperId":"cc78babfacce48e715dac56886d7dd9746cfcab0","externalIds":{"DBLP":"journals/corr/abs-2306-05212","ArXiv":"2306.05212","DOI":"10.48550/arXiv.2306.05212","CorpusId":259108339},"title":"RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit"},{"paperId":"fbd2c8089870814449f9254a711041bbae145a82","externalIds":{"ArXiv":"2306.04751","DBLP":"journals/corr/abs-2306-04751","DOI":"10.48550/arXiv.2306.04751","CorpusId":259108263},"title":"How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources"},{"paperId":"405f8f5f1c6df1b3343c812832479aad5180b65f","externalIds":{"ArXiv":"2306.03341","DBLP":"journals/corr/abs-2306-03341","CorpusId":259088877},"title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language Model"},{"paperId":"7a1e71cb1310c4a873e7a4e54d1a6dab0553adce","externalIds":{"ArXiv":"2306.01116","DBLP":"journals/corr/abs-2306-01116","DOI":"10.48550/arXiv.2306.01116","CorpusId":259063761},"title":"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"},{"paperId":"be8db99310602d66bba64bcf41a572c45816fbfc","externalIds":{"ArXiv":"2305.20050","DBLP":"conf/iclr/LightmanKBEBLLS24","DOI":"10.48550/arXiv.2305.20050","CorpusId":258987659},"title":"Let's Verify Step by Step"},{"paperId":"ad934a9344f68fcc0b9aa704102aa48c39c5b591","externalIds":{"ArXiv":"2305.19187","DBLP":"journals/corr/abs-2305-19187","DOI":"10.48550/arXiv.2305.19187","CorpusId":258967487},"title":"Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models"},{"paperId":"c18e13ba65c7247774301314d181c87ee5ebc847","externalIds":{"DBLP":"journals/corr/abs-2305-18248","ArXiv":"2305.18248","ACL":"2024.findings-eacl.62","DOI":"10.48550/arXiv.2305.18248","CorpusId":258960346},"title":"Do Language Models Know When They’re Hallucinating References?"},{"paperId":"27cb586fcea5ec076b984750e9c77f0d7fc976e5","externalIds":{"ACL":"2023.acl-long.634","DBLP":"conf/acl/ZhaYLH23","ArXiv":"2305.16739","DOI":"10.48550/arXiv.2305.16739","CorpusId":258947273},"title":"AlignScore: Evaluating Factual Consistency with A Unified Alignment Function"},{"paperId":"f197bf0fc2f228483f6af3285000d54d8d97f9eb","externalIds":{"ArXiv":"2305.16291","DBLP":"journals/tmlr/WangX0MXZFA24","DOI":"10.48550/arXiv.2305.16291","CorpusId":258887849},"title":"Voyager: An Open-Ended Embodied Agent with Large Language Models"},{"paperId":"3dbbe6909d7b53dd49e059c7f61a3613045a8db0","externalIds":{"DBLP":"conf/iclr/MundlerHJV24","ArXiv":"2305.15852","DOI":"10.48550/arXiv.2305.15852","CorpusId":258887694},"title":"Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"},{"paperId":"d3f79210b54e168c76b8c311488f42d7d1048b81","externalIds":{"DBLP":"journals/corr/abs-2305-16355","ArXiv":"2305.16355","ACL":"2023.tllm-1.2","DOI":"10.48550/arXiv.2305.16355","CorpusId":258947721},"title":"PandaGPT: One Model To Instruction-Follow Them All"},{"paperId":"984d4a1d41bfc8184fb77b8aa0eb8e96d536d048","externalIds":{"DBLP":"conf/naacl/ShiHLTZY24","ArXiv":"2305.14739","ACL":"2024.naacl-short.69","DOI":"10.48550/arXiv.2305.14739","CorpusId":258866080},"title":"Trusting Your Evidence: Hallucinate Less with Context-aware Decoding"},{"paperId":"85b5068d3e1364b44ec9f46b0930b521b4089df6","externalIds":{"DBLP":"conf/naacl/LiPGGZ24","ArXiv":"2305.14623","DOI":"10.48550/arXiv.2305.14623","CorpusId":258865801},"title":"Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models"},{"paperId":"e7c97e953849f1a8e5d85ceb4cfcc0a5d54d2365","externalIds":{"DBLP":"conf/emnlp/GaoYYC23","ArXiv":"2305.14627","DOI":"10.48550/arXiv.2305.14627","CorpusId":258865710},"title":"Enabling Large Language Models to Generate Text with Citations"},{"paperId":"56e952fd463accff09cf2e35432aaabd7c7c57f3","externalIds":{"DBLP":"conf/emnlp/ZhongWMPC23","ArXiv":"2305.14795","DOI":"10.48550/arXiv.2305.14795","CorpusId":258865984},"title":"MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions"},{"paperId":"7db7653c581d7823cb9c328f2d742ec70d7a0ce4","externalIds":{"DBLP":"journals/corr/abs-2305-14908","ArXiv":"2305.14908","DOI":"10.48550/arXiv.2305.14908","CorpusId":258865339},"title":"PURR: Efficiently Editing Language Model Hallucinations by Denoising Language Model Corruptions"},{"paperId":"4780d0a027c5c5a8e01d7cf697f6296880ffc945","externalIds":{"ArXiv":"2305.14325","DBLP":"journals/corr/abs-2305-14325","DOI":"10.48550/arXiv.2305.14325","CorpusId":258841118},"title":"Improving Factuality and Reasoning in Language Models through Multiagent Debate"},{"paperId":"bd5deadc58ee45b5e004378ba1d54a96bc947b4a","externalIds":{"ArXiv":"2305.14251","DBLP":"conf/emnlp/MinKLLYKIZH23","DOI":"10.48550/arXiv.2305.14251","CorpusId":258841470},"title":"FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"},{"paperId":"4115a24474ef5f184f5cbae3f43aca4d3bb07bea","externalIds":{"ArXiv":"2305.14002","DBLP":"journals/corr/abs-2305-14002","DOI":"10.48550/arXiv.2305.14002","CorpusId":258841029},"title":"Improving Language Models via Plug-and-Play Retrieval Feedback"},{"paperId":"62b322b0bead56d6a252a2e24de499ea8385ad7f","externalIds":{"DBLP":"journals/corr/abs-2305-13669","DOI":"10.48550/arXiv.2305.13669","CorpusId":258840979},"title":"Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment"},{"paperId":"2c67ee597ed38f43ec0f123a3f1cce38cbd3b5b4","externalIds":{"DBLP":"journals/corr/abs-2305-14552","ArXiv":"2305.14552","DOI":"10.48550/arXiv.2305.14552","CorpusId":258865517},"title":"Sources of Hallucination by Large Language Models on Inference Tasks"},{"paperId":"6825ba09383bc758f9a2feaebabe35a6cd4adc4c","externalIds":{"DBLP":"conf/icml/ZhangPMLS24","ArXiv":"2305.13534","DOI":"10.48550/arXiv.2305.13534","CorpusId":258841857},"title":"How Language Model Hallucinations Can Snowball"},{"paperId":"7919cb1a1dcf70ed7803c43a71d43dba696ef149","externalIds":{"DBLP":"conf/naacl/QiaoGLJC024","ArXiv":"2305.13068","ACL":"2024.naacl-long.195","DOI":"10.48550/arXiv.2305.13068","CorpusId":258832372},"title":"Making Language Models Better Tool Learners with Execution Feedback"},{"paperId":"10f829a80a7ee0cdb16307f04e206133d75f81da","externalIds":{"ArXiv":"2305.13300","DBLP":"conf/iclr/Xie0CL024","CorpusId":263610324},"title":"Adaptive Chameleon or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts"},{"paperId":"ed0ed87161a2beab9e1bed3e783d7487a5f1062a","externalIds":{"ArXiv":"2305.13281","DBLP":"conf/emnlp/CohenHGG23","DOI":"10.48550/arXiv.2305.13281","CorpusId":258833288},"title":"LM vs LM: Detecting Factual Errors via Cross Examination"},{"paperId":"ff2a0fb125e7f03428420230c6ecbeafd4cf07a8","externalIds":{"DBLP":"journals/corr/abs-2305-12740","ArXiv":"2305.12740","DOI":"10.48550/arXiv.2305.12740","CorpusId":258832407},"title":"Can We Edit Factual Knowledge by In-Context Learning?"},{"paperId":"bcdaf6c98ddbd6809cf6241aa77200d7394db163","externalIds":{"DBLP":"conf/iclr/GouSGSYDC24","ArXiv":"2305.11738","DOI":"10.48550/arXiv.2305.11738","CorpusId":258823123},"title":"CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing"},{"paperId":"e0384ba36555232c587d4a80d527895a095a9001","externalIds":{"DBLP":"journals/corr/abs-2305-11747","ArXiv":"2305.11747","DOI":"10.48550/arXiv.2305.11747","CorpusId":258832847},"title":"HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models"},{"paperId":"546d0624adfc6e18fb87d8cc77e7705bb9ea7445","externalIds":{"ArXiv":"2305.11206","DBLP":"conf/nips/ZhouLX0SMMEYYZG23","CorpusId":258822910},"title":"LIMA: Less Is More for Alignment"},{"paperId":"206400aba5f12f734cdd2e4ab48ef6014ea60773","externalIds":{"DBLP":"journals/corr/abs-2305-10355","ArXiv":"2305.10355","DOI":"10.48550/arXiv.2305.10355","CorpusId":258740697},"title":"Evaluating Object Hallucination in Large Vision-Language Models"},{"paperId":"6d0656d9bb60a2bea50c4b894fbcc5d1e32134e7","externalIds":{"DBLP":"journals/jdiq/NavigliCR23","DOI":"10.1145/3597307","CorpusId":258688053},"title":"Biases in Large Language Models: Origins, Inventory, and Discussion"},{"paperId":"acf90b4d165690fe27c62c4af1a28d540c784000","externalIds":{"DBLP":"journals/corr/abs-2305-06311","ArXiv":"2305.06311","DOI":"10.48550/arXiv.2305.06311","CorpusId":258587884},"title":"Automatic Evaluation of Attribution by Large Language Models"},{"paperId":"e0dc8e113dbdd2896fb6420ac93e0b976c47f2a2","externalIds":{"ArXiv":"2305.04757","DBLP":"journals/corr/abs-2305-04757","DOI":"10.48550/arXiv.2305.04757","CorpusId":258556855},"title":"Augmented Large Language Models with Parametric Knowledge Guiding"},{"paperId":"629c441076da3f8185b1cf85e8036064b714e249","externalIds":{"DBLP":"conf/acl/ZhaoLJQB23","ACL":"2023.acl-long.320","ArXiv":"2305.03268","DOI":"10.48550/arXiv.2305.03268","CorpusId":258547173},"title":"Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework"},{"paperId":"56da914761e445a24481629cfc116336a0aec978","externalIds":{"DBLP":"journals/corr/abs-2305-01651","ArXiv":"2305.01651","ACL":"2023.acl-long.300","DOI":"10.48550/arXiv.2305.01651","CorpusId":258437155},"title":"Can LMs Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge"},{"paperId":"74b05bba46db21e589a2cc0f916f81069b0368ef","externalIds":{"DBLP":"journals/corr/abs-2305-00955","ArXiv":"2305.00955","DOI":"10.48550/arXiv.2305.00955","CorpusId":258426970},"title":"Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation"},{"paperId":"7e32aac43e9f1df49e116add03327ee6f365dbf3","externalIds":{"DBLP":"journals/corr/abs-2304-14178","ArXiv":"2304.14178","DOI":"10.48550/arXiv.2304.14178","CorpusId":258352455},"title":"mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"},{"paperId":"f406aceba4f29cc7cfbe7edb2f52f01374486589","externalIds":{"ArXiv":"2304.13734","DBLP":"journals/corr/abs-2304-13734","DOI":"10.18653/v1/2023.findings-emnlp.68","CorpusId":258352729},"title":"The Internal State of an LLM Knows When its Lying"},{"paperId":"fd689ba4d1db7c92664ea4176943d640405f0ef2","externalIds":{"ArXiv":"2304.10513","CorpusId":258865162},"title":"Why Does ChatGPT Fall Short in Providing Truthful Answers?"},{"paperId":"a5036f31f0e629dc661f120b8c3b1f374d479ab8","externalIds":{"DBLP":"journals/corr/abs-2304-08485","ArXiv":"2304.08485","DOI":"10.48550/arXiv.2304.08485","CorpusId":258179774},"title":"Visual Instruction Tuning"},{"paperId":"ae736662f64d56f3ab1894fbd9c45f8f37251843","externalIds":{"ArXiv":"2304.07327","DBLP":"conf/nips/KopfKRATSBNSNES23","DOI":"10.48550/arXiv.2304.07327","CorpusId":258179434},"title":"OpenAssistant Conversations - Democratizing Large Language Model Alignment"},{"paperId":"dfbfa21a93c3164ae8a033398c8de42b03b1b84d","externalIds":{"DBLP":"journals/corr/abs-2304-05613","ArXiv":"2304.05613","DOI":"10.48550/arXiv.2304.05613","CorpusId":258079179},"title":"ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning"},{"paperId":"5278a8eb2ba2429d4029745caf4e661080073c81","externalIds":{"DBLP":"conf/uist/ParkOCMLB23","ArXiv":"2304.03442","DOI":"10.1145/3586183.3606763","CorpusId":258040990},"title":"Generative Agents: Interactive Simulacra of Human Behavior"},{"paperId":"9e8cb8c91a0acb6e661b58ad724aa758490f2bea","externalIds":{"ArXiv":"2304.03277","DBLP":"journals/corr/abs-2304-03277","CorpusId":257985497},"title":"Instruction Tuning with GPT-4"},{"paperId":"44bab2836177f8bf9775e7ca536b8e200757aac7","externalIds":{"DBLP":"journals/tacl/GuerreiroAWHBCM23","ArXiv":"2303.16104","DOI":"10.1162/tacl_a_00615","CorpusId":257771892},"title":"Hallucinations in Large Multilingual Translation Models"},{"paperId":"62ad7ea9467bbcdbfe325b9ee561cab3908e4583","externalIds":{"ArXiv":"2303.12528","DBLP":"conf/emnlp/AhujaDHORJNGSAB23","DOI":"10.18653/v1/2023.emnlp-main.258","CorpusId":257663467},"title":"MEGA: Multilingual Evaluation of Generative AI"},{"paperId":"12c826f4195da172b212a529f8fcf10cc79e35da","externalIds":{"ArXiv":"2303.11315","DBLP":"journals/corr/abs-2303-11315","DOI":"10.48550/arXiv.2303.11315","CorpusId":257632259},"title":"Context-faithful Prompting for Large Language Models"},{"paperId":"7c1707db9aafd209aa93db3251e7ebd593d55876","externalIds":{"DBLP":"conf/emnlp/ManakulLG23","ArXiv":"2303.08896","DOI":"10.48550/arXiv.2303.08896","CorpusId":257557820},"title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"e5c72b92c48d68594b290c84a8904da7c8335554","externalIds":{"ArXiv":"2302.12813","DBLP":"journals/corr/abs-2302-12813","DOI":"10.48550/arXiv.2302.12813","CorpusId":257205781},"title":"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"},{"paperId":"ecd0b23e4828fca585a05eff56563852d35858d9","externalIds":{"DOI":"10.1007/s00113-023-01296-y","CorpusId":256787765,"PubMed":"36763148"},"title":"ChatGPT"},{"paperId":"bf8491bef353df126e2306ad2fe4b898697b906a","externalIds":{"ArXiv":"2302.04023","DBLP":"conf/ijcnlp/BangCLDSWLJYCDXF23","ACL":"2023.ijcnlp-main.45","DOI":"10.18653/v1/2023.ijcnlp-main.45","CorpusId":256662612},"title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity"},{"paperId":"3d68522abfadfc8ee6b7ec9edaaf91f1b2f38e5e","externalIds":{"DBLP":"journals/corr/abs-2302-00093","ArXiv":"2302.00093","DOI":"10.48550/arXiv.2302.00093","CorpusId":256459776},"title":"Large Language Models Can Be Easily Distracted by Irrelevant Context"},{"paperId":"465471bb5bf1a945549d6291c2d23367966b4957","externalIds":{"ArXiv":"2302.00083","DBLP":"journals/corr/abs-2302-00083","DOI":"10.1162/tacl_a_00605","CorpusId":256459451},"title":"In-Context Retrieval-Augmented Language Models"},{"paperId":"07b14c24833400b79978b0a5f084803337e30a15","externalIds":{"DBLP":"conf/naacl/ShiMYS0LZY24","ACL":"2024.naacl-long.463","ArXiv":"2301.12652","DOI":"10.48550/arXiv.2301.12652","CorpusId":256389797},"title":"REPLUG: Retrieval-Augmented Black-Box Language Models"},{"paperId":"a9be51698e7c2247853b7b6f1f70fc4d6d7ef605","externalIds":{"DBLP":"journals/corr/abs-2301-09785","ArXiv":"2301.09785","DOI":"10.48550/arXiv.2301.09785","CorpusId":256194369},"title":"Transformer-Patcher: One Mistake worth One Neuron"},{"paperId":"e65b346d442e9962a4276dc1c1af2956d9d5f1eb","externalIds":{"DBLP":"journals/corr/abs-2212-10560","ArXiv":"2212.10560","ACL":"2023.acl-long.754","DOI":"10.48550/arXiv.2212.10560","CorpusId":254877310},"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions"},{"paperId":"c6ee979c2da4b55a8486abae4cd720422ab09b26","externalIds":{"ArXiv":"2212.10511","ACL":"2023.acl-long.546","DBLP":"conf/acl/MallenAZDKH23","DOI":"10.18653/v1/2023.acl-long.546","CorpusId":254877603},"title":"When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories"},{"paperId":"e9d6cad994fd48567198ef260fbc5f5241aa9746","externalIds":{"DBLP":"journals/corr/abs-2212-10711","ArXiv":"2212.10711","DOI":"10.48550/arXiv.2212.10711","CorpusId":254926490},"title":"Task Ambiguity in Humans and Language Models"},{"paperId":"cef330bacf014d60daabbd489647b2006af130ca","externalIds":{"DBLP":"journals/corr/abs-2212-09251","ArXiv":"2212.09251","DOI":"10.48550/arXiv.2212.09251","CorpusId":254854519},"title":"Discovering Language Model Behaviors with Model-Written Evaluations"},{"paperId":"597d9134ffc53d9c3ba58368d12a3e4d24893bf0","externalIds":{"DBLP":"conf/acl/DaleVBC23","ACL":"2023.acl-long.3","ArXiv":"2212.08597","DOI":"10.48550/arXiv.2212.08597","CorpusId":254823170},"title":"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better"},{"paperId":"3a07a87090a061ca41dd30ac8398a9a5d9d39826","externalIds":{"DBLP":"journals/tois/ZhaoLRW24","ArXiv":"2211.14876","DOI":"10.1145/3637870","CorpusId":254044526},"title":"Dense Text Retrieval Based on Pretrained Language Models: A Survey"},{"paperId":"7cf1944c133679356afd75d735abcbe5332d76e7","externalIds":{"DBLP":"conf/emnlp/FabbriCVWX22","ACL":"2022.emnlp-main.623","ArXiv":"2211.06196","DOI":"10.48550/arXiv.2211.06196","CorpusId":253499045},"title":"Improving Factual Consistency in Summarization with Compression-Based Post-Editing"},{"paperId":"964bd39b546f0f6625ff3b9ef1083f797807ef2e","externalIds":{"DBLP":"journals/corr/abs-2211-05100","ArXiv":"2211.05100","DOI":"10.48550/arXiv.2211.05100","CorpusId":253420279},"title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"},{"paperId":"61ddf932488405ab1c7b275460d2b3c5dfa274a0","externalIds":{"DBLP":"journals/corr/abs-2211-03318","ArXiv":"2211.03318","ACL":"2022.emnlp-main.797","DOI":"10.48550/arXiv.2211.03318","CorpusId":249147353},"title":"Fixing Model Bugs with Natural Language Patches"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"fb3dc5e20e0a71134ca916f0d6d8d41f01225b4b","externalIds":{"DBLP":"conf/icml/GaoSH23","ArXiv":"2210.10760","CorpusId":252992904},"title":"Scaling Laws for Reward Model Overoptimization"},{"paperId":"c8d594f09413b1555970f43e68847c211235d60f","externalIds":{"DBLP":"journals/corr/abs-2210-09150","ArXiv":"2210.09150","DOI":"10.48550/arXiv.2210.09150","CorpusId":252917981},"title":"Prompting GPT-3 To Be Reliable"},{"paperId":"66242baf48b0f6b828e7547ac39ffaa5e1b2cb3e","externalIds":{"ArXiv":"2210.08726","DBLP":"conf/acl/GaoDPCCFZLLJG23","ACL":"2023.acl-long.910","DOI":"10.18653/v1/2023.acl-long.910","CorpusId":254247260},"title":"RARR: Researching and Revising What Language Models Say, Using Language Models"},{"paperId":"2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413","externalIds":{"DBLP":"conf/iclr/MengSABB23","ArXiv":"2210.07229","DOI":"10.48550/arXiv.2210.07229","CorpusId":252873467},"title":"Mass-Editing Memory in a Transformer"},{"paperId":"99832586d55f540f603637e458a292406a0ed75d","externalIds":{"DBLP":"conf/iclr/YaoZYDSN023","ArXiv":"2210.03629","CorpusId":252762395},"title":"ReAct: Synergizing Reasoning and Acting in Language Models"},{"paperId":"1d26c947406173145a4665dd7ab255e03494ea28","externalIds":{"DBLP":"journals/corr/abs-2210-02414","ArXiv":"2210.02414","DOI":"10.48550/arXiv.2210.02414","CorpusId":252715691},"title":"GLM-130B: An Open Bilingual Pre-trained Model"},{"paperId":"193fc3bc9f200ccb28892c02979e6c2068a85138","externalIds":{"ArXiv":"2208.05309","DBLP":"conf/eacl/GuerreiroVM23","ACL":"2023.eacl-main.75","DOI":"10.48550/arXiv.2208.05309","CorpusId":251468136},"title":"Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation"},{"paperId":"142ebbf4760145f591166bde2564ac70c001e927","externalIds":{"ArXiv":"2207.05221","DBLP":"journals/corr/abs-2207-05221","DOI":"10.48550/arXiv.2207.05221","CorpusId":250451161},"title":"Language Models (Mostly) Know What They Know"},{"paperId":"1d650f1afd45c59ff907396fe8b678595dcb85ea","externalIds":{"DBLP":"conf/icml/MitchellLBMF22","ArXiv":"2206.06520","CorpusId":249642147},"title":"Memory-Based Model Editing at Scale"},{"paperId":"f12a6168ed8de1aee69fee51b469b1aecd5f903e","externalIds":{"ArXiv":"2206.04624","DBLP":"conf/nips/LeePXPFSC22","DOI":"10.48550/arXiv.2206.04624","CorpusId":249538460},"title":"Factuality Enhanced Language Models for Open-Ended Text Generation"},{"paperId":"750448e5d852ec0a2e4f7f809f16a1470b2b479b","externalIds":{"DBLP":"journals/corr/abs-2205-11388","ArXiv":"2205.11388","CorpusId":248986583},"title":"StreamingQA: A Benchmark for Adaptation to New Knowledge over Time in Question Answering Models"},{"paperId":"47e15941c8b157873c8264e4bf50318d1ba5cd18","externalIds":{"DBLP":"journals/corr/abs-2204-11454","ACL":"2022.emnlp-main.231","ArXiv":"2204.11454","DOI":"10.48550/arXiv.2204.11454","CorpusId":248377325},"title":"Natural Language to Code Translation with Execution"},{"paperId":"e9f28c98a00766e484810598886cf48b0de66cfa","externalIds":{"DBLP":"journals/corr/abs-2204-07931","ACL":"2022.naacl-main.387","ArXiv":"2204.07931","DOI":"10.48550/arXiv.2204.07931","CorpusId":248227301},"title":"On the Origin of Hallucinations in Conversational Models: Is it the Datasets or the Models?"},{"paperId":"0286b2736a114198b25fb5553c671c33aed5d477","externalIds":{"ArXiv":"2204.05862","DBLP":"journals/corr/abs-2204-05862","DOI":"10.48550/arXiv.2204.05862","CorpusId":248118878},"title":"Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"f2b0869b17bace854d73c19b449e3f88b9fed82e","externalIds":{"DBLP":"conf/acl/LiLSDSLJJL22","ACL":"2022.findings-acl.136","ArXiv":"2203.16747","DOI":"10.48550/arXiv.2203.16747","CorpusId":247839380},"title":"How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"c70eb74e09c41e8fcc71dd59e3b4d631f657f7cd","externalIds":{"DBLP":"journals/corr/abs-2203-05115","ArXiv":"2203.05115","DOI":"10.48550/arXiv.2203.05115","CorpusId":247362809},"title":"Internet-augmented language models through few-shot prompting for open-domain question answering"},{"paperId":"340b8d8f710459d809a3da1868cd3e011aeded67","externalIds":{"ACL":"2022.acl-long.250","DBLP":"conf/acl/DuR0KLK22","ArXiv":"2203.03802","DOI":"10.18653/v1/2022.acl-long.250","CorpusId":247315166},"title":"Understanding Iterative Revision from Human-Written Text"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"996445d847f06e99b0bd259345408a0cf1bce87e","externalIds":{"DBLP":"conf/nips/MengBAB22","ArXiv":"2202.05262","CorpusId":255825985},"title":"Locating and Editing Factual Associations in GPT"},{"paperId":"3def68bd0f856886d34272840a7f81588f2bc082","externalIds":{"DBLP":"journals/corr/abs-2202-03629","ArXiv":"2202.03629","DOI":"10.1145/3571730","CorpusId":246652372},"title":"Survey of Hallucination in Natural Language Generation"},{"paperId":"e6770e3f5e74210c6863aaeed527ac4c1da419d7","externalIds":{"DBLP":"journals/corr/abs-2202-01110","ArXiv":"2202.01110","CorpusId":246472929},"title":"A Survey on Retrieval-Augmented Text Generation"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"0c181f508ec9de8e48f62523ba8a9bcb1f51f83a","externalIds":{"ArXiv":"2201.05273","DBLP":"journals/csur/LiTZNW24","DOI":"10.1145/3649449","CorpusId":260435365},"title":"Pre-Trained Language Models for Text Generation: A Survey"},{"paperId":"002c58077a1f1b296468b117230a1199e91f35c2","externalIds":{"ArXiv":"2201.03514","DBLP":"conf/icml/SunSQHQ22","CorpusId":245836882},"title":"Black-Box Tuning for Language-Model-as-a-Service"},{"paperId":"2f3efe44083af91cef562c1a3451eee2f8601d22","externalIds":{"DBLP":"journals/corr/abs-2112-09332","ArXiv":"2112.09332","CorpusId":245329531},"title":"WebGPT: Browser-assisted question-answering with human feedback"},{"paperId":"9a970e7ec3158655738d4f8494d27ab9e00337cc","externalIds":{"ArXiv":"2112.08542","DBLP":"conf/naacl/FabbriWLX22","ACL":"2022.naacl-main.187","DOI":"10.18653/v1/2022.naacl-main.187","CorpusId":245218667},"title":"QAFactEval: Improved QA-Based Factual Consistency Evaluation for Summarization"},{"paperId":"9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e","externalIds":{"DBLP":"conf/emnlp/Ni0LDAMZLHCY22","ACL":"2022.emnlp-main.669","ArXiv":"2112.07899","DOI":"10.18653/v1/2022.emnlp-main.669","CorpusId":245144556},"title":"Large Dual Encoders Are Generalizable Retrievers"},{"paperId":"002c256d30d6be4b23d365a8de8ae0e67e4c9641","externalIds":{"DBLP":"journals/corr/abs-2112-04426","ArXiv":"2112.04426","CorpusId":244954723},"title":"Improving language models by retrieving from trillions of tokens"},{"paperId":"17d7fd18123e12efbb9c255c8b986a5e84578b07","externalIds":{"ACL":"2022.naacl-main.435","DBLP":"conf/naacl/LuuKGMS22","ArXiv":"2111.07408","DOI":"10.18653/v1/2022.naacl-main.435","CorpusId":244117116},"title":"Time Waits for No One! Analysis and Challenges of Temporal Misalignment"},{"paperId":"c23d9d44e8bc68408cea9f305d1f24d915bc0d0d","externalIds":{"ArXiv":"2111.01243","DBLP":"journals/corr/abs-2111-01243","DOI":"10.1145/3605943","CorpusId":240420063},"title":"Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"},{"paperId":"7af90c66039e5a4a93501090f12b3a7324f83c91","externalIds":{"DBLP":"conf/emnlp/Cui00021","ACL":"2021.emnlp-main.179","ArXiv":"2109.05487","DOI":"10.18653/v1/2021.emnlp-main.179","CorpusId":237490367},"title":"Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation"},{"paperId":"77d956cdab4508d569ae5741549b78e715fd0749","externalIds":{"DBLP":"journals/corr/abs-2109-07958","ACL":"2022.acl-long.229","ArXiv":"2109.07958","DOI":"10.18653/v1/2022.acl-long.229","CorpusId":237532606},"title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods"},{"paperId":"ff0b2681d7b05e16c46dfb71d980cc2f605907cd","externalIds":{"DBLP":"journals/corr/abs-2109-01652","ArXiv":"2109.01652","CorpusId":237416585},"title":"Finetuned Language Models Are Zero-Shot Learners"},{"paperId":"2b615180ac839026ad7ffa5420014eb9c3aa8f94","externalIds":{"DBLP":"journals/information/ZarriessVS21","DOI":"10.3390/info12090355","CorpusId":238862913},"title":"Decoding Methods in Neural Language Generation: A Survey"},{"paperId":"443e7918db6428fbd7256d26f39932bba93c6c26","externalIds":{"DBLP":"conf/naacl/ZhuHXZZHJ21","ACL":"2021.naacl-main.58","MAG":"3141940864","DOI":"10.18653/V1/2021.NAACL-MAIN.58","CorpusId":235097229},"title":"Enhancing Factual Consistency of Abstractive Summarization"},{"paperId":"73ee65c312e64d7c5e581d55082d61c0f26707fb","externalIds":{"DBLP":"conf/acl/00020LLL20","ACL":"2021.acl-long.567","ArXiv":"2105.11269","DOI":"10.18653/v1/2021.acl-long.567","CorpusId":235166182},"title":"Neural Machine Translation with Monolingual Translation Memory"},{"paperId":"d7a7ebd1565c3795bc2bcdec4334d42a65ad17c5","externalIds":{"ArXiv":"2105.10311","DBLP":"journals/corr/abs-2105-10311","CorpusId":235125595},"title":"Pretrained Language Models for Text Generation: A Survey"},{"paperId":"c6bf48f25e0a65d64d658b47326de5922ea7dd44","externalIds":{"DBLP":"journals/corr/abs-2104-08704","ArXiv":"2104.08704","ACL":"2022.acl-long.464","DOI":"10.18653/v1/2022.acl-long.464","CorpusId":233296648},"title":"A Token-level Reference-free Hallucination Detection Benchmark for Free-form Text Generation"},{"paperId":"240b0caabb415578bdea4da7d0a32bdff2e8163f","externalIds":{"DBLP":"journals/corr/abs-2104-08164","ArXiv":"2104.08164","ACL":"2021.emnlp-main.522","DOI":"10.18653/v1/2021.emnlp-main.522","CorpusId":233289412},"title":"Editing Factual Knowledge in Language Models"},{"paperId":"2476832edb11cb3de46587f55e270d6df328b32d","externalIds":{"ACL":"2021.eacl-main.236","DBLP":"conf/eacl/XiaoW21","ArXiv":"2103.15025","DOI":"10.18653/v1/2021.eacl-main.236","CorpusId":232404053},"title":"On Hallucination and Predictive Uncertainty in Conditional Language Generation"},{"paperId":"aa28873534c24e4a8c5deb7bff723cd5fc69a6f0","externalIds":{"ACL":"2021.naacl-main.472","MAG":"3171639395","ArXiv":"2104.05938","DBLP":"journals/corr/abs-2104-05938","DOI":"10.18653/V1/2021.NAACL-MAIN.472","CorpusId":233219904},"title":"QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization"},{"paperId":"c0e6cd2ec3bc9eb46c7d45bb708854da3327339e","externalIds":{"MAG":"3134678353","DOI":"10.20944/PREPRINTS202103.0049.V1","CorpusId":233832881},"title":"A Survey on Bias in Deep NLP"},{"paperId":"0368a16887369a56d9abb41ae8d697d4691a2021","externalIds":{"ArXiv":"2102.02810","DBLP":"journals/corr/abs-2102-02810","DOI":"10.1007/s10618-021-00801-4","CorpusId":231802211},"title":"Controlling hallucinations at word level in data-to-text generation"},{"paperId":"33422275fbb9958f55419620697faf531482699b","externalIds":{"DBLP":"journals/tacl/JiangADN21","ArXiv":"2012.00955","DOI":"10.1162/tacl_a_00407","CorpusId":235078802},"title":"How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering"},{"paperId":"186c3507e3f0acf80bfe65ea19d408554f688665","externalIds":{"MAG":"3095962368","DBLP":"journals/corr/abs-2011-02593","ACL":"2021.findings-acl.120","ArXiv":"2011.02593","DOI":"10.18653/v1/2021.findings-acl.120","CorpusId":226254579},"title":"Detecting Hallucinated Content in Conditional Neural Sequence Generation"},{"paperId":"d030535287d17cfd215048354c928aa69ca60c62","externalIds":{"MAG":"3102645206","ACL":"2020.emnlp-main.506","DBLP":"conf/emnlp/CaoDWC20","ArXiv":"2010.08712","DOI":"10.18653/v1/2020.emnlp-main.506","CorpusId":224706057},"title":"Factual Error Correction for Abstractive Summarization Models"},{"paperId":"eea463ed69db876cdc12371d2bec200849b608a7","externalIds":{"DBLP":"journals/corr/abs-1709-07809","MAG":"2757291580","DOI":"10.1017/9781108608480","CorpusId":45492851},"title":"Neural Machine Translation"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"659bf9ce7175e1ec266ff54359e2bd76e0b7ff31","externalIds":{"DBLP":"conf/nips/LewisPPPKGKLYR020","MAG":"3027879771","ArXiv":"2005.11401","CorpusId":218869575},"title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"},{"paperId":"11b6d1fee0f47a8f9f892ab0d86f370c449097aa","externalIds":{"MAG":"3099766584","DBLP":"journals/corr/abs-2005-03754","ACL":"2020.acl-main.454","ArXiv":"2005.03754","DOI":"10.18653/V1/2020.ACL-MAIN.454","CorpusId":218571335},"title":"FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization"},{"paperId":"0b15c6acfc9f7f92c52aa6a185a829f88975c743","externalIds":{"MAG":"3022463379","ArXiv":"2005.03642","ACL":"2020.acl-main.326","DBLP":"journals/corr/abs-2005-03642","DOI":"10.18653/v1/2020.acl-main.326","CorpusId":218538004},"title":"On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation"},{"paperId":"dbeeca8466e0c177ec67c60d529899232415ca87","externalIds":{"DBLP":"conf/acl/MaynezNBM20","MAG":"3021338988","ArXiv":"2005.00661","ACL":"2020.acl-main.173","DOI":"10.18653/v1/2020.acl-main.173","CorpusId":218487034},"title":"On Faithfulness and Factuality in Abstractive Summarization"},{"paperId":"47fd2e73a9be04ed2186c03d8f88d5c87f64e4e4","externalIds":{"MAG":"3022814719","DBLP":"journals/corr/abs-2004-14373","ArXiv":"2004.14373","ACL":"2020.emnlp-main.89","DOI":"10.18653/v1/2020.emnlp-main.89","CorpusId":216641852},"title":"ToTTo: A Controlled Table-To-Text Generation Dataset"},{"paperId":"e165b379f983152874299e0f5a6e0c9596c9a3e8","externalIds":{"DBLP":"conf/iclr/SinitsinPPPB20","ArXiv":"2004.00345","MAG":"3014924543","CorpusId":213938729},"title":"Editable Neural Networks"},{"paperId":"3bcb17559ce96eb20fa79af8194f4af0380d194a","externalIds":{"DBLP":"journals/corr/abs-2003-08271","MAG":"3088409176","ArXiv":"2003.08271","DOI":"10.1007/s11431-020-1647-3","CorpusId":212747830},"title":"Pre-trained models for natural language processing: A survey"},{"paperId":"43f2ad297941db230c089ba353efc3f281ab678c","externalIds":{"MAG":"3033156098","CorpusId":226096901},"title":"5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"80376bdec5f534be78ba82821f540590ebce5559","externalIds":{"DBLP":"journals/corr/abs-2002-08910","MAG":"3102659883","ACL":"2020.emnlp-main.437","ArXiv":"2002.08910","DOI":"10.18653/v1/2020.emnlp-main.437","CorpusId":211205183},"title":"How Much Knowledge Can You Pack into the Parameters of a Language Model?"},{"paperId":"c2c3220b9faf95db43d90a5ed42fa824b4b3d2f0","externalIds":{"DBLP":"journals/corr/abs-2001-03830","ACL":"W19-8639","ArXiv":"2001.03830","MAG":"2996285556","DOI":"10.18653/v1/W19-8639","CorpusId":209387583},"title":"Revisiting Challenges in Data-to-Text Generation with Fact Grounding"},{"paperId":"c0ba20d689e3d09f35ff038358e1a1b4a10a82f9","externalIds":{"MAG":"2997607995","DBLP":"conf/emnlp/ChangPO19","CorpusId":209325068},"title":"Bias and Fairness in Natural Language Processing"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"0c5598424cc96d8fb500eb553cb7969f86a0ede0","externalIds":{"MAG":"2981456979","ArXiv":"1910.12840","DBLP":"journals/corr/abs-1910-12840","ACL":"2020.emnlp-main.750","DOI":"10.18653/v1/2020.emnlp-main.750","CorpusId":204976362},"title":"Evaluating the Factual Consistency of Abstractive Text Summarization"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"7a064df1aeada7e69e5173f7d4c8606f4470365b","externalIds":{"MAG":"2996428491","DBLP":"journals/corr/abs-1909-11942","ArXiv":"1909.11942","CorpusId":202888986},"title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"cf4aa38ae31b43fd07abe13b4ffdb265babb7be1","externalIds":{"DBLP":"journals/corr/abs-1904-09751","MAG":"2938704169","ArXiv":"1904.09751","CorpusId":127986954},"title":"The Curious Case of Neural Text Degeneration"},{"paperId":"295065d942abca0711300b2b4c39829551060578","externalIds":{"MAG":"2936695845","ArXiv":"1904.09675","DBLP":"journals/corr/abs-1904-09675","CorpusId":127986044},"title":"BERTScore: Evaluating Text Generation with BERT"},{"paperId":"97685859d4bcbc3b893425e6cb8fda8e9c15cfcb","externalIds":{"MAG":"2909737760","CorpusId":53593076},"title":"Hallucinations in Neural Machine Translation"},{"paperId":"35da1cd669ad5492a6358ea53aea95de28d39ded","externalIds":{"DBLP":"conf/ijcai/TorabiWS18","MAG":"2952876086","ArXiv":"1805.01954","DOI":"10.24963/ijcai.2018/687","CorpusId":23206414},"title":"Behavioral Cloning from Observation"},{"paperId":"a6401e102c03a441992b3e45f7b63eec09d4b89d","externalIds":{"MAG":"2953126480","DBLP":"journals/sigkdd/ChenLYT17","ArXiv":"1711.01731","DOI":"10.1145/3166054.3166058","CorpusId":5523008},"title":"A Survey on Dialogue Systems: Recent Advances and New Frontiers"},{"paperId":"19a632b17b2ee5f64df41bdd23755316a02fb939","externalIds":{"ACL":"P17-1017","MAG":"2739874095","DBLP":"conf/acl/GardentSNP17","DOI":"10.18653/v1/P17-1017","CorpusId":6702871},"title":"Creating Training Corpora for NLG Micro-Planners"},{"paperId":"dce6f9d4017b1785979e7520fd0834ef8cf02f4b","externalIds":{"MAG":"2736601468","DBLP":"journals/corr/SchulmanWDRK17","ArXiv":"1707.06347","CorpusId":28695052},"title":"Proximal Policy Optimization Algorithms"},{"paperId":"d65ce2b8300541414bfe51d03906fca72e93523c","externalIds":{"MAG":"2950953798","ArXiv":"1706.04599","DBLP":"journals/corr/GuoPSW17","CorpusId":28671436},"title":"On Calibration of Modern Neural Networks"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"a417fa9de77ea01cf145bcdf882f88efb67733fc","externalIds":{"MAG":"2952843865","ArXiv":"1702.04066","DBLP":"journals/corr/NapolesST17","ACL":"E17-2037","DOI":"10.18653/V1/E17-2037","CorpusId":6922426},"title":"JFLEG: A Fluency Corpus and Benchmark for Grammatical Error Correction"},{"paperId":"1bc49abe5145055f1fa259bd4e700b1eb6b7f08d","externalIds":{"MAG":"2574535369","DBLP":"conf/aaai/NallapatiZZ17","ArXiv":"1611.04230","DOI":"10.1609/aaai.v31i1.10958","CorpusId":6405271},"title":"SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents"},{"paperId":"2bb1df67e235015d867bc2d3fdbf12028976a299","externalIds":{"MAG":"2128808215","DBLP":"conf/acl/PaulsK11","ACL":"P11-1027","CorpusId":10463701},"title":"Faster and Smaller N-Gram Language Models"},{"paperId":"47ced790a563344efae66588b5fb7fe6cca29ed3","externalIds":{"MAG":"2155482025","DBLP":"journals/ftir/RobertsonZ09","DOI":"10.1561/1500000019","CorpusId":207178704},"title":"The Probabilistic Relevance Framework: BM25 and Beyond"},{"paperId":"10b005f48cf23cb66a82d016300f6960e4f035c6","externalIds":{"DBLP":"conf/naacl/BickelHS05","ACL":"H05-1025","MAG":"2123842387","DOI":"10.3115/1220575.1220600","CorpusId":6178017},"title":"Predicting Sentences using N-Gram Language Models"},{"paperId":"60b05f32c32519a809f21642ef1eb3eaf3848008","externalIds":{"MAG":"2154652894","ACL":"W04-1013","CorpusId":964287},"title":"ROUGE: A Package for Automatic Evaluation of Summaries"},{"paperId":"d7da009f457917aa381619facfa5ffae9329a6e9","externalIds":{"DBLP":"conf/acl/PapineniRWZ02","MAG":"2101105183","ACL":"P02-1040","DOI":"10.3115/1073083.1073135","CorpusId":11080756},"title":"Bleu: a Method for Automatic Evaluation of Machine Translation"},{"paperId":"2b10cac2e3af2d09993c095fdea781ae7ec05d0d","externalIds":{"MAG":"2908210055","CorpusId":158882697},"title":"What Can We Know"},{"paperId":"3efcafca6a9283b0265d2f55f333c113d3ae9055","externalIds":{"DBLP":"journals/corr/abs-2507-16806","DOI":"10.48550/arXiv.2507.16806","CorpusId":280675947},"title":"Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty"},{"paperId":"e024be4cb6aec4b3a5cdc4134c76346b42e163f8","externalIds":{"DBLP":"conf/iclr/HuCLGWYG24","CorpusId":271532780},"title":"Towards Understanding Factual Knowledge of Large Language Models"},{"paperId":"2db77485736cf29778a4464fe500a289bd46e7ac","externalIds":{"DBLP":"journals/corr/abs-2303-15621","DOI":"10.48550/arXiv.2303.15621","CorpusId":257771744},"title":"ChatGPT as a Factual Inconsistency Evaluator for Abstractive Text Summarization"},{"paperId":"92746dfa09dcad92ecf1e6272ebb300c1112b7eb","externalIds":{"DBLP":"journals/corr/abs-2306-16564","DOI":"10.48550/arXiv.2306.16564","CorpusId":259287216},"title":"Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision"},{"paperId":"80fd20e175f83a699258b8780cf365418d1538b0","externalIds":{"DBLP":"journals/corr/abs-2305-13269","DOI":"10.48550/arXiv.2305.13269","CorpusId":258833025},"title":"Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases"},{"paperId":"84dc889beff9d51fe429cff8c92735e7410ee3c2","externalIds":{"DBLP":"journals/corr/abs-2306-14565","DOI":"10.48550/arXiv.2306.14565","CorpusId":263860779},"title":"Aligning Large Multi-Modal Model with Robust Instruction Tuning"},{"paperId":"a863e5b80f5d79a9fc9d73e41bc7f7c91250a571","externalIds":{"DBLP":"journals/corr/abs-2307-05300","DOI":"10.48550/arXiv.2307.05300","CorpusId":279000557},"title":"Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration"},{"paperId":"9118ad81a145313cef0b31d3e3a3c8213e75e491","externalIds":{"DBLP":"journals/corr/abs-2308-04215","DOI":"10.48550/arXiv.2308.04215","CorpusId":280035099},"title":"Hybrid Retrieval-Augmented Generation for Real-time Composition Assistance"},{"paperId":"e730164e17975547564a1eaa70cea5884b16c89d","externalIds":{"CorpusId":259937133},"title":"Instruction : Translate the phrase ” Bonne chance ” into English Response : Good Luck"},{"paperId":"944aefbf748ad7172dd7e1a532675bc3647c0e23","externalIds":{"CorpusId":259267023},"title":"Reinforcement Learning for Language Models"},{"paperId":"5424e311319c58847b4c690d5c91090e3b6a4ac3","externalIds":{"DBLP":"journals/corr/abs-2307-01379","DOI":"10.48550/arXiv.2307.01379","CorpusId":259342406},"title":"Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models"},{"paperId":"ac4ffaab10f6b6ad83e79ca5691f338abf5cff82","externalIds":{"DBLP":"journals/corr/abs-2307-06290","DOI":"10.48550/arXiv.2307.06290","CorpusId":259837472},"title":"Instruction Mining: High-Quality Instruction Data Selection for Large Language Models"},{"paperId":"3d473cbb7a377cf960abff31748a1a39bb6c7d7c","externalIds":{"DBLP":"journals/corr/abs-2307-15337","DOI":"10.48550/arXiv.2307.15337","CorpusId":260315904},"title":"Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding"},{"paperId":"ea0d41514a41f8273f13b3b277e7fcbbc65a8549","externalIds":{"DBLP":"journals/corr/abs-2307-10236","DOI":"10.48550/arXiv.2307.10236","CorpusId":259991714},"title":"Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models"},{"paperId":"8aa98fbfb6f1e979dead13ce24075503fe47658e","externalIds":{"DBLP":"journals/corr/abs-2301-00234","CorpusId":263886074},"title":"A Survey for In-context Learning"},{"paperId":"f3a41a5bfec0d8ccb597d9313416130a2e0b2459","externalIds":{"DBLP":"journals/corr/abs-2306-04528","DOI":"10.48550/arXiv.2306.04528","CorpusId":271493049},"title":"PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts"},{"paperId":"a931d9cdb11671d7fe4de6522b67ae139509e356","externalIds":{"DBLP":"journals/corr/abs-2205-11482","DOI":"10.48550/arXiv.2205.11482","CorpusId":263871624},"title":"Tracing Knowledge in Language Models Back to the Training Data"},{"paperId":"787d8ae2d303619b7009cf84e13950d1f330c185","externalIds":{"DBLP":"journals/corr/abs-2105-00071","CorpusId":263881474},"title":"Evaluating Groundedness in Dialogue Systems: The BEGIN Benchmark"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"0c0a778e6fdf7e36b1750c533dcc916f86608607","externalIds":{"MAG":"2527310337","DBLP":"journals/tkde/XunJGZ17","DOI":"10.1109/TKDE.2016.2614508","CorpusId":13490401},"title":"A Survey on Context Learning"},{"paperId":"9819b600a828a57e1cde047bbe710d3446b30da5","externalIds":{"MAG":"179875071","DBLP":"conf/interspeech/MikolovKBCK10","DOI":"10.21437/Interspeech.2010-343","CorpusId":17048224},"title":"Recurrent neural network based language model"}]}