{"references":[{"paperId":"d111795c38a9ce45fbc767abae141206ac583f23","externalIds":{"ArXiv":"2408.14811","DBLP":"journals/corr/abs-2408-14811","DOI":"10.48550/arXiv.2408.14811","CorpusId":271963102},"title":"Brain-inspired Artificial Intelligence: A Comprehensive Review"},{"paperId":"50c337cb047be63614342f5d2e9e492762b7cc5c","externalIds":{"DBLP":"conf/nips/RenBKGPYMPMKFH24","ArXiv":"2407.21792","DOI":"10.48550/arXiv.2407.21792","CorpusId":271571299},"title":"Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?"},{"paperId":"b244b80d0a2d36412b56c0156532d9cbeb298ffa","externalIds":{"DBLP":"journals/corr/abs-2408-00113","ArXiv":"2408.00113","DOI":"10.48550/arXiv.2408.00113","CorpusId":271600890},"title":"Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models"},{"paperId":"fec3d7e1272d640eddd55307127bebf4fa55ac33","externalIds":{"ArXiv":"2407.20311","DBLP":"conf/iclr/0011XLA25a","DOI":"10.48550/arXiv.2407.20311","CorpusId":271544257},"title":"Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process"},{"paperId":"117d228727a3ad84052f72f14cb59f51a4e8fddc","externalIds":{"ArXiv":"2407.19200","DBLP":"journals/corr/abs-2407-19200","DOI":"10.48550/arXiv.2407.19200","CorpusId":271534289},"title":"On Behalf of the Stakeholders: Trends in NLP Model Interpretability in the Era of LLMs"},{"paperId":"7f0ad3a6aef6bb51b599138ff83437fcbe6d6072","externalIds":{"ArXiv":"2407.14985","DBLP":"conf/iclr/0003AEAAZW25","DOI":"10.48550/arXiv.2407.14985","CorpusId":271328219},"title":"Generalization v.s. Memorization: Tracing Language Models' Capabilities Back to Pretraining Data"},{"paperId":"e561b7b1a0548b3c9c2902641b6fdcc3f29deb41","externalIds":{"ArXiv":"2407.14981","DBLP":"journals/corr/abs-2407-14981","DOI":"10.48550/arXiv.2407.14981","CorpusId":271329366},"title":"Open Problems in Technical AI Governance"},{"paperId":"eca3d92e298f1f042cae4ee55257f2d9ceb2182b","externalIds":{"ArXiv":"2407.13765","DBLP":"journals/corr/abs-2407-13765","DOI":"10.48550/arXiv.2407.13765","CorpusId":271270337},"title":"Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data"},{"paperId":"dc2858166d68e29288fd3d6a25c4b62ef23e24f9","externalIds":{"DBLP":"journals/corr/abs-2407-07612","ArXiv":"2407.07612","DOI":"10.48550/arXiv.2407.07612","CorpusId":271088512},"title":"Teaching Transformers Causal Reasoning through Axiomatic Training"},{"paperId":"4fba55c4477577e744bf0ee946a77a2c0615c6c9","externalIds":{"ArXiv":"2407.07011","DBLP":"journals/corr/abs-2407-07011","DOI":"10.48550/arXiv.2407.07011","CorpusId":271064685},"title":"Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning"},{"paperId":"35ab93f41115e860bee5e202b71061addfd0fd5d","externalIds":{"DBLP":"conf/icml/0020LDXVZDC0KHG25","ArXiv":"2407.04620","DOI":"10.48550/arXiv.2407.04620","CorpusId":271039606},"title":"Learning to (Learn at Test Time): RNNs with Expressive Hidden States"},{"paperId":"37378907affc28677dc9db6c16633a930477419a","externalIds":{"ArXiv":"2407.03779","DBLP":"conf/emnlp/YuNZCP25","DOI":"10.18653/v1/2025.emnlp-main.446","CorpusId":271038711},"title":"Sheaf Discovery with Joint Computation Graph Pruning and Flexible Granularity"},{"paperId":"0ac43cb23cdb84b6c7dc6986c036fb3152e9a286","externalIds":{"ArXiv":"2407.03282","DBLP":"journals/corr/abs-2407-03282","ACL":"2024.blackboxnlp-1.6","DOI":"10.48550/arXiv.2407.03282","CorpusId":270923744},"title":"LLM Internal States Reveal Hallucination Risk Faced With a Query"},{"paperId":"4d04fa53fa9cd499c7070dae5ff3bc1e3357715b","externalIds":{"DBLP":"conf/emnlp/QinZHYLJ24","ACL":"2024.emnlp-main.700","ArXiv":"2407.12828","DOI":"10.48550/arXiv.2407.12828","CorpusId":271270722},"title":"Why Does New Knowledge Create Messy Ripple Effects in LLMs?"},{"paperId":"8deb5fd40e310dc4feb27f7db7019e734b44631b","externalIds":{"DBLP":"journals/corr/abs-2407-00215","ArXiv":"2407.00215","DOI":"10.48550/arXiv.2407.00215","CorpusId":270844127},"title":"LLM Critics Help Catch LLM Bugs"},{"paperId":"5c6eeda9cce18e6d468c1b8835e4161a0d789647","externalIds":{"ArXiv":"2406.18400","DBLP":"journals/corr/abs-2406-18400","DOI":"10.48550/arXiv.2406.18400","CorpusId":270737871},"title":"Do LLMs dream of elephants (when told not to)? Latent concept association and associative memory in transformers"},{"paperId":"431c85f7cb5436981c798697acc13aa72f3e133b","externalIds":{"DBLP":"journals/corr/abs-2406-18312","ArXiv":"2406.18312","DOI":"10.48550/arXiv.2406.18312","CorpusId":270738167},"title":"AI-native Memory: A Pathway from LLMs Towards AGI"},{"paperId":"abdc28cc33ff5449df9427c82c9caa7b5b79f40f","externalIds":{"DBLP":"conf/iclr/PrashanthDOVKBC25","ArXiv":"2406.17746","DOI":"10.48550/arXiv.2406.17746","CorpusId":270710931},"title":"Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon"},{"paperId":"e17cbc224181bff88246357f7ae167b0c0a5ccf6","externalIds":{"ArXiv":"2406.17241","CorpusId":270711055},"title":"Understanding Language Model Circuits through Knowledge Editing"},{"paperId":"932208192d319141f3e9041fc4d661615d77574a","externalIds":{"ArXiv":"2406.16254","DBLP":"conf/nips/StolfoWGBSSN24","DOI":"10.48550/arXiv.2406.16254","CorpusId":270702325},"title":"Confidence Regulation Neurons in Language Models"},{"paperId":"3c6da6f1601aee99b8e5b8dcf2d21c42d9252b04","externalIds":{"DBLP":"journals/corr/abs-2406-11944","ArXiv":"2406.11944","DOI":"10.48550/arXiv.2406.11944","CorpusId":270562552},"title":"Transcoders Find Interpretable LLM Feature Circuits"},{"paperId":"c04e6bab808c0d5f0344159190ed21a20039c4e9","externalIds":{"ArXiv":"2406.11776","DBLP":"conf/emnlp/LiDZHGLI24","DOI":"10.48550/arXiv.2406.11776","CorpusId":270559026},"title":"Improving Multi-Agent Debate with Sparse Communication Topology"},{"paperId":"2b0b9c9b7f5d3fc692dfa408862d9b18931ffc52","externalIds":{"ArXiv":"2406.10868","DBLP":"conf/aaai/ChenDT25","DOI":"10.1609/aaai.v39i22.34529","CorpusId":270560657},"title":"Identifying Query-Relevant Neurons in Large Language Models for Long-Form Texts"},{"paperId":"208d489c73ebf182faa974191355fb2505ce8da5","externalIds":{"DBLP":"journals/corr/abs-2406-07155","ArXiv":"2406.07155","DOI":"10.48550/arXiv.2406.07155","CorpusId":270379482},"title":"Scaling Large-Language-Model-based Multi-Agent Collaboration"},{"paperId":"508f50f171b4aee6cbc573da1bed0472a86eaa8b","externalIds":{"ArXiv":"2406.06326","DBLP":"journals/corr/abs-2406-06326","DOI":"10.48550/arXiv.2406.06326","CorpusId":270371584},"title":"Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching"},{"paperId":"bd2dd8efcc4a56548abbf50da468af1d7b7ae379","externalIds":{"DBLP":"conf/nips/KongWMDZZSZW024","ArXiv":"2406.05954","DOI":"10.48550/arXiv.2406.05954","CorpusId":270372048},"title":"Aligning Large Language Models with Representation Editing: A Control Perspective"},{"paperId":"a8c3c55a246b8656268e766602f6748f2d04ccbb","externalIds":{"DBLP":"conf/acl/WangTXYCCJ24","ArXiv":"2406.06485","DOI":"10.48550/arXiv.2406.06485","CorpusId":270371867},"title":"Can Language Models Serve as Text-Based World Simulators?"},{"paperId":"2b01cbe125ed13ccb3ef02e9536582825f2afd57","externalIds":{"DBLP":"journals/corr/abs-2406-05644","ArXiv":"2406.05644","DOI":"10.48550/arXiv.2406.05644","CorpusId":270371990},"title":"How Alignment and Jailbreak Work: Explain LLM Safety through Intermediate Hidden States"},{"paperId":"ae16c93bf3a33c43e8f57293530069e77c89bcaa","externalIds":{"DBLP":"journals/corr/abs-2406-04313","ArXiv":"2406.04313","DOI":"10.48550/arXiv.2406.04313","CorpusId":270286008},"title":"Improving Alignment and Robustness with Circuit Breakers"},{"paperId":"3072ad4982cd916606ac88ea1883d4d725c4eda4","externalIds":{"DBLP":"journals/corr/abs-2406-04151","ArXiv":"2406.04151","DOI":"10.48550/arXiv.2406.04151","CorpusId":270285866},"title":"AgentGym: Evolving Large Language Model-based Agents across Diverse Environments"},{"paperId":"286e3a89933c5f2d1103e64e627b5580bba89813","externalIds":{"DBLP":"journals/corr/abs-2406-03372","ArXiv":"2406.03372","DOI":"10.1038/s41586-025-09384-2","CorpusId":270257694,"PubMed":"40903603"},"title":"Training of physical neural networks"},{"paperId":"f82f49c20c6acc69f884f05e3a9f1ceea91061ce","externalIds":{"PubMedCentral":"11186750","DBLP":"journals/nature/FarquharKKG24","DOI":"10.1038/s41586-024-07421-0","CorpusId":270615909,"PubMed":"38898292"},"title":"Detecting hallucinations in large language models using semantic entropy"},{"paperId":"5e9937dbc375c0942e58070e1c0d2fc82109cf39","externalIds":{"ArXiv":"2405.20192","DBLP":"journals/corr/abs-2405-20192","DOI":"10.48550/arXiv.2405.20192","CorpusId":270123761},"title":"TAIA: Large Language Models are Out-of-Distribution Data Learners"},{"paperId":"f1481b4eba72c1e1d355413af37352a0bcfc50e9","externalIds":{"ArXiv":"2405.17969","DBLP":"journals/corr/abs-2405-17969","DOI":"10.48550/arXiv.2405.17969","CorpusId":270068372},"title":"Knowledge Circuits in Pretrained Transformers"},{"paperId":"c3f1fae241a3c2449e675ab750873d800f95513c","externalIds":{"DBLP":"journals/corr/abs-2405-14734","ArXiv":"2405.14734","DOI":"10.48550/arXiv.2405.14734","CorpusId":269983560},"title":"SimPO: Simple Preference Optimization with a Reference-Free Reward"},{"paperId":"5b1120f547d3969afc49b4a094e874d568e53aca","externalIds":{"ArXiv":"2405.15071","DBLP":"journals/corr/abs-2405-15071","DOI":"10.48550/arXiv.2405.15071","CorpusId":270045579},"title":"Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization"},{"paperId":"f091acf9dc2cc486c253dcead3a74ba916c64eb7","externalIds":{"ArXiv":"2405.13021","DBLP":"journals/corr/abs-2405-13021","DOI":"10.1145/3626772.3657760","CorpusId":269983269},"title":"IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning Inner Monologues"},{"paperId":"66de49b3dcbbf0cca535335d597f94b702e2b95a","externalIds":{"ArXiv":"2405.07987","DBLP":"journals/corr/abs-2405-07987","DOI":"10.48550/arXiv.2405.07987","CorpusId":269757765},"title":"The Platonic Representation Hypothesis"},{"paperId":"e780c1d6aebacbd00aa83bdb57089e1c5435cad9","externalIds":{"DBLP":"conf/www/MaRCS24","DOI":"10.1145/3589334.3645354","CorpusId":269639397},"title":"Temporal Conformity-aware Hawkes Graph Network for Recommendations"},{"paperId":"d81e8d1d3c8acbcf9755ef470098b9c02adf5963","externalIds":{"ArXiv":"2405.06624","DBLP":"journals/corr/abs-2405-06624","DOI":"10.48550/arXiv.2405.06624","CorpusId":269741228},"title":"Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems"},{"paperId":"54972b2e4304d2164a61036ae947df2503c07009","externalIds":{"DBLP":"conf/emnlp/GekhmanYAEFRH24","ACL":"2024.emnlp-main.444","ArXiv":"2405.05904","DOI":"10.48550/arXiv.2405.05904","CorpusId":269635770},"title":"Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"},{"paperId":"fe6473bcbb3f44d5cfebee4347dc821a05500684","externalIds":{"DBLP":"journals/jbd/StengerLFKB24","DOI":"10.1186/s40537-024-00924-7","CorpusId":269614786},"title":"Evaluation is key: a survey on evaluation measures for synthetic time series"},{"paperId":"b4eea0939283ed47552484a673c86cdf1cf268e1","externalIds":{"ArXiv":"2405.01660","DBLP":"journals/corr/abs-2405-01660","ACL":"2024.starsem-1.23","DOI":"10.48550/arXiv.2405.01660","CorpusId":269588087},"title":"Investigating Wit, Creativity, and Detectability of Large Language Models in Domain-Specific Writing Style Adaptation of Reddit’s Showerthoughts"},{"paperId":"a3b1479f2b1cba23d21ddd30450a5f432da6a0d0","externalIds":{"DBLP":"journals/interactions/KraljicL24","DOI":"10.1145/3652622","CorpusId":269521716},"title":"From Prompt Engineering to Collaborating: A Human-Centered Approach to AI Interfaces"},{"paperId":"ddb1937e1ec3e09499bbf8dc4aae62369372f2bd","externalIds":{"DBLP":"journals/neuroimage/CoronelOliverosMORLCTBOKI24","DOI":"10.1016/j.neuroimage.2024.120633","CorpusId":270069292,"PubMed":"38704057"},"title":"Gaming expertise induces meso‑scale brain plasticity and efficiency mechanisms as revealed by whole-brain modeling"},{"paperId":"3ec648362481eaa44e439fa0955533da390cacfd","externalIds":{"DBLP":"conf/acl/Zheng00H025","ArXiv":"2404.16792","DOI":"10.18653/v1/2025.acl-long.51","CorpusId":269362293},"title":"Model Extrapolation Expedites Alignment"},{"paperId":"13f2985246d6b91f788bb222360a199967af32c8","externalIds":{"DBLP":"conf/nips/SchwarzschildFM24","ArXiv":"2404.15146","DOI":"10.48550/arXiv.2404.15146","CorpusId":269303166},"title":"Rethinking LLM Memorization through the Lens of Adversarial Compression"},{"paperId":"8b750488d139f9beba0815ff8f46ebe15ebb3e58","externalIds":{"ArXiv":"2404.14082","DBLP":"journals/corr/abs-2404-14082","DOI":"10.48550/arXiv.2404.14082","CorpusId":269293418},"title":"Mechanistic Interpretability for AI Safety - A Review"},{"paperId":"80189591290fc06a12ed3fa20c8465009c990b66","externalIds":{"DOI":"10.1162/99608f92.d949f941","CorpusId":269182882},"title":"Government Interventions to Avert Future Catastrophic AI Risks"},{"paperId":"8c5aab75826620559d33e99652f4cac9f6efd2fc","externalIds":{"DBLP":"journals/corr/abs-2404-08806","ArXiv":"2404.08806","DOI":"10.1109/LAD62341.2024.10691798","CorpusId":269148855},"title":"CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation"},{"paperId":"544f2bb75294ced19fc0f80d50c3f4f7bc7b327a","externalIds":{"ArXiv":"2404.05405","DBLP":"journals/corr/abs-2404-05405","DOI":"10.48550/arXiv.2404.05405","CorpusId":269005957},"title":"Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws"},{"paperId":"4a2f4cd788896d9e9b52eaf5ca303c5cdcb280c6","externalIds":{"DBLP":"journals/corr/abs-2404-04436","ArXiv":"2404.04436","DOI":"10.2139/ssrn.4738442","CorpusId":268777266},"title":"AI Knowledge and Reasoning: Emulating Expert Creativity in Scientific Research"},{"paperId":"5664f7f52264ff656faa3671d83e2009f4f390fd","externalIds":{"ArXiv":"2404.03646","DBLP":"journals/corr/abs-2404-03646","DOI":"10.48550/arXiv.2404.03646","CorpusId":268889738},"title":"Locating and Editing Factual Associations in Mamba"},{"paperId":"2717e5c7384ec12cfd6cf9c34897c6adad3230ed","externalIds":{"DBLP":"journals/tmlr/Li0DYC25","ArXiv":"2404.02060","DOI":"10.48550/arXiv.2404.02060","CorpusId":268857023},"title":"Long-context LLMs Struggle with Long In-context Learning"},{"paperId":"41b4cd49570fc4330b600d85da1994b0532a8f95","externalIds":{"ArXiv":"2404.02062","DBLP":"journals/corr/abs-2404-02062","DOI":"10.1007/s10462-024-11078-6","CorpusId":268856658},"title":"Digital forgetting in large language models: a survey of unlearning methods"},{"paperId":"b8f280d8bf685f8da7c83068e73f000528072d6b","externalIds":{"ArXiv":"2403.19647","DBLP":"conf/iclr/MarksRMBBM25","DOI":"10.48550/arXiv.2403.19647","CorpusId":268732732},"title":"Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models"},{"paperId":"33c8910107f3fcb17d140cc88554652508ae3674","externalIds":{"ArXiv":"2403.14472","DBLP":"conf/acl/Wang0XXDYZY0C24","DOI":"10.48550/arXiv.2403.14472","CorpusId":268553537},"title":"Detoxifying Large Language Models via Knowledge Editing"},{"paperId":"d4e9db1048e37add4ef194b5531d4366e2d80383","externalIds":{"DBLP":"journals/ojcomps/LiuYCZL25","ArXiv":"2403.13682","DOI":"10.1109/OJCS.2025.3543483","CorpusId":268536826},"title":"Threats, Attacks, and Defenses in Machine Unlearning: A Survey"},{"paperId":"97352d95cc1fd9b7d9e959d61dd751a619975bfe","externalIds":{"DBLP":"journals/corr/abs-2403-13257","ACL":"2024.emnlp-industry.36","ArXiv":"2403.13257","DOI":"10.48550/arXiv.2403.13257","CorpusId":268537132},"title":"Arcee’s MergeKit: A Toolkit for Merging Large Language Models"},{"paperId":"828f98e0feba2baa55a5486f354fd074cca0880c","externalIds":{"DBLP":"journals/natmi/AkibaSTSH25","ArXiv":"2403.13187","DOI":"10.1038/s42256-024-00975-8","CorpusId":268537290},"title":"Evolutionary optimization of model merging recipes"},{"paperId":"b8fd607ed1a3c897b44770a60ab9055f7d533bdf","externalIds":{"DBLP":"conf/vr/NormoyleSD24","DOI":"10.1109/VRW62533.2024.00124","CorpusId":270097059},"title":"Using LLMs to Animate Interactive Story Characters with Emotions and Personality"},{"paperId":"d96933cba676edbaad3a0564352ad29dbfe2c1f4","externalIds":{"DBLP":"journals/ijautcomp/MumuniMG24","ArXiv":"2403.10075","DOI":"10.1007/s11633-022-1411-7","CorpusId":268584668},"title":"A Survey of Synthetic Data Augmentation Methods in Machine Vision"},{"paperId":"ab8e6df5001dbb9b48445220099425aff536b3e8","externalIds":{"DBLP":"journals/corr/abs-2403-08319","ArXiv":"2403.08319","ACL":"2024.emnlp-main.486","DOI":"10.48550/arXiv.2403.08319","CorpusId":268379757},"title":"Knowledge Conflicts for LLMs: A Survey"},{"paperId":"1aeb53f240f3f509bcc97ef529d9547a936f1099","externalIds":{"ArXiv":"2403.07350","DBLP":"conf/nips/HuangZY0W0T24","DOI":"10.52202/079017-0294","CorpusId":268364273},"title":"VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark"},{"paperId":"4e274196324bad3e750e83235516af06733e701d","externalIds":{"ArXiv":"2403.05612","DBLP":"journals/corr/abs-2403-05612","DOI":"10.48550/arXiv.2403.05612","CorpusId":268358368},"title":"Unfamiliar Finetuning Examples Control How Language Models Hallucinate"},{"paperId":"42f8532eb5db0a1333e04add5576737bd4f31635","externalIds":{"ArXiv":"2403.04571","DBLP":"journals/corr/abs-2403-04571","DOI":"10.48550/arXiv.2403.04571","CorpusId":268264795},"title":"Machine learning and information theory concepts towards an AI Mathematician"},{"paperId":"e85da6a8c542046a6222b64372ceb9913a756a7d","externalIds":{"DBLP":"journals/natmi/SoltoggioBBEEGHHIJKLLLM24","DOI":"10.1038/s42256-024-00800-2","CorpusId":268653528},"title":"A collective AI via lifelong learning and sharing at the edge"},{"paperId":"ab15463babf98fffc6f683fe2026de0725b5e1a9","externalIds":{"ArXiv":"2402.19473","DBLP":"journals/corr/abs-2402-19473","DOI":"10.48550/arXiv.2402.19473","CorpusId":268091298},"title":"Retrieval-Augmented Generation for AI-Generated Content: A Survey"},{"paperId":"4c0a545b1eb73084e3d395435af9cf6649c2b1da","externalIds":{"DBLP":"conf/acl/JinCY0XLJ0024","ArXiv":"2402.18154","DOI":"10.48550/arXiv.2402.18154","CorpusId":268041323},"title":"Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models"},{"paperId":"97994e4526ef7eeea59190aa466fbab05fad9187","externalIds":{"DBLP":"journals/tmlr/DuttaSC024","ArXiv":"2402.18312","DOI":"10.48550/arXiv.2402.18312","CorpusId":268041831},"title":"How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning"},{"paperId":"3bdd3d56ef9054aba47f83879b531a4842640295","externalIds":{"DBLP":"journals/corr/abs-2402-18243","ArXiv":"2402.18243","DOI":"10.48550/arXiv.2402.18243","CorpusId":268041894},"title":"Learning or Self-aligning? Rethinking Instruction Fine-tuning"},{"paperId":"d9a449e1123ca37375c9977f51b7ea6129905803","externalIds":{"DBLP":"journals/corr/abs-2402-17700","ArXiv":"2402.17700","DOI":"10.48550/arXiv.2402.17700","CorpusId":268032000},"title":"RAVEL: Evaluating Interpretability Methods on Disentangling Language Model Representations"},{"paperId":"96edfa3441bb3624ea2b8bdfc5eec2c87efa9637","externalIds":{"DBLP":"conf/acl/TangLH0WZWW24","ArXiv":"2402.16438","DOI":"10.48550/arXiv.2402.16438","CorpusId":268032136},"title":"Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models"},{"paperId":"b21b1b41b91390c255b09fd4d68b3827bc5e717f","externalIds":{"DBLP":"conf/coling/Ju0DYRL24","ACL":"2024.lrec-main.722","ArXiv":"2402.16061","DOI":"10.48550/arXiv.2402.16061","CorpusId":267938459},"title":"How Large Language Models Encode Context Knowledge? A Layer-Wise Probing Study"},{"paperId":"812b87876b22260fe046af447c5f40a4ce2906ea","externalIds":{"ArXiv":"2402.14409","DBLP":"conf/coling/JinC0LJXLZ24","ACL":"2024.lrec-main.1466","DOI":"10.48550/arXiv.2402.14409","CorpusId":267782658},"title":"Tug-of-War between Knowledge: Exploring and Resolving Knowledge Conflicts in Retrieval-Augmented Language Models"},{"paperId":"e98392f4906cf8fc912697b8fdb808e5cef0aa71","externalIds":{"DBLP":"journals/corr/abs-2402-14273","ArXiv":"2402.14273","CorpusId":267783113},"title":"Can Language Models Act as Knowledge Bases at Scale?"},{"paperId":"50bf7984f3405ec2ec9d5199615a5e4b88f4f8ae","externalIds":{"ArXiv":"2402.13462","DBLP":"journals/corr/abs-2402-13462","DOI":"10.48550/arXiv.2402.13462","CorpusId":267770177},"title":"Potential and Challenges of Model Editing for Social Debiasing"},{"paperId":"1301ed763095097ff424c668e16a265b3ae2f231","externalIds":{"ArXiv":"2402.12201","DBLP":"journals/corr/abs-2402-12201","DOI":"10.48550/arXiv.2402.12201","CorpusId":267751496},"title":"Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability: A Case Study on Othello-GPT"},{"paperId":"b8ffaec3e8e64a246ac4b9e4016e4efea0e156ac","externalIds":{"DBLP":"journals/corr/abs-2402-09656","ArXiv":"2402.09656","DOI":"10.48550/arXiv.2402.09656","CorpusId":267682284},"title":"The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse"},{"paperId":"32ee92044a93aa7acb6b6d7010611c4ee0a3a559","externalIds":{"DBLP":"journals/corr/abs-2402-08797","ArXiv":"2402.08797","CorpusId":267657812},"title":"Computing Power and the Governance of Artificial Intelligence"},{"paperId":"bcc2a6593c7667d341a36e76a0d9d40b4efdf787","externalIds":{"DBLP":"journals/corr/abs-2402-07233","ArXiv":"2402.07233","DOI":"10.48550/arXiv.2402.07233","CorpusId":267627853},"title":"TransGPT: Multi-modal Generative Pre-trained Transformer for Transportation"},{"paperId":"775e9844a13b518aeb0cde401ba6891ba3538611","externalIds":{"DBLP":"journals/corr/abs-2402-04559","ArXiv":"2402.04559","DOI":"10.48550/arXiv.2402.04559","CorpusId":267523076},"title":"Can Large Language Model Agents Simulate Human Trust Behaviors?"},{"paperId":"c0d8e5ee66c279299012cc3b8d0519011b3f4998","externalIds":{"DBLP":"journals/corr/abs-2402-01306","ArXiv":"2402.01306","CorpusId":267406810},"title":"KTO: Model Alignment as Prospect Theoretic Optimization"},{"paperId":"3a9b43368a09d07657abe0e62a6c4a1d2428d40c","externalIds":{"ArXiv":"2401.11839","DBLP":"journals/ipm/XuSRGPLSH24","DOI":"10.48550/arXiv.2401.11839","CorpusId":267069237},"title":"AI for social science and social science of AI: A Survey"},{"paperId":"b2f4d22fddf3619a38a1754d9497935aa0848426","externalIds":{"DBLP":"journals/tmlr/0003XLPK24","ArXiv":"2401.11624","DOI":"10.48550/arXiv.2401.11624","CorpusId":267069067},"title":"In-context Learning with Retrieved Demonstrations for Language Models: A Survey"},{"paperId":"f5df0667365764a970fc6abfa0a68b7d1d0ae413","externalIds":{"DBLP":"conf/icml/GhandehariounCP24","ArXiv":"2401.06102","DOI":"10.48550/arXiv.2401.06102","CorpusId":266933130},"title":"Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models"},{"paperId":"5c40aa8b6c611f85578e8465a252e72dbfa24459","externalIds":{"ArXiv":"2401.03646","DBLP":"journals/corr/abs-2401-03646","DOI":"10.48550/arXiv.2401.03646","CorpusId":266843932},"title":"Evaluating Brain-Inspired Modular Training in Automated Circuit Discovery for Mechanistic Interpretability"},{"paperId":"26b2adbe089ea36617c3ec0aa009319929da0550","externalIds":{"DBLP":"conf/icml/LeeBPWKM24","ArXiv":"2401.01967","DOI":"10.48550/arXiv.2401.01967","CorpusId":266755904},"title":"A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity"},{"paperId":"6d408c2c56a73cec8b21c450b6588c6d98026bc3","externalIds":{"DBLP":"journals/corr/abs-2401-00434","ArXiv":"2401.00434","DOI":"10.48550/arXiv.2401.00434","CorpusId":266693296},"title":"GeoGalactica: A Scientific Large Language Model in Geoscience"},{"paperId":"0c4f46e4dcae5527018e6432fb60cfe8c3354e97","externalIds":{"DBLP":"journals/corr/abs-2312-14125","ArXiv":"2312.14125","DOI":"10.48550/arXiv.2312.14125","CorpusId":266435847},"title":"VideoPoet: A Large Language Model for Zero-Shot Video Generation"},{"paperId":"07c2c3b4af7e4ff1577f36f47f1c93398a6df648","externalIds":{"DBLP":"conf/iclr/GouldOOC24","ArXiv":"2312.09230","DOI":"10.48550/arXiv.2312.09230","CorpusId":266210012},"title":"Successor Heads: Recurring, Interpretable Attention Heads In The Wild"},{"paperId":"6b97aa78bcdb88548c44e7e1671c0ed37ed37976","externalIds":{"ArXiv":"2312.09390","DBLP":"conf/icml/BurnsIKBGACEJLS24","DOI":"10.48550/arXiv.2312.09390","CorpusId":266312608},"title":"Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision"},{"paperId":"b512451d431df9e411bea4c99f7135d010275445","externalIds":{"DBLP":"journals/corr/abs-2312-05934","ArXiv":"2312.05934","ACL":"2024.emnlp-main.15","DOI":"10.48550/arXiv.2312.05934","CorpusId":266162497},"title":"Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"},{"paperId":"7bbc7595196a0606a07506c4fb1473e5e87f6082","externalIds":{"ArXiv":"2312.00752","DBLP":"journals/corr/abs-2312-00752","CorpusId":265551773},"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces"},{"paperId":"fce6367bb0a97efe1baded2ff311947e696caab2","externalIds":{"ArXiv":"2311.17371","DBLP":"conf/icml/SmitGDBP24","CorpusId":265498583},"title":"Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs"},{"paperId":"ee14bc1ad3690eebd6bdc1b6bd4b0e43e8b375eb","externalIds":{"PubMedCentral":"10705274","DOI":"10.1101/2023.08.21.554072","CorpusId":261124872,"PubMed":"38077041"},"title":"Gaming expertise induces meso-scale brain plasticity and efficiency mechanisms as revealed by whole-brain modeling Gaming expertise, neuroplasticity and functional dynamics"},{"paperId":"321160254c3b059ec7aed0bcbd7d7c6d1be17372","externalIds":{"ArXiv":"2312.03718","DBLP":"journals/corr/abs-2312-03718","DOI":"10.48550/arXiv.2312.03718","CorpusId":266054920},"title":"Large Language Models in Law: A Survey"},{"paperId":"698d454e4602442696c659520ac2de23f80fbd4f","externalIds":{"DBLP":"journals/corr/abs-2311-13110","ArXiv":"2311.13110","DOI":"10.48550/arXiv.2311.13110","CorpusId":265352045},"title":"White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?"},{"paperId":"4ea5ca620122e6a9a2b000444d36491cebf49c7c","externalIds":{"DBLP":"journals/corr/abs-2311-12351","ArXiv":"2311.12351","DOI":"10.48550/arXiv.2311.12351","CorpusId":265308945},"title":"Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey"},{"paperId":"e92e8ff1becb9a9e4a7dd09878eaacb2a62ffb6b","externalIds":{"ArXiv":"2311.09096","DBLP":"conf/acl/ZhangYKMWH24","DOI":"10.48550/arXiv.2311.09096","CorpusId":265212812},"title":"Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization"},{"paperId":"38449fadc86ae2a469fecdddf1351c82907078db","externalIds":{"DBLP":"journals/corr/abs-2311-07470","ArXiv":"2311.07470","DOI":"10.48550/arXiv.2311.07470","CorpusId":265149487},"title":"Finding and Editing Multi-Modal Neurons in Pre-Trained Transformer"},{"paperId":"e5379c6b2328c1d4832a2efaf276e49324fbb05a","externalIds":{"ArXiv":"2311.05876","DBLP":"journals/corr/abs-2311-05876","DOI":"10.48550/arXiv.2311.05876","CorpusId":265128686},"title":"Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications"},{"paperId":"49a02664e552320a43cea541c07ca312e45350b5","externalIds":{"ACL":"2023.conll-1.37","DBLP":"conf/conll/PalSYWB23","ArXiv":"2311.04897","DOI":"10.18653/v1/2023.conll-1.37","CorpusId":265050744},"title":"Future Lens: Anticipating Subsequent Tokens from a Single Hidden State"},{"paperId":"c0230760f644f6b7538d93e4296a5e9aa7028e45","externalIds":{"DBLP":"conf/icml/Yu0Y0L24","ArXiv":"2311.03099","DOI":"10.48550/arXiv.2311.03099","CorpusId":265034087},"title":"Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch"},{"paperId":"1145c42897cc70b4401b0b52c490c794a09789d8","externalIds":{"DBLP":"journals/tnn/MazziaPCRB25","ArXiv":"2310.19704","DOI":"10.1109/TNNLS.2024.3498935","CorpusId":264820150,"PubMed":"40030360"},"title":"A Survey on Knowledge Editing of Neural Networks"},{"paperId":"9f20b0aa426c18512e820d1c1311378f71114d8a","externalIds":{"ArXiv":"2310.17230","DBLP":"journals/corr/abs-2310-17230","DOI":"10.48550/arXiv.2310.17230","CorpusId":264490402},"title":"Codebook Features: Sparse and Discrete Interpretability for Neural Networks"},{"paperId":"2996da066a48e4674454f5f75ad5cc6f85f23ff6","externalIds":{"DOI":"10.1126/science.adn0117","CorpusId":269929051,"PubMed":"38768279"},"title":"Managing extreme AI risks amid rapid progress"},{"paperId":"42016f91e5b1da63174d45acb96bc89b64aa124d","externalIds":{"DBLP":"journals/csur/WangZLZCL25","ArXiv":"2310.16218","DOI":"10.1145/3698590","CorpusId":264487359},"title":"Knowledge Editing for Large Language Models: A Survey"},{"paperId":"70ca99ac3c21f353b3db948004510a09fdebc4f2","externalIds":{"DBLP":"journals/corr/abs-2310-14491","ArXiv":"2310.14491","DOI":"10.48550/arXiv.2310.14491","CorpusId":264426404},"title":"Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models"},{"paperId":"eeefe82172135523517cbe19624f2fab54e4a846","externalIds":{"ArXiv":"2310.13018","DBLP":"journals/tmlr/SucholutskyMWPBKLCGGATC25","DOI":"10.48550/arXiv.2310.13018","CorpusId":264405712},"title":"Getting aligned on representational alignment"},{"paperId":"203a297db586ffb4cd858fe5f219a9a1571c87b2","externalIds":{"DBLP":"conf/emnlp/Gomez-Rodriguez23a","ArXiv":"2310.08433","DOI":"10.48550/arXiv.2310.08433","CorpusId":263908973},"title":"A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing"},{"paperId":"03fab98a9be74a253688840dba9144737a8ca92d","externalIds":{"DBLP":"journals/corr/abs-2310-07521","ArXiv":"2310.07521","DOI":"10.48550/arXiv.2310.07521","CorpusId":263835211},"title":"Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity"},{"paperId":"d6354e91d8dcf73bff50097b76a81de874f7bd7a","externalIds":{"ArXiv":"2310.02031","DBLP":"journals/corr/abs-2310-02031","DOI":"10.48550/arXiv.2310.02031","CorpusId":263608392},"title":"OceanGPT: A Large Language Model for Ocean Science Tasks"},{"paperId":"9fcdbfdf28245010c875ce85502351fe05c04b49","externalIds":{"ArXiv":"2310.02124","DBLP":"journals/corr/abs-2310-02124","DOI":"10.48550/arXiv.2310.02124","CorpusId":263608682},"title":"Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View"},{"paperId":"b47e96762351b2dbf7e863ece4640df6194bcc0c","externalIds":{"DBLP":"journals/corr/abs-2310-01061","ArXiv":"2310.01061","DOI":"10.48550/arXiv.2310.01061","CorpusId":263605944},"title":"Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning"},{"paperId":"58fdf550600fc3873729d466601c5d08a51ba8a0","externalIds":{"DBLP":"journals/corr/abs-2310-01405","ArXiv":"2310.01405","DOI":"10.48550/arXiv.2310.01405","CorpusId":263605618},"title":"Representation Engineering: A Top-Down Approach to AI Transparency"},{"paperId":"c16c05ca0a3d24519405849fd24604fc1ce47751","externalIds":{"DBLP":"conf/iclr/ZhangN24","ArXiv":"2309.16042","DOI":"10.48550/arXiv.2309.16042","CorpusId":263131114},"title":"Towards Best Practices of Activation Patching in Language Models: Metrics and Methods"},{"paperId":"47daf5f81470564f94adcac672405c2cd39dd186","externalIds":{"ArXiv":"2309.14402","DBLP":"conf/iclr/Allen-ZhuL25a","DOI":"10.48550/arXiv.2309.14402","CorpusId":262898066},"title":"Physics of Language Models: Part 3.2, Knowledge Manipulation"},{"paperId":"7b1a6db0909856a345f055a9607f43711b3df375","externalIds":{"ArXiv":"2309.14556","DBLP":"conf/chi/ChakrabartyLAMW24","DOI":"10.1145/3613904.3642731","CorpusId":262826094},"title":"Art or Artifice? Large Language Models and the False Promise of Creativity"},{"paperId":"f29f8b8aa2b7e608199b65d3cf751969d4024132","externalIds":{"DBLP":"conf/icml/Allen-ZhuL24","ArXiv":"2309.14316","DOI":"10.48550/arXiv.2309.14316","CorpusId":262825178},"title":"Physics of Language Models: Part 3.1, Knowledge Storage and Extraction"},{"paperId":"8eafec7014d08043517834b5a2ed26384f188873","externalIds":{"ArXiv":"2309.12288","DBLP":"journals/corr/abs-2309-12288","CorpusId":262083829},"title":"The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\""},{"paperId":"0b7942129e39059f5964877e28c19c497d3724c3","externalIds":{"DBLP":"journals/corr/abs-2309-09640","ArXiv":"2309.09640","DOI":"10.1145/3613904.3642436","CorpusId":262044555},"title":"An Ontology of Dark Patterns Knowledge: Foundations, Definitions, and a Pathway for Shared Knowledge-Building"},{"paperId":"edb548fe7574d99454b352ffdb61bca93c3072ba","externalIds":{"DBLP":"conf/iclr/HubenCRES24","ArXiv":"2309.08600","DOI":"10.48550/arXiv.2309.08600","CorpusId":261934663},"title":"Sparse Autoencoders Find Highly Interpretable Features in Language Models"},{"paperId":"bc73cff91ed01d6c7cdff0636900d8e74b817e40","externalIds":{"DOI":"10.1109/TNSRE.2023.3314642","CorpusId":261704344,"PubMed":"37698960"},"title":"Aligning Semantic in Brain and Language: A Curriculum Contrastive Method for Electroencephalography-to-Text Generation"},{"paperId":"d8acb1d0ca84d81c15b3e2f36012de552370df8d","externalIds":{"DBLP":"journals/corr/abs-2309-05973","ArXiv":"2309.05973","DOI":"10.48550/arXiv.2309.05973","CorpusId":261697142},"title":"Circuit Breaking: Removing Model Behaviors with Targeted Ablation"},{"paperId":"47fff0f40e52d7ad55bdfcae690bef3f889453d6","externalIds":{"ArXiv":"2309.03886","DBLP":"conf/nips/SchwettmannSMCL23","CorpusId":261582916},"title":"FIND: A Function Description Benchmark for Evaluating Interpretability Methods"},{"paperId":"26089bdfdbca1e6eaaceca71e3116b715bec6d47","externalIds":{"DBLP":"journals/corr/abs-2309-01029","ArXiv":"2309.01029","DOI":"10.1145/3639372","CorpusId":261530292},"title":"Explainability for Large Language Models: A Survey"},{"paperId":"b32a6770239aeeec31c782a2a25be3ffa6b7a051","externalIds":{"DBLP":"journals/corr/abs-2309-00244","ArXiv":"2309.00244","DOI":"10.48550/arXiv.2309.00244","CorpusId":261494219},"title":"NeuroSurgeon: A Toolkit for Subnetwork Analysis"},{"paperId":"628b131f8f309d583ccf1da268f520c051169ddd","externalIds":{"DBLP":"conf/aaai/ChenCCLZ24","ArXiv":"2308.13198","DOI":"10.48550/arXiv.2308.13198","CorpusId":261214558},"title":"Journey to the Center of the Knowledge Neurons: Discoveries of Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons"},{"paperId":"70ba95384664ab7becfd8196d20a46fe66112c91","externalIds":{"DBLP":"journals/ijcv/LiRJLWZWC25","ArXiv":"2308.09388","DOI":"10.1007/s11263-025-02570-9","CorpusId":261031011},"title":"Diffusion Models for Image Restoration and Enhancement: A Comprehensive Survey"},{"paperId":"a95ee02fd85a3734bf19bb4bbc6ef3ea22c96cc9","externalIds":{"DBLP":"journals/corr/abs-2308-08742","ArXiv":"2308.08742","DOI":"10.48550/arXiv.2308.08742","CorpusId":261030625},"title":"PMET: Precise Model Editing in a Transformer"},{"paperId":"ec58a564fdda29e6a9a0a7bab5eeb4c290f716d7","externalIds":{"ArXiv":"2308.07201","DBLP":"journals/corr/abs-2308-07201","DOI":"10.48550/arXiv.2308.07201","CorpusId":260887105},"title":"ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"},{"paperId":"c2f9006993d9d84d48eb894aab3ba60f946d0e15","externalIds":{"ArXiv":"2308.02773","DBLP":"journals/corr/abs-2308-02773","DOI":"10.48550/arXiv.2308.02773","CorpusId":260681803},"title":"EduChat: A Large-Scale Language Model-based Chatbot System for Intelligent Education"},{"paperId":"f840eb1c5ab5cd76b52f4935094161cb0784ca4f","externalIds":{"DBLP":"conf/iccvw/SchwettmannCKB023","ArXiv":"2308.01544","DOI":"10.1109/ICCVW60793.2023.00308","CorpusId":260438635},"title":"Multimodal Neurons in Pretrained Text-Only Transformers"},{"paperId":"1fdf449c96fbac0789cf8dfae15b788905407fd3","externalIds":{"DBLP":"journals/tacl/CohenBYGG24","ACL":"2024.tacl-1.16","ArXiv":"2307.12976","DOI":"10.1162/tacl_a_00644","CorpusId":260356612},"title":"Evaluating the Ripple Effects of Knowledge Editing in Language Models"},{"paperId":"d62c4d00b277e948956b6610ce2644e88fe1577b","externalIds":{"DBLP":"journals/cacm/Cerf23c","ArXiv":"2307.05782","DOI":"10.1007/978-981-96-6259-3","CorpusId":259837466,"PubMed":"38320147"},"title":"Large Language Models"},{"paperId":"f8e99be4f9a01761fab74bade2c3c18de9fc686b","externalIds":{"DBLP":"journals/corr/abs-2307-02477","ArXiv":"2307.02477","ACL":"2024.naacl-long.102","DOI":"10.48550/arXiv.2307.02477","CorpusId":259341893},"title":"Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks"},{"paperId":"929305892d4ddae575a0fc23227a8139f7681632","externalIds":{"DBLP":"journals/corr/abs-2307-02483","ArXiv":"2307.02483","DOI":"10.48550/arXiv.2307.02483","CorpusId":259342528},"title":"Jailbroken: How Does LLM Safety Training Fail?"},{"paperId":"3e826e52754d0876611c8cf2fa7a781a701c39e6","externalIds":{"ArXiv":"2306.09296","DBLP":"journals/corr/abs-2306-09296","DOI":"10.48550/arXiv.2306.09296","CorpusId":259165244},"title":"KoLA: Carefully Benchmarking World Knowledge of Large Language Models"},{"paperId":"9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6","externalIds":{"ArXiv":"2306.08302","DBLP":"journals/corr/abs-2306-08302","DOI":"10.1109/TKDE.2024.3352100","CorpusId":259165563},"title":"Unifying Large Language Models and Knowledge Graphs: A Roadmap"},{"paperId":"32f541216112de78037d8e0f95ddc152eb6f05fa","externalIds":{"DBLP":"conf/wsdm/DengZHCSXF0WZLH24","ArXiv":"2306.05064","DOI":"10.1145/3616855.3635772","CorpusId":259108887},"title":"K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization"},{"paperId":"405f8f5f1c6df1b3343c812832479aad5180b65f","externalIds":{"ArXiv":"2306.03341","DBLP":"journals/corr/abs-2306-03341","CorpusId":259088877},"title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language Model"},{"paperId":"ead6121fbc787d508dc6a6d7106f72bf0d647d03","externalIds":{"DBLP":"journals/corr/abs-2306-03314","ArXiv":"2306.03314","DOI":"10.48550/arXiv.2306.03314","CorpusId":259088724},"title":"Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents"},{"paperId":"2651f0179874bd010f58d2c9fa7d118807c80977","externalIds":{"ArXiv":"2306.01708","DBLP":"conf/nips/YadavTCRB23","CorpusId":259064039},"title":"TIES-Merging: Resolving Interference When Merging Models"},{"paperId":"385c74957858e7d6856d48e72b5a902b4c1aa28c","externalIds":{"DBLP":"journals/corr/abs-2305-19118","ACL":"2024.emnlp-main.992","ArXiv":"2305.19118","DOI":"10.48550/arXiv.2305.19118","CorpusId":258967540},"title":"Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"},{"paperId":"0d1c76d45afa012ded7ab741194baf142117c495","externalIds":{"DBLP":"conf/nips/RafailovSMMEF23","ArXiv":"2305.18290","CorpusId":258959321},"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model"},{"paperId":"d4858bea740099064de31d39c8c3c4a366bcc76b","externalIds":{"DBLP":"journals/corr/abs-2305-17073","ArXiv":"2305.17073","ACL":"2023.acl-demo.21","DOI":"10.48550/arXiv.2305.17073","CorpusId":258947701},"title":"NeuroX Library for Neuron Analysis of Deep NLP Models"},{"paperId":"984d4a1d41bfc8184fb77b8aa0eb8e96d536d048","externalIds":{"DBLP":"conf/naacl/ShiHLTZY24","ArXiv":"2305.14739","ACL":"2024.naacl-short.69","DOI":"10.48550/arXiv.2305.14739","CorpusId":258866080},"title":"Trusting Your Evidence: Hallucinate Less with Context-aware Decoding"},{"paperId":"ddcd2bcc809bd0c2755a4a9487473d61ac327c50","externalIds":{"DBLP":"conf/eacl/ShapiraLAZCGSS24","ArXiv":"2305.14763","ACL":"2024.eacl-long.138","DOI":"10.48550/arXiv.2305.14763","CorpusId":258865502},"title":"Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models"},{"paperId":"56e952fd463accff09cf2e35432aaabd7c7c57f3","externalIds":{"DBLP":"conf/emnlp/ZhongWMPC23","ArXiv":"2305.14795","DOI":"10.48550/arXiv.2305.14795","CorpusId":258865984},"title":"MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions"},{"paperId":"6cb35dd6e1338faa0c3d6a6b0020bbcbcc18653d","externalIds":{"DBLP":"conf/iclr/Liu0HL024","ArXiv":"2305.14342","DOI":"10.48550/arXiv.2305.14342","CorpusId":258841030},"title":"Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training"},{"paperId":"f5c73d9e6641b018b633690102121f5605d34fb0","externalIds":{"DBLP":"conf/emnlp/YaoWT0LDC023","ArXiv":"2305.13172","DOI":"10.48550/arXiv.2305.13172","CorpusId":258833129},"title":"Editing Large Language Models: Problems, Methods, and Opportunities"},{"paperId":"5ae6fb6b5a3c7df515ff4a82ac9673bae6a8e200","externalIds":{"DBLP":"journals/corr/abs-2305-13245","ArXiv":"2305.13245","DOI":"10.48550/arXiv.2305.13245","CorpusId":258833177},"title":"GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints"},{"paperId":"1b36bd7672cbdf296645276303f4596bc7ed5468","externalIds":{"ArXiv":"2305.11169","DBLP":"conf/icml/JinR24","CorpusId":258762618},"title":"Emergent Representations of Program Semantics in Language Models Trained on Programs"},{"paperId":"e01c2a01d54365c8833b816de8ef39a752ffa9b0","externalIds":{"DBLP":"conf/acl/ZhangG023","ArXiv":"2305.11159","DOI":"10.48550/arXiv.2305.11159","CorpusId":258762464},"title":"Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors"},{"paperId":"546d0624adfc6e18fb87d8cc77e7705bb9ea7445","externalIds":{"ArXiv":"2305.11206","DBLP":"conf/nips/ZhouLX0SMMEYYZG23","CorpusId":258822910},"title":"LIMA: Less Is More for Alignment"},{"paperId":"7b7649b59d62d2ebfb3c34b7bc91204b9b7cefe8","externalIds":{"DBLP":"journals/corr/abs-2305-09144","ArXiv":"2305.09144","ACL":"2024.lrec-main.1222","DOI":"10.48550/arXiv.2305.09144","CorpusId":258715133},"title":"Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models"},{"paperId":"f8029060e91209f048b3f9882f2cdd3607785ccd","externalIds":{"DBLP":"journals/corr/abs-2305-08746","ArXiv":"2305.08746","DOI":"10.48550/arXiv.2305.08746","CorpusId":258686335},"title":"Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability"},{"paperId":"12910786da7a34c9ee26798fd81b0ed7b0e38789","externalIds":{"DBLP":"journals/tmlr/GurneeNPHTB23","ArXiv":"2305.01610","DOI":"10.48550/arXiv.2305.01610","CorpusId":258437237},"title":"Finding Neurons in a Haystack: Case Studies with Sparse Probing"},{"paperId":"133b97e40017a9bbbadd10bcd7f13088a97ca3cc","externalIds":{"DBLP":"conf/emnlp/GevaBFG23","ArXiv":"2304.14767","DOI":"10.48550/arXiv.2304.14767","CorpusId":258417932},"title":"Dissecting Recall of Factual Associations in Auto-Regressive Language Models"},{"paperId":"eefbd8b384a58f464827b19e30a6920ba976def9","externalIds":{"ArXiv":"2304.14997","DBLP":"conf/nips/ConmyMLHG23","DOI":"10.48550/arXiv.2304.14997","CorpusId":258418244},"title":"Towards Automated Circuit Discovery for Mechanistic Interpretability"},{"paperId":"f406aceba4f29cc7cfbe7edb2f52f01374486589","externalIds":{"ArXiv":"2304.13734","DBLP":"journals/corr/abs-2304-13734","DOI":"10.18653/v1/2023.findings-emnlp.68","CorpusId":258352729},"title":"The Internal State of an LLM Knows When its Lying"},{"paperId":"7f0e3b307a3f7d98876d3f22797754a5dd490e9b","externalIds":{"DBLP":"journals/cacm/Raiola23","DOI":"10.1145/3587998","CorpusId":258259353},"title":"ChatGPT, Can You Tell Me a Story? An Exercise in Challenging the True Creativity of Generative AI"},{"paperId":"97b1f4980fc173e59ff3a3bdaf1b9a13965fb32e","externalIds":{"PubMedCentral":"10968883","DBLP":"journals/corr/abs-2304-09355","ArXiv":"2304.09355","DOI":"10.3390/e26030252","CorpusId":258212721,"PubMed":"38539763"},"title":"To Compress or Not to Compress—Self-Supervised Learning and Information Theory: A Review"},{"paperId":"78f599fbd62dcc4a8dbab9d2f6056815dfc5b84c","externalIds":{"DBLP":"journals/corr/abs-2304-08442","ArXiv":"2304.08442","DOI":"10.48550/arXiv.2304.08442","CorpusId":258180536},"title":"The MiniPile Challenge for Data-Efficient Language Models"},{"paperId":"8d8fc878bf4c7005546c866824a72d0c46ca91a3","externalIds":{"ArXiv":"2304.05969","DBLP":"journals/corr/abs-2304-05969","DOI":"10.48550/arXiv.2304.05969","CorpusId":258079237},"title":"Localizing Model Behavior with Path Patching"},{"paperId":"ece77610adfb0fb162dd22ef694f2777393c319a","externalIds":{"DBLP":"journals/corr/abs-2304-03208","ArXiv":"2304.03208","DOI":"10.48550/arXiv.2304.03208","CorpusId":257985427},"title":"Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"1a6af6214f33187bc2c9d78bb1dc28cf5b038e16","externalIds":{"ArXiv":"2303.11873","DBLP":"journals/corr/abs-2303-11873","DOI":"10.48550/arXiv.2303.11873","CorpusId":257636667},"title":"A Tale of Two Circuits: Grokking as Competition of Sparse and Dense Subnetworks"},{"paperId":"10a372a03eaf893f126e17f03f203d60164fce7c","externalIds":{"ArXiv":"2303.12003","DBLP":"journals/corr/abs-2303-12003","DOI":"10.1016/j.yjoc.2023.100066","CorpusId":257637118},"title":"Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity"},{"paperId":"dcd8dff20f4f490acd5f94001d34c774167f053e","externalIds":{"DBLP":"journals/corr/abs-2303-09435","ACL":"2024.lrec-main.840","ArXiv":"2303.09435","DOI":"10.48550/arXiv.2303.09435","CorpusId":257557722},"title":"Jump to Conclusions: Short-Cutting Transformers with Linear Transformations"},{"paperId":"8018a68956d6751d7ea76110537d5a2e86ec05c4","externalIds":{"DBLP":"journals/corr/abs-2303-07616","ArXiv":"2303.07616","DOI":"10.1007/s11633-023-1416-x","CorpusId":257505035},"title":"The Life Cycle of Knowledge in Big Language Models: A Survey"},{"paperId":"762ca2711eb167f19b79e39c175708ca15e1f5d7","externalIds":{"ArXiv":"2303.08112","DBLP":"journals/corr/abs-2303-08112","DOI":"10.48550/arXiv.2303.08112","CorpusId":257504984},"title":"Eliciting Latent Predictions from Transformers with the Tuned Lens"},{"paperId":"66c286df54551baba7351a1ed44019367e5aa7ea","externalIds":{"PubMedCentral":"10038805","DOI":"10.1038/s41562-022-01516-2","CorpusId":257309545,"PubMed":"36864133"},"title":"Evidence of a predictive coding hierarchy in the human brain listening to speech"},{"paperId":"5969eff0e72e4a5bc0c7392c700be74a01ac2822","externalIds":{"DBLP":"conf/icml/ChughtaiCN23","ArXiv":"2302.03025","DOI":"10.48550/arXiv.2302.03025","CorpusId":256615287},"title":"A Toy Model of Universality: Reverse Engineering How Networks Learn Group Operations"},{"paperId":"835c305e52769a8433f8383e91d33ba6c66ad55b","externalIds":{"DOI":"10.1038/s41587-022-01618-2","CorpusId":256304602,"PubMed":"36702895"},"title":"Large language models generate functional protein sequences across diverse families"},{"paperId":"83c2bb56f58d4ce63adb2faf073fc35c3515cda8","externalIds":{"DBLP":"journals/corr/abs-2301-11293","ArXiv":"2301.11293","DOI":"10.48550/arXiv.2301.11293","CorpusId":256274877},"title":"Understanding Finetuning for Factual Knowledge Extraction from Language Models"},{"paperId":"9a9e68d400069f023f7dc9b982226c95159a509d","externalIds":{"DBLP":"journals/corr/abs-2301-06627","ArXiv":"2301.06627","CorpusId":255941592},"title":"Dissociating language and thought in large language models: a cognitive perspective"},{"paperId":"9c0a434b240299cec0029a1be93ab263d7ec9963","externalIds":{"DBLP":"journals/corr/abs-2301-04213","ArXiv":"2301.04213","DOI":"10.48550/arXiv.2301.04213","CorpusId":255595518},"title":"Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models"},{"paperId":"6052486bc9144dc1730c12bf35323af3792a1fd0","externalIds":{"ArXiv":"2212.13138","DBLP":"journals/corr/abs-2212-13138","PubMedCentral":"10396962","DOI":"10.1038/s41586-023-06291-2","CorpusId":255124952,"PubMed":"37438534"},"title":"Large language models encode clinical knowledge"},{"paperId":"c6ee979c2da4b55a8486abae4cd720422ab09b26","externalIds":{"ArXiv":"2212.10511","ACL":"2023.acl-long.546","DBLP":"conf/acl/MallenAZDKH23","DOI":"10.18653/v1/2023.acl-long.546","CorpusId":254877603},"title":"When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories"},{"paperId":"6845bea94b2fb17d4377b3bb2bd10f73a959f9cc","externalIds":{"DBLP":"journals/corr/abs-2212-09597","ArXiv":"2212.09597","ACL":"2023.acl-long.294","DOI":"10.48550/arXiv.2212.09597","CorpusId":254854219},"title":"Reasoning with Language Model Prompting: A Survey"},{"paperId":"8db5adadc0ab39f95a26a2eb6499d340d6c5ea21","externalIds":{"ACL":"2023.cl-2.7","DBLP":"journals/coling/Apidianaki23","DOI":"10.1162/coli_a_00474","CorpusId":254960044},"title":"From Word Types to Tokens and Back: A Survey of Approaches to Word Meaning Representation and Interpretation"},{"paperId":"75f7e9e2b59fb640ef9d1dff94097175daf46c4d","externalIds":{"ArXiv":"2211.08411","DBLP":"journals/corr/abs-2211-08411","CorpusId":253522998},"title":"Large Language Models Struggle to Learn Long-Tail Knowledge"},{"paperId":"9a5f6fc16f00270c0baca335a8105b48824e6d4a","externalIds":{"ArXiv":"2211.05853","DBLP":"journals/corr/abs-2211-05853","DOI":"10.48550/arXiv.2211.05853","CorpusId":253499179},"title":"Measuring Reliability of Large Language Models through Semantic Consistency"},{"paperId":"0d1f82861dca4c8e7d5f91a79f0ab216694f4ddd","externalIds":{"DOI":"10.1126/science.abq2591","CorpusId":253307584,"PubMed":"36378968"},"title":"The emergent properties of the connected brain"},{"paperId":"8a90b67ca5d3c9bec77a3bfd6bc4ae24fdd58cdd","externalIds":{"DOI":"10.1126/science.abq3868","CorpusId":253302458,"PubMed":"36327349"},"title":"Solving brain circuit function and dysfunction with computational modeling and optogenetic fMRI"},{"paperId":"6edd112383ad494f5f2eba72b6f4ffae122ce61f","externalIds":{"DBLP":"journals/corr/abs-2211-00593","ArXiv":"2211.00593","DOI":"10.48550/arXiv.2211.00593","CorpusId":253244237},"title":"Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"},{"paperId":"d10f3857f69edf74565ff786afd5d8632849666a","externalIds":{"ArXiv":"2210.16978","ACL":"2023.acl-demo.25","DBLP":"journals/corr/abs-2210-16978","DOI":"10.48550/arXiv.2210.16978","CorpusId":253237010},"title":"XMD: An End-to-End Framework for Interactive Explanation-Based Debugging of NLP Models"},{"paperId":"c90a99eeb57019732a6cc996bb9eaf13faedf00f","externalIds":{"ArXiv":"2209.11895","DBLP":"journals/corr/abs-2209-11895","DOI":"10.48550/arXiv.2209.11895","CorpusId":252532078},"title":"In-context Learning and Induction Heads"},{"paperId":"9d125f45b1d2dea01f05281470bc08e12b6c7cba","externalIds":{"DBLP":"journals/corr/abs-2209-10652","ArXiv":"2209.10652","DOI":"10.48550/arXiv.2209.10652","CorpusId":252439050},"title":"Toy Models of Superposition"},{"paperId":"dc5518e1db565a8c52084f27353461df474403d8","externalIds":{"DBLP":"conf/nips/KasaiST0A0RS0I23","ArXiv":"2207.13332","DOI":"10.48550/arXiv.2207.13332","CorpusId":251105205},"title":"RealTime QA: What's the Answer Right Now?"},{"paperId":"e58170676ddb4bcf428b7b3d69d7779f1bf32512","externalIds":{"DBLP":"journals/aiethics/HagendorffD23","DOI":"10.1007/s43681-022-00188-y","CorpusId":249970811},"title":"Ethical and methodological challenges in building morally informed AI systems"},{"paperId":"f12a6168ed8de1aee69fee51b469b1aecd5f903e","externalIds":{"ArXiv":"2206.04624","DBLP":"conf/nips/LeePXPFSC22","DOI":"10.48550/arXiv.2206.04624","CorpusId":249538460},"title":"Factuality Enhanced Language Models for Open-Ended Text Generation"},{"paperId":"eed787154cd7ae521d32033a599e48184e09b058","externalIds":{"ArXiv":"2205.11482","CorpusId":253107911},"title":"Towards Tracing Factual Knowledge in Language Models Back to the Training Data"},{"paperId":"3b9b1aba877ecd3f7e508cbc78a41b623349902b","externalIds":{"ACL":"2022.emnlp-main.26","DBLP":"journals/corr/abs-2204-11817","ArXiv":"2204.11817","DOI":"10.48550/arXiv.2204.11817","CorpusId":248376906},"title":"Translation between Molecules and Natural Language"},{"paperId":"0286b2736a114198b25fb5553c671c33aed5d477","externalIds":{"ArXiv":"2204.05862","DBLP":"journals/corr/abs-2204-05862","DOI":"10.48550/arXiv.2204.05862","CorpusId":248118878},"title":"Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"},{"paperId":"f2b0869b17bace854d73c19b449e3f88b9fed82e","externalIds":{"DBLP":"conf/acl/LiLSDSLJJL22","ACL":"2022.findings-acl.136","ArXiv":"2203.16747","DOI":"10.48550/arXiv.2203.16747","CorpusId":247839380},"title":"How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis"},{"paperId":"cf36236015c9f93f15bfafbf282f69e08bdc9c16","externalIds":{"DBLP":"conf/emnlp/GevaCWG22","ArXiv":"2203.14680","ACL":"2022.emnlp-main.3","DOI":"10.48550/arXiv.2203.14680","CorpusId":247762385},"title":"Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"b0ceba96db8b7b71beb2f0906568ffc143fddbf9","externalIds":{"ArXiv":"2202.11912","DBLP":"journals/corr/abs-2202-11912","CorpusId":247084007},"title":"A Rigorous Study of Integrated Gradients Method and Extensions to Internal Neuron Attributions"},{"paperId":"d3dd80269f2542cc173afb3a1df24b582a1e4af2","externalIds":{"ArXiv":"2202.12172","DBLP":"conf/acl/0001C22","ACL":"2022.acl-long.527","DOI":"10.18653/v1/2022.acl-long.527","CorpusId":247084324},"title":"Overcoming a Theoretical Limitation of Self-Attention"},{"paperId":"8703985fd545ba7498a75fcbcc27845a3b549833","externalIds":{"DBLP":"conf/wsdm/Choi22","DOI":"10.1145/3488560.3500242","CorpusId":246828626},"title":"Knowledge is Power: Symbolic Knowledge Distillation, Commonsense Morality, & Multimodal Script Knowledge"},{"paperId":"996445d847f06e99b0bd259345408a0cf1bce87e","externalIds":{"DBLP":"conf/nips/MengBAB22","ArXiv":"2202.05262","CorpusId":255825985},"title":"Locating and Editing Factual Associations in GPT"},{"paperId":"9e7227ae2fbccc4c54f986d4e72eae5d0f66387a","externalIds":{"DBLP":"conf/acit3/AbufaddaM21","DOI":"10.1109/acit53391.2021.9677302","CorpusId":246038013},"title":"A Survey of Synthetic Data Generation for Machine Learning"},{"paperId":"ccd04c27bf1237368b35eb456b3dd1c18ef9a9b9","externalIds":{"ArXiv":"2112.00826","DBLP":"journals/corr/abs-2112-00826","CorpusId":244798694},"title":"Inducing Causal Structure for Interpretable Neural Networks"},{"paperId":"4497f092aa44d4b47659226fad348a1834efd416","externalIds":{"PubMedCentral":"9704706","DBLP":"journals/corr/abs-2111-09259","ArXiv":"2111.09259","DOI":"10.1073/pnas.2206625119","CorpusId":244270420,"PubMed":"36375061"},"title":"Acquisition of chess knowledge in AlphaZero"},{"paperId":"026fb797afa8ca9809d27b878823c6e37096227b","externalIds":{"DBLP":"journals/complexity/DebboucheOBGKJA21","DOI":"10.1155/2021/3394666","CorpusId":243918198},"title":"Chaotic Behavior Analysis of a New Incommensurate Fractional-Order Hopfield Neural Network System"},{"paperId":"77805d75199e7b9e580b4827f56a069ba0ddd13f","externalIds":{"DBLP":"journals/jcisd/BagalAVP22","DOI":"10.1021/acs.jcim.1c00600","CorpusId":263484152,"PubMed":"34694798"},"title":"MolGPT: Molecular Generation Using a Transformer-Decoder Model"},{"paperId":"3dea52fa41958411114f10679531758fde2aefcc","externalIds":{"DBLP":"journals/cacm/HanZL21","DOI":"10.1145/3481608","CorpusId":239770276},"title":"Knowledgeable machine learning for natural language processing"},{"paperId":"52a027e80c24ecf9bcc468609dbb5be72478ec7a","externalIds":{"DBLP":"conf/iclr/WangZX022","ArXiv":"2111.09189","CorpusId":244270768},"title":"ToM2C: Target-oriented Multi-agent Communication and Cooperation with Theory of Mind"},{"paperId":"521ccc898395a2818fced22b4cf371b0e5121f94","externalIds":{"ACL":"2022.naacl-main.341","DBLP":"journals/corr/abs-2110-07178","ArXiv":"2110.07178","DOI":"10.18653/v1/2022.naacl-main.341","CorpusId":238857304},"title":"Symbolic Knowledge Distillation: from General Language Models to Commonsense Models"},{"paperId":"4c5f4ddc68be643fb34ea969bf2c105ff7538995","externalIds":{"DBLP":"journals/corr/abs-2109-07154","ArXiv":"2109.07154","ACL":"2021.emnlp-main.388","DOI":"10.18653/v1/2021.emnlp-main.388","CorpusId":237513360},"title":"Can Language Models be Biomedical Knowledge Bases?"},{"paperId":"e337ed6543c2e6e7e51c312c7d998798fc79fdde","externalIds":{"DBLP":"conf/acl/CaoLHSYLXX20","ArXiv":"2106.09231","ACL":"2021.acl-long.146","DOI":"10.18653/v1/2021.acl-long.146","CorpusId":235458643},"title":"Knowledgeable or Educated Guess? Revisiting Language Models as Knowledge Bases"},{"paperId":"da454295392cf4caaa39cc465734237ffe55392f","externalIds":{"DBLP":"journals/corr/abs-2105-11259","ArXiv":"2105.11259","DOI":"10.1016/j.aiopen.2022.11.003","CorpusId":235166723},"title":"PTR: Prompt Tuning with Rules for Text Classification"},{"paperId":"206a34781fa3b976ec1bbf0b9b231bf6a94424f1","externalIds":{"DOI":"10.1126/science.abd0380","CorpusId":234794569,"PubMed":"34016775"},"title":"A brain-computer interface that evokes tactile sensations improves robotic arm control"},{"paperId":"89bc95b30f147fd24dac91f43be1f2c3541f02ea","externalIds":{"PubMedCentral":"8065141","DOI":"10.1038/s41467-021-22732-w","CorpusId":232128835,"PubMed":"33893299"},"title":"Protein design and variant prediction using autoregressive generative models"},{"paperId":"240b0caabb415578bdea4da7d0a32bdff2e8163f","externalIds":{"DBLP":"journals/corr/abs-2104-08164","ArXiv":"2104.08164","ACL":"2021.emnlp-main.522","DOI":"10.18653/v1/2021.emnlp-main.522","CorpusId":233289412},"title":"Editing Factual Knowledge in Language Models"},{"paperId":"a7721b6523971394a8bd4bfda139122ef59b22cd","externalIds":{"ACL":"2021.emnlp-main.523","ArXiv":"2104.07012","DBLP":"journals/corr/abs-2104-07012","MAG":"3214537789","DOI":"10.18653/v1/2021.emnlp-main.523","CorpusId":233231308},"title":"Sparse Attention with Linear Units"},{"paperId":"f2885c6a25756cf81aa23b41bc62696a5be5c94d","externalIds":{"DBLP":"journals/corr/abs-2104-05240","MAG":"3166986030","ACL":"2021.naacl-main.398","ArXiv":"2104.05240","DOI":"10.18653/V1/2021.NAACL-MAIN.398","CorpusId":233210199},"title":"Factual Probing Is [MASK]: Learning vs. Learning to Recall"},{"paperId":"5c0705d856eb18666db4318cf76416560764a856","externalIds":{"ArXiv":"2103.16547","DBLP":"conf/nips/ChenCWGLW21","CorpusId":232417266},"title":"The Elastic Lottery Ticket Hypothesis"},{"paperId":"7cc88a1a904e8bb6edc1123c0800d1c5a0ea435d","externalIds":{"MAG":"3170470779","ArXiv":"2103.15949","DBLP":"journals/corr/abs-2103-15949","ACL":"2021.deelio-1.1","DOI":"10.18653/V1/2021.DEELIO-1.1","CorpusId":232417301},"title":"Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors"},{"paperId":"ca2f1088d3e581b2c6c75cf0ebc96506d620f64d","externalIds":{"DBLP":"conf/fat/BenderGMS21","DOI":"10.1145/3442188.3445922","CorpusId":262580630},"title":"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜"},{"paperId":"3dcfa05a1c162e6cab927c5b08d0444f7b6691f4","externalIds":{"ArXiv":"2102.12452","DBLP":"journals/coling/Belinkov22","ACL":"2022.cl-1.7","DOI":"10.1162/coli_a_00422","CorpusId":236924832},"title":"Probing Classifiers: Promises, Shortcomings, and Advances"},{"paperId":"fdacf2a732f55befdc410ea927091cad3b791f13","externalIds":{"DBLP":"journals/jmlr/FedusZS22","ArXiv":"2101.03961","CorpusId":231573431},"title":"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"},{"paperId":"4a54d58a4b20e4f3af25cea3c188a12082a95e02","externalIds":{"DBLP":"conf/emnlp/GevaSBL21","ACL":"2021.emnlp-main.446","ArXiv":"2012.14913","DOI":"10.18653/v1/2021.emnlp-main.446","CorpusId":229923720},"title":"Transformer Feed-Forward Layers Are Key-Value Memories"},{"paperId":"1d7f3297924a9dd90cfc0df522ebe9138c28b46f","externalIds":{"DBLP":"journals/tacl/ElazarRJG21","MAG":"3111367603","DOI":"10.1162/tacl_a_00359","CorpusId":227408471},"title":"Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"MAG":"3094502228","ArXiv":"2010.11929","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"51ae2c451a1a05293334a509b71c9c9e0377d35c","externalIds":{"MAG":"3079786700","DBLP":"journals/corr/abs-2008-09036","ACL":"2021.eacl-main.153","ArXiv":"2008.09036","DOI":"10.18653/v1/2021.eacl-main.153","CorpusId":221186765},"title":"Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries"},{"paperId":"d1615484d8af03aef212b2764bca93d70ac9707c","externalIds":{"MAG":"3204153914","DOI":"10.6028/nist.ir.8312-draft","CorpusId":242690810},"title":"Four Principles of Explainable Artificial Intelligence"},{"paperId":"4aef8b617230a1aef2be52513a2d5207d2e61ef8","externalIds":{"DBLP":"conf/acsos/BrownE20","MAG":"3090173111","DOI":"10.1109/ACSOS-C51401.2020.00035","CorpusId":221847717},"title":"I’m already optimal: the Dunning-Kruger Effect, Sociogenesis, and Self-Integration"},{"paperId":"3a24bfb77ed271fef948058e414850f89b0955a7","externalIds":{"DBLP":"conf/icml/KohNTMPKL20","ArXiv":"2007.04612","MAG":"3041871339","CorpusId":220424448},"title":"Concept Bottleneck Models"},{"paperId":"6150a2dab1b63b246eb2cd418fcdb5a6b6b8ae62","externalIds":{"MAG":"3038035611","DBLP":"conf/acl/HooverSG20","ACL":"2020.acl-demos.22","DOI":"10.18653/v1/2020.acl-demos.22","CorpusId":260539432},"title":"exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models"},{"paperId":"02eaaf87f9cae34cca398fed146079e6eeb1f868","externalIds":{"MAG":"3034723486","ACL":"2020.acl-main.463","DBLP":"conf/acl/BenderK20","DOI":"10.18653/v1/2020.acl-main.463","CorpusId":211029226},"title":"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"bb6c2a64ecb6e4c9f3f5720d53cca76a2c37505d","externalIds":{"MAG":"3020712669","ArXiv":"2004.10151","DBLP":"conf/emnlp/BiskHTABCLLMNPT20","ACL":"2020.emnlp-main.703","DOI":"10.18653/v1/2020.emnlp-main.703","CorpusId":216035815},"title":"Experience Grounds Language"},{"paperId":"d3237070ba08ac5a8d75540ba66af404b9ab9b09","externalIds":{"DBLP":"journals/access/LiZY20a","MAG":"3012334039","DOI":"10.1109/ACCESS.2020.2980935","CorpusId":214692423},"title":"Complexity Analysis and Synchronization Control of Fractional-Order Jafari-Sprott Chaotic System"},{"paperId":"80376bdec5f534be78ba82821f540590ebce5559","externalIds":{"DBLP":"journals/corr/abs-2002-08910","MAG":"3102659883","ACL":"2020.emnlp-main.437","ArXiv":"2002.08910","DOI":"10.18653/v1/2020.emnlp-main.437","CorpusId":211205183},"title":"How Much Knowledge Can You Pack into the Parameters of a Language Model?"},{"paperId":"7a15950dc71079285a4eaf195de5aadd87c41b40","externalIds":{"MAG":"2973379954","DBLP":"journals/corr/abs-1909-08593","ArXiv":"1909.08593","CorpusId":202660943},"title":"Fine-Tuning Language Models from Human Preferences"},{"paperId":"d0086b86103a620a86bc918746df0aa642e2a8a3","externalIds":{"DBLP":"journals/corr/abs-1909-01066","MAG":"2996758945","ArXiv":"1909.01066","ACL":"D19-1250","DOI":"10.18653/v1/D19-1250","CorpusId":202539551},"title":"Language Models as Knowledge Bases?"},{"paperId":"c53ae5c2601de32c87dab796ab686c70e48c356f","externalIds":{"DBLP":"journals/corr/abs-1906-02773","MAG":"2970072941","ArXiv":"1906.02773","CorpusId":174801046},"title":"One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers"},{"paperId":"5f994dc8cae24ca9d1ed629e517fcc652660ddde","externalIds":{"MAG":"2953356739","DBLP":"conf/acl/ZhangHLJSL19","ArXiv":"1905.07129","ACL":"P19-1139","DOI":"10.18653/v1/P19-1139","CorpusId":158046772},"title":"ERNIE: Enhanced Language Representation with Informative Entities"},{"paperId":"726320cdbd04804ffa8f3a78c095bd1b55a2a695","externalIds":{"MAG":"2949558627","ArXiv":"1905.00414","DBLP":"journals/corr/abs-1905-00414","CorpusId":141460329},"title":"Similarity of Neural Network Representations Revisited"},{"paperId":"63a08fac8cf8ca7ea9c75ec05bdc737a1b38a503","externalIds":{"DOI":"10.1201/9781420049107-67","CorpusId":1527228},"title":"Knowledge representation"},{"paperId":"47d79963ac69111d8dc82a228d26e6a746a4d087","externalIds":{"DOI":"10.1201/9781351190435-21","CorpusId":240081945},"title":"Transformers"},{"paperId":"29de7c0fb3c09eaf55b20619bceaeafe72fd87a6","externalIds":{"MAG":"2963096510","DBLP":"conf/acl/LewisDF18","ArXiv":"1805.04833","ACL":"P18-1082","DOI":"10.18653/v1/P18-1082","CorpusId":44134226},"title":"Hierarchical Neural Story Generation"},{"paperId":"21937ecd9d66567184b83eca3d3e09eb4e6fbd60","externalIds":{"ArXiv":"1803.03635","MAG":"2951099858","DBLP":"conf/iclr/FrankleC19","CorpusId":53388625},"title":"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"744464cd6fa8341633cd3b5d378faab18a3b543a","externalIds":{"MAG":"2952857044","ArXiv":"1704.05796","DBLP":"journals/corr/BauZKOT17","DOI":"10.1109/CVPR.2017.354","CorpusId":378410},"title":"Network Dissection: Quantifying Interpretability of Deep Visual Representations"},{"paperId":"54ddb00fa691728944fd8becea90a373d21597cf","externalIds":{"MAG":"2950220847","ArXiv":"1611.03530","DBLP":"journals/corr/ZhangBHRV16","CorpusId":6212000},"title":"Understanding deep learning requires rethinking generalization"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"2dcef55a07f8607a819c21fe84131ea269cc2e3c","externalIds":{"MAG":"2129069237","DBLP":"journals/corr/Sohl-DicksteinW15","ArXiv":"1503.03585","CorpusId":14888175},"title":"Deep Unsupervised Learning using Nonequilibrium Thermodynamics"},{"paperId":"d709465fb98a099e7654aa62c3d23d7b857e3711","externalIds":{"ArXiv":"1304.6736","MAG":"1992444821","DBLP":"journals/corr/abs-1304-6736","DOI":"10.1016/j.tics.2013.04.010","CorpusId":8014879,"PubMed":"23726319"},"title":"Networks in Cognitive Science"},{"paperId":"56662c89f7cff0347275a9cc8f55b7acf558e494","externalIds":{"MAG":"2171960331","DOI":"10.1080/10400419.2012.650092","CorpusId":146772784},"title":"The Standard Definition of Creativity"},{"paperId":"05066be776f99bb74ac41405ac980be0abf88a6c","externalIds":{"MAG":"2123776155","DOI":"10.1111/J.1747-9991.2010.00351.X","CorpusId":43425247},"title":"The Philosophy of Creativity"},{"paperId":"d5a9a2f895b35acf3288040218b68ae6b09c30b7","externalIds":{"MAG":"2170792687","DOI":"10.11645/4.1.189","CorpusId":55850854},"title":"Mapping Student Information Literacy Activity against Bloom’s Taxonomy of Cognitive Skills"},{"paperId":"25ad81d2f575d045bd1083c95a02b9b4b68a912e","externalIds":{"DOI":"10.2469/faj.v65.n1.5","CorpusId":218510903},"title":"Models"},{"paperId":"59cf698630a4aa25e5772a199a5d4745eae48156","externalIds":{"MAG":"2127151274","DOI":"10.5860/choice.45-4685","CorpusId":145291217},"title":"The Continuity Of Mind"},{"paperId":"7777df8c215114d510e1cc15eef937f1aa5bb019","externalIds":{"MAG":"2139690701","DOI":"10.1097/CHI.0b013e318161e509","CorpusId":431414,"PubMed":"18512292"},"title":"What is an image?"},{"paperId":"e64a9960734215e2b1866ea3cb723ffa5585ac14","externalIds":{"DBLP":"conf/nips/LeeBRN06","MAG":"2113606819","DOI":"10.7551/mitpress/7503.003.0105","CorpusId":303727},"title":"Efficient sparse coding algorithms"},{"paperId":"b89ca116234e0e16cda60958069ef253e76e4ecd","externalIds":{"MAG":"1495906371","DOI":"10.4324/9780203968932","CorpusId":142135262},"title":"Cognitive Science: An Introduction to Mind and Brain"},{"paperId":"a5ee09628e99a2dd30dda10826f68ed982c095d4","externalIds":{"MAG":"2115223032","DOI":"10.1076/neur.9.5.369.16553","CorpusId":6592186,"PubMed":"14972752"},"title":"Creative Innovation: Possible Brain Mechanisms"},{"paperId":"37c39c90b5a60f08131bbbe429201ea9813ef4fd","externalIds":{"MAG":"2126510731","DOI":"10.1111/1467-9213.00152","CorpusId":145240304},"title":"How Knowledge Works"},{"paperId":"2805537bec87a6177037b18f9a3a9d3f1038867b","externalIds":{"MAG":"2105464873","DOI":"10.1016/S0042-6989(97)00169-7","CorpusId":14208692,"PubMed":"9425546"},"title":"Sparse coding with an overcomplete basis set: A strategy employed by V1?"},{"paperId":"8c38d6c2adbcd47623820a8aa192d90ce4d936b7","externalIds":{"DBLP":"journals/sigact/Hochba97","MAG":"2123761655","DOI":"10.1145/261342.571216","CorpusId":33683322},"title":"Approximation Algorithms for NP-Hard Problems"},{"paperId":"b2b243792066faaeb696a74dda67c7aab0a647dc","externalIds":{"MAG":"2323603378","DOI":"10.1007/BF02676357","CorpusId":43734544},"title":"Fundamental neuroscience"},{"paperId":"b125dc47c9770a9b4ecb407970b2e027309b11d8","externalIds":{"MAG":"2162380575","DOI":"10.1177/03058298930220010601","CorpusId":146149320},"title":"'Level of Analysis' and 'Unit of Analysis': A Case for Distinction"},{"paperId":"6445d9101d5e8fec0b57da6d196f8ae00b14c24c","externalIds":{"MAG":"2088180562","DOI":"10.1108/EB005923","CorpusId":62571911},"title":"The Nature of Creativity"},{"paperId":"3be11f7bf16347e686d22f613c38279b5a71eb92","externalIds":{"MAG":"1580749063","CorpusId":272155150},"title":"Taxonomy of Educational Objectives: The Classification of Educational Goals."},{"paperId":"31ccf19d7c8e0d5f5ad485a0a9127eac9af941d3","externalIds":{"DBLP":"journals/corr/abs-2406-06144","DOI":"10.48550/arXiv.2406.06144","CorpusId":270371935},"title":"Language Models Resist Alignment"},{"paperId":"cb1bfd79445b7c4838cf59b6a93c898a8270f42e","externalIds":{"DBLP":"journals/corr/abs-2405-18727","DOI":"10.48550/arXiv.2405.18727","CorpusId":270094735},"title":"CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control"},{"paperId":"56019756e85646883855e3583523317de465af42","externalIds":{"DBLP":"journals/corr/abs-2404-07066","DOI":"10.48550/arXiv.2404.07066","CorpusId":269033222},"title":"Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?"},{"paperId":"df403ff1331117ec316a741d691bd2b2c5030cc4","externalIds":{"DBLP":"journals/corr/abs-2404-16032","DOI":"10.48550/arXiv.2404.16032","CorpusId":269362749},"title":"Studying Large Language Model Behaviors Under Realistic Knowledge Conflicts"},{"paperId":"d366d206223c816fdd3f19fb01d5b6a047d55075","externalIds":{"DBLP":"journals/corr/abs-2405-05409","DOI":"10.48550/arXiv.2405.05409","CorpusId":269635384},"title":"Initialization is Critical to Whether Transformers Fit Composite Functions by Inference or Memorizing"},{"paperId":"ff7391dff405fc6f5aebd5d5f14257af19a0c26c","externalIds":{"DBLP":"journals/corr/abs-2407-15176","DOI":"10.48550/arXiv.2407.15176","CorpusId":274179433},"title":"Farewell to Length Extrapolation, a Training-Free Infinite Context with Finite Attention Scope"},{"paperId":"5ca298600704d76adfc546742f85010f168efd1f","externalIds":{"DBLP":"journals/corr/abs-2403-18167","DOI":"10.48550/arXiv.2403.18167","CorpusId":278637063},"title":"Mechanisms of non-factual hallucinations in language models"},{"paperId":"06a4491fadcb68a5d2f03110f9b54881dd8611e4","externalIds":{"DBLP":"journals/corr/abs-2404-18870","DOI":"10.48550/arXiv.2404.18870","CorpusId":278498222},"title":"More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness"},{"paperId":"2b18e63caff82f1a688714aed099b8856db92581","externalIds":{"DBLP":"journals/corr/abs-2301-11259","DOI":"10.48550/arXiv.2301.11259","CorpusId":258762849},"title":"Domain-Agnostic Molecular Generation with Self-feedback"},{"paperId":"286e67c251d0e3e8776dc5c536a5b1f8009d664a","externalIds":{"DBLP":"journals/staeors/JiaoHLYMZYHYLMLCFTGZQWLBLSF23","DOI":"10.1109/JSTARS.2023.3247455","CorpusId":257120881},"title":"Brain-Inspired Remote Sensing Interpretation: A Comprehensive Survey"},{"paperId":"e661de406d8105e52a5351a2cd66db84cc4af115","externalIds":{"DBLP":"journals/corr/abs-2303-13988","DOI":"10.48550/arXiv.2303.13988","CorpusId":257757370},"title":"Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods"},{"paperId":"06d8562831c32844285a691c5250d04726df3c61","externalIds":{"DBLP":"journals/corr/abs-2307-12980","DOI":"10.48550/arXiv.2307.12980","CorpusId":260357841},"title":"A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models"},{"paperId":"667526e216f36212d74fb1887da0481e791d9c98","externalIds":{"DBLP":"conf/iclr/2022","CorpusId":251648822},"title":"The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022"},{"paperId":"2a122fced172013633e679abeb204b8808d518d0","externalIds":{"DOI":"10.1007/978-1-4842-6643-4_6","CorpusId":240648555},"title":"Expressions"},{"paperId":"78d08b8ab4132defffe98ec7f80a51452203f70d","externalIds":{"DBLP":"conf/nips/VigGBQNSS20","MAG":"3104142662","CorpusId":227275068},"title":"Investigating Gender Bias in Language Models Using Causal Mediation Analysis"},{"paperId":"0e8076fb95eb120fe5c369458eb8f82276053534","externalIds":{"DBLP":"conf/complexnetworks/Segretain0TG20","DOI":"10.1007/978-3-030-65351-4_30","CorpusId":232369387},"title":"A Methodology for Evaluating the Extensibility of Boolean Networks' Structure and Function"},{"paperId":"c68796f833a7151f0a63d1d1608dc902b4fdc9b6","externalIds":{"CorpusId":10319744},"title":"GENERATIVE ADVERSARIAL NETS"},{"paperId":"616ce395059ff5ae014e9e2f12a859ad083278e8","externalIds":{"MAG":"2400179639","DBLP":"conf/cogsci/MahmoodiAB13","CorpusId":41086749},"title":"The Less You Know, You Think You Know More; Dunning and Kruger effect in Collective Decision Making"},{"paperId":"ca301cd3018f2bae19c7cc78b41ca8da80387513","externalIds":{"MAG":"29661100","DOI":"10.1007/978-1-4471-2954-7_16","CorpusId":59709716},"title":"What is Knowledge"},{"paperId":"562669105ea3103879120e440c284d4014ec06b9","externalIds":{"MAG":"2804759158","DOI":"10.18848/1447-9494/CGP/V16I04/46223","CorpusId":158448807},"title":"Collective Learning: Applying Distributed Cognition for Collective Intelligence"},{"paperId":"6a07515741593b34b9a60db857703b6255b76122","externalIds":{"MAG":"2120128500","DOI":"10.1021/cen-v039n019.p011","CorpusId":168017541},"title":"What will you need"},{"paperId":"29bd61a8c5be2f080698c822c80877577dec1a21","externalIds":{"MAG":"1997233900","DOI":"10.1146/ANNUREV.PS.44.020193.003101","CorpusId":12928288,"PubMed":"8434897"},"title":"Social foundations of cognition."},{"paperId":"69f73ba8706d860a0093464380eeb92deb2f9ba2","externalIds":{"MAG":"2258614675","DOI":"10.1057/JORS.1991.209","CorpusId":32127708},"title":"Knowledge Acquisition: Principles and Guidelines"},{"paperId":"8ea9f53f3c1190d0a28e84690b694c2bf9344f7f","externalIds":{"MAG":"3022367466","CorpusId":228275698},"title":"Innovative applications of artificial intelligence"}]}