{"paperId":"efc50d7ee5bcd8039ba5d686d7d943be3ff199b0","externalIds":{"DBLP":"journals/corr/abs-2405-10739","ArXiv":"2405.10739","DOI":"10.1007/s44267-025-00099-6","CorpusId":269899856},"title":"Efficient multimodal large language models: a survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2405.10739, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2267492043","name":"Yizhang Jin"},{"authorId":"2302162727","name":"Jian Li"},{"authorId":"2284727141","name":"Yexin Liu"},{"authorId":"2302155099","name":"Tianjun Gu"},{"authorId":"2302286722","name":"Kai Wu"},{"authorId":"2275290482","name":"Zhengkai Jiang"},{"authorId":"2219723109","name":"Muyang He"},{"authorId":"2284660362","name":"Bo Zhao"},{"authorId":"2302505492","name":"Xin Tan"},{"authorId":"2066402135","name":"Zhenye Gan"},{"authorId":"2628601","name":"Yabiao Wang"},{"authorId":"2238285797","name":"Chengjie Wang"},{"authorId":"2109606150","name":"Lizhuang Ma"}],"abstract":"In the past years, multimodal large language models (MLLMs) have demonstrated remarkable performance in tasks such as visual question answering and visual understanding and reasoning. However, the extensive model size and high training and inference costs have hindered the widespread application of MLLMs in academia and industry. Thus, studying efficient and lightweight MLLMs has enormous potential, especially in edge computing scenarios. In this survey, we provide a comprehensive and systematic review of the current state of efficient MLLMs. Specifically, this survey summarizes the timeline of representative efficient MLLMs, the current state of research in structures and strategies, and the applications. Finally, the limitations of current efficient MLLM research and promising future directions are discussed."}