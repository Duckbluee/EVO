{"references":[{"paperId":"4b4c77e60abb37894792a50649f4d6954dcdc7e6","externalIds":{"ArXiv":"2407.21720","DBLP":"conf/iclr/WenL0L24","DOI":"10.48550/arXiv.2407.21720","CorpusId":270309880},"title":"Detecting, Explaining, and Mitigating Memorization in Diffusion Models"},{"paperId":"ed96b566c3a5182c7cd50894782dd81ad7d7380d","externalIds":{"ArXiv":"2405.16534","DBLP":"journals/corr/abs-2405-16534","DOI":"10.48550/arXiv.2405.16534","CorpusId":270063676},"title":"Pruning for Robust Concept Erasing in Diffusion Models"},{"paperId":"7e7540e8550022199301b1d0e591abf799da3a9a","externalIds":{"DOI":"10.2139/ssrn.4608809","CorpusId":264474179},"title":"The Economics of Copyright in the Digital Age"},{"paperId":"0402a87f87509b040bdcf1d9e0c0be8463c055f8","externalIds":{"ArXiv":"2405.01536","DBLP":"conf/siggrapha/JonesWKBZ24","DOI":"10.1145/3680528.3687642","CorpusId":269502574},"title":"Customizing Text-to-Image Models with a Single Image Pair"},{"paperId":"046fa7fa879f5d702bf8507ccf18d1c1f867a5f8","externalIds":{"DBLP":"conf/codaspy/DasDZA25","ArXiv":"2404.19227","DOI":"10.1145/3714393.3726502","CorpusId":269457418},"title":"Espresso: Robust Concept Filtering in Text-to-Image Models"},{"paperId":"5eaebb0d8344bc89320d765eb6a35b9e72f7a08c","externalIds":{"DBLP":"conf/cvpr/XuLLLW024","ArXiv":"2404.15081","DOI":"10.1109/CVPR52733.2024.02316","CorpusId":269302832},"title":"Perturbing Attention Gives You More Bang for the Buck: Subtle Imaging Perturbations That Efficiently Fool Customized Diffusion Models"},{"paperId":"d23f8a143b4520cb1df939d01ccf93344b30e7cf","externalIds":{"DBLP":"journals/ijcv/WangSTY26","ArXiv":"2404.13788","DOI":"10.1007/s11263-025-02633-x","CorpusId":269293225},"title":"AnyPattern: Towards In-context Image Copy Detection"},{"paperId":"365eeee6a9eab83d8565f5faba42ca1648158b86","externalIds":{"ArXiv":"2404.13706","DBLP":"journals/corr/abs-2404-13706","DOI":"10.48550/arXiv.2404.13706","CorpusId":269293130},"title":"Concept Arithmetics for Circumventing Concept Inhibition in Diffusion Models"},{"paperId":"3a9d79d44eae3b455a5d5a71cd51011caec6eebc","externalIds":{"DBLP":"journals/corr/abs-2404-12590","ArXiv":"2404.12590","DOI":"10.48550/arXiv.2404.12590","CorpusId":269282669},"title":"The Files are in the Computer: Copyright, Memorization, and Generative AI"},{"paperId":"17e7b58f99d5dbf6d7a117102f68d01aa84335b3","externalIds":{"DBLP":"journals/corr/abs-2404-11962","ArXiv":"2404.11962","DOI":"10.48550/arXiv.2404.11962","CorpusId":269214015},"title":"\\copyright Plug-in Authorization for Human Content Copyright Protection in Text-to-Image Model"},{"paperId":"d7e421ffbbac776aa385999cd0b97108364066f6","externalIds":{"ArXiv":"2404.09401","DBLP":"conf/cvpr/Zhu0K24","DOI":"10.1109/CVPR52733.2024.02305","CorpusId":269148397},"title":"Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models"},{"paperId":"2a95c02992f7a6ca514f37691b5b1cde9e98fc4b","externalIds":{"DBLP":"journals/corr/abs-2404-08030","ArXiv":"2404.08030","DOI":"10.48550/arXiv.2404.08030","CorpusId":269137659},"title":"Rethinking Artistic Copyright Infringements in the Era of Text-to-Image Generative Models"},{"paperId":"970111f19cbb20af52a8a1772e8d4b36570b5679","externalIds":{"ArXiv":"2404.06666","DBLP":"conf/ccs/LiYD0C0024","DOI":"10.1145/3658644.3670295","CorpusId":269033441},"title":"SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models"},{"paperId":"0bd4a6f0701dd0f9f936730468699a7e7d920172","externalIds":{"ArXiv":"2404.03631","DBLP":"journals/corr/abs-2404-03631","DOI":"10.48550/arXiv.2404.03631","CorpusId":268889354},"title":"Robust Concept Erasure Using Task Vectors"},{"paperId":"fc7c347df3b1988228ab8180be6de98e82ba598f","externalIds":{"DBLP":"journals/corr/abs-2404-00922","ArXiv":"2404.00922","DOI":"10.1109/CVPR52733.2024.00805","CorpusId":268819999},"title":"Towards Memorization-Free Diffusion Models"},{"paperId":"dfed4d075baa110a4bec56d9b0e7252bc794a5e7","externalIds":{"ArXiv":"2404.01292","DBLP":"journals/corr/abs-2404-01292","DOI":"10.48550/arXiv.2404.01292","CorpusId":268857122},"title":"Measuring Style Similarity in Diffusion Models"},{"paperId":"3304335743a06642c2d703dae6d410010c6ab5b9","externalIds":{"DBLP":"journals/corr/abs-2403-19254","ArXiv":"2403.19254","DOI":"10.48550/arXiv.2403.19254","CorpusId":268733141},"title":"Imperceptible Protection against Style Imitation from Diffusion Models"},{"paperId":"817721d43f5792f1db88015a0b330f4facf115fb","externalIds":{"ArXiv":"2403.19593","DBLP":"conf/wacv/RahmanPP25","DOI":"10.1109/WACV61041.2025.00274","CorpusId":268733347},"title":"Frame by Familiar Frame: Understanding Replication in Video Diffusion Models"},{"paperId":"be22779419d92b60f65909224b5100b07e369314","externalIds":{"ArXiv":"2403.19050","DBLP":"journals/corr/abs-2403-19050","DOI":"10.48550/arXiv.2403.19050","CorpusId":268732888},"title":"Detecting Generative Parroting through Overfitting Masked Autoencoders"},{"paperId":"c0875f62cf69911fc9599c5d0f96df0972d489d9","externalIds":{"DBLP":"journals/corr/abs-2403-14421","ArXiv":"2403.14421","DOI":"10.48550/arXiv.2403.14421","CorpusId":268553771},"title":"DP-RDM: Adapting Diffusion Models to Private Domains Without Fine-Tuning"},{"paperId":"91e297b9a6e7cf7f56b4537f0ed127e12d0ae728","externalIds":{"ArXiv":"2403.13807","DBLP":"journals/corr/abs-2403-13807","DOI":"10.48550/arXiv.2403.13807","CorpusId":268536809},"title":"Editing Massive Concepts in Text-to-Image Diffusion Models"},{"paperId":"f7b4211d53a05737b5efc161da69c78e2e7b8850","externalIds":{"DBLP":"conf/icml/DarasDD24","ArXiv":"2404.10177","DOI":"10.48550/arXiv.2404.10177","CorpusId":269157394},"title":"Consistent Diffusion Meets Tweedie: Training Exact Ambient Diffusion Models with Noisy Data"},{"paperId":"520f1f30cadd1a1d6189f8f2a4e025959ca8c328","externalIds":{"DBLP":"journals/corr/abs-2403-11162","ArXiv":"2403.11162","DOI":"10.1109/CVPR52733.2024.01028","CorpusId":268513090},"title":"CGI-DM: Digital Copyright Authentication for Diffusion Models via Contrasting Gradient Inversion"},{"paperId":"6ec711bdee0a56c023957618552881f0291964c4","externalIds":{"DBLP":"conf/vr/ShenXL24","DOI":"10.1109/VR58804.2024.00039","CorpusId":269174149},"title":"Context-Aware Head-and-Eye Motion Generation with Diffusion Model"},{"paperId":"82c174ba4239b7539e4f4a87c1f89cb3e17aa6fa","externalIds":{"DBLP":"conf/eccv/RenLZXLXT24","ArXiv":"2403.11052","DOI":"10.48550/arXiv.2403.11052","CorpusId":268512681},"title":"Unveiling and Mitigating Memorization in Text-to-image Diffusion Models through Cross Attention"},{"paperId":"4f0254bc8989693d96275cc281d45c51197beb8b","externalIds":{"DBLP":"conf/cvpr/WengHQHLZC24","ArXiv":"2403.09093","DOI":"10.1109/CVPR52733.2024.01209","CorpusId":268385148},"title":"Desigen: A Pipeline for Controllable Design Template Generation"},{"paperId":"425737a02a33799dc8e5f86c2f8eab9e777812db","externalIds":{"DBLP":"journals/corr/abs-2403-09450","ArXiv":"2403.09450","DOI":"10.1109/SaTML59370.2024.00010","CorpusId":268385205},"title":"Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative Privacy Risk"},{"paperId":"d70796e918365bbad0d8911161df2576e45b736a","externalIds":{"ArXiv":"2403.07838","DBLP":"journals/corr/abs-2403-07838","DOI":"10.48550/arXiv.2403.07838","CorpusId":268364242},"title":"MPCPA: Multi-Center Privacy Computing with Predictions Aggregation based on Denoising Diffusion Probabilistic Model"},{"paperId":"08f20fadfb51974a6883b935593a93e2f39408b6","externalIds":{"DBLP":"journals/corr/abs-2403-06951","ArXiv":"2403.06951","DOI":"10.1109/CVPR52733.2024.00830","CorpusId":268363879},"title":"DEADiff: An Efficient Stylization Diffusion Model with Disentangled Representations"},{"paperId":"f42881b52212860263a162cf83a718bb44ba15cd","externalIds":{"DBLP":"journals/corr/abs-2403-06135","ArXiv":"2403.06135","DOI":"10.1109/CVPR52733.2024.00615","CorpusId":268351735},"title":"MACE: Mass Concept Erasure in Diffusion Models"},{"paperId":"41a66997ce0a366bba3becf7c3f37c9aebb13fbd","externalIds":{"DBLP":"journals/corr/abs-2403-03206","ArXiv":"2403.03206","DOI":"10.48550/arXiv.2403.03206","CorpusId":268247980},"title":"Scaling Rectified Flow Transformers for High-Resolution Image Synthesis"},{"paperId":"ad7ab96f4d4314f9fc23b55c83e9847461851e93","externalIds":{"DBLP":"journals/digital/LimZOP24","DOI":"10.3390/digital4010013","CorpusId":268194495},"title":"Decoding the Relationship of Artificial Intelligence, Advertising, and Generative Models"},{"paperId":"4bda2650cb9e5c7fe09b30a78d1974f5876f7b18","externalIds":{"DBLP":"journals/corr/abs-2403-00025","ArXiv":"2403.00025","DOI":"10.48550/arXiv.2403.00025","CorpusId":268201483},"title":"On the Challenges and Opportunities in Generative AI"},{"paperId":"9e106189176e3e2e98b480cfdee803a0514c18ad","externalIds":{"DBLP":"conf/aaai/LuoXLK0Z25","ArXiv":"2402.11989","DOI":"10.1609/aaai.v39i6.32628","CorpusId":267751449},"title":"Privacy-Preserving Low-Rank Adaptation Against Membership Inference Attacks for Latent Diffusion Models"},{"paperId":"0eef8f9beebce793fb5be5077be1a888d5daaacc","externalIds":{"DBLP":"conf/iclr/Li0HKHW024","ArXiv":"2402.05375","DOI":"10.48550/arXiv.2402.05375","CorpusId":267547985},"title":"Get What You Want, Not What You Don't: Image Content Suppression for Text-to-Image Diffusion Models"},{"paperId":"836c652834b0f6ffe10e53ede1c0b9433cfad9ea","externalIds":{"ArXiv":"2402.02333","DBLP":"journals/corr/abs-2402-02333","DOI":"10.48550/arXiv.2402.02333","CorpusId":267412857},"title":"Copyright Protection in Generative AI: A Technical Perspective"},{"paperId":"5c3cee8d2ce4bd7d424e6bc281ac74acf47ad0e9","externalIds":{"DBLP":"journals/corr/abs-2402-05947","ArXiv":"2402.05947","DOI":"10.48550/arXiv.2402.05947","CorpusId":267617107},"title":"Separable Multi-Concept Erasure from Diffusion Models"},{"paperId":"fd3c485e1b129b2bcf8b0b7468febd959514474f","externalIds":{"ArXiv":"2402.00351","DBLP":"journals/corr/abs-2402-00351","DOI":"10.48550/arXiv.2402.00351","CorpusId":267365224},"title":"Machine Unlearning for Image-to-Image Generative Models"},{"paperId":"12ed45473dee6d0917f8577157cb86952cb162ce","externalIds":{"DBLP":"journals/corr/abs-2402-00045","ArXiv":"2402.00045","DOI":"10.48550/arXiv.2402.00045","CorpusId":267365030},"title":"Detecting Multimedia Generated by Large AI Models: A Survey"},{"paperId":"145e944a7889ce5cbd9580b5123d1103fb3193e5","externalIds":{"ArXiv":"2401.05779","DBLP":"conf/cvpr/00210HH25","DOI":"10.1109/CVPR52734.2025.02632","CorpusId":266933547},"title":"Erasing Undesirable Influence in Diffusion Models"},{"paperId":"1e33027c18740ece794d07d334b794412788522b","externalIds":{"DBLP":"journals/corr/abs-2401-04856","ArXiv":"2401.04856","DOI":"10.48550/arXiv.2401.04856","CorpusId":266902723},"title":"A Good Score Does not Lead to A Good Generative Model"},{"paperId":"86307d23d25cefe451a53fd76ddbe5798b592c3b","externalIds":{"DBLP":"conf/icml/WangSTZK24","ArXiv":"2401.04136","DOI":"10.48550/arXiv.2401.04136","CorpusId":266900037},"title":"The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright Breaches Without Adjusting Finetuning Pipeline"},{"paperId":"52b7c596185233ca269b4db5fe54ab6e356e64fa","externalIds":{"ArXiv":"2401.01623","DBLP":"journals/corr/abs-2401-01623","DOI":"10.48550/arXiv.2401.01623","CorpusId":266741474},"title":"Can AI Be as Creative as Humans?"},{"paperId":"3b07dd8eeb08aa90012b8602d43c2f9aa03373df","externalIds":{"DBLP":"conf/aaai/HongLW24","ArXiv":"2312.12807","DOI":"10.48550/arXiv.2312.12807","CorpusId":266374816},"title":"All but One: Surgical Concept Erasing with Model Preservation in Text-to-Image Diffusion Models"},{"paperId":"c06e364790020996f4b605ee44812ebdc759d389","externalIds":{"DBLP":"conf/ndss/Pang025","ArXiv":"2312.08207","DOI":"10.14722/ndss.2025.23324","CorpusId":266191072},"title":"Black-box Membership Inference Attacks against Fine-tuned Diffusion Models"},{"paperId":"a92d4224fdca1cea4bdc7e56bc473aec16a3fbf2","externalIds":{"ArXiv":"2312.06205","DBLP":"journals/corr/abs-2312-06205","DOI":"10.48550/arXiv.2312.06205","CorpusId":266162342},"title":"The Journey, Not the Destination: How Data Guides Diffusion Models"},{"paperId":"d0933ef0b4b9142ea2ca53d95c9d9ae49ee38a82","externalIds":{"DBLP":"journals/corr/abs-2312-05140","ArXiv":"2312.05140","DOI":"10.48550/arXiv.2312.05140","CorpusId":266149496},"title":"Membership Inference Attacks on Diffusion Models via Quantile Regression"},{"paperId":"1662e03b29266ebe75a74cb704ec0eff50278216","externalIds":{"DBLP":"journals/corr/abs-2312-03692","ArXiv":"2312.03692","DOI":"10.48550/arXiv.2312.03692","CorpusId":265698255},"title":"Memory Triggers: Unveiling Memorization in Text-To-Image Generative Models through Word-Level Duplication"},{"paperId":"9bfeb4baec1640ea4413354ab693eed083bd0d9f","externalIds":{"ArXiv":"2312.07550","DBLP":"journals/corr/abs-2312-07550","DOI":"10.48550/arXiv.2312.07550","CorpusId":266191550},"title":"Understanding (Un)Intended Memorization in Text-to-Image Generative Models"},{"paperId":"efc7c8d72897585f9086795810eb986bb918651c","externalIds":{"DBLP":"conf/aies/WuNG24","ArXiv":"2312.03027","DOI":"10.48550/arXiv.2312.03027","CorpusId":265693712},"title":"Stable Diffusion Exposed: Gender Bias from Prompt to Image"},{"paperId":"05c7eabf85ab246fa30beb191c6b13cf1181d1ba","externalIds":{"ArXiv":"2312.01725","DBLP":"conf/cvpr/KimG00C24","DOI":"10.1109/CVPR52733.2024.00781","CorpusId":265609458},"title":"Stable VITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On"},{"paperId":"9d967d4a15b55bba08b9f2df85d8e05384f2516c","externalIds":{"DBLP":"journals/corr/abs-2311-18815","ArXiv":"2311.18815","DOI":"10.48550/arXiv.2311.18815","CorpusId":265506125},"title":"IMMA: Immunizing text-to-image Models against Malicious Adaptation"},{"paperId":"4d9572d6491aa0431eb68f3c15607bc849ae22a5","externalIds":{"DBLP":"journals/corr/abs-2312-00084","ArXiv":"2312.00084","DOI":"10.1109/CVPR52733.2024.02303","CorpusId":265551592},"title":"Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?"},{"paperId":"9557fdd24eb15a70eebc7a8093fd44a0ae7f4294","externalIds":{"DBLP":"conf/eccv/HuangCTLYW24","ArXiv":"2311.17717","DOI":"10.48550/arXiv.2311.17717","CorpusId":265498506},"title":"Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via Lightweight Erasers"},{"paperId":"400034697509369b7023406a75eff3f570769502","externalIds":{"DBLP":"conf/cvpr/LiSK24","ArXiv":"2312.00057","DOI":"10.1109/CVPR52733.2024.01175","CorpusId":265551515},"title":"VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models"},{"paperId":"185e88645dfc07d6ca81a55dfc66bd3452400276","externalIds":{"ArXiv":"2311.13600","DBLP":"journals/corr/abs-2311-13600","DOI":"10.48550/arXiv.2311.13600","CorpusId":265351656},"title":"ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs"},{"paperId":"56c208850c4ef8ea95aa87a5d2d6157ba174fbb5","externalIds":{"DBLP":"journals/corr/abs-2311-13619","ArXiv":"2311.13619","DOI":"10.48550/arXiv.2311.13619","CorpusId":265445146},"title":"Steal My Artworks for Fine-tuning? A Watermarking Framework for Detecting Art Theft Mimicry in Text-to-Image Models"},{"paperId":"5698d1f43d2ee9fafbfab839706fd51585dd0fed","externalIds":{"DBLP":"journals/corr/abs-2311-06477","ArXiv":"2311.06477","DOI":"10.48550/arXiv.2311.06477","CorpusId":265150555},"title":"Report of the 1st Workshop on Generative AI and Law"},{"paperId":"b36b190e911a8958078e16b9de3384a0d1bacff1","externalIds":{"DBLP":"conf/ictai/QinGZY23","DOI":"10.1109/ICTAI59109.2023.00093","CorpusId":266438560},"title":"Destruction-Restoration Suppresses Data Protection Perturbations against Diffusion Models"},{"paperId":"a3eff696eef2d9cf155a4433f8a4e77c78229373","externalIds":{"DBLP":"conf/nips/LiLZ023","ArXiv":"2311.01797","DOI":"10.48550/arXiv.2311.01797","CorpusId":265019387},"title":"On the Generalization Properties of Diffusion Models"},{"paperId":"5e1015f87ccc0ef57c0a098395ebecc9bc6b2379","externalIds":{"DBLP":"conf/wacv/ZhangYW0Z24","ArXiv":"2310.19410","DOI":"10.1109/WACV57701.2024.00477","CorpusId":264820351},"title":"Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models"},{"paperId":"c0359ad23c7374bde0a361e01854553f7d73b80e","externalIds":{"DBLP":"conf/nips/CaoL0JLC23","ArXiv":"2310.19248","DOI":"10.48550/arXiv.2310.19248","CorpusId":264813738},"title":"IMPRESS: Evaluating the Resilience of Imperceptible Perturbations Against Unauthorized Data Usage in Diffusion-Based Generative AI"},{"paperId":"d77dda5c281637dcabfa72adc0c3c843da18ee12","externalIds":{"ArXiv":"2310.16613","DBLP":"journals/corr/abs-2310-16613","DOI":"10.48550/arXiv.2310.16613","CorpusId":264451736},"title":"On the Proactive Generation of Unsafe Images From Text-To-Image Models Using Benign Prompts"},{"paperId":"1b672e2ea961ef45a9f3322430ca5df9ff8ba165","externalIds":{"DBLP":"journals/corr/abs-2310-16825","ArXiv":"2310.16825","DOI":"10.48550/arXiv.2310.16825","CorpusId":264451536},"title":"CommonCanvas: An Open Diffusion Model Trained with Creative-Commons Images"},{"paperId":"795b3d3341c7c93daf316a59794f67a6c1c230f1","externalIds":{"ArXiv":"2310.18362","DBLP":"journals/corr/abs-2310-18362","DOI":"10.48550/arXiv.2310.18362","CorpusId":264590727},"title":"SoK: Memorization in General-Purpose Large Language Models"},{"paperId":"d2726daa50c4dba55913d11f63f122700f0a033a","externalIds":{"ArXiv":"2310.12508","DBLP":"journals/corr/abs-2310-12508","DOI":"10.48550/arXiv.2310.12508","CorpusId":264305818},"title":"SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation"},{"paperId":"2d895c3153a80d281428a14d14ae121536fe790d","externalIds":{"ArXiv":"2310.13165","DBLP":"conf/nips/XuMHLC23","DOI":"10.48550/arXiv.2310.13165","CorpusId":264405630},"title":"CycleNet: Rethinking Cycle Consistency in Text-Guided Diffusion for Image Manipulation"},{"paperId":"11551d9311339daa37613eef74adc099b31fcd86","externalIds":{"DBLP":"conf/eccv/ZhangJCCZLDL24","ArXiv":"2310.11868","DOI":"10.48550/arXiv.2310.11868","CorpusId":264289091},"title":"To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now"},{"paperId":"04983bbf48ab9649e3e6dcb7f4fadd7d04c89bbd","externalIds":{"DBLP":"journals/corr/abs-2310-10012","ArXiv":"2310.10012","DOI":"10.48550/arXiv.2310.10012","CorpusId":264146485},"title":"Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models?"},{"paperId":"4792d1728cc8c9d2245aecc2d42bc2726ada59ad","externalIds":{"DBLP":"conf/icassp/BraliosWGPKHR24","ArXiv":"2310.10604","DOI":"10.1109/ICASSP48485.2024.10447705","CorpusId":264146396},"title":"Generation or Replication: Auscultating Audio Latent Diffusion Models"},{"paperId":"41c5731e22663c86fb94230b80e39b2607996685","externalIds":{"ArXiv":"2311.12847","DBLP":"journals/corr/abs-2311-12847","DOI":"10.48550/arXiv.2311.12847","CorpusId":265351912},"title":"CopyScope: Model-level Copyright Infringement Quantification in the Diffusion Workflow"},{"paperId":"6487ec82f6d8082a5b402a5416ea03009acb1679","externalIds":{"DBLP":"journals/cgf/PoYGABBCDHKLLMNOTWW24","ArXiv":"2310.07204","DOI":"10.1111/cgf.15063","CorpusId":263835355},"title":"State of the Art on Diffusion Models for Visual Computing"},{"paperId":"37fbaa328e7867e4b63de070ee834a3fb510f666","externalIds":{"ArXiv":"2310.05873","DBLP":"conf/eccv/LiuCZHHXLYK24","DOI":"10.1007/978-3-031-72664-4_26","CorpusId":263831139},"title":"Implicit Concept Removal of Diffusion Models"},{"paperId":"28d781e7504fdbe0916e7167f500a0d062350abe","externalIds":{"ArXiv":"2310.04687","DBLP":"conf/iclr/ZhengLW25","CorpusId":263830452},"title":"Targeted Attack Improves Protection against Unauthorized Diffusion Customization"},{"paperId":"122a7e217fe70d5a1a44a6e2b67e859d1fc8e28d","externalIds":{"DBLP":"journals/tmlr/GuDPLL025","ArXiv":"2310.02664","DOI":"10.48550/arXiv.2310.02664","CorpusId":263620137},"title":"On Memorization in Diffusion Models"},{"paperId":"a8724abaf519ab9113cf9dcc4c6d17f984de52cf","externalIds":{"DBLP":"journals/corr/abs-2310-02557","ArXiv":"2310.02557","DOI":"10.48550/arXiv.2310.02557","CorpusId":263620724},"title":"Generalization in diffusion models arises from geometry-adaptive harmonic representation"},{"paperId":"e77a6fca31b12298c87a41a4384f3d1be2afc8c2","externalIds":{"DBLP":"journals/corr/abs-2310-02401","ArXiv":"2310.02401","DOI":"10.1145/3715073.3715080","CorpusId":263622213},"title":"FT-Shield: A Watermark Against Unauthorized Fine-tuning in Text-to-Image Diffusion Models"},{"paperId":"ac4acb63115eb7de8c0a872a7d6c7aa806b5beba","externalIds":{"DBLP":"conf/iclr/XueLWC24","ArXiv":"2311.12832","DOI":"10.48550/arXiv.2311.12832","CorpusId":265351716},"title":"Toward effective protection against diffusion based mimicry through score distillation"},{"paperId":"ff543923421694ded755eb26db7f4a8196331f9a","externalIds":{"DBLP":"journals/corr/abs-2310-01506","ArXiv":"2310.01506","DOI":"10.48550/arXiv.2310.01506","CorpusId":264306183},"title":"Direct Inversion: Boosting Diffusion-based Editing with 3 Lines of Code"},{"paperId":"cec9d26e91631f41b70254e13d18c66dca3e0288","externalIds":{"DBLP":"journals/corr/abs-2309-14751","ArXiv":"2309.14751","DOI":"10.1109/DICTA60407.2023.00055","CorpusId":262825503},"title":"Text-image guided Diffusion Model for generating Deepfake celebrity interactions"},{"paperId":"e78722bd95ace8c29458ac22967784edf54658b2","externalIds":{"DBLP":"journals/corr/abs-2309-11575","ACL":"2023.artofsafety-1.3","ArXiv":"2309.11575","DOI":"10.48550/arXiv.2309.11575","CorpusId":262083985},"title":"Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge"},{"paperId":"a11c695b34bb7f5cc8e6e96d8e6e037229394514","externalIds":{"DBLP":"journals/csur/WangZQZXW25","ArXiv":"2309.09435","DOI":"10.1145/3703626","CorpusId":262044913},"title":"Security and Privacy on Generative Data in AIGC: A Survey"},{"paperId":"b41adf707afdcdfa64d1daa9805b4532eac2d1ee","externalIds":{"ArXiv":"2309.09553","DBLP":"journals/corr/abs-2309-09553","DOI":"10.1109/ICASSP48485.2024.10446420","CorpusId":261959414},"title":"Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning for Visual Story Synthesis"},{"paperId":"095a1d8e58091a44f4416673277d573b4b2926d5","externalIds":{"DBLP":"conf/cslaw/LeeCG24","ArXiv":"2309.08133","DOI":"10.1145/3614407.3643696","CorpusId":260416806},"title":"Talkin' 'Bout AI Generation: Copyright and the Generative-AI Supply Chain (The Short Version)"},{"paperId":"811a5ecd5161f1354e89e3d143e471fa6762efc7","externalIds":{"ArXiv":"2311.12803","CorpusId":265352103},"title":"On Copyright Risks of Text-to-Image Diffusion Models"},{"paperId":"cdca8d98fc23f99bec1e45c51abb89cf2c885f18","externalIds":{"DBLP":"conf/icassp/LiCZB24","ArXiv":"2309.07254","DOI":"10.1109/ICASSP48485.2024.10446820","CorpusId":261823108},"title":"Mitigate Replication and Copying in Diffusion Models with Generalized Caption and Dual Fusion Enhancement"},{"paperId":"e73674126761bfba885a2a6b2594e3a27a2c2f2d","externalIds":{"DBLP":"journals/corr/abs-2309-03198","ArXiv":"2309.03198","DOI":"10.48550/arXiv.2309.03198","CorpusId":261557150},"title":"My Art My Choice: Adversarial Protection Against Unruly AI"},{"paperId":"e367992ca8deed39d18717a3ef08aa05a94128c0","externalIds":{"ArXiv":"2308.14761","DBLP":"conf/wacv/GandikotaOBMB24","DOI":"10.1109/WACV57701.2024.00503","CorpusId":261276613},"title":"Unified Concept Editing in Diffusion Models"},{"paperId":"493631660094a07105018fb5b378d2e73eb97fc0","externalIds":{"ArXiv":"2308.12143","DBLP":"journals/corr/abs-2308-12143","DOI":"10.48550/arXiv.2308.12143","CorpusId":261241592},"title":"A Probabilistic Fluctuation based Membership Inference Attack for Diffusion Models"},{"paperId":"a32cfc2e12430cfe109a12087c9e0d8177c94397","externalIds":{"ArXiv":"2308.09889","DBLP":"journals/corr/abs-2308-09889","DOI":"10.48550/arXiv.2308.09889","CorpusId":261049723},"title":"DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization"},{"paperId":"115f8fd513c38214ea15ceb49add5b970831cd7e","externalIds":{"DBLP":"conf/mm/SunZHM23","ArXiv":"2308.07605","DOI":"10.1145/3581783.3613806","CorpusId":260900110},"title":"SGDiff: A Style Guided Diffusion Model for Fashion Synthesis"},{"paperId":"60e53d9f34e71cbbfe87ab75ca3a909233a6b356","externalIds":{"DBLP":"journals/corr/abs-2308-06405","ArXiv":"2308.06405","DOI":"10.48550/arXiv.2308.06405","CorpusId":260887617},"title":"White-box Membership Inference Attacks against Diffusion Models"},{"paperId":"ef43bf117f04d80bc359c778ea6be3900a79dd20","externalIds":{"DBLP":"journals/corr/abs-2308-06101","ArXiv":"2308.06101","DOI":"10.1145/3581783.3612255","CorpusId":260866168},"title":"Taming the Power of Diffusion Models for High-Quality Virtual Try-On with Appearance Flow"},{"paperId":"7dbd3d51c453caf77cc1f9681f9b888095b97443","externalIds":{"DBLP":"conf/aies/JiangBCKGWHFG23","DOI":"10.1145/3600211.3604681","CorpusId":261279983},"title":"AI Art and its Impact on Artists"},{"paperId":"bcad06aca47861d5445fc077cca412200dbf9a8e","externalIds":{"ArXiv":"2308.01508","DBLP":"journals/corr/abs-2308-01508","DOI":"10.48550/arXiv.2308.01508","CorpusId":260438511},"title":"Circumventing Concept Erasure Methods For Text-to-Image Generative Models"},{"paperId":"5bc18d44a8c021f15c5fb9ba3350c9da2076db19","externalIds":{"DBLP":"journals/corr/abs-2308-02552","ArXiv":"2308.02552","DOI":"10.1145/3581783.3611867","CorpusId":260682786},"title":"Degeneration-Tuning: Using Scrambled Grid shield Unwanted Concepts from Stable Diffusion"},{"paperId":"115a293a9f4d458d472ec3a6a8aa60892fbbc7c3","externalIds":{"DBLP":"journals/corr/abs-2308-01937","ArXiv":"2308.01937","DOI":"10.48550/arXiv.2308.01937","CorpusId":260611170},"title":"Training Data Protection with Compositional Diffusion Models"},{"paperId":"3e0a92b488ea919bc5c24c72280cc84208a32d2a","externalIds":{"ArXiv":"2308.04448","DBLP":"journals/corr/abs-2308-04448","DOI":"10.48550/arXiv.2308.04448","CorpusId":260735975},"title":"Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI"},{"paperId":"cd3dc6a05fd47213aa6ed9b0505fa88c0275d6ea","externalIds":{"DBLP":"journals/corr/abs-2307-13527","ArXiv":"2307.13527","DOI":"10.48550/arXiv.2307.13527","CorpusId":260155285},"title":"Not with my name! Inferring artists' names of input strings employed by Diffusion Models"},{"paperId":"d4a60ef37125fcde198781c2eb578a9c9dc78c1c","externalIds":{"DBLP":"journals/corr/abs-2307-12348","ArXiv":"2307.12348","DOI":"10.48550/arXiv.2307.12348","CorpusId":260125321},"title":"ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting"},{"paperId":"a756c588cb1de7a67a693450ef21271451294871","externalIds":{"ArXiv":"2307.11410","DBLP":"journals/corr/abs-2307-11410","DOI":"10.1145/3641519.3657469","CorpusId":260091569},"title":"Subject-Diffusion: Open Domain Personalized Text-to-Image Generation without Test-time Fine-tuning"},{"paperId":"367a161324a3b6d1b64b75bb8b44a797fc6a948b","externalIds":{"DOI":"10.1126/science.adi0656","CorpusId":259844568,"PubMed":"37440639"},"title":"Generative AI meets copyright"},{"paperId":"bd5c066a63ae6a5fcf99e53551161446baf54a27","externalIds":{"DBLP":"conf/siggrapha/ArarGACCSB23","ArXiv":"2307.06925","DOI":"10.1145/3610548.3618173","CorpusId":259847716},"title":"Domain-Agnostic Tuning-Encoder for Fast Personalization of Text-To-Image Models"},{"paperId":"40719b9f384077bc077ccb8a37b214074672049d","externalIds":{"ArXiv":"2307.05977","DBLP":"journals/corr/abs-2307-05977","DOI":"10.48550/arXiv.2307.05977","CorpusId":259837117},"title":"Towards Safe Self-Distillation of Internet-Scale Text-to-Image Diffusion Models"},{"paperId":"c1caa303549764d220ff17dc1785985dd1ba6047","externalIds":{"DBLP":"journals/corr/abs-2307-04725","ArXiv":"2307.04725","DOI":"10.48550/arXiv.2307.04725","CorpusId":259501509},"title":"AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning"},{"paperId":"92a12f130113563b5f8319091d1c7e1afb428551","externalIds":{"DBLP":"journals/corr/abs-2307-04028","ArXiv":"2307.04028","DOI":"10.48550/arXiv.2307.04028","CorpusId":259501495},"title":"Measuring the Success of Diffusion Models at Imitating Human Artists"},{"paperId":"2cfaa5b3571d3b75f040f6d639359a3c673f5561","externalIds":{"DBLP":"journals/corr/abs-2307-02421","ArXiv":"2307.02421","DOI":"10.48550/arXiv.2307.02421","CorpusId":259342813},"title":"DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models"},{"paperId":"d7890d1906d95c4ae4c430b350455156d6d8aed9","externalIds":{"DBLP":"conf/iclr/PodellELBDMPR24","ArXiv":"2307.01952","CorpusId":259341735},"title":"SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"},{"paperId":"b227166ca6ce3daab43217847f5b1d8c9a06c050","externalIds":{"DBLP":"journals/corr/abs-2307-01148","ArXiv":"2307.01148","DOI":"10.48550/arXiv.2307.01148","CorpusId":259316983},"title":"Investigating Data Memorization in 3D Latent Diffusion Models for Medical Image Synthesis"},{"paperId":"03a281a176413ed4d140293edc5bf04a3ad7a1f1","externalIds":{"DBLP":"conf/cvpr/ShiXLPYZTB24","ArXiv":"2306.14435","DOI":"10.1109/CVPR52733.2024.00844","CorpusId":259252555},"title":"DragDiffusion: Harnessing Diffusion Models for Interactive Point-Based Image Editing"},{"paperId":"04a880d1f01e773e3f739d27d388f6100874933a","externalIds":{"DBLP":"journals/corr/abs-2306-12983","ArXiv":"2306.12983","DOI":"10.1109/WACV57701.2024.00479","CorpusId":259224343},"title":"Towards More Realistic Membership Inference Attacks on Large Diffusion Models"},{"paperId":"24680e194359ebd0a117302244a0a4c7721739fe","externalIds":{"DBLP":"journals/corr/abs-2307-15067","ArXiv":"2307.15067","DOI":"10.48550/arXiv.2307.15067","CorpusId":260316115},"title":"Set-Membership Inference Attacks using Data Watermarking"},{"paperId":"b4aa95a9088613c1613011ebf158cc24b39597aa","externalIds":{"ArXiv":"2306.09345","DBLP":"journals/corr/abs-2306-09345","DOI":"10.1109/ICCV51070.2023.00661","CorpusId":259171757},"title":"Evaluating Data Attribution for Text-to-Image Models"},{"paperId":"c108f86e614082c6d58245c86b3410e4680c0689","externalIds":{"ArXiv":"2306.07754","DBLP":"journals/corr/abs-2306-07754","DOI":"10.48550/arXiv.2306.07754","CorpusId":259144790},"title":"Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis"},{"paperId":"510aa735e65939f49ed490e314687450fa4dfcf5","externalIds":{"ArXiv":"2306.07440","DBLP":"journals/corr/abs-2306-07440","DOI":"10.1109/IUS51837.2023.10306544","CorpusId":259144787},"title":"Deep Ultrasound Denoising Using Diffusion Probabilistic Models"},{"paperId":"223cdf1198a045c049f2359ad9d1db77e8028e80","externalIds":{"ArXiv":"2306.04141","DBLP":"journals/corr/abs-2306-04141","DOI":"10.1126/science.adh4451","CorpusId":259095707,"PubMed":"37319193"},"title":"Art and the science of generative AI"},{"paperId":"57c61a12a9a152ca3641785234dc1477844e39b8","externalIds":{"PubMedCentral":"10904731","DBLP":"journals/corr/abs-2306-02986","ArXiv":"2306.02986","DOI":"10.1038/s41597-024-03073-x","CorpusId":259075590,"PubMed":"38424097"},"title":"Brain tumor segmentation using synthetic MR images - A comparison of GANs and diffusion models"},{"paperId":"d887c04d66b6fa0a526cd049d89a66b4d53246e6","externalIds":{"ArXiv":"2306.01902","DBLP":"journals/corr/abs-2306-01902","DOI":"10.48550/arXiv.2306.01902","CorpusId":259075262},"title":"Unlearnable Examples for Diffusion Models: Protect Data from Unauthorized Exploitation"},{"paperId":"4b4c1a930261d3890317ac50244c8332c3412301","externalIds":{"DBLP":"journals/corr/abs-2306-01272","ArXiv":"2306.01272","DOI":"10.48550/arXiv.2306.01272","CorpusId":259064265},"title":"DeepfakeArt Challenge: A Benchmark Dataset for Generative AI Art Forgery and Data Poisoning Detection"},{"paperId":"e8753374e402cd756dcfec9bc74a34f8a5047f80","externalIds":{"ArXiv":"2306.00973","DBLP":"journals/corr/abs-2306-00973","DOI":"10.1109/CVPR52733.2024.00592","CorpusId":258999141},"title":"Intelligent Grimm - Open-ended Visual Storytelling via Latent Diffusion Models"},{"paperId":"5766b1300ce9a386706ee308d83fbe82500553d6","externalIds":{"DBLP":"journals/corr/abs-2306-00419","ArXiv":"2306.00419","DOI":"10.48550/arXiv.2306.00419","CorpusId":258999304},"title":"Challenges and Remedies to Privacy and Security in AIGC: Exploring the Potential of Privacy Computing, Blockchain, and Beyond"},{"paperId":"ec4398c262169eb7c8bcec0ad9916dd898a9a5d1","externalIds":{"DBLP":"conf/nips/SomepalliSGGG23","ArXiv":"2305.20086","DOI":"10.48550/arXiv.2305.20086","CorpusId":258987384},"title":"Understanding and Mitigating Copying in Diffusion Models"},{"paperId":"c7e4efe1d20e9a1598a45c8cc6acb75656d900de","externalIds":{"DBLP":"journals/corr/abs-2306-00080","ArXiv":"2306.00080","DOI":"10.48550/arXiv.2306.00080","CorpusId":258999627},"title":"AI Imagery and the Overton Window"},{"paperId":"fdc04fe7c4a3fb4038d1bbd5f4e2fdf2599566e3","externalIds":{"DBLP":"journals/corr/abs-2305-19256","ArXiv":"2305.19256","DOI":"10.48550/arXiv.2305.19256","CorpusId":258967610},"title":"Ambient Diffusion: Learning Clean Distributions from Corrupted Data"},{"paperId":"ecb0cb2fceb713d8d760baf979fc9f3190f965db","externalIds":{"DBLP":"journals/corr/abs-2305-18355","ArXiv":"2305.18355","DOI":"10.48550/arXiv.2305.18355","CorpusId":258967241},"title":"An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization"},{"paperId":"9a6ea2211c53bedb2e4035e981bd08254222381c","externalIds":{"DBLP":"journals/sigkdd/CuiRXHLSXT24","ArXiv":"2306.04642","DOI":"10.1145/3715073.3715079","CorpusId":259108818},"title":"DiffusionShield: A Watermark for Data Copyright Protection against Generative Diffusion Models"},{"paperId":"57053dd68e22e326e24969d4253c74ba1fc19820","externalIds":{"ArXiv":"2305.15759","DBLP":"journals/corr/abs-2305-15759","DOI":"10.48550/arXiv.2305.15759","CorpusId":258887668},"title":"Differentially Private Latent Diffusion Models"},{"paperId":"0fbf7ea1a3bd1754ed9aa12ed25906b731ece589","externalIds":{"ACL":"2023.trustnlp-1.23","ArXiv":"2305.16157","DBLP":"journals/corr/abs-2305-16157","DOI":"10.48550/arXiv.2305.16157","CorpusId":258888114},"title":"Training Data Extraction From Pre-trained Language Models: A Survey"},{"paperId":"a502c1d4ef8c0113812a5236cad12ba9f22cc91d","externalIds":{"DBLP":"conf/forc/Elkin-KorenHLM24","ArXiv":"2305.14822","DOI":"10.48550/arXiv.2305.14822","CorpusId":258865475},"title":"Can Copyright be Reduced to Privacy?"},{"paperId":"a2c67ff763de7170264cc245afebee158b7ed775","externalIds":{"ArXiv":"2305.14712","DBLP":"journals/corr/abs-2305-14712","DOI":"10.48550/arXiv.2305.14712","CorpusId":258866094},"title":"On the Generalization of Diffusion Model"},{"paperId":"5bfa8bd2645a87093684bb9538b38455bee2d596","externalIds":{"DBLP":"journals/tog/AlalufRMC23","ArXiv":"2305.15391","DOI":"10.1145/3618322","CorpusId":258866047},"title":"A Neural Space-Time Representation for Text-to-Image Personalization"},{"paperId":"c9e548d72f5ad72215025602be36f72042219baf","externalIds":{"DBLP":"conf/ccs/QuSH0Z023","ArXiv":"2305.13873","DOI":"10.1145/3576915.3616679","CorpusId":258841623},"title":"Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models"},{"paperId":"e665e77f3996c3f3f71a421965db5927c6706c95","externalIds":{"ArXiv":"2305.13501","DBLP":"conf/mm/MorelliBCC0C23","DOI":"10.1145/3581783.3612137","CorpusId":258840871},"title":"LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On"},{"paperId":"1e3ebdc3d92fbbb7c9a3dfed07468501cef30269","externalIds":{"DBLP":"journals/corr/abs-2305-12683","ArXiv":"2305.12683","DOI":"10.48550/arXiv.2305.12683","CorpusId":258833412},"title":"Mist: Towards Improved Adversarial Examples for Diffusion Models"},{"paperId":"f80c152ebfc0ad39d68f0160dadb1e215e8679d1","externalIds":{"ArXiv":"2305.12015","CorpusId":258833473},"title":"Inventing art styles with no artistic training data"},{"paperId":"4e75ae56dc134abb076c3c6513d4d80751393df1","externalIds":{"ArXiv":"2305.10120","DBLP":"conf/nips/HengS23","DOI":"10.48550/arXiv.2305.10120","CorpusId":258740988},"title":"Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models"},{"paperId":"0966305117f8ea021d702ee904cf43a3b8922171","externalIds":{"DBLP":"journals/corr/abs-2305-08694","ArXiv":"2305.08694","DOI":"10.48550/arXiv.2305.08694","CorpusId":258685782},"title":"A Reproducible Extraction of Training Images from Diffusion Models"},{"paperId":"1915fe29827b429af2cc7f0452550faa3d24de03","externalIds":{"ArXiv":"2305.07644","DBLP":"journals/mlst/AkbarWE25","DOI":"10.1088/2632-2153/ad9a3a","CorpusId":264439363},"title":"Beware of diffusion models for synthesizing medical imagesâ€”a comparison with GANs in terms of memorizing brain MRI and chest x-ray images"},{"paperId":"94831cbd104369092b08f3711e6ac95c5f5f2c7b","externalIds":{"DBLP":"journals/corr/abs-2305-06402","ArXiv":"2305.06402","DOI":"10.1109/IJCB57857.2023.10449200","CorpusId":258615767},"title":"Analyzing Bias in Diffusion-based Face Generation Models"},{"paperId":"5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891","externalIds":{"DBLP":"journals/corr/abs-2304-07193","ArXiv":"2304.07193","DOI":"10.48550/arXiv.2304.07193","CorpusId":258170077},"title":"DINOv2: Learning Robust Visual Features without Supervision"},{"paperId":"940da2b97449e3aaa138570cebb7064a53210b11","externalIds":{"ArXiv":"2304.06720","DBLP":"journals/corr/abs-2304-06720","DOI":"10.1109/ICCV51070.2023.00694","CorpusId":258108187},"title":"Expressive Text-to-Image Generation with Rich Text"},{"paperId":"9733025aea2ba71792be10c18d635e8fc1455e31","externalIds":{"DBLP":"journals/corr/abs-2304-03411","ArXiv":"2304.03411","DOI":"10.1109/CVPR52733.2024.00816","CorpusId":258041269},"title":"InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning"},{"paperId":"6c925427841ea4a776a578d438f9e47a64c3014e","externalIds":{"ArXiv":"2304.02051","DBLP":"journals/corr/abs-2304-02051","DOI":"10.1109/ICCV51070.2023.02138","CorpusId":257952394},"title":"Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing"},{"paperId":"1775333ad759bc827b8fde72c93ccbaca821c1e7","externalIds":{"PubMedCentral":"10160739","DOI":"10.1088/1361-6560/acca5c","CorpusId":257954358,"PubMed":"37015231"},"title":"2D medical image synthesis using transformer-based denoising diffusion probabilistic model"},{"paperId":"83b8e18488d8f31dd017ec0b26531cef4b635b36","externalIds":{"DBLP":"conf/nips/ChenHLRJCC23","ArXiv":"2304.00186","DOI":"10.48550/arXiv.2304.00186","CorpusId":257913352},"title":"Subject-driven Text-to-Image Generation via Apprenticeship Learning"},{"paperId":"d9b95937934d7291b7c253b28b6c9aaee033c91d","externalIds":{"DBLP":"journals/corr/abs-2303-17591","ArXiv":"2303.17591","DOI":"10.1109/CVPRW63382.2024.00182","CorpusId":257833863},"title":"Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models"},{"paperId":"7b18bdf21b74b7d97bace715f78d05bd447ee30f","externalIds":{"DBLP":"conf/aies/NaikN23","ArXiv":"2304.06034","DOI":"10.1145/3600211.3604711","CorpusId":258108384},"title":"Social Biases through the Text-to-Image Generation Lens"},{"paperId":"98e6e0b3b811193e89b1a033da6c0a454220877a","externalIds":{"ArXiv":"2303.15715","DBLP":"journals/corr/abs-2303-15715","DOI":"10.48550/arXiv.2303.15715","CorpusId":257771630},"title":"Foundation Models and Fair Use"},{"paperId":"d544dd9a6ba9ea5f2c1217bc554cf7fded732fbf","externalIds":{"DBLP":"conf/iccv/LePNDT023","ArXiv":"2303.15433","DOI":"10.1109/ICCV51070.2023.00202","CorpusId":257766375},"title":"Anti-DreamBooth: Protecting users from personalized text-to-image synthesis"},{"paperId":"62b368417eca18fe68d209e5a077392748450a29","externalIds":{"DBLP":"journals/corr/abs-2303-13516","ArXiv":"2303.13516","DOI":"10.1109/ICCV51070.2023.02074","CorpusId":257687839},"title":"Ablating Concepts in Text-to-Image Diffusion Models"},{"paperId":"923a03032014a12c4e8b26511c0394e1b915fe74","externalIds":{"DBLP":"conf/iccv/KhachatryanMTHW23","ArXiv":"2303.13439","DOI":"10.1109/ICCV51070.2023.01462","CorpusId":257687280},"title":"Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators"},{"paperId":"9116c50561007cd69cc24a60c7593a5425f57fcc","externalIds":{"DBLP":"conf/nips/LuccioniAMJ23","ArXiv":"2303.11408","CorpusId":257636849},"title":"Stable Bias: Evaluating Societal Representations in Diffusion Models"},{"paperId":"9ff9ea4a504874a04b674002f090a650a1efe9a0","externalIds":{"DBLP":"journals/corr/abs-2303-12733","ArXiv":"2303.12733","DOI":"10.48550/arXiv.2303.12733","CorpusId":257663363},"title":"On the De-duplication of LAION-2B"},{"paperId":"14ccb8bcceb6de10eda6ad08bec242a4f2946497","externalIds":{"DBLP":"conf/iccv/QiCZLWSC23","ArXiv":"2303.09535","DOI":"10.1109/ICCV51070.2023.01460","CorpusId":257557738},"title":"FateZero: Fusing Attentions for Zero-shot Text-based Video Editing"},{"paperId":"638b08154fbb71fd34db2aae6cb40045577fe0de","externalIds":{"DBLP":"journals/corr/abs-2303-09540","ArXiv":"2303.09540","DOI":"10.48550/arXiv.2303.09540","CorpusId":257557221},"title":"SemDeDup: Data-efficient learning at web-scale through semantic deduplication"},{"paperId":"29f791191ef3c6fcabe33f776484a243fa10ab24","externalIds":{"DBLP":"conf/cvpr/InoueKSOY23","ArXiv":"2303.08137","DOI":"10.1109/CVPR52729.2023.00980","CorpusId":257505427},"title":"LayoutDM: Discrete Diffusion Model for Controllable Layout Generation"},{"paperId":"35ccd924de9e8483bdcf144cbf2edf09be157b7e","externalIds":{"ArXiv":"2303.07909","DBLP":"journals/corr/abs-2303-07909","DOI":"10.48550/arXiv.2303.07909","CorpusId":257505012},"title":"Text-to-image Diffusion Models in Generative AI: A Survey"},{"paperId":"7a106b9e32a40b523e80ef1ef262f39213aeed81","externalIds":{"DBLP":"conf/iccv/GandikotaMFB23","ArXiv":"2303.07345","DOI":"10.1109/ICCV51070.2023.00230","CorpusId":257495777},"title":"Erasing Concepts from Diffusion Models"},{"paperId":"dac1541f9052ec74637cf8556d9fd7da05f8cf7c","externalIds":{"ArXiv":"2303.01325","DBLP":"journals/corr/abs-2303-01325","DOI":"10.48550/arXiv.2303.01325","CorpusId":257280234},"title":"A Pathway Towards Responsible AI Generated Content"},{"paperId":"35df2a7d78a8b7057d40d73bbb9a61f4643f92c4","externalIds":{"ArXiv":"2302.12228","DBLP":"journals/tog/GalAABCC23","DOI":"10.1145/3592133","CorpusId":257364757},"title":"Encoder-based Domain Tuning for Fast Personalization of Text-to-Image Models"},{"paperId":"36e21d8093361027088c1977ebaa2acf105c2b28","externalIds":{"DBLP":"conf/icml/VyasKB23","ArXiv":"2302.10870","CorpusId":257050406},"title":"On Provable Copyright Protection for Generative Models"},{"paperId":"5fe1146088392539a30218a7a67c5512f78f3826","externalIds":{"DBLP":"journals/corr/abs-2302-06826","ArXiv":"2302.06826","DOI":"10.1109/TMM.2023.3318297","CorpusId":256846452},"title":"DiffFashion: Reference-Based Fashion Design With Structure-Aware Transfer by Diffusion Models"},{"paperId":"435640467611474172ccf702d631bc652f6cd7a8","externalIds":{"DBLP":"journals/corr/abs-2302-04578","ArXiv":"2302.04578","DOI":"10.48550/arXiv.2302.04578","CorpusId":256697414},"title":"Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples"},{"paperId":"897c0aedead3105b7b6cd1afbb6aeb4f62a06e11","externalIds":{"DBLP":"conf/uss/ShanCW0HZ23","ArXiv":"2302.04222","DOI":"10.48550/arXiv.2302.04222","CorpusId":256662278},"title":"GLAZE: Protecting Artists from Style Mimicry by Text-to-Image Models"},{"paperId":"55707013ab7912450a4632d13e8b919a58cb1077","externalIds":{"DBLP":"conf/eaamo/ZhangJTY24","ArXiv":"2302.03675","DOI":"10.1145/3689904.3694710","CorpusId":256627441},"title":"Auditing Gender Presentation Differences in Text-to-Image Models"},{"paperId":"0c26bfc15a7caecce0ed4567dc2f2909b80e5bdd","externalIds":{"ArXiv":"2302.03668","DBLP":"journals/corr/abs-2302-03668","DOI":"10.48550/arXiv.2302.03668","CorpusId":256627601},"title":"Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery"},{"paperId":"495086152953cb3ef08a83a399230141cb31b0a3","externalIds":{"DBLP":"conf/sp/MatsumotoMY23","ArXiv":"2302.03262","DOI":"10.1109/SPW59333.2023.00013","CorpusId":256627812},"title":"Membership Inference Attacks against Diffusion Models"},{"paperId":"0949978a51943a8547632b273496375616a9931b","externalIds":{"ArXiv":"2302.03018","DBLP":"conf/iclr/XiangYSSC23","DOI":"10.48550/arXiv.2302.03018","CorpusId":256615188},"title":"DDM2: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models"},{"paperId":"daf61010eee0fbf6f9bab7db71c395ffca6f3ff3","externalIds":{"ArXiv":"2302.03027","DBLP":"conf/siggraph/ParmarS0LLZ23","DOI":"10.1145/3588432.3591513","CorpusId":256616002},"title":"Zero-shot Image-to-Image Translation"},{"paperId":"38c14931cf5dc7781b4f24af15e8938dfb898317","externalIds":{"DBLP":"conf/icml/DuanK0SX23","ArXiv":"2302.01316","DOI":"10.48550/arXiv.2302.01316","CorpusId":256503774},"title":"Are Diffusion Models Vulnerable to Membership Inference Attacks?"},{"paperId":"5f996fd3592478b6923590ed5347d6206357e95a","externalIds":{"DOI":"10.1038/d41586-023-00340-6","CorpusId":256618795,"PubMed":"36747115"},"title":"What ChatGPT and generative AI mean for science"},{"paperId":"c3c7464acb90049c5f520b0732dc7435ba3690bd","externalIds":{"DBLP":"journals/tog/CheferAVWC23","ArXiv":"2301.13826","DOI":"10.1145/3592116","CorpusId":256416326},"title":"Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models"},{"paperId":"2e965b5d97c2d6fb4af284307735be39283792ba","externalIds":{"ArXiv":"2301.13188","DBLP":"conf/uss/CarliniHNJSTBIW23","DOI":"10.48550/arXiv.2301.13188","CorpusId":256389993},"title":"Extracting Training Data from Diffusion Models"},{"paperId":"646ec133173ac3aa1a602935d2ea7eb2ec87f19d","externalIds":{"DBLP":"journals/corr/abs-2301-08330","ArXiv":"2301.08330","DOI":"10.48550/arXiv.2301.08330","CorpusId":256080486,"PubMed":"37769551"},"title":"The role of noise in denoising models for anomaly detection in medical images"},{"paperId":"994a1ce6677b496bd3c0c63aceafc6556005e994","externalIds":{"DBLP":"conf/cvpr/LiLWMYGLL23","ArXiv":"2301.07093","DOI":"10.1109/CVPR52729.2023.02156","CorpusId":255942528},"title":"GLIGEN: Open-Set Grounded Text-to-Image Generation"},{"paperId":"98ae411778f53138070441ec8f98377bca1e8670","externalIds":{"DBLP":"journals/corr/abs-2301-10227","PubMedCentral":"10906858","ArXiv":"2301.10227","DOI":"10.48550/arXiv.2301.10227","CorpusId":256194252,"PubMed":"38377165"},"title":"Denoising diffusion probabilistic models for generation of realistic fully-annotated microscopy image datasets"},{"paperId":"736973165f98105fec3729b7db414ae4d80fcbeb","externalIds":{"DBLP":"journals/corr/abs-2212-09748","ArXiv":"2212.09748","DOI":"10.1109/ICCV51070.2023.00387","CorpusId":254854389},"title":"Scalable Diffusion Models with Transformers"},{"paperId":"4a899f4f65ea022f949d9506b659d095f64c17fc","externalIds":{"DBLP":"conf/miccai/PengABPZP23","ArXiv":"2212.08034","DOI":"10.1007/978-3-031-43993-3_2","CorpusId":254685633,"PubMed":"38169668"},"title":"Generating Realistic Brain MRIs via a Conditional Diffusion Probabilistic Model"},{"paperId":"25de00096c45121a06668bc501f91adec5d0aff9","externalIds":{"ArXiv":"2212.05032","DBLP":"conf/iclr/FengHFJANBWW23","DOI":"10.48550/arXiv.2212.05032","CorpusId":254535649},"title":"Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis"},{"paperId":"144eca44e250cc462f6fc3a172abb865978f66f5","externalIds":{"DBLP":"conf/cvpr/KumariZ0SZ23","ArXiv":"2212.04488","DOI":"10.1109/CVPR52729.2023.00192","CorpusId":254408780},"title":"Multi-Concept Customization of Text-to-Image Diffusion"},{"paperId":"c287fac6c4c3f913e0e91a196e979ce251e0c624","externalIds":{"DBLP":"journals/corr/abs-2212-03860","ArXiv":"2212.03860","DOI":"10.1109/CVPR52729.2023.00586","CorpusId":254366634},"title":"Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models"},{"paperId":"444d7286e421839aeb7731127bbaedd29d8b401b","externalIds":{"ArXiv":"2211.13319","DBLP":"conf/cvpr/RahmanLRTMS23","DOI":"10.1109/CVPR52729.2023.00246","CorpusId":254017562},"title":"Make-A-Story: Visual Memory Conditioned Consistent Story Generation"},{"paperId":"831c240d7725b8e4ba3e4039f16a693253fab2ab","externalIds":{"DBLP":"conf/cvpr/ZhangHTHMDX23","ArXiv":"2211.13203","DOI":"10.1109/CVPR52729.2023.00978","CorpusId":257427673},"title":"Inversion-based Style Transfer with Diffusion Models"},{"paperId":"4f1502111d35aa6651dfaedfeb1184b3c3dd2fcb","externalIds":{"DBLP":"journals/corr/abs-2211-13227","ArXiv":"2211.13227","DOI":"10.1109/CVPR52729.2023.01763","CorpusId":253802085},"title":"Paint by Example: Exemplar-based Image Editing with Diffusion Models"},{"paperId":"c1ddae8106deaeb15120a6a0f04111a63f4e2a7c","externalIds":{"ArXiv":"2211.11743","DBLP":"journals/corr/abs-2211-11743","DOI":"10.48550/arXiv.2211.11743","CorpusId":253734983},"title":"SinFusion: Training Diffusion Models on a Single Image or Video"},{"paperId":"4cc5266166478592ec8539a2b940740b8d380cdd","externalIds":{"DBLP":"conf/cvpr/Zeng0ZLCK023","ArXiv":"2211.11742","DOI":"10.1109/CVPR52729.2023.02152","CorpusId":253734941},"title":"SceneComposer: Any-Level Semantic Image Synthesis"},{"paperId":"a2d2bbe4c542173662a444b33b76c66992697830","externalIds":{"DBLP":"conf/cvpr/BrooksHE23","ArXiv":"2211.09800","DOI":"10.1109/CVPR52729.2023.01764","CorpusId":253581213},"title":"InstructPix2Pix: Learning to Follow Image Editing Instructions"},{"paperId":"b57b8b6b8052bf2e7f6fe5c8e91cdcb385b75ab6","externalIds":{"DBLP":"journals/mia/KazerouniAHAFHM23","ArXiv":"2211.07804","DOI":"10.1016/j.media.2023.102846","CorpusId":253523207,"PubMed":"37295311"},"title":"Diffusion models in medical imaging: A comprehensive survey"},{"paperId":"0231f2aed9a96cb516242fb57f2cb63f5651c4d8","externalIds":{"DBLP":"journals/corr/abs-2211-05105","ArXiv":"2211.05105","DOI":"10.1109/CVPR52729.2023.02157","CorpusId":253420366},"title":"Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models"},{"paperId":"51aafc680ccf6ba7d879e31fce49c55fd299f760","externalIds":{"DBLP":"journals/corr/abs-2211-00902","ArXiv":"2211.00902","DOI":"10.48550/arXiv.2211.00902","CorpusId":253255062},"title":"Spot the fake lungs: Generating Synthetic Medical Images using Neural Diffusion Models"},{"paperId":"ee9c6f9f9702553f404856287e1388a2916d5383","externalIds":{"DBLP":"journals/corr/abs-2210-15257","ArXiv":"2210.15257","DOI":"10.1109/CVPR52729.2023.00977","CorpusId":253157690},"title":"ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts"},{"paperId":"9dea2c15a044a3c83d0d66b9c3daa91d457d905f","externalIds":{"DBLP":"journals/tmlr/DockhornCVK23","ArXiv":"2210.09929","DOI":"10.48550/arXiv.2210.09929","CorpusId":252968205},"title":"Differentially Private Diffusion Models"},{"paperId":"e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9","externalIds":{"DBLP":"conf/nips/SchuhmannBVGWCC22","ArXiv":"2210.08402","DOI":"10.48550/arXiv.2210.08402","CorpusId":252917726},"title":"LAION-5B: An open large-scale dataset for training next generation image-text models"},{"paperId":"0eca1993fd78649aa94c49a73277546aeeb76e21","externalIds":{"ArXiv":"2210.00939","DBLP":"journals/corr/abs-2210-00939","DOI":"10.1109/ICCV51070.2023.00686","CorpusId":252683688},"title":"Improving Sample Quality of Diffusion Models Using Self-Attention Guidance"},{"paperId":"166804591abf73b79d9f8e8153299a1a2fa2a1f8","externalIds":{"DBLP":"journals/corr/abs-2210-00968","ArXiv":"2210.00968","DOI":"10.48550/arXiv.2210.00968","CorpusId":252683365},"title":"Membership Inference Attacks Against Text-to-image Generation Models"},{"paperId":"1300e9287ae63473b05f8808883ca83b02943dbf","externalIds":{"ArXiv":"2210.04610","DBLP":"journals/corr/abs-2210-04610","DOI":"10.48550/arXiv.2210.04610","CorpusId":252780252},"title":"Red-Teaming the Stable Diffusion Safety Filter"},{"paperId":"4494d7639ab0377c33433acee687887c002ecd52","externalIds":{"ArXiv":"2209.08891","DBLP":"journals/jair/StruppekHFBSK23","DOI":"10.1613/jair.1.15388","CorpusId":256827140},"title":"Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis"},{"paperId":"fd2c67344891dfa1b76631bf11da51b1d97e22fb","externalIds":{"ArXiv":"2209.07667","DBLP":"journals/corr/abs-2209-07667","DOI":"10.48550/arXiv.2209.07667","CorpusId":252355133},"title":"Can There be Art Without an Artist?"},{"paperId":"e924a5cc4739f18fb225b7a8b506099042567ffa","externalIds":{"DBLP":"journals/corr/abs-2209-07162","ArXiv":"2209.07162","DOI":"10.48550/arXiv.2209.07162","CorpusId":252280355},"title":"Brain Imaging Generation with Latent Diffusion Models"},{"paperId":"efa1647594b236361610a20d507127f0586a379b","externalIds":{"DBLP":"journals/corr/abs-2209-04747","ArXiv":"2209.04747","DOI":"10.1109/TPAMI.2023.3261988","CorpusId":252199918,"PubMed":"37030794"},"title":"Diffusion Models in Vision: A Survey"},{"paperId":"35a29c47d5292e8967e5a9a8a21b23d8637b7d07","externalIds":{"DBLP":"journals/tkde/CaoTGXCHL24","ArXiv":"2209.02646","DOI":"10.1109/TKDE.2024.3361474","CorpusId":265039918},"title":"A Survey on Generative Diffusion Models"},{"paperId":"e342165a614588878ad0f4bc9bacf3905df34d08","externalIds":{"DBLP":"journals/corr/abs-2209-00796","ArXiv":"2209.00796","DOI":"10.1145/3626235","CorpusId":252070859},"title":"Diffusion Models: A Comprehensive Survey of Methods and Applications"},{"paperId":"5b19bf6c3f4b25cac96362c98b930cf4b37f6744","externalIds":{"ArXiv":"2208.12242","DBLP":"conf/cvpr/RuizLJPRA23","DOI":"10.1109/CVPR52729.2023.02155","CorpusId":251800180},"title":"DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation"},{"paperId":"5406129d9d7d00dc310671c43597101b0ee93629","externalIds":{"ArXiv":"2208.01618","DBLP":"journals/corr/abs-2208-01618","DOI":"10.48550/arXiv.2208.01618","CorpusId":251253049},"title":"An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion"},{"paperId":"04e541391e8dce14d099d00fb2c21dbbd8afe87f","externalIds":{"DBLP":"journals/corr/abs-2208-01626","ArXiv":"2208.01626","DOI":"10.48550/arXiv.2208.01626","CorpusId":251252882},"title":"Prompt-to-Prompt Image Editing with Cross Attention Control"},{"paperId":"6c46b7b401be5ada79f00b36cb8e5b41286ae2aa","externalIds":{"DBLP":"conf/iclr/Jagielski0TILCW23","ArXiv":"2207.00099","DOI":"10.48550/arXiv.2207.00099","CorpusId":250243645},"title":"Measuring Forgetting of Memorized Training Examples"},{"paperId":"ef669bb2d0a3e957a91c1dde85ce01c6984ad7d6","externalIds":{"DBLP":"journals/tog/AvrahamiFL23","ArXiv":"2206.02779","DOI":"10.1145/3592450","CorpusId":249394540},"title":"Blended Latent Diffusion"},{"paperId":"9695824d7a01fad57ba9c01d7d76a519d78d65e7","externalIds":{"DBLP":"journals/corr/abs-2205-11487","ArXiv":"2205.11487","DOI":"10.48550/arXiv.2205.11487","CorpusId":248986576},"title":"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"},{"paperId":"c57293882b2561e1ba03017902df9fc2f289dea2","externalIds":{"ArXiv":"2204.06125","DBLP":"journals/corr/abs-2204-06125","DOI":"10.48550/arXiv.2204.06125","CorpusId":248097655},"title":"Hierarchical Text-Conditional Image Generation with CLIP Latents"},{"paperId":"c0e8812789e96f5a7aa3ad940dba1c237aec822d","externalIds":{"ArXiv":"2204.02491","DBLP":"journals/corr/abs-2204-02491","DOI":"10.1007/978-3-031-19784-0_41","CorpusId":247996703},"title":"Text2LIVE: Text-Driven Layered Image and Video Editing"},{"paperId":"dc21d8ee24038e99ddfd0fe88b263e0eabc54337","externalIds":{"DBLP":"journals/corr/abs-2203-04306","ArXiv":"2203.04306","DOI":"10.48550/arXiv.2203.04306","CorpusId":247318844},"title":"Diffusion Models for Medical Anomaly Detection"},{"paperId":"cfebfd27c0dfb53c3596a313db5890487b96a7fd","externalIds":{"DBLP":"conf/cvpr/PizziRRGD22","ArXiv":"2202.10261","DOI":"10.1109/CVPR52688.2022.01413","CorpusId":247011159},"title":"A Self-Supervised Descriptor for Image Copy Detection"},{"paperId":"a32fa13941f9c9beaa86000f8873e7c6422825e2","externalIds":{"DBLP":"journals/corr/abs-2201-11760","ArXiv":"2201.11760","DOI":"10.1117/12.2612235","CorpusId":246411397},"title":"Unsupervised denoising of retinal OCT with diffusion probabilistic model"},{"paperId":"a02a3e4e3f8c1f185954af9b401f7100a45075a2","externalIds":{"ArXiv":"2112.15283","DBLP":"journals/corr/abs-2112-15283","CorpusId":245634812},"title":"ERNIE-ViLG: Unified Generative Pre-training for Bidirectional Vision-Language Generation"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","externalIds":{"ArXiv":"2112.10752","DBLP":"journals/corr/abs-2112-10752","DOI":"10.1109/CVPR52688.2022.01042","CorpusId":245335280},"title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"bccda2f709927583022533b496ab4f800ba2304e","externalIds":{"DBLP":"journals/corr/abs-2112-04323","ArXiv":"2112.04323","CorpusId":244954456},"title":"Contrastive Learning with Large Memory Bank and Negative Embedding Subtraction for Accurate Copy Detection"},{"paperId":"88e8801e4daf404d3d40f1648ef29faeb8e6d58a","externalIds":{"ArXiv":"2111.14818","DBLP":"conf/cvpr/AvrahamiLF22","DOI":"10.1109/CVPR52688.2022.01767","CorpusId":244714366},"title":"Blended Diffusion for Text-driven Editing of Natural Images"},{"paperId":"3aec4cae46578eab16ab7169661a6e30b614ec55","externalIds":{"ArXiv":"2111.08004","DBLP":"journals/corr/abs-2111-08004","CorpusId":244129858},"title":"Bag of Tricks and A Strong baseline for Image Copy Detection"},{"paperId":"5b517c2aa19b5c6d4b155876b5c737c2af7a28ab","externalIds":{"DBLP":"journals/corr/abs-2111-07090","ArXiv":"2111.07090","CorpusId":244117418},"title":"D^2LV: A Data-Driven and Local-Verification Approach for Image Copy Detection"},{"paperId":"f671a09e3e5922e6d38cb77dda8d76d5ceac2a27","externalIds":{"DBLP":"conf/iclr/MengHSSWZE22","ArXiv":"2108.01073","CorpusId":245704504},"title":"SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations"},{"paperId":"ad4a0938c48e61b7827869e4ac3baffd0aefab35","externalIds":{"ArXiv":"2104.14294","DBLP":"journals/corr/abs-2104-14294","DOI":"10.1109/ICCV48922.2021.00951","CorpusId":233444273},"title":"Emerging Properties in Self-Supervised Vision Transformers"},{"paperId":"bc7e6165b00f0c39d40ca2c7a4eb33fcc0e3200d","externalIds":{"DBLP":"journals/pami/SahariaHCSFN23","ArXiv":"2104.07636","DOI":"10.1109/TPAMI.2022.3204461","CorpusId":233241040,"PubMed":"36094974"},"title":"Image Super-Resolution via Iterative Refinement"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"2cd605106b88c85d7d8b865b1ef0f8c8293debf1","externalIds":{"ArXiv":"2102.12092","DBLP":"conf/icml/RameshPGGVRCS21","MAG":"3170016573","CorpusId":232035663},"title":"Zero-Shot Text-to-Image Generation"},{"paperId":"633e2fbfc0b21e959a244100937c5853afca4853","externalIds":{"DBLP":"journals/corr/abs-2011-13456","ArXiv":"2011.13456","MAG":"3110257065","CorpusId":227209335},"title":"Score-Based Generative Modeling through Stochastic Differential Equations"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"ArXiv":"2010.11929","MAG":"3119786062","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"5c126ae3421f05768d8edd97ecd44b1364e2c99a","externalIds":{"DBLP":"conf/nips/HoJA20","MAG":"3100572490","ArXiv":"2006.11239","CorpusId":219955663},"title":"Denoising Diffusion Probabilistic Models"},{"paperId":"37f7b0261170f60d3b5c33da660d7a6889037cfc","externalIds":{"DOI":"10.1093/oso/9780198826491.001.0001","CorpusId":169098226},"title":"The EU General Data Protection Regulation (GDPR)"},{"paperId":"8e58dc63817a2a26e5a2ddad38d8b1d19d1c3795","externalIds":{"ArXiv":"1912.03817","DBLP":"journals/corr/abs-1912-03817","DOI":"10.1109/SP40001.2021.00019","CorpusId":208909851},"title":"Machine Unlearning"},{"paperId":"965359b3008ab50dd04e171551220ec0e7f83aba","externalIds":{"MAG":"2971034910","ArXiv":"1907.05600","DBLP":"conf/nips/SongE19","CorpusId":196470871},"title":"Generative Modeling by Estimating Gradients of the Data Distribution"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"6364fdaa0a0eccd823a779fcdd489173f938e91a","externalIds":{"MAG":"1901129140","DBLP":"journals/corr/RonnebergerFB15","ArXiv":"1505.04597","DOI":"10.1007/978-3-319-24574-4_28","CorpusId":3719281},"title":"U-Net: Convolutional Networks for Biomedical Image Segmentation"},{"paperId":"2dcef55a07f8607a819c21fe84131ea269cc2e3c","externalIds":{"MAG":"2129069237","DBLP":"journals/corr/Sohl-DicksteinW15","ArXiv":"1503.03585","CorpusId":14888175},"title":"Deep Unsupervised Learning using Nonequilibrium Thermodynamics"},{"paperId":"6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4","externalIds":{"MAG":"1834627138","ArXiv":"1411.7766","DBLP":"journals/corr/LiuLWT14","DOI":"10.1109/ICCV.2015.425","CorpusId":459456},"title":"Deep Learning Face Attributes in the Wild"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","externalIds":{"DBLP":"conf/cvpr/DengDSLL009","MAG":"2108598243","DOI":"10.1109/CVPR.2009.5206848","CorpusId":57246310},"title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"02b28f3b71138a06e40dbd614abf8568420ae183","externalIds":{"DBLP":"conf/icvgip/NilsbackZ08","MAG":"2533598788","DOI":"10.1109/ICVGIP.2008.47","CorpusId":15193013},"title":"Automated Flower Classification over a Large Number of Classes"},{"paperId":"85983d70db7bef99103c3833793f503c18445546","externalIds":{"MAG":"2610955953","DBLP":"conf/icalp/Dwork06","DOI":"10.1007/11787006_1","CorpusId":2565493},"title":"Differential Privacy"},{"paperId":"3c2a1dad88a4d280d0d4348181d5c40afaa3fc47","externalIds":{"DOI":"10.1177/016059768100500308","CorpusId":220319053},"title":"â€œModelâ€"},{"paperId":"d0422f16489ca06a9b50d37a6c9e3c17718b1ec8","externalIds":{"DOI":"10.5694/j.1326-5377.1926.tb39133.x","CorpusId":219992492},"title":"DICHOTOMY"},{"paperId":"626d97e16cd923d237256bf5ecbb495323eb6703","externalIds":{"DOI":"10.1111/j.1651-2227.1977.tb15057.x","CorpusId":203911161},"title":"COMPOSITION"},{"paperId":"99c2ba6717264cfd998cac2f9735fda90538a556","externalIds":{"DBLP":"journals/ijimai/BartlettC24","DOI":"10.9781/ijimai.2024.02.006","CorpusId":268164961},"title":"Generative Artificial Intelligence in Product Design Education: Navigating Concerns of Originality and Ethics"},{"paperId":"735553000aab84eefc040360916fe51a362ab1cc","externalIds":{"DBLP":"conf/uss/WangWWLYQ24","CorpusId":271325362},"title":"Property Existence Inference against Generative Models"},{"paperId":"23ddaa93f7471bca5f7e4b51af211918a11e3447","externalIds":{"DBLP":"journals/corr/abs-2402-11846","DOI":"10.48550/arXiv.2402.11846","CorpusId":267751349},"title":"UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning for Diffusion Models"},{"paperId":"9b93dd409df3fcf3d9d0690317da35f37b1b7c72","externalIds":{"DBLP":"journals/corr/abs-2403-06069","DOI":"10.48550/arXiv.2403.06069","CorpusId":268358253},"title":"Implicit Image-to-Image Schrodinger Bridge for CT Super-Resolution and Denoising"},{"paperId":"e0c7374f06a1cfe5c1b38436e1785954782f6c75","externalIds":{"DBLP":"conf/bildmed/DarAKPSE24","DOI":"10.1007/978-3-658-44037-4_27","CorpusId":267940802},"title":"Effect of Training Epoch Number on Patient Data Memorization in Unconditional Latent Diffusion Models"},{"paperId":"2bbc4f7cbc106c41976de54a913def4b36ffa581","externalIds":{"DBLP":"journals/corr/abs-2403-12326","DOI":"10.48550/arXiv.2403.12326","CorpusId":268532295},"title":"Removing Undesirable Concepts in Text-to-Image Generative Models with Learnable Prompts"},{"paperId":"3126535bfe78cd7d93fa897ca2925bbb0ff5dbfb","externalIds":{"DBLP":"journals/corr/abs-2402-01054","DOI":"10.48550/arXiv.2402.01054","CorpusId":267406812},"title":"Unconditional Latent Diffusion Models Memorize Patient Imaging Data"},{"paperId":"222763d7652e38b3628d2a63a74daf5f308ed36b","externalIds":{"DBLP":"conf/icml/ZhangZLGWS024","DOI":"10.48550/arXiv.2310.05264","CorpusId":272202125},"title":"The Emergence of Reproducibility and Consistency in Diffusion Models"},{"paperId":"bdaaed32039464995f5da97caf8f63e01e7fbfdf","externalIds":{"DBLP":"conf/miccai/FernandezSPJTC23","DOI":"10.1007/978-3-031-53767-7_1","CorpusId":268241009},"title":"Privacy Distillation: Reducing Re-identification Risk of Diffusion Models"},{"paperId":"90428f3a8caa5082f825ebf3138514ddf273dae3","externalIds":{"CorpusId":253581838},"title":"Supplementary Materials for: NULL-text Inversion for Editing Real Images using Guided Diffusion Models"},{"paperId":"01ae50e7dfea38e133160cf154e0d6634c9c1ab1","externalIds":{"DBLP":"conf/isw/HuP23","DOI":"10.1007/978-3-031-49187-0_7","CorpusId":266126263},"title":"Loss and Likelihood Based Membership Inference of Diffusion Models"},{"paperId":"6af902c7b5fb3e604c84ce7385abd1186f7ac3db","externalIds":{"DOI":"10.2139/ssrn.4438593","CorpusId":258515384},"title":"Copyright Safety for Generative AI"},{"paperId":"daa474faf231ed6b67b41cfdcdaa145eac4828fa","externalIds":{"DOI":"10.2139/ssrn.4483539","CorpusId":259255995},"title":"Generative AI Art: Copyright Infringement and Fair Use"},{"paperId":"368224c8f18e2c383fc65c48b762c881a2d719ca","externalIds":{"CorpusId":263313784},"title":"data of"},{"paperId":"527359b4da39364da70187619f2cbb862068afce","externalIds":{"CorpusId":261971578},"title":"Generative Artificial Intelligence and Copyright Law"},{"paperId":"eb4b7c9c9e2126813fadb1ca4df3d89a0ec48153","externalIds":{"DOI":"10.25236/ajhss.2023.060601","CorpusId":258684279},"title":"Analyzing Copyright Infringement by Artificial Intelligence: The Case of the Diffusion Model"},{"paperId":"93a35e557ce41a0642165496e9df5046f38796aa","externalIds":{"DBLP":"journals/corr/abs-2307-16680","DOI":"10.48550/arXiv.2307.16680","CorpusId":260333997},"title":"On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey"},{"paperId":"42c8c76d08ffbb64dc41a690fe9ff50f16dbe31a","externalIds":{"DOI":"10.2139/ssrn.4602033","CorpusId":265174601},"title":"Identifying Race and Gender Bias in Latent Diffusion AI Image Generation"},{"paperId":"34652f60e182e712913cb95600ef18f86a07a7f2","externalIds":{"DOI":"10.2139/ssrn.4517702","CorpusId":260234034},"title":"How Generative Ai Turns Copyright Law on its Head"},{"paperId":"1b82e94afb73af4b452f00170db25b70d6f423f5","externalIds":{"DBLP":"conf/nips/DongGWWZL23","CorpusId":268042077},"title":"Towards Test-Time Refusals via Concept Negation"},{"paperId":"757de10dd72ff25810e98d56a4733b77fd31c066","externalIds":{"DBLP":"journals/corr/abs-2302-04440","DOI":"10.48550/arXiv.2302.04440","CorpusId":256697309},"title":"Feature Likelihood Score: Evaluating Generalization of Generative Models Using Samples"},{"paperId":"315507c96a818b28543ec422ec03aefadae8bdea","externalIds":{"DBLP":"journals/corr/abs-2311-13127","DOI":"10.48550/arXiv.2311.13127","CorpusId":271431301},"title":"Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis"},{"paperId":"c38d7f05cf71b9e98f959f4d727069143fbf8f02","externalIds":{"DOI":"10.2139/ssrn.4580739","CorpusId":265673048},"title":"AI and Law: The Next Generation"},{"paperId":"4a3e55cec6b0c422503bacad262a8fc6bce7c9ac","externalIds":{"DBLP":"journals/corr/abs-2307-04684","DOI":"10.48550/arXiv.2307.04684","CorpusId":274024181},"title":"FreeDrag: Point Tracking is Not What You Need for Interactive Point-based Image Editing"},{"paperId":"ef4f5a50837a7c1b3e87b9300ffc7ba00d461a0f","externalIds":{"CorpusId":211146177},"title":"AUTO-ENCODING VARIATIONAL BAYES"},{"paperId":"8430b3f9cb681c4a81d4465773391f43b4cc6391","externalIds":{"DOI":"10.5040/9781350088771.ch-004","CorpusId":68788162},"title":"Conducting Research"},{"paperId":"c68796f833a7151f0a63d1d1608dc902b4fdc9b6","externalIds":{"CorpusId":10319744},"title":"GENERATIVE ADVERSARIAL NETS"},{"paperId":"c51807126b600a40705b0e48e75e993190b927b4","externalIds":{"DOI":"10.7551/mitpress/9609.003.0036","CorpusId":11017788},"title":"mutual information"},{"paperId":"623593cf567cdf494fdecafdd9b575b04a9819d2","externalIds":{"MAG":"910441819","CorpusId":190629529},"title":"Legal guide for the visual artist"},{"paperId":"cfee1826dd4743eab44c6e27a0cc5970effa4d80","externalIds":{"CorpusId":264403242},"title":"Improving Image Generation with Better Captions"},{"paperId":"82253f0ff30342eba416e7debe2e74e7801a572b","externalIds":{"CorpusId":271912514},"title":"Understanding the Influence of Artificial Intelligence Art on Transaction in the Art World"}]}