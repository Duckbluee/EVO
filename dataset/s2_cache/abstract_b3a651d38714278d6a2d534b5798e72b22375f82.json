{"abstract":"Deep learning for procedural level generation has been explored in many recent works, however, experimental comparisons with previous works are rare and usually limited to the work they extend upon. The goal of this article is to conduct an experimental study on four recent deep learning procedural level generators for Sokoban to explore their strengths and weaknesses. The methods will be bootstrapping conditional generative models, controllable and uncontrollable procedural content generation via reinforcement learning (PCGRL), and generative playing networks. We will propose some modifications to either adapt the methods to the task or improve their performance. For the bootstrapping method, we propose using diversity sampling to improve the solution diversity, training with auxiliary targets to enhance the modelsâ€™ quality and sampling conditions from Gaussian mixture models (GMMs) to improve the sample quality. The results show that the generated solutions are more diverse by at least 16% when diversity sampling is used during training. It also shows that training with auxiliary targets and sampling conditions from GMMs can be used to increase the playability percentage. In our experiments, PCGRL shows superior quality and diversity, while the bootstrapped long-short term memory generators exhibit the least control confusion."}