{"paperId":"eacb66ac30b489f704dedae7abc6e98429f95c88","externalIds":{"DBLP":"journals/corr/abs-2311-11796","ArXiv":"2311.11796","DOI":"10.48550/arXiv.2311.11796","CorpusId":265828538},"title":"Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI Systems","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2311.11796, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2152584697","name":"Guangjing Wang"},{"authorId":"2187669795","name":"Ce Zhou"},{"authorId":"2239197334","name":"Yuanda Wang"},{"authorId":"2152689250","name":"Bocheng Chen"},{"authorId":"7014630","name":"Hanqing Guo"},{"authorId":"2239197902","name":"Qiben Yan"}],"abstract":"As Artificial Intelligence (AI) systems increasingly underpin critical applications, from autonomous vehicles to biometric authentication, their vulnerability to transferable attacks presents a growing concern. These attacks, designed to generalize across instances, domains, models, tasks, modalities, or even hardware platforms, pose severe risks to security, privacy, and system integrity. This survey delivers the first comprehensive review of transferable attacks across seven major categories, including evasion, backdoor, data poisoning, model stealing, model inversion, membership inference, and side-channel attacks. We introduce a unified six-dimensional taxonomy: cross-instance, cross-domain, cross-modality, cross-model, cross-task, and cross-hardware, which systematically captures the diverse transfer pathways of adversarial strategies. Through this framework, we examine both the underlying mechanics and practical implications of transferable attacks on AI systems. Furthermore, we review cutting-edge methods for enhancing attack transferability, organized around data augmentation and optimization strategies. By consolidating fragmented research and identifying critical future directions, this work provides a foundational roadmap for understanding, evaluating, and defending against transferable threats in real-world AI systems."}