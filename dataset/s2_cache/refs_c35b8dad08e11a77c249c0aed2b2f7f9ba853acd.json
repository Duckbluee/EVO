{"references":[{"paperId":"769a6941b3e8728ba99c9de1a8f9b768e27a76db","externalIds":{"DOI":"10.1145/3771095","CorpusId":281923038},"title":"PokéLLMon: A Grounding and Reasoning Benchmark for Large Language Models in Pokémon Battles"},{"paperId":"e2fd1d0a4daabf799d6426cf76b3ba5552e23f47","externalIds":{"DBLP":"journals/corr/abs-2507-08616","ArXiv":"2507.08616","DOI":"10.48550/arXiv.2507.08616","CorpusId":280298162},"title":"AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs"},{"paperId":"6c5f3dd82ee674d929a8eb4b256ca2045e02ae60","externalIds":{"ArXiv":"2506.15841","DBLP":"journals/corr/abs-2506-15841","DOI":"10.48550/arXiv.2506.15841","CorpusId":279465470},"title":"MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents"},{"paperId":"461d8c01e6cc8ab11930adb44215768de8502d1a","externalIds":{"ArXiv":"2506.08292","DBLP":"conf/icml/YiZCNL025","DOI":"10.48550/arXiv.2506.08292","CorpusId":279260557},"title":"From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium"},{"paperId":"7b8f769f55357a782804dcd64a4deadb91ba1dfd","externalIds":{"ArXiv":"2506.03610","DBLP":"journals/corr/abs-2506-03610","DOI":"10.48550/arXiv.2506.03610","CorpusId":279155428},"title":"Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games"},{"paperId":"c34cee11069f9181e83b8dfc3023b2fb6bac0811","externalIds":{"DBLP":"journals/corr/abs-2505-19481","ArXiv":"2505.19481","DOI":"10.48550/arXiv.2505.19481","CorpusId":278904558},"title":"Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs"},{"paperId":"51b733cc81f0ec5cfbd8d4e6ea901dcf7b27b8d9","externalIds":{"ArXiv":"2505.15146","DBLP":"journals/corr/abs-2505-15146","DOI":"10.48550/arXiv.2505.15146","CorpusId":278782258},"title":"lmgame-Bench: How Good are LLMs at Playing Games?"},{"paperId":"a752537e3970d4be7335c4aa2e90b5dd8ab9fb92","externalIds":{"DBLP":"journals/corr/abs-2504-07425","ArXiv":"2504.07425","DOI":"10.48550/arXiv.2504.07425","CorpusId":277667415},"title":"Enhancing Player Enjoyment with a Two-Tier DRL and LLM-Based Agent System for Fighting Games"},{"paperId":"d1958a7fc89303cad736884bd52c7d1dfd4469b5","externalIds":{"ArXiv":"2504.02441","DBLP":"journals/corr/abs-2504-02441","DOI":"10.48550/arXiv.2504.02441","CorpusId":277510128},"title":"Cognitive Memory in Large Language Models"},{"paperId":"5db8a5f40f4da1de0aeae6d0d065203f1a0d02c4","externalIds":{"DBLP":"conf/emnlp/ZhangCBYWZ25","ArXiv":"2502.13723","DOI":"10.48550/arXiv.2502.13723","CorpusId":276450266},"title":"Direct Value Optimization: Improving Chain-of-Thought Reasoning in LLMs with Refined Values"},{"paperId":"1f35a15fe9df43d24ec6ea551ec6c9766c17eccf","externalIds":{"ArXiv":"2502.12110","DBLP":"journals/corr/abs-2502-12110","DOI":"10.48550/arXiv.2502.12110","CorpusId":276421617},"title":"A-MEM: Agentic Memory for LLM Agents"},{"paperId":"2eed1fad9bbf887d4395de40f20144c4fafefd7f","externalIds":{"PubMedCentral":"12443585","DBLP":"journals/nature/GuoYZSWZXZMBZY025","ArXiv":"2501.12948","DOI":"10.1038/s41586-025-09422-z","CorpusId":275789950,"PubMed":"40962978"},"title":"DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning"},{"paperId":"e1aade9d6dd726cc15cecaf66c7d594e4cd4314c","externalIds":{"DBLP":"journals/corr/abs-2412-05255","ArXiv":"2412.05255","DOI":"10.48550/arXiv.2412.05255","CorpusId":274581634},"title":"TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft"},{"paperId":"9e576b3d5afd79791ead4d2a2a8bf5640b2de513","externalIds":{"DBLP":"journals/corr/abs-2412-01981","ArXiv":"2412.01981","DOI":"10.48550/arXiv.2412.01981","CorpusId":274445748},"title":"Free Process Rewards without Process Labels"},{"paperId":"46494476c0463a371cf6faa0aed8d61a9944764d","externalIds":{"ArXiv":"2411.00114","DBLP":"journals/corr/abs-2411-00114","DOI":"10.48550/arXiv.2411.00114","CorpusId":273798155},"title":"Project Sid: Many-agent simulations toward AI civilization"},{"paperId":"86aea18148fa67c6fd0eecdc0ee68137fe16a75d","externalIds":{"DBLP":"journals/corr/abs-2410-14052","ArXiv":"2410.14052","DOI":"10.48550/arXiv.2410.14052","CorpusId":273482193},"title":"From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs"},{"paperId":"344a289365081eafd66afb3c2757f736a087e7a6","externalIds":{"DBLP":"conf/nips/TangLLZZZ24","ArXiv":"2410.08126","DOI":"10.48550/arXiv.2410.08126","CorpusId":273233208},"title":"Mars: Situated Inductive Reasoning in an Open-World Environment"},{"paperId":"b9289af1bcbc9dbba438ca400f97719dad5eb317","externalIds":{"ArXiv":"2409.12889","DBLP":"journals/corr/abs-2409-12889","DOI":"10.48550/arXiv.2409.12889","CorpusId":272753397},"title":"Can VLMs Play Action Role-Playing Games? Take Black Myth Wukong as a Study Case"},{"paperId":"1d67e374db528795faee1aa0b9a09fda1b4fd576","externalIds":{"ArXiv":"2409.02387","DBLP":"journals/corr/abs-2409-02387","DOI":"10.48550/arXiv.2409.02387","CorpusId":272397970},"title":"Large Language Models and Cognitive Science: A Comprehensive Review of Similarities, Differences, and Challenges"},{"paperId":"13ee82805c6169c5b8f58a7bae1ad96bc2031c9a","externalIds":{"ArXiv":"2408.15950","CorpusId":271974920},"title":"Atari-GPT: Benchmarking Multimodal Large Language Models as Low-Level Policies in Atari Games"},{"paperId":"a7fb4245b412f0e54ec26d5973f041d52c83c0ad","externalIds":{"DBLP":"conf/acl/HuCC0S025","ArXiv":"2408.09559","DOI":"10.48550/arXiv.2408.09559","CorpusId":271903203},"title":"HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model"},{"paperId":"ea750468ca11428fc8515ac3b2227e5d297f2fb6","externalIds":{"DBLP":"conf/ijcai/0001LZCFZZS25","ArXiv":"2407.15325","DOI":"10.24963/ijcai.2025/22","CorpusId":271329319},"title":"Odyssey : Empowering Minecraft Agents with Open-World Skills"},{"paperId":"e2687f80077e8466918e4aeb2ea52e591bfe7e81","externalIds":{"ArXiv":"2407.04363","DBLP":"conf/ijcai/AnokhinSSEK0B25","DOI":"10.48550/arXiv.2407.04363","CorpusId":271039035},"title":"AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents"},{"paperId":"d5932d9927df0bc8aad0df8687966bb11d279bb5","externalIds":{"ArXiv":"2406.14373","DBLP":"journals/corr/abs-2406-14373","DOI":"10.48550/arXiv.2406.14373","CorpusId":270620538},"title":"Artificial Leviathan: Exploring Social Evolution of LLM Agents Through the Lens of Hobbesian Social Contract Theory"},{"paperId":"d269ad2a38bcbfc533303ce0f9be2537ba7b71c2","externalIds":{"DBLP":"journals/corr/abs-2406-14283","ArXiv":"2406.14283","DOI":"10.48550/arXiv.2406.14283","CorpusId":270620269},"title":"Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning"},{"paperId":"dbfb49de5ae1b351991d6c55e8179ff4640ed60e","externalIds":{"DBLP":"conf/emnlp/LiHGBBLLQLOS024","ArXiv":"2406.14550","DOI":"10.48550/arXiv.2406.14550","CorpusId":270620354},"title":"GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models"},{"paperId":"394e14ae60bae4c41162056717d9e30a8168abaa","externalIds":{"DBLP":"journals/corr/abs-2406-11176","ACL":"2024.emnlp-main.93","ArXiv":"2406.11176","DOI":"10.48550/arXiv.2406.11176","CorpusId":270558898},"title":"Watch Every Step! LLM Agent Learning via Iterative Step-level Process Refinement"},{"paperId":"844ce36b30b50a3f611e4b670eeec60aae5b1878","externalIds":{"ArXiv":"2405.14205","DBLP":"journals/corr/abs-2405-14205","DOI":"10.48550/arXiv.2405.14205","CorpusId":269982252},"title":"Agent Planning with World Knowledge Model"},{"paperId":"f7749635a5fc0492ef4705bee963ffa887bb2865","externalIds":{"DBLP":"conf/nips/ZhaiBLPTZSXL0L24","ArXiv":"2405.10292","DOI":"10.48550/arXiv.2405.10292","CorpusId":269790773},"title":"Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning"},{"paperId":"c1799bf28d1ae93e1631be5b59196ee1e568f538","externalIds":{"DBLP":"journals/corr/abs-2404-16130","ArXiv":"2404.16130","CorpusId":269363075},"title":"From Local to Global: A Graph RAG Approach to Query-Focused Summarization"},{"paperId":"47c8f0d7232f52f1a48e933e32309dc35ad85f49","externalIds":{"DBLP":"journals/corr/abs-2404-11672","ArXiv":"2404.11672","DOI":"10.48550/arXiv.2404.11672","CorpusId":269214524},"title":"MemLLM: Finetuning LLMs to Use An Explicit Read-Write Memory"},{"paperId":"36daf0578aad5d3180d531cccbd32d65d62c8317","externalIds":{"DOI":"10.3390/app14073076","CorpusId":269020190},"title":"Extending Context Window in Large Language Models with Segmented Base Adjustment for Rotary Position Embeddings"},{"paperId":"edd8d7e47dd32ffcbb9707ca6fecacae9255f96f","externalIds":{"ArXiv":"2403.08282","DBLP":"journals/corr/abs-2403-08282","DOI":"10.48550/arXiv.2403.08282","CorpusId":268379102},"title":"Hierarchical Auto-Organizing System for Open-Ended Multi-Agent Navigation"},{"paperId":"6a1d85d1a73d2b80f8a61db62e9b64299eb2dd7e","externalIds":{"DBLP":"journals/corr/abs-2403-05468","ArXiv":"2403.05468","DOI":"10.1109/TG.2024.3497601","CorpusId":268297162},"title":"Will GPT-4 Run DOOM?"},{"paperId":"0bc72e0c31df7bd821b8becd8f43c77c27af5155","externalIds":{"ArXiv":"2403.02613","DBLP":"conf/cui/Sweetser24","DOI":"10.1145/3640794.3665582","CorpusId":268248196},"title":"Large Language Models and Video Games: A Preliminary Scoping Review"},{"paperId":"f95da5b7be2fac2381eb5dfe26dc7dc5bc2d9a90","externalIds":{"DBLP":"journals/corr/abs-2403-02502","ArXiv":"2403.02502","DOI":"10.48550/arXiv.2403.02502","CorpusId":268249221},"title":"Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents"},{"paperId":"fa8fa745f58d362925dd44f02750bab1b30a1189","externalIds":{"ArXiv":"2402.19299","DBLP":"journals/corr/abs-2402-19299","DOI":"10.48550/arXiv.2402.19299","CorpusId":268063625},"title":"RL-GPT: Integrating Reinforcement Learning and Code-as-policy"},{"paperId":"5a9ce2055a0f200fd53b7eeddf1c05f9e01ccf5a","externalIds":{"DBLP":"journals/corr/abs-2402-18659","ArXiv":"2402.18659","DOI":"10.1109/TG.2024.3461510","CorpusId":268063348},"title":"Large Language Models and Games: A Survey and Roadmap"},{"paperId":"789485978d69e248832df358ee0fb062012925b8","externalIds":{"ArXiv":"2402.17574","DBLP":"conf/acl/ZhangTWW0HTLZ024","DOI":"10.48550/arXiv.2402.17574","CorpusId":268032624},"title":"Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization"},{"paperId":"c9603ec967879c24973b5bd48861df2e5555932e","externalIds":{"ArXiv":"2402.13753","DBLP":"conf/icml/DingZZXSX0Y24","DOI":"10.48550/arXiv.2402.13753","CorpusId":267770308},"title":"LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens"},{"paperId":"fbf18a32422798077ccc4a5fba8cf88a7203d7b2","externalIds":{"DBLP":"journals/corr/abs-2402-14034","ArXiv":"2402.14034","DOI":"10.48550/arXiv.2402.14034","CorpusId":267782737},"title":"AgentScope: A Flexible yet Robust Multi-Agent Platform"},{"paperId":"20fae5b3b9f34a7f1f44983fd2a4c5381016f6d9","externalIds":{"ArXiv":"2402.13184","DBLP":"journals/corr/abs-2402-13184","DOI":"10.48550/arXiv.2402.13184","CorpusId":267760150},"title":"What if LLMs Have Different World Views: Simulating Alien Civilizations with LLM-based Agents"},{"paperId":"2f066a5d75aed8c35d5ab696e15d643827da01f3","externalIds":{"ArXiv":"2402.04578","DBLP":"journals/corr/abs-2402-04578","DOI":"10.48550/arXiv.2402.04578","CorpusId":267523322},"title":"S-Agents: Self-organizing Agents in Open-ended Environments"},{"paperId":"12c27a40fbcc9dfbf483185291e7c80114a2a9ae","externalIds":{"DBLP":"conf/icml/WangGCJLYYLLYSM24","ArXiv":"2402.04624","DOI":"10.48550/arXiv.2402.04624","CorpusId":267523037},"title":"MEMORYLLM: Towards Self-Updatable Large Language Models"},{"paperId":"35b142ea69598e6241f0011312128031df55895c","externalIds":{"ArXiv":"2402.03300","DBLP":"journals/corr/abs-2402-03300","DOI":"10.48550/arXiv.2402.03300","CorpusId":267412607},"title":"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models"},{"paperId":"b6b6e59f3bfdda9d4a4dfe56c46b30706fd18cf3","externalIds":{"DBLP":"journals/corr/abs-2402-02330","ArXiv":"2402.02330","DOI":"10.48550/arXiv.2402.02330","CorpusId":267413027},"title":"Enhance Reasoning for Large Language Models in the Game Werewolf"},{"paperId":"5cb8fc293567f4f2930712a3bf7dec97b4dd1776","externalIds":{"ArXiv":"2402.01118","DBLP":"journals/corr/abs-2402-01118","DOI":"10.48550/arXiv.2402.01118","CorpusId":267406392},"title":"PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language Models"},{"paperId":"0e0a513624426e017a125d0498235b8f32ce9aa5","externalIds":{"ArXiv":"2401.17749","DBLP":"journals/corr/abs-2401-17749","DOI":"10.48550/arXiv.2401.17749","CorpusId":267334921},"title":"SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models"},{"paperId":"1d40f07569482d24e3335ffb31394d4bf1567e6f","externalIds":{"DBLP":"conf/iclr/SarthiATKGM24","ArXiv":"2401.18059","DOI":"10.48550/arXiv.2401.18059","CorpusId":267334785},"title":"RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"},{"paperId":"94701d9c6cfc1aecc174ff62ccda939f790c1710","externalIds":{"DBLP":"conf/icml/Stengel-EskinPB24","ArXiv":"2401.16467","DOI":"10.48550/arXiv.2401.16467","CorpusId":267320463},"title":"ReGAL: Refactoring Programs to Discover Generalizable Abstractions"},{"paperId":"28cbd1f2a472ba9a0330c97e7e6820b29883a69e","externalIds":{"ArXiv":"2401.14151","DBLP":"journals/corr/abs-2401-14151","DOI":"10.48550/arXiv.2401.14151","CorpusId":267212097},"title":"True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning"},{"paperId":"0e3c90f70019f7c736e3abd762c652e3e2561fec","externalIds":{"DBLP":"journals/corr/abs-2401-10568","ArXiv":"2401.10568","DOI":"10.48550/arXiv.2401.10568","CorpusId":267061073},"title":"CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"},{"paperId":"7ca300c16abbd38382dec5b7ea6809fee570be54","externalIds":{"DBLP":"journals/corr/abs-2401-08967","ArXiv":"2401.08967","DOI":"10.48550/arXiv.2401.08967","CorpusId":267027728},"title":"ReFT: Reasoning with Reinforced Fine-Tuning"},{"paperId":"deb7c1867cc5ec4ab51f67f84b7ffb8fc949ddf4","externalIds":{"ArXiv":"2401.06781","DBLP":"journals/corr/abs-2401-06781","DOI":"10.48550/arXiv.2401.06781","CorpusId":266999783},"title":"PokerGPT: An End-to-End Lightweight Solver for Multi-Player Texas Hold'em via Large Language Model"},{"paperId":"6b2cbaf69bd372c90aba9781721d79893f4a2fc4","externalIds":{"DBLP":"journals/corr/abs-2401-01275","ArXiv":"2401.01275","DOI":"10.48550/arXiv.2401.01275","CorpusId":266725287},"title":"CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation"},{"paperId":"29d02b653ea90f3f0b8793aefcca0c0b39882946","externalIds":{"ArXiv":"2312.17515","DBLP":"journals/corr/abs-2312-17515","DOI":"10.48550/arXiv.2312.17515","CorpusId":266690878},"title":"Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game"},{"paperId":"51adf629996e7b515e250720858d1cf660bc7adb","externalIds":{"DBLP":"conf/atal/LiuYG0LWW24","ArXiv":"2312.15224","DOI":"10.48550/arXiv.2312.15224","CorpusId":266551662},"title":"LLM-Powered Hierarchical Language Agent for Real-time Human-AI Coordination"},{"paperId":"592ac35991e583fc37c26ee6659d2deb85142ad9","externalIds":{"DBLP":"journals/corr/abs-2312-11970","ArXiv":"2312.11970","DOI":"10.1057/s41599-024-03611-3","CorpusId":266362356},"title":"Large language models empowered agent-based modeling and simulation: a survey and perspectives"},{"paperId":"9f22f66cacac8eebc5728cd0a28513b5e75a9a58","externalIds":{"DBLP":"journals/corr/abs-2312-11865","ArXiv":"2312.11865","DOI":"10.48550/arXiv.2312.11865","CorpusId":266362531},"title":"Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach"},{"paperId":"d17f666085018f19f6ab8253979d0d727af43f00","externalIds":{"DBLP":"conf/cvpr/Li0WZZQWLLD24","ArXiv":"2312.09238","DOI":"10.1109/CVPR52733.2024.01554","CorpusId":266210361},"title":"Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft"},{"paperId":"4ba57555bef02f988f2ed3bab2f102733dc55221","externalIds":{"ArXiv":"2312.08935","DBLP":"journals/corr/abs-2312-08935","DOI":"10.48550/arXiv.2312.08935","CorpusId":266209760},"title":"Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations"},{"paperId":"a8d81d868f408615255a253e8566ba05b9bc2ea6","externalIds":{"DBLP":"conf/uai/CaiZFYL25","ArXiv":"2312.02519","DOI":"10.48550/arXiv.2312.02519","CorpusId":265659447},"title":"Creative Agents: Empowering Agents with Imagination for Creative Tasks"},{"paperId":"c36b4aec0c26f1ff5b3cf7e86c0b90f51575ebea","externalIds":{"DBLP":"journals/corr/abs-2312-00746","ArXiv":"2312.00746","DOI":"10.48550/arXiv.2312.00746","CorpusId":265551867},"title":"Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games"},{"paperId":"9ad3edeea4732cb44a26f39652a668d1a562b0cf","externalIds":{"DBLP":"journals/corr/abs-2311-17227","ArXiv":"2311.17227","DOI":"10.48550/arXiv.2311.17227","CorpusId":265498466},"title":"War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars"},{"paperId":"cbecf91df39ac5837e4c8bb021fcc1292beb24de","externalIds":{"ArXiv":"2311.08590","ACL":"2024.naacl-long.336","DBLP":"conf/naacl/KimKB24","DOI":"10.18653/v1/2024.naacl-long.336","CorpusId":265212976},"title":"PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language Models"},{"paperId":"00e479efbe90aa839e70d515260554ee173146d6","externalIds":{"ArXiv":"2311.07687","DBLP":"journals/corr/abs-2311-07687","DOI":"10.48550/arXiv.2311.07687","CorpusId":265157947},"title":"Language Model-In-The-Loop: Data Optimal Approach to Learn-To-Recommend Actions in Text Games"},{"paperId":"fde266447d68b2728752a7835e8c97e1af316ac4","externalIds":{"DBLP":"journals/pami/WangCLJHZLHZYML25","ArXiv":"2311.05997","DOI":"10.1109/TPAMI.2024.3511593","CorpusId":265129059},"title":"JARVIS-1: Open-World Multi-Task Agents With Memory-Augmented Multimodal Language Models"},{"paperId":"0725b276e351bba6b2a52ecb64f3c964b9acc2f9","externalIds":{"DBLP":"conf/naacl/PrasadKHCSBK24","ArXiv":"2311.05772","DOI":"10.48550/arXiv.2311.05772","CorpusId":265128575},"title":"ADaPT: As-Needed Decomposition and Planning with Language Models"},{"paperId":"572f1d731009c90706f19938937cbae783af3bfc","externalIds":{"DBLP":"journals/corr/abs-2310-20499","ArXiv":"2310.20499","DOI":"10.48550/arXiv.2310.20499","CorpusId":264828822},"title":"Leveraging Word Guessing Games to Assess the Intelligence of Large Language Models"},{"paperId":"ac258100ebe178287ae4ae3dc7ac78f8c27e017d","externalIds":{"DBLP":"conf/icml/Xu000W24","ArXiv":"2310.18940","DOI":"10.48550/arXiv.2310.18940","CorpusId":264590387},"title":"Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game"},{"paperId":"4b530e7756a08af082c0ec2b242882b70873f753","externalIds":{"ArXiv":"2310.17976","DBLP":"conf/acl/WangXHYXGTFL0CL24","DOI":"10.18653/v1/2024.acl-long.102","CorpusId":264555532},"title":"InCharacter: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews"},{"paperId":"02a00ce9e7bce14937f46af0423eea40b7b63303","externalIds":{"ArXiv":"2310.13255","DBLP":"journals/corr/abs-2310-13255","DOI":"10.48550/arXiv.2310.13255","CorpusId":264405778},"title":"Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open Worlds"},{"paperId":"6ca16c1c2c60ceda87242c8f8e522d12cc4a13bc","externalIds":{"DBLP":"journals/corr/abs-2310-12931","ArXiv":"2310.12931","DOI":"10.48550/arXiv.2310.12931","CorpusId":264306288},"title":"Eureka: Human-Level Reward Design via Coding Large Language Models"},{"paperId":"46fe9ce789408b8a50fb4259e6bf0cc5855f4ed5","externalIds":{"ArXiv":"2310.12823","DBLP":"conf/acl/ZengLLWLD024","DOI":"10.48550/arXiv.2310.12823","CorpusId":264306101},"title":"AgentTuning: Enabling Generalized Agent Abilities for LLMs"},{"paperId":"6628f9ee35e36cdfdcac8a46cef4dba8d529a83b","externalIds":{"DBLP":"journals/corr/abs-2310-10158","ArXiv":"2310.10158","DOI":"10.48550/arXiv.2310.10158","CorpusId":264145862},"title":"Character-LLM: A Trainable Agent for Role-Playing"},{"paperId":"e17c58d7a48b6b811df023484161a3b9c03e0d6b","externalIds":{"DBLP":"journals/corr/abs-2310-10701","ArXiv":"2310.10701","DOI":"10.18653/v1/2023.emnlp-main.13","CorpusId":264172518},"title":"Theory of Mind for Multi-Agent Collaboration via Large Language Models"},{"paperId":"01a5d0ed2300ec86aa82d0e56222932f200ad692","externalIds":{"ArXiv":"2310.08922","DBLP":"journals/corr/abs-2310-08922","DOI":"10.48550/arXiv.2310.08922","CorpusId":264128263},"title":"LLaMA Rider: Spurring Large Language Models to Explore the Open World"},{"paperId":"b6c8c1745a18d6e59c7a8a99f0df7aa4c18a1e73","externalIds":{"ArXiv":"2310.08588","DBLP":"journals/corr/abs-2310-08588","DOI":"10.48550/arXiv.2310.08588","CorpusId":263909250},"title":"Octopus: Embodied Vision-Language Programmer from Environmental Feedback"},{"paperId":"680f2cf76602b9e90cb54fc661ff58beac3f0df4","externalIds":{"DBLP":"journals/pacmhci/LiSZ25","ArXiv":"2310.06500","DOI":"10.1145/3711032","CorpusId":263829557},"title":"MetaAgents: Large Language Model Based Agents for Decision-Making on Teaming"},{"paperId":"acae2561c319a5b3ecfdc3d188be238f22a24d69","externalIds":{"ArXiv":"2310.05418","DBLP":"conf/emnlp/WangCC23","DOI":"10.48550/arXiv.2310.05418","CorpusId":263830637},"title":"Humanoid Agents: Platform for Simulating Human-like Generative Agents"},{"paperId":"67daf8c4fe1958d20ebdf95c2a36dd490c73836f","externalIds":{"DBLP":"journals/corr/abs-2310-05915","ArXiv":"2310.05915","DOI":"10.48550/arXiv.2310.05915","CorpusId":263829338},"title":"FireAct: Toward Language Agent Fine-tuning"},{"paperId":"3720255c8c12d4a827d52d188c0571c68f5ed391","externalIds":{"ArXiv":"2310.05036","DBLP":"journals/corr/abs-2310-05036","DOI":"10.48550/arXiv.2310.05036","CorpusId":263828774},"title":"From Text to Tactic: Evaluating LLMs Playing the Game of Avalon"},{"paperId":"1266477120913d274346b044b4cc72ea893b1382","externalIds":{"DBLP":"journals/corr/abs-2310-05029","ArXiv":"2310.05029","DOI":"10.48550/arXiv.2310.05029","CorpusId":263831502},"title":"Walking Down the Memory Maze: Beyond Context Limit through Interactive Reading"},{"paperId":"7f0d1740e74ce36424d64d608270077b64dfe7c0","externalIds":{"DBLP":"conf/naacl/AgasheFRW25","ArXiv":"2310.03903","DOI":"10.18653/v1/2025.findings-naacl.448","CorpusId":263830046},"title":"LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models"},{"paperId":"a889b8f3b46f968c709088223ba79efd5bc831e0","externalIds":{"ArXiv":"2310.02172","DBLP":"journals/corr/abs-2310-02172","DOI":"10.48550/arXiv.2310.02172","CorpusId":263608891},"title":"Lyfe Agents: Generative agents for low-cost real-time social interactions"},{"paperId":"531b37c44c7e39539f617fb1a4149ef8cce8f4ec","externalIds":{"DBLP":"journals/corr/abs-2310-01732","ArXiv":"2310.01732","DOI":"10.48550/arXiv.2310.01732","CorpusId":260957214},"title":"Nugget: Neural Agglomerative Embeddings of Text"},{"paperId":"208a08e7df7ed5f951d1ffddf0e038bb1429aa9f","externalIds":{"ArXiv":"2310.01152","DBLP":"conf/tpsisa/HuHIT023","DOI":"10.1109/TPS-ISA58951.2023.00044","CorpusId":263605729},"title":"Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives"},{"paperId":"b783168c885ecbae0fccdb46ec8e9afd0ef99b7f","externalIds":{"ArXiv":"2310.01320","DBLP":"journals/corr/abs-2310-01320","DOI":"10.48550/arXiv.2310.01320","CorpusId":263605971},"title":"Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation"},{"paperId":"0ea1d396ce3804054c1919d7b78d3bcddaa761c0","externalIds":{"DBLP":"conf/acl/WangPQLZWGGN00024","ArXiv":"2310.00746","DOI":"10.48550/arXiv.2310.00746","CorpusId":263334495},"title":"RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models"},{"paperId":"c3e2bec83b9105b7925aa76c0f38b88d2e337b31","externalIds":{"DBLP":"journals/corr/abs-2310-00166","ArXiv":"2310.00166","DOI":"10.48550/arXiv.2310.00166","CorpusId":263334319},"title":"Motif: Intrinsic Motivation from Artificial Intelligence Feedback"},{"paperId":"c74e9642ec71c6dfaadd3b8638c110d4048ff53e","externalIds":{"DBLP":"journals/corr/abs-2309-17277","ArXiv":"2309.17277","DOI":"10.48550/arXiv.2309.17277","CorpusId":263310339},"title":"Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4"},{"paperId":"63549bf78e4b1e7e1cec505ce65e6e8f90474f41","externalIds":{"DBLP":"journals/corr/abs-2309-13007","ArXiv":"2309.13007","DOI":"10.48550/arXiv.2309.13007","CorpusId":262217323},"title":"ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs"},{"paperId":"21091f8133ab034baacb92fdb958e14989eb427f","externalIds":{"DBLP":"conf/iclr/DeletangRDCGMGW24","ArXiv":"2309.10668","DOI":"10.48550/arXiv.2309.10668","CorpusId":262054258},"title":"Language Modeling Is Compression"},{"paperId":"73290ecbec2f38d1d647ddef1ada69cee41725b3","externalIds":{"DBLP":"conf/iclr/Zhu00SWWL24","ArXiv":"2309.10400","DOI":"10.48550/arXiv.2309.10400","CorpusId":262053659},"title":"PoSE: Efficient Context Window Extension of LLMs via Positional Skip-wise Training"},{"paperId":"d7d712e507c1c6273b05c773c825a668c5cf1504","externalIds":{"DBLP":"conf/naacl/GongHMNDZTFGV24","ArXiv":"2309.09971","DOI":"10.48550/arXiv.2309.09971","CorpusId":261898118},"title":"MindAgent: Emergent Gaming Interaction"},{"paperId":"0c72450890a54b68d63baa99376131fda8f06cf9","externalIds":{"ArXiv":"2309.07864","DBLP":"journals/corr/abs-2309-07864","DOI":"10.48550/arXiv.2309.07864","CorpusId":261817592},"title":"The Rise and Potential of Large Language Model Based Agents: A Survey"},{"paperId":"5e2d50f7745d7d1cd92c1f8fb79ec03735605b08","externalIds":{"PubMedCentral":"11086867","ArXiv":"2309.05076","DBLP":"journals/corr/abs-2309-05076","DOI":"10.1371/journal.pone.0301033","CorpusId":261681777,"PubMed":"38728280"},"title":"An appraisal-based chain-of-emotion architecture for affective language model game agents"},{"paperId":"24d52678c887331b9da0368e8a2f58bec07f7203","externalIds":{"DBLP":"journals/corr/abs-2309-04658","ArXiv":"2309.04658","DOI":"10.48550/arXiv.2309.04658","CorpusId":261681932},"title":"Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf"},{"paperId":"e4bb1b1f97711a7634bf4bff72c56891be2222e6","externalIds":{"DBLP":"journals/corr/abs-2309-02427","ArXiv":"2309.02427","DOI":"10.48550/arXiv.2309.02427","CorpusId":261556862},"title":"Cognitive Architectures for Language Agents"},{"paperId":"819bbdc2dac9e13d9ca3e2508a6e063186ce5e40","externalIds":{"DBLP":"conf/iclr/PengQFS24","ArXiv":"2309.00071","DOI":"10.48550/arXiv.2309.00071","CorpusId":261493986},"title":"YaRN: Efficient Context Window Extension of Large Language Models"},{"paperId":"946e213164cccf15bc3f4ff776d81369dbae1b77","externalIds":{"DBLP":"journals/corr/abs-2308-12466","ArXiv":"2308.12466","DOI":"10.48550/arXiv.2308.12466","CorpusId":261101103},"title":"Are ChatGPT and GPT-4 Good Poker Players? - A Pre-Flop Analysis"},{"paperId":"28c6ac721f54544162865f41c5692e70d61bccab","externalIds":{"DBLP":"journals/fcsc/WangMFZYZCTCLZWW24","ArXiv":"2308.11432","DOI":"10.1007/s11704-024-40231-1","CorpusId":261064713},"title":"A survey on large language model based autonomous agents"},{"paperId":"9fbde8d0315f52e598c5b4a1409ed2aee215ace9","externalIds":{"DBLP":"conf/aaai/ZhangYHWLSZZLZC24","ArXiv":"2308.11339","DOI":"10.1609/aaai.v38i16.29710","CorpusId":261064959},"title":"ProAgent: Building Proactive Cooperative Agents with Large Language Models"},{"paperId":"5e4597eb21a393b23e473cf66cb5ae8b27cab03e","externalIds":{"DBLP":"conf/aaai/Zhao0XLLH24","ArXiv":"2308.10144","DOI":"10.48550/arXiv.2308.10144","CorpusId":261048772},"title":"ExpeL: LLM Agents Are Experiential Learners"},{"paperId":"6f28ca1e6c007c46cbc30aad531d800b8e6bc405","externalIds":{"DBLP":"journals/corr/abs-2308-10032","ArXiv":"2308.10032","DOI":"10.48550/arXiv.2308.10032","CorpusId":261048971},"title":"GameEval: Evaluating LLMs on Conversational Games"},{"paperId":"aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3","externalIds":{"DBLP":"conf/aaai/BestaBKGPGGLNNH24","ArXiv":"2308.09687","DOI":"10.1609/aaai.v38i16.29720","CorpusId":261030303},"title":"Graph of Thoughts: Solving Elaborate Problems with Large Language Models"},{"paperId":"d1a0179fc0e59c41f8098555510133264d0055dd","externalIds":{"ArXiv":"2308.09597","DBLP":"journals/corr/abs-2308-09597","DOI":"10.48550/arXiv.2308.09597","CorpusId":261031210},"title":"ChatHaruhi: Reviving Anime Character in Reality via Large Language Model"},{"paperId":"13c3a649797990c63408dbcee031569f43f35c2d","externalIds":{"ArXiv":"2308.07540","DBLP":"journals/corr/abs-2308-07540","DOI":"10.1609/aiide.v19i1.27534","CorpusId":260900406},"title":"CALYPSO: LLMs as Dungeon Masters' Assistants"},{"paperId":"cd73c6870a28d13f553356c61c877b6ee684b5b4","externalIds":{"ArXiv":"2308.04026","DBLP":"journals/corr/abs-2308-04026","DOI":"10.48550/arXiv.2308.04026","CorpusId":260704607},"title":"AgentSims: An Open-Source Sandbox for Large Language Model Evaluation"},{"paperId":"ebbffe5db352a10fde868843b8d5787b87843f09","externalIds":{"ArXiv":"2308.03656","DBLP":"journals/corr/abs-2308-03656","DOI":"10.48550/arXiv.2308.03656","CorpusId":260682960},"title":"Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench"},{"paperId":"91206346edbe28abb606d7b3425cd455d4019d4f","externalIds":{"DBLP":"journals/corr/abs-2308-01825","ArXiv":"2308.01825","DOI":"10.48550/arXiv.2308.01825","CorpusId":260438790},"title":"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models"},{"paperId":"e01ab53663e5df5961a021506a9cb09f4efc3788","externalIds":{"DBLP":"journals/corr/abs-2307-10169","ArXiv":"2307.10169","DOI":"10.48550/arXiv.2307.10169","CorpusId":259982665},"title":"Challenges and Applications of Large Language Models"},{"paperId":"60b0476a97c00e355df28ba35422764a7fbe88e8","externalIds":{"DBLP":"conf/iclr/00010WWCW24","ArXiv":"2307.06945","DOI":"10.48550/arXiv.2307.06945","CorpusId":259847425},"title":"In-context Autoencoder for Context Compression in a Large Language Model"},{"paperId":"888728745dbb769e29ed475d4f7661eebe1a71cf","externalIds":{"DBLP":"journals/tist/ChangWWWYZCYWWYZCYYX24","ArXiv":"2307.03109","DOI":"10.1145/3641289","CorpusId":259360395},"title":"A Survey on Evaluation of Large Language Models"},{"paperId":"587352c3b95c90de6d37f061c8e117f42be0b575","externalIds":{"DBLP":"journals/corr/abs-2307-02485","ArXiv":"2307.02485","DOI":"10.48550/arXiv.2307.02485","CorpusId":259342833},"title":"Building Cooperative Embodied Agents Modularly with Large Language Models"},{"paperId":"f5afaccfe90268485a9961c5771ec5e71e9b806c","externalIds":{"ArXiv":"2306.15595","DBLP":"journals/corr/abs-2306-15595","DOI":"10.48550/arXiv.2306.15595","CorpusId":259262376},"title":"Extending Context Window of Large Language Models via Positional Interpolation"},{"paperId":"b9a1189f2de7fd5e66551d7c425556e5642b823a","externalIds":{"DBLP":"journals/corr/abs-2306-09200","ArXiv":"2306.09200","DOI":"10.48550/arXiv.2306.09200","CorpusId":259165028},"title":"ChessGPT: Bridging Policy Learning and Language Modeling"},{"paperId":"80980cd10d19f021c14a6b7eee871b6a5d328024","externalIds":{"ArXiv":"2306.07174","DBLP":"conf/nips/Wang0CLYGW23","DOI":"10.48550/arXiv.2306.07174","CorpusId":259137816},"title":"Augmenting Language Models with Long-Term Memory"},{"paperId":"60e6e3767c36bf9e16b58b7221c5712b4d3d5293","externalIds":{"DBLP":"conf/nips/ZhangCZXZ023","ArXiv":"2306.07929","CorpusId":259145016},"title":"Large Language Models Are Semi-Parametric Reinforcement Learning Agents"},{"paperId":"45f1dbf9ccc10fd0a46268967582c835866d788d","externalIds":{"DBLP":"journals/corr/abs-2306-01711","ArXiv":"2306.01711","DOI":"10.48550/arXiv.2306.01711","CorpusId":259064135},"title":"OMNI: Open-endedness via Models of human Notions of Interestingness"},{"paperId":"be8db99310602d66bba64bcf41a572c45816fbfc","externalIds":{"ArXiv":"2305.20050","DBLP":"conf/iclr/LightmanKBEBLLS24","DOI":"10.48550/arXiv.2305.20050","CorpusId":258987659},"title":"Let's Verify Step by Step"},{"paperId":"0d1c76d45afa012ded7ab741194baf142117c495","externalIds":{"DBLP":"conf/nips/RafailovSMMEF23","ArXiv":"2305.18290","CorpusId":258959321},"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model"},{"paperId":"d671d62a1eb4d57343e4a0928297266dffc0c118","externalIds":{"DBLP":"conf/nips/LinFYBHBA0023","ArXiv":"2305.17390","DOI":"10.48550/arXiv.2305.17390","CorpusId":258960143},"title":"SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks"},{"paperId":"f197bf0fc2f228483f6af3285000d54d8d97f9eb","externalIds":{"ArXiv":"2305.16291","DBLP":"journals/tmlr/WangX0MXZFA24","DOI":"10.48550/arXiv.2305.16291","CorpusId":258887849},"title":"Voyager: An Open-Ended Embodied Agent with Large Language Models"},{"paperId":"c695c4e68561347564ea0daa50dc339dff73d8c5","externalIds":{"DBLP":"journals/corr/abs-2305-17144","ArXiv":"2305.17144","DOI":"10.48550/arXiv.2305.17144","CorpusId":258959262},"title":"Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory"},{"paperId":"2f7364d8e5cf94315bf8905f57de9c5543e9a4bf","externalIds":{"DBLP":"journals/corr/abs-2305-14788","ArXiv":"2305.14788","DOI":"10.48550/arXiv.2305.14788","CorpusId":258865249},"title":"Adapting Language Models to Compress Contexts"},{"paperId":"c7a3f9cc61cfafdc307f8ae24430b6b1121f9b2c","externalIds":{"DBLP":"journals/corr/abs-2305-11554","ArXiv":"2305.11554","DOI":"10.48550/arXiv.2305.11554","CorpusId":258823133},"title":"ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings"},{"paperId":"6f821d75968bc8de070af3ce5aa7f57bc031fafb","externalIds":{"DBLP":"conf/nips/XiangTGSWYH23","ArXiv":"2305.10626","DOI":"10.48550/arXiv.2305.10626","CorpusId":258762577},"title":"Language Models Meet World Models: Embodied Experiences Enhance Language Models"},{"paperId":"c3a59e1e405e7c28319e5a1c5b5241f9b340cf63","externalIds":{"DBLP":"journals/corr/abs-2305-10250","ArXiv":"2305.10250","DOI":"10.48550/arXiv.2305.10250","CorpusId":258741194},"title":"MemoryBank: Enhancing Large Language Models with Long-Term Memory"},{"paperId":"2f3822eb380b5e753a6d579f31dfc3ec4c4a0820","externalIds":{"ArXiv":"2305.10601","DBLP":"journals/corr/abs-2305-10601","DOI":"10.48550/arXiv.2305.10601","CorpusId":258762525},"title":"Tree of Thoughts: Deliberate Problem Solving with Large Language Models"},{"paperId":"237c4abc5922aa4cf5775fd88e22ff2e8c98809b","externalIds":{"DBLP":"conf/aaai/GongWW24","ArXiv":"2305.03731","DOI":"10.1609/aaai.v38i9.28868","CorpusId":259202964},"title":"Working Memory Capacity of ChatGPT: An Empirical Study"},{"paperId":"5f1774f1aca24046de5f6d9eef53dd354725149f","externalIds":{"DBLP":"journals/air/UludagliO23","DOI":"10.1007/s10462-023-10491-7","CorpusId":258425816},"title":"Non-player character decision-making in computer games"},{"paperId":"f711aae062ae30c0888910b2bdcc5be6c1d1c340","externalIds":{"DBLP":"conf/dasfaa/WangLYHWWML25","ArXiv":"2304.13343","DOI":"10.1007/978-981-95-4158-4_12","CorpusId":258331553},"title":"SCM: Enhancing Large Language Model with Self-Controlled Memory Framework"},{"paperId":"17170575aa8b4fa4e3eef5d366ada706a94dd836","externalIds":{"ArXiv":"2304.11406","DBLP":"conf/acl/SalemiMBZ24","DOI":"10.48550/arXiv.2304.11406","CorpusId":258298303},"title":"LaMP: When Large Language Models Meet Personalization"},{"paperId":"b9870e130f61ff900fe00dbcc5782c9b31773d32","externalIds":{"DBLP":"journals/corr/abs-2304-08467","ArXiv":"2304.08467","DOI":"10.48550/arXiv.2304.08467","CorpusId":258179012},"title":"Learning to Compress Prompts with Gist Tokens"},{"paperId":"5278a8eb2ba2429d4029745caf4e661080073c81","externalIds":{"DBLP":"conf/uist/ParkOCMLB23","ArXiv":"2304.03442","DOI":"10.1145/3586183.3606763","CorpusId":258040990},"title":"Generative Agents: Interactive Simulacra of Human Behavior"},{"paperId":"23678972c3423d12e738f8ab34dd0018d47fb151","externalIds":{"ArXiv":"2304.02868","DBLP":"journals/corr/abs-2304-02868","DOI":"10.48550/arXiv.2304.02868","CorpusId":257985065},"title":"Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"7bf72a3b5fbac8bc0f461780810fbc781c28ef53","externalIds":{"DBLP":"conf/nips/LiHIKG23","ArXiv":"2303.17760","CorpusId":268042527},"title":"CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society"},{"paperId":"3aaf6a2cbad5850ad81ab5c163599cb3d523436f","externalIds":{"DBLP":"journals/corr/abs-2303-17651","ArXiv":"2303.17651","DOI":"10.48550/arXiv.2303.17651","CorpusId":257900871},"title":"Self-Refine: Iterative Refinement with Self-Feedback"},{"paperId":"9a75e23639bfcc3a51da57a3b682a984d1d8ac0b","externalIds":{"ArXiv":"2303.17491","DBLP":"conf/nips/KimBM23","DOI":"10.48550/arXiv.2303.17491","CorpusId":257834038},"title":"Language Models can Solve Computer Tasks"},{"paperId":"ae783820a1487b964411cd0086324b89a3d64e0d","externalIds":{"ArXiv":"2303.16563","CorpusId":265609805},"title":"Skill Reinforcement Learning and Planning for Open-World Long-Horizon Tasks"},{"paperId":"0671fd553dd670a4e820553a974bc48040ba0819","externalIds":{"DBLP":"conf/nips/ShinnCGNY23","ArXiv":"2303.11366","CorpusId":258833055},"title":"Reflexion: language agents with verbal reinforcement learning"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"d318e0169f649656c71f02a1f84194a734fe1962","externalIds":{"ArXiv":"2303.00001","DBLP":"conf/iclr/KwonXBS23","DOI":"10.48550/arXiv.2303.00001","CorpusId":257255456},"title":"Reward Design with Language Models"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"89e184d2bc830af568e439db9476caa0c047e11a","externalIds":{"ArXiv":"2302.06692","DBLP":"journals/corr/abs-2302-06692","DOI":"10.48550/arXiv.2302.06692","CorpusId":256846700},"title":"Guiding Pretraining in Reinforcement Learning with Large Language Models"},{"paperId":"477fa196b87964671a52c0c034627342840c1568","externalIds":{"DBLP":"journals/corr/abs-2302-04831","ArXiv":"2302.04831","DOI":"10.48550/arXiv.2302.04831","CorpusId":256697436},"title":"Cooperative Open-ended Learning Framework for Zero-shot Coordination"},{"paperId":"0b58f4ec8cbf6f63fb65b7e3c368cf511eadecd3","externalIds":{"ArXiv":"2302.02662","DBLP":"journals/corr/abs-2302-02662","DOI":"10.48550/arXiv.2302.02662","CorpusId":256615643},"title":"Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning"},{"paperId":"ccb1ccc4deacc4fb18000f0e1ce24329548963ae","externalIds":{"ArXiv":"2302.01560","DBLP":"journals/corr/abs-2302-01560","DOI":"10.48550/arXiv.2302.01560","CorpusId":256598146},"title":"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents"},{"paperId":"980e55d9226cac302d0fae7732da4e67b8bc952c","externalIds":{"DBLP":"conf/acl/RatnerLBRMAKSLS23","ACL":"2023.acl-long.352","ArXiv":"2212.10947","DOI":"10.18653/v1/2023.acl-long.352","CorpusId":258686160},"title":"Parallel Context Windows for Large Language Models"},{"paperId":"db4ab91d5675c37795e719e997a2827d3d83cd45","externalIds":{"ArXiv":"2212.10403","DBLP":"conf/acl/0009C23","DOI":"10.48550/arXiv.2212.10403","CorpusId":254877753},"title":"Towards Reasoning in Large Language Models: A Survey"},{"paperId":"e65b346d442e9962a4276dc1c1af2956d9d5f1eb","externalIds":{"DBLP":"journals/corr/abs-2212-10560","ArXiv":"2212.10560","ACL":"2023.acl-long.754","DOI":"10.48550/arXiv.2212.10560","CorpusId":254877310},"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions"},{"paperId":"8ee45aeb7c97e3346cc62f216f673b91277ac718","externalIds":{"DBLP":"conf/iccv/SongSWCW023","ArXiv":"2212.04088","DOI":"10.1109/ICCV51070.2023.00280","CorpusId":254408960},"title":"LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models"},{"paperId":"e89ed6bb1864558e3889f5f2fb8931643c633479","externalIds":{"DOI":"10.1126/science.ade9097","CorpusId":253759631,"PubMed":"36413172"},"title":"Human-level play in the game of Diplomacy by combining language models with strategic reasoning"},{"paperId":"d5295f7ddcf281f3d30a7579d5ce482036a8e27c","externalIds":{"DBLP":"journals/corr/abs-2210-13382","ArXiv":"2210.13382","DOI":"10.48550/arXiv.2210.13382","CorpusId":253098566},"title":"Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task"},{"paperId":"99832586d55f540f603637e458a292406a0ed75d","externalIds":{"DBLP":"conf/iclr/YaoZYDSN023","ArXiv":"2210.03629","CorpusId":252762395},"title":"ReAct: Synergizing Reasoning and Acting in Language Models"},{"paperId":"4fcf18bda55414c5f31cc4be560bae92e8e4b7e9","externalIds":{"DBLP":"conf/aaai/ZhaoYLLX22","DOI":"10.1609/aaai.v36i4.20394","CorpusId":250296452},"title":"AlphaHoldem: High-Performance Artificial Intelligence for Heads-Up No-Limit Poker via End-to-End Reinforcement Learning"},{"paperId":"32c9b3859086d15184989454eb878638659e64c6","externalIds":{"ArXiv":"2206.08853","DBLP":"conf/nips/FanWJMYZTHZA22","DOI":"10.48550/arXiv.2206.08853","CorpusId":249848263},"title":"MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"5922f437512158970c417f4413bface021df5f78","externalIds":{"DBLP":"journals/corr/abs-2205-06175","ArXiv":"2205.06175","DOI":"10.48550/arXiv.2205.06175","CorpusId":248722148},"title":"A Generalist Agent"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"cb5e3f085caefd1f3d5e08637ab55d39e61234fc","externalIds":{"DBLP":"conf/corl/IchterBCFHHHIIJ22","ArXiv":"2204.01691","CorpusId":247939706},"title":"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"0e41fd22d483047bd8fdb1757d90c7702493567e","externalIds":{"ArXiv":"2203.07540","ACL":"2022.emnlp-main.775","DBLP":"conf/emnlp/WangJCA22","DOI":"10.48550/arXiv.2203.07540","CorpusId":247451124},"title":"ScienceWorld: Is your Agent Smarter than a 5th Grader?"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"b9b220b485d2add79118ffdc2aaa148b67fa53ef","externalIds":{"DBLP":"journals/corr/abs-2202-01771","ArXiv":"2202.01771","CorpusId":246485514},"title":"Pre-Trained Language Models for Interactive Decision-Making"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"92a8f7f09f3705cb5a6009a42220a6f01ea084e8","externalIds":{"DBLP":"journals/corr/abs-2201-07207","ArXiv":"2201.07207","CorpusId":246035276},"title":"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"},{"paperId":"3b61bc41dff751edbead03aab5e4a1da1aafcc06","externalIds":{"DBLP":"conf/iclr/TuylsYKN22","ArXiv":"2201.01251","CorpusId":245668925},"title":"Multi-Stage Episodic Control for Strategic Exploration in Text Games"},{"paperId":"4270f2493dfd9ae26b9f7c707cf1398ddbbdc0a1","externalIds":{"ArXiv":"2112.11701","DBLP":"journals/corr/abs-2112-11701","DOI":"10.1609/aaai.v37i5.25758","CorpusId":245385180},"title":"Maximum Entropy Population Based Training for Zero-Shot Human-AI Coordination"},{"paperId":"a7aa150b55d64d339b1c154d6d88455fc3cbc44f","externalIds":{"DBLP":"journals/corr/abs-2111-09734","ArXiv":"2111.09734","CorpusId":244346239},"title":"ClipCap: CLIP Prefix for Image Captioning"},{"paperId":"8e128a1b2efb0ddf688902ade4405d22d5b61eec","externalIds":{"DBLP":"conf/iclr/Hafner22","ArXiv":"2109.06780","CorpusId":237504552},"title":"Benchmarking the Spectrum of Agent Capabilities"},{"paperId":"76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2","externalIds":{"DBLP":"journals/corr/abs-2108-07258","ArXiv":"2108.07258","CorpusId":237091588},"title":"On the Opportunities and Risks of Foundation Models"},{"paperId":"c0c9f77cb097f2ce53feb91802bcfbae57fcc42f","externalIds":{"DBLP":"conf/corl/Srivastava0LMXV21","ArXiv":"2108.03332","CorpusId":236957374},"title":"BEHAVIOR: Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments"},{"paperId":"faca792068386ee4d906e8b8ddd524c892ae42fd","externalIds":{"DBLP":"journals/corr/abs-2107-08408","ArXiv":"2107.08408","DOI":"10.5555/3535850.3536091","CorpusId":236087322},"title":"Pre-trained Language Models as Prior Knowledge for Playing Text-based Games"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"66c10bf1f11bc1b2d92204d8f8391d087f6de1c4","externalIds":{"DBLP":"journals/ijon/SuALPBL24","ArXiv":"2104.09864","DOI":"10.1016/j.neucom.2023.127063","CorpusId":233307138},"title":"RoFormer: Enhanced Transformer with Rotary Position Embedding"},{"paperId":"ffdbd7f0b03b85747b001b4734d5ee31b5229aa4","externalIds":{"DBLP":"journals/corr/abs-2104-08691","ArXiv":"2104.08691","ACL":"2021.emnlp-main.243","DOI":"10.18653/v1/2021.emnlp-main.243","CorpusId":233296808},"title":"The Power of Scale for Parameter-Efficient Prompt Tuning"},{"paperId":"69625c4aa0ade91a4b8758e720fb27926835e25a","externalIds":{"DBLP":"conf/icra/GanZSABGYDM0T22","ArXiv":"2103.14025","DOI":"10.1109/icra46639.2022.9812329","CorpusId":232352654},"title":"The ThreeDWorld Transport Challenge: A Visually Guided Task-and-Motion Planning Benchmark Towards Physically Realistic Embodied AI"},{"paperId":"453fc588d97958c6fefad96e79edd896873b3e09","externalIds":{"ArXiv":"2102.13249","DBLP":"conf/aaai/ToshniwalWLG22","DOI":"10.1609/aaai.v36i10.21390","CorpusId":248811258},"title":"Chess as a Testbed for Language Model State Tracking"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"c562477737cc35e08d5a84aef01163ee4652d796","externalIds":{"DBLP":"journals/corr/abs-2010-09890","MAG":"3093967600","ArXiv":"2010.09890","CorpusId":224803224},"title":"Watch-And-Help: A Challenge for Social Perception and Human-AI Collaboration"},{"paperId":"398a0625e8707a0b41ac58eaec51e8feb87dd7cb","externalIds":{"DBLP":"journals/corr/abs-2010-03768","MAG":"3092516542","ArXiv":"2010.03768","CorpusId":222208810},"title":"ALFWorld: Aligning Text and Embodied Environments for Interactive Learning"},{"paperId":"8aed57b61457655e8354f1b68b34ed1cc0a222ef","externalIds":{"MAG":"3099204253","DBLP":"conf/emnlp/YaoRHN20","ACL":"2020.emnlp-main.704","ArXiv":"2010.02903","DOI":"10.18653/v1/2020.emnlp-main.704","CorpusId":222142129},"title":"Keep CALM and Explore: Language Models for Action Generation in Text-based Games"},{"paperId":"061d113a7b3f32deab6bc50fea676fa0b1e0f658","externalIds":{"DBLP":"conf/emnlp/GuoYGGCC20","ArXiv":"2010.02386","MAG":"3092035259","ACL":"2020.emnlp-main.624","DOI":"10.18653/v1/2020.emnlp-main.624","CorpusId":222140924},"title":"Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with Reinforcement Learning"},{"paperId":"85ae09edef1dac1f147ca80a743e878a7a4e1547","externalIds":{"DBLP":"conf/nips/GanSAMSTFKBHSKW21","ArXiv":"2007.04954","MAG":"3042040243","CorpusId":220424686},"title":"ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation"},{"paperId":"02eaaf87f9cae34cca398fed146079e6eeb1f868","externalIds":{"MAG":"3034723486","ACL":"2020.acl-main.463","DBLP":"conf/acl/BenderK20","DOI":"10.18653/v1/2020.acl-main.463","CorpusId":211029226},"title":"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"595c7aeb6a9c9033a68aff1b25067ce967ea2a77","externalIds":{"MAG":"3024044737","ArXiv":"2005.05842","DBLP":"journals/corr/abs-2005-05842","DOI":"10.1016/j.robot.2022.104096","CorpusId":218595872},"title":"A Survey of Behavior Trees in Robotics and AI"},{"paperId":"ae2a71f3731b76acac71c63cf38af87f45ef730a","externalIds":{"DBLP":"books/ox/22/WangWEPTK22","MAG":"3040507763","DOI":"10.1111/tops.12525","CorpusId":220364175,"PubMed":"33829670"},"title":"Too Many Cooks: Bayesian Inference for Coordinating Multi-Agent Collaboration"},{"paperId":"84db50ec1f9b092a56f7d2cd12d3d2894ca68982","externalIds":{"DBLP":"journals/ki/Lucas20","MAG":"3007144933","DOI":"10.1007/s13218-020-00646-x","CorpusId":3345054},"title":"Artificial Intelligence and Games"},{"paperId":"028c1a07ac62bbdb681d11cacf4c7485f9aa3ef7","externalIds":{"DBLP":"journals/corr/abs-2001-08837","MAG":"2996681978","ArXiv":"2001.08837","CorpusId":210911499},"title":"Graph Constrained Reinforcement Learning for Natural Language Action Spaces"},{"paperId":"a2e43270a9b1421e452c2975e5163e2a216abeac","externalIds":{"MAG":"2996726407","DBLP":"journals/corr/abs-1912-10944","ArXiv":"1912.10944","CorpusId":209444848},"title":"A Survey of Deep Reinforcement Learning in Video Games"},{"paperId":"f4cf4246f3882aa6337e9c05d5675a3b8463a32e","externalIds":{"MAG":"2993086250","ArXiv":"1912.01734","DBLP":"journals/corr/abs-1912-01734","DOI":"10.1109/cvpr42600.2020.01075","CorpusId":208617407},"title":"ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks"},{"paperId":"8d814620a1ca77e745bc8a33b96b86148f2804fe","externalIds":{"DBLP":"journals/corr/abs-1912-01588","MAG":"3034946435","ArXiv":"1912.01588","CorpusId":208547624},"title":"Leveraging Procedural Generation to Benchmark Reinforcement Learning"},{"paperId":"44bf5cf0c245395f36f13a494e9b3772d1a951c4","externalIds":{"DBLP":"journals/ral/XiaSLKTTMS20","MAG":"2998903229","ArXiv":"1910.14442","DOI":"10.1109/LRA.2020.2965078","CorpusId":210931408},"title":"Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in Cluttered Environments"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"eb41a0cffa84d3d6035e6f5f420806ddc962b1e6","externalIds":{"ArXiv":"1910.05789","MAG":"2980061931","DBLP":"journals/corr/abs-1910-05789","CorpusId":202770731},"title":"On the Utility of Learning about Humans for Human-AI Coordination"},{"paperId":"221d453c165aca6bc1a054289eb510e558a23dca","externalIds":{"DBLP":"journals/corr/abs-1909-05398","ArXiv":"1909.05398","MAG":"2972550240","DOI":"10.1609/AAAI.V34I05.6297","CorpusId":202565447},"title":"Interactive Fiction Games: A Colossal Adventure"},{"paperId":"b4a35e548de27b6924e5f2ee41d37238a5c4a1d5","externalIds":{"MAG":"2929928372","ArXiv":"1904.01201","DBLP":"journals/corr/abs-1904-01201","DOI":"10.1109/ICCV.2019.00943","CorpusId":91184540},"title":"Habitat: A Platform for Embodied AI Research"},{"paperId":"1b19f433a3e8497e9d9bd67efb108521d16b5b85","externalIds":{"MAG":"2994943647","ArXiv":"1810.08272","DBLP":"conf/iclr/Chevalier-Boisvert19","CorpusId":59536625},"title":"BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning"},{"paperId":"e9ac4a5244b67308bfb78900f509dfe014d8d077","externalIds":{"DBLP":"journals/air/KotserubaT20","MAG":"2883445328","DOI":"10.1007/s10462-018-9646-y","CorpusId":51888132},"title":"40 years of cognitive architectures: core cognitive abilities and practical applications"},{"paperId":"c52dddfbb4a3af4cc5e72849fe965c62801539e7","externalIds":{"DBLP":"journals/corr/abs-1806-11525","ArXiv":"1806.11525","MAG":"2810305479","CorpusId":49547885},"title":"Counting to Explore and Generalize in Text-based Games"},{"paperId":"89daae27e7df4a418b9610d307ce3df0e30fc8a2","externalIds":{"DBLP":"conf/ijcai/CoteKYKBFMHAATT18","MAG":"2810346659","ArXiv":"1806.11532","DOI":"10.1007/978-3-030-24337-1_3","CorpusId":49552345},"title":"TextWorld: A Learning Environment for Text-based Games"},{"paperId":"898977d26d7c30f08c79b8137e69c6908144f64a","externalIds":{"DOI":"10.4324/9781315168722-2","CorpusId":239911441},"title":"EDITION"},{"paperId":"7139a5f730652abbeabf9e140009907d2c7da3e5","externalIds":{"MAG":"2799002257","DBLP":"conf/cvpr/PuigRBLWF018","ArXiv":"1806.07011","DOI":"10.1109/CVPR.2018.00886","CorpusId":49317780},"title":"VirtualHome: Simulating Household Activities Via Programs"},{"paperId":"89c8aad71433f7638d2e2c009e1ea20e039f832d","externalIds":{"DBLP":"journals/corr/abs-1712-05474","MAG":"2776202271","ArXiv":"1712.05474","CorpusId":28328610},"title":"AI2-THOR: An Interactive 3D Environment for Visual AI"},{"paperId":"c27db32efa8137cbf654902f8f728f338e55cd1c","externalIds":{"MAG":"2766447205","DBLP":"journals/nature/SilverSSAHGHBLB17","DOI":"10.1038/nature24270","CorpusId":205261034,"PubMed":"29052630"},"title":"Mastering the game of Go without human knowledge"},{"paperId":"6127b8dc39497a2388a0fce2512595e0dcb7121b","externalIds":{"DBLP":"journals/corr/abs-1708-04782","MAG":"2749807327","ArXiv":"1708.04782","CorpusId":28808621},"title":"StarCraft II: A New Challenge for Reinforcement Learning"},{"paperId":"dce6f9d4017b1785979e7520fd0834ef8cf02f4b","externalIds":{"MAG":"2736601468","DBLP":"journals/corr/SchulmanWDRK17","ArXiv":"1707.06347","CorpusId":28695052},"title":"Proximal Policy Optimization Algorithms"},{"paperId":"5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd","externalIds":{"MAG":"2626804490","ArXiv":"1706.03741","DBLP":"conf/nips/ChristianoLBMLA17","CorpusId":4787508},"title":"Deep Reinforcement Learning from Human Preferences"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"471f9742b4e32d8ee68f9ee493768ff0466a231d","externalIds":{"ArXiv":"1705.06366","MAG":"2616430965","DBLP":"conf/icml/FlorensaHGA18","CorpusId":22729745},"title":"Automatic Goal Generation for Reinforcement Learning Agents"},{"paperId":"a473f545318325ba23b7a6b477485d29777ba873","externalIds":{"MAG":"2362143032","ArXiv":"1605.02097","DBLP":"journals/corr/KempkaWRTJ16","DOI":"10.1109/CIG.2016.7860433","CorpusId":430714},"title":"ViZDoom: A Doom-based AI research platform for visual reinforcement learning"},{"paperId":"846aedd869a00c09b40f1f1f35673cb22bc87490","externalIds":{"DBLP":"journals/nature/SilverHMGSDSAPL16","MAG":"2257979135","DOI":"10.1038/nature16961","CorpusId":515925,"PubMed":"26819042"},"title":"Mastering the game of Go with deep neural networks and tree search"},{"paperId":"2f2961362355e45fa014ca0bb8ce4495aedf8824","externalIds":{"MAG":"2753615671","CorpusId":36031679,"PubMed":"25577814"},"title":"Thinking fast and slow."},{"paperId":"7ef4064b8613b658190f0de6394d051d305d054c","externalIds":{"MAG":"2227426300","DOI":"10.9776/14057","CorpusId":46322261},"title":"Facet Analysis of Video Game Genres"},{"paperId":"88789ee88311acef28475ad33dbcd6b3c4be8358","externalIds":{"MAG":"1978012692","DOI":"10.1177/1527476412450193","CorpusId":46997949},"title":"Wikipedia"},{"paperId":"2319a491378867c7049b3da055c5df60e1671158","externalIds":{"DBLP":"journals/corr/MnihKSGAWR13","MAG":"1757796397","ArXiv":"1312.5602","CorpusId":15238391},"title":"Playing Atari with Deep Reinforcement Learning"},{"paperId":"219560bb8955db8d49142d1cdfbededefc68adcb","externalIds":{"PubMedCentral":"4117135","DOI":"10.5214/ans.0972.7531.200408","CorpusId":31173730},"title":"Memory: A Contribution to Experimental Psychology"},{"paperId":"36123eedda1b9daf16eddf0cedc68a2a174c3b3f","externalIds":{"MAG":"2005738692","PubMedCentral":"3664921","DOI":"10.1016/j.cortex.2011.06.001","CorpusId":10461127,"PubMed":"21774923"},"title":"Working, declarative and procedural memory in specific language impairment"},{"paperId":"f48750080a8b93857b4fff932120e4281741a91a","externalIds":{"MAG":"605763657","DOI":"10.1093/acprof:oso/9780199646739.001.0001","CorpusId":141394018},"title":"The foundations of metacognition"},{"paperId":"f82e4ff4f003581330338aaae71f60316e58dd26","externalIds":{"ArXiv":"1207.4708","DBLP":"journals/jair/BellemareNVB13","MAG":"2150468603","DOI":"10.1613/jair.3912","CorpusId":1552061},"title":"The Arcade Learning Environment: An Evaluation Platform for General Agents"},{"paperId":"6067b80d698ec3f84bd5329f7154f302e0cde788","externalIds":{"MAG":"2155610381","PubMedCentral":"3318765","DOI":"10.1098/rstb.2011.0417","CorpusId":1908317,"PubMed":"22492751"},"title":"The neural basis of metacognitive ability"},{"paperId":"cdf4f9f19514456e80655970a3b698a477526db8","externalIds":{"MAG":"2149129640","PubMedCentral":"3318764","DOI":"10.1098/rstb.2011.0416","CorpusId":2179163,"PubMed":"22492749"},"title":"Metacognition in human decision-making: confidence and error monitoring"},{"paperId":"fb05f4fd1d629b8736c5f91842026acc80a6bdd4","externalIds":{"MAG":"2988698064","DOI":"10.1073/pnas.1012933107","CorpusId":15080556,"PubMed":"20956326"},"title":"Mental models and human reasoning"},{"paperId":"5c41252db73e543bc6a4935e5743f6a85055d191","externalIds":{"DBLP":"journals/jagi/Goertzel14","MAG":"656438723","DOI":"10.2478/jagi-2014-0001","CorpusId":4794432},"title":"Artificial General Intelligence: Concept, State of the Art, and Future Prospects"},{"paperId":"81445052dfd839de284c0ea0225ee2855df15038","externalIds":{"MAG":"2155479778","DOI":"10.1146/ANNUREV.PSYCH.59.103006.093629","CorpusId":12246493,"PubMed":"18154502"},"title":"Dual-processing accounts of reasoning, judgment, and social cognition."},{"paperId":"701fa2444ee1a1c3a5982329477ab6f8e4a3b9e9","externalIds":{"MAG":"152052037","DBLP":"conf/aaai/NuxollL07","CorpusId":7897551},"title":"Extending Cognitive Architecture with Episodic Memory"},{"paperId":"7f877e8b42c2a0ef210edff65f572dd43b2e00a8","externalIds":{"MAG":"2254007555","DOI":"10.1016/j.cub.2005.08.041","CorpusId":13539270,"PubMed":"16139190"},"title":"Theory of mind"},{"paperId":"24bac83f244cbbff359a271b2fce7cab9ef3d34b","externalIds":{"MAG":"2168356773","ArXiv":"1207.1411","DBLP":"journals/corr/abs-1207-1411","CorpusId":16132697},"title":"Bayes' Bluff: Opponent Modelling in Poker"},{"paperId":"ff96fff4b7b211e54ae049888a6cc05786e6c378","externalIds":{"MAG":"2165031188","DOI":"10.1016/j.nlm.2004.06.005","CorpusId":9008932,"PubMed":"15464402"},"title":"Memory systems of the brain: A brief history and current perspective"},{"paperId":"1a8cc98ad8f023a9078a5ace98e777a88239854d","externalIds":{"MAG":"2137016812","DOI":"10.1016/S1364-6613(03)00029-9","CorpusId":206129621,"PubMed":"12639696"},"title":"The cognitive revolution: a historical perspective"},{"paperId":"707c4efd5452de0ef4f3806f8f90529b41f995bd","externalIds":{"DBLP":"journals/ki/Messing03","MAG":"2145790759","CorpusId":39272125},"title":"An Introduction to MultiAgent Systems"},{"paperId":"c8f359b3967ddef8e6d7f6ad58213a543d33ea22","externalIds":{"MAG":"2166667242","DOI":"10.1017/S0140525X01003922","CorpusId":8739159,"PubMed":"11515286"},"title":"The magical number 4 in short-term memory: A reconsideration of mental storage capacity"},{"paperId":"55ec99d2b74e85bbbeb22931da72473c2da0c227","externalIds":{"MAG":"2165683312","DOI":"10.1037/0033-2909.123.2.162","CorpusId":1063416,"PubMed":"9522683"},"title":"Situation models in language comprehension and memory."},{"paperId":"3f3527ffc3de56afefb0747877ed0179986809a8","externalIds":{"MAG":"1977308918","DOI":"10.7551/mitpress/1552.001.0001","CorpusId":12144937},"title":"Being There: Putting Brain, Body, and World Together Again"},{"paperId":"27f1b54ee5c8e6afe0398486b2dcd1e1d779d76e","externalIds":{"MAG":"1896824914","DOI":"10.1162/jocn.1991.3.3.301","CorpusId":41404636,"PubMed":"23964845"},"title":"Unified Theories of Cognition"},{"paperId":"1e8817b3efd3f5ca8b16d0cc2930b4d0821a8c44","externalIds":{"MAG":"3009986018","DOI":"10.2307/414498","CorpusId":142764128},"title":"Mental Models: Towards a Cognitive Science of Language, Inference, and Consciousness"},{"paperId":"35a2b204ee6da98232674728e82f7fedd9f46931","externalIds":{"MAG":"3014309392","DOI":"10.1017/S0033291700003548","CorpusId":1916803},"title":"Working memory"},{"paperId":"1412f5ee973976e6c69f972e8427d1adba02e3ed","externalIds":{"DBLP":"journals/corr/abs-2403-03186","DOI":"10.48550/arXiv.2403.03186","CorpusId":271040254},"title":"Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study"},{"paperId":"965406129f7ce1dc5acd1374493e7d091a17cc6e","externalIds":{"DBLP":"conf/iclr/TanZLZW024","CorpusId":271746329},"title":"True Knowledge Comes from Practice: Aligning Large Language Models with Embodied Environments via Reinforcement Learning"},{"paperId":"2d1ad38d83a5b8a6bb47630972ada82b62ea4aac","externalIds":{"DBLP":"journals/corr/abs-2303-16563","DOI":"10.48550/arXiv.2303.16563","CorpusId":257805102},"title":"Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks"},{"paperId":"46299fee72ca833337b3882ae1d8316f44b32b3c","externalIds":{"DBLP":"journals/corr/abs-2303-11366","CorpusId":257636839},"title":"Reflexion: an autonomous agent with dynamic memory and self-reflection"},{"paperId":"e803362bb0e31a126c5fbfb14bab4f690be0564d","externalIds":{"DBLP":"conf/nips/WuMPBSAML23","CorpusId":268042522},"title":"SPRING: Studying Papers and Reasoning to play Games"},{"paperId":"464c3a3512d5bde8078185114f38777843d88256","externalIds":{"DBLP":"journals/corr/abs-2302-02083","DOI":"10.48550/arXiv.2302.02083","CorpusId":263890629},"title":"Theory of Mind May Have Spontaneously Emerged in Large Language Models"},{"paperId":"c52b30a60fda5f23cc0d2241c4e127f5191bbb2d","externalIds":{"DBLP":"journals/corr/abs-2309-11489","DOI":"10.48550/arXiv.2309.11489","CorpusId":262053612},"title":"Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning"},{"paperId":"9bfc28cab6f0e35ccfdbf94e568838e3b0530726","externalIds":{"DBLP":"conf/eacl/ShiXFC23","ACL":"2023.eacl-main.50","DOI":"10.18653/v1/2023.eacl-main.50","CorpusId":258378233},"title":"Self-imitation Learning for Action Generation in Text-based Games"},{"paperId":"e2465990c43bed768e2025de7889c2ffefce6a30","externalIds":{"DBLP":"journals/corr/abs-2305-02547","CorpusId":258480251},"title":"PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences"},{"paperId":"99bf7219b8d3e6ac1ad8dc9bfd8589cbcf843f23","externalIds":{"DBLP":"conf/nips/WangCCLML23","CorpusId":268042457},"title":"Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents"},{"paperId":"69764fcc646e4c608ac08eeb4c784cf8465268d2","externalIds":{"DBLP":"conf/corl/0002ZWGSMWLLSAH22","CorpusId":255198985},"title":"BEHAVIOR-1K: A Benchmark for Embodied AI with 1, 000 Everyday Activities and Realistic Simulation"},{"paperId":"53d8b356551a2361020a948f64454a6d599af69f","externalIds":{"DBLP":"conf/acl/LiL20","ACL":"2021.acl-long.353","ArXiv":"2101.00190","DOI":"10.18653/v1/2021.acl-long.353","CorpusId":230433941},"title":"Prefix-Tuning: Optimizing Continuous Prompts for Generation"},{"paperId":"35a32d01192c68cf82ef0b7e58162acba2b5bae7","externalIds":{"CorpusId":15493262},"title":"Toward Integrating Cognitive Linguistics and Cognitive Language Processing"},{"paperId":"d77d03fb7ae5572ad0d9e728ff05c73263852278","externalIds":{"CorpusId":60627476},"title":"& Computer"},{"paperId":"1c507556272da9a8367e13a0ca26bfeb13b1be8c","externalIds":{"MAG":"2162437324","DOI":"10.1146/annurev-psych-120710-100452","CorpusId":7529970,"PubMed":"21838546"},"title":"Sources of method bias in social science research and recommendations on how to control it."},{"paperId":"25f8e9e35cafd7fb686d939f274111bcffeafd6b","externalIds":{"MAG":"2103104224","DBLP":"journals/alife/SmithG05","DOI":"10.1162/1064546053278973","CorpusId":7107473,"PubMed":"15811218"},"title":"The Development of Embodied Cognition: Six Lessons from Babies"},{"paperId":"3615cf3527779967c9f07f3a98190c315433ecb8","externalIds":{"MAG":"2085529605","DOI":"10.7551/mitpress/1881.001.0001","CorpusId":145183659},"title":"Cognition in the wild"},{"paperId":"8b8ba26fdc9b65567733c8568f182ae3dbf2773e","externalIds":{"MAG":"2134917048","CorpusId":145694528},"title":"Cognitive Psychology and Its Implications"},{"paperId":"d792562462dbb687015954805d31620240db57a1","externalIds":{"MAG":"3041214984","DOI":"10.4135/9781446212967.n15","CorpusId":140830322},"title":"Episodic and semantic memory"},{"paperId":"56c16d9e2a5270ba6b1d83271e2c10916591968d","externalIds":{"MAG":"1878893887","DBLP":"books/el/68/AtkinsonS68","DOI":"10.1016/S0079-7421(08)60422-3","CorpusId":22958289},"title":"Human Memory: A Proposed System and its Control Processes"},{"paperId":"9c422194b1c7cc8b6c001929305ecf98ee4e4360","externalIds":{"CorpusId":320913},"title":"Whatever Next? Predictive Brains, Situated Agents, and the Future of Cognitive Science."},{"paperId":"677962f5397947a6355c9407ed025b6c9ea5e711","externalIds":{"CorpusId":8511110},"title":"PSYCHOLOGICAL SCIENCE Research Article REFLECTIONS OF THE ENVIRONMENT IN MEMORY"}]}