{"paperId":"a79f6474f0bec1cf0501e48dfc7b2b36cf7338dc","externalIds":{"DBLP":"journals/corr/abs-2312-15223","ArXiv":"2312.15223","DOI":"10.48550/arXiv.2312.15223","CorpusId":266551742},"title":"A Survey on Large Language Models for Software Engineering","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2312.15223, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"1409701329","name":"Quanjun Zhang"},{"authorId":"7595994","name":"Chunrong Fang"},{"authorId":"2276541220","name":"Yang Xie"},{"authorId":"2276451834","name":"Yaxin Zhang"},{"authorId":"2276454592","name":"Yun Yang"},{"authorId":"3433022","name":"Weisong Sun"},{"authorId":"150311588","name":"Shengcheng Yu"},{"authorId":"2238950128","name":"Zhenyu Chen"}],"abstract":"Software Engineering (SE) is the systematic design, development, maintenance, and management of software applications underpinning the digital infrastructure of our modern world. Very recently, the SE community has seen a rapidly increasing number of techniques employing Large Language Models (LLMs) to automate a broad range of SE tasks. Nevertheless, existing information of the applications, effects, and possible limitations of LLMs within SE is still not well-studied. In this paper, we provide a systematic survey to summarize the current state-of-the-art research in the LLM-based SE community. We summarize 62 representative LLMs of Code across three model architectures, 15 pre-training objectives across four categories, and 16 downstream tasks across five categories. We then present a detailed summarization of the recent SE studies for which LLMs are commonly utilized, including 947 studies for 112 specific code-related tasks across five crucial phases within the SE workflow. We also discuss several critical aspects during the integration of LLMs into SE, such as empirical evaluation, benchmarking, security and reliability, domain tuning, compressing and distillation. Finally, we highlight several challenges and potential opportunities on applying LLMs for future SE studies, such as exploring domain LLMs and constructing clean evaluation datasets. Overall, our work can help researchers gain a comprehensive understanding about the achievements of the existing LLM-based SE studies and promote the practical application of these techniques. Our artifacts are publicly available and will be continuously updated at the living repository: https://github.com/iSEngLab/AwesomeLLM4SE."}