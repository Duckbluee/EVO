{"paperId":"6912a12f3710bf4bbdfd9f55f90311426fc1c32c","externalIds":{"ArXiv":"2310.11829","DBLP":"journals/pami/LiuYLCLZBFSYS25","DOI":"10.1109/TPAMI.2025.3548729","CorpusId":264288909,"PubMed":"40048343"},"title":"Graph Foundation Models: Concepts, Opportunities and Challenges","openAccessPdf":{"url":"","status":"CLOSED","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2310.11829, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2260178816","name":"Jiawei Liu"},{"authorId":"2257052319","name":"Cheng Yang"},{"authorId":"2110327382","name":"Zhiyuan Lu"},{"authorId":"2260645232","name":"Junze Chen"},{"authorId":"2274190647","name":"Yibo Li"},{"authorId":"16003017","name":"Mengmei Zhang"},{"authorId":"2300370790","name":"Ting Bai"},{"authorId":"2267220071","name":"Yuan Fang"},{"authorId":"2257354508","name":"Lichao Sun"},{"authorId":"2258679535","name":"Philip S. Yu"},{"authorId":"2257131498","name":"Chuan Shi"}],"abstract":"Foundation models have emerged as critical components in a variety of artificial intelligence applications, and showcase significant success in natural language processing and several other domains. Meanwhile, the field of graph machine learning is witnessing a paradigm transition from shallow methods to more sophisticated deep learning approaches. The capabilities of foundation models in generalization and adaptation motivate graph machine learning researchers to discuss the potential of developing a new graph learning paradigm. This paradigm envisions models that are pre-trained on extensive graph data and can be adapted for various graph tasks. Despite this burgeoning interest, there is a noticeable lack of clear definitions and systematic analyses pertaining to this neuicew domain. To this end, this article introduces the concept of Graph Foundation Models (GFMs), and offers an exhaustive explanation of their key characteristics and underlying technologies. We proceed to classify the existing work related to GFMs into three distinct categories, based on their dependence on graph neural networks and large language models. In addition to providing a thorough review of the current state of GFMs, this article also outlooks potential avenues for future research in this rapidly evolving domain."}