{"abstract":"Medical image segmentation is crucial for facilitating pathology assessment, ensuring reliable diagnosis and monitoring disease progression. Deep-learning models have been extensively applied in automating medical image analysis to reduce human effort. However, the non-transparency of deep-learning models limits their clinical practicality due to the unaffordably high risk of misdiagnosis resulted from the misleading model output. In this paper, we propose a explainability metric as part of the loss function. The proposed explainability metric comes from Class Activation Map(CAM) with learnable weights such that the model can be optimized to achieve desirable balance between segmentation performance and explainability. Experiments found that the proposed model visibly heightened Dice score from to , Jaccard similarity from to and Recall from to respectively compared with U-net. In addition, results make clear that the drawn model outdistances the conventional U-net in terms of explainability performance."}