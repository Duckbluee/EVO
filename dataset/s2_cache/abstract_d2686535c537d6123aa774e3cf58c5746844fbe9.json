{"abstract":"Federated learning (FL) has recently emerged as a transformative paradigm that jointly train a model with distributed devices while avoiding the need for central data collection. Due to the limited observation range, the devices only contain local information, which limits the quality of trained models. In this case, combining the global information into FL may be helpful. However, in horizontal FL, the central agency only acts as a model aggregator without utilizing its global observation. Meanwhile, the global data may not be directly transmitted to agents for data security. Then how to utilize the global observation residing in the central agency while protecting its safety thus rises up as an important problem in FL. In this paper, we develop a vertical-horizontal federated learning (VHFL) scheme, where the global feature is shared with the agents in a procedure similar to that of vertical FL. It is shown by experiments that the proposed VHFL could enhance the accuracy compared with horizontal FL while protecting the central data from being announced."}