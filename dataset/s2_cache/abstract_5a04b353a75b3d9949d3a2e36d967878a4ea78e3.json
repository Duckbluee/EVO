{"abstract":"Recommender systems have become indispensable for several Web sites, helping users deal with big amounts of data. They are capable of analyzing user/item interactions taking place on-line, and provide each user with a list of suggestions sorted by relevance. Items with the same or very close relevance, however, may occupy different positions in the ranking and may be exposed to completely different levels of attention. This promotes unfair treatment and can only be addressed by a long term strategy. Variational Autoencoders (VAEs) were recently proposed as the state-of-the-art for collaborative filtering recommendations, but as every other approach, they generate homogeneous prediction scores among the highest positions. In this paper, we propose incorporating randomness in the regular operation of VAEs in order to increase the fairness (mitigate the position bias) in multiple rounds of recommendation. We argue that adding a noise component when sampling values from VAE's latent representation provides long term fairness, despite of a tolerable decrease in ranking quality (NDCG). We calculate the trade-off between unfairness and NDCG when introducing 4 different noise distributions. The solution has proved to be a very practical one and the results point for a clear positive effect of turning recommendation far more fair, despite some small NDCG loss in Movie Lens, Netflix and MSD datasets. In our best scenario, the unfairness was reduced by 76% despite a decrease of 5% in the quality of ranking."}