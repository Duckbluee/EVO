{"abstract":"In this paper, we focus on a problem remaining to be studied: multi-source model adaptation, which is derived from multi-source unsupervised domain adaptation and replaces the source-domain data with source-domain pre-trained models. Pre-trained models are always easier to share than training data so that multiple source-domain models are available in many practical scenarios. Therefore, the problem setting of multi-source domain adaptation is practical in real-world applications. In this setting, we challenge the task of semantic segmentation which is difficult also in the traditional unsupervised domain adaptation due to the pixel-level knowledge transfer. Our method takes full advantage of the multiple source-domain models by learning model-invariant features, which aims to obtain target-domain features with similar distributions from the models pre-trained in different source domains. The adaptation models trained with the model-invariant feature learning benefit from the diversity of the source-domain models and can thus produce more generalizable features to the target domain. Experimental results in several adaptation settings validate the effectiveness and superiority of our method."}