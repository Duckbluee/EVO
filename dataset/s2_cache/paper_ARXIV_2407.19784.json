{"paperId":"4df609838f79c84e7e68d38c32072bc0d41efb09","externalIds":{"ArXiv":"2407.19784","DBLP":"journals/corr/abs-2407-19784","DOI":"10.48550/arXiv.2407.19784","CorpusId":271533367},"title":"Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2407.19784, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2267907280","name":"Jingjing Xu"},{"authorId":"2208905904","name":"Caesar Wu"},{"authorId":"2357227955","name":"Yuan-Fang Li"},{"authorId":"1781003","name":"Gr√©goire Danoy"},{"authorId":"2239024049","name":"Pascal Bouvry"}],"abstract":"Alongside the continuous process of improving AI performance through the development of more sophisticated models, researchers have also focused their attention to the emerging concept of data-centric AI, which emphasizes the important role of data in a systematic machine learning training process. Nonetheless, the development of models has also continued apace. One result of this progress is the development of the Transformer Architecture, which possesses a high level of capability in multiple domains such as Natural Language Processing (NLP), Computer Vision (CV) and Time Series Forecasting (TSF). Its performance is, however, heavily dependent on input data preprocessing and output data evaluation, justifying a data-centric approach to future research. We argue that data-centric AI is essential for training AI models, particularly for transformer-based TSF models efficiently. However, there is a gap regarding the integration of transformer-based TSF and data-centric AI. This survey aims to pin down this gap via the extensive literature review based on the proposed taxonomy. We review the previous research works from a data-centric AI perspective and we intend to lay the foundation work for the future development of transformer-based architecture and data-centric AI."}