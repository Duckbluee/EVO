{"paperId":"d0840037657abc03765cee36ad837a80ef0769de","externalIds":{"DBLP":"journals/corr/abs-2405-16640","ArXiv":"2405.16640","DOI":"10.48550/arXiv.2405.16640","CorpusId":270062943},"title":"A Survey of Multimodal Large Language Model from A Data-centric Perspective","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2405.16640, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2168279268","name":"Tianyi Bai"},{"authorId":"2303856806","name":"Hao Liang"},{"authorId":"2399035466","name":"Binwang Wan"},{"authorId":"2249513224","name":"Ling Yang"},{"authorId":"2303441380","name":"Bozhou Li"},{"authorId":"2303418962","name":"Yifan Wang"},{"authorId":"2277742543","name":"Bin Cui"},{"authorId":"2291040348","name":"Conghui He"},{"authorId":"2303407552","name":"Binhang Yuan"},{"authorId":"2277807793","name":"Wentao Zhang"}],"abstract":"Multimodal large language models (MLLMs) enhance the capabilities of standard large language models by integrating and processing data from multiple modalities, including text, vision, audio, video, and 3D environments. Data plays a pivotal role in the development and refinement of these models. In this survey, we comprehensively review the literature on MLLMs from a data-centric perspective. Specifically, we explore methods for preparing multimodal data during the pretraining and adaptation phases of MLLMs. Additionally, we analyze the evaluation methods for the datasets and review the benchmarks for evaluating MLLMs. Our survey also outlines potential future research directions. This work aims to provide researchers with a detailed understanding of the data-driven aspects of MLLMs, fostering further exploration and innovation in this field."}