{"abstract":"Vertical federated learning is a subset of federated learning whose training dataset is vertically distributed among the federations. However, as a natural synchronous algorithm, classical vertical federated learning suffers from “Liebig's Law”. In this paper, we propose a novel asynchronous vertical federated learning framework with gradient prediction and double-end sparse compression to accelerate the training process and reduce the intermediate result transmission. Our simulation results show that our framework can achieve 65.41 % training acceleration and 86.90% traffic volume reduction at no cost of accuracy compared with the classical framework."}