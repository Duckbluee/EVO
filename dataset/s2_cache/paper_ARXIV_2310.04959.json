{"paperId":"12a4c41b087629548b07d0dadb9da05147fa4f81","externalIds":{"ArXiv":"2310.04959","DBLP":"journals/corr/abs-2310-04959","DOI":"10.48550/arXiv.2310.04959","CorpusId":263829198},"title":"Towards Better Chain-of-Thought Prompting Strategies: A Survey","openAccessPdf":{"url":"https://arxiv.org/pdf/2310.04959","status":"CLOSED","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2310.04959, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2257083891","name":"Zihan Yu"},{"authorId":"2257338987","name":"Liang He"},{"authorId":"2146267846","name":"Zhen Wu"},{"authorId":"2257010530","name":"Xinyu Dai"},{"authorId":"1838162","name":"Jiajun Chen"}],"abstract":"Chain-of-Thought (CoT), a step-wise and coherent reasoning chain, shows its impressive strength when used as a prompting strategy for large language models (LLM). Recent years, the prominent effect of CoT prompting has attracted emerging research. However, there still lacks of a systematic summary about key factors of CoT prompting and comprehensive guide for prompts utilizing. For a deeper understanding about CoT prompting, we survey on a wide range of current research, presenting a systematic and comprehensive analysis on several factors that may influence the effect of CoT prompting, and introduce how to better apply it in different applications under these discussions. We further analyze the challenges and propose some future directions about CoT prompting. This survey could provide an overall reference on related research."}