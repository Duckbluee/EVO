{"abstract":"Source-free domain adaptation (SFDA) aims to train a well-performed model in the target domain given both a trained source model and unlabeled target samples. Although achieving remarkable progress, existing SFDA methods do not explicitly reduce the distribution shift across domains, which is the key to a good adaptation. However, the absence of source samples makes it difficult to estimate and reduce domain discrepancy. Although there are no source samples available, fortunately, we find that some target samples can be used to approximate the source domain, which is denoted as the pseudo-source domain for approximatively estimating domain discrepancy. In this paper, inspired by this observation, we propose a novel method based on the pseudo-source domain to explicitly reduce the domain discrepancy even without source samples. The proposed method generates and augments the pseudo-source domain, and then employs distribution alignment with four novel losses based on pseudo-label based strategy. Thus, the domain shift can be reduced. The extensive results on three real-world datasets verify the effectiveness of the proposed method. The source code is available at https://github.com/yuntaodu/PS_code."}