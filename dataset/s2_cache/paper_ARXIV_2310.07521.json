{"paperId":"03fab98a9be74a253688840dba9144737a8ca92d","externalIds":{"DBLP":"journals/corr/abs-2310-07521","ArXiv":"2310.07521","DOI":"10.48550/arXiv.2310.07521","CorpusId":263835211},"title":"Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity","openAccessPdf":{"url":"https://arxiv.org/pdf/2310.07521","status":"CLOSED","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2310.07521, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"35504092","name":"Cunxiang Wang"},{"authorId":"2109052548","name":"Xiaoze Liu"},{"authorId":"2302785323","name":"Yuanhao Yue"},{"authorId":"47274259","name":"Xiangru Tang"},{"authorId":"2257868315","name":"Tianhang Zhang"},{"authorId":"2109077713","name":"Cheng Jiayang"},{"authorId":"4841460","name":"Yunzhi Yao"},{"authorId":"2257122746","name":"Wenyang Gao"},{"authorId":"2257129624","name":"Xuming Hu"},{"authorId":"2257044451","name":"Zehan Qi"},{"authorId":"2108024279","name":"Yidong Wang"},{"authorId":"2145500840","name":"Linyi Yang"},{"authorId":"2145270616","name":"Jindong Wang"},{"authorId":"2249681654","name":"Xing Xie"},{"authorId":"2260691874","name":"Zheng Zhang"},{"authorId":"2250437942","name":"Yue Zhang"}],"abstract":"This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs."}