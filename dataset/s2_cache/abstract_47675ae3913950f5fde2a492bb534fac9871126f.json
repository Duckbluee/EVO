{"abstract":"Federated learning (FL) ensures multi-party can train a model together while avoiding privacy leakage. Our vertical federated learning (VFL) task tackles the following scenarios: i) all parties share the same sample space but differ in feature space, ii) only one party holds the label data. Our contribution is twofold: i) proposing a novel aggregation strategy to show that embedding learning is qualified to handle the challenge of VFL, ii) Incorporating specific strategy of Secure Multi-party Computation (MPC) into the training phase to remain the dataset at each local machine. We focus on time series scenarios and choose Gated Recurrent Unit (GRU) as our basic algorithm. We evaluate our method on both Google stock data for regression prediction and Kyoto University Benchmark Data for classification prediction to illustrate the performance of the results in terms of computational and communication complexities."}