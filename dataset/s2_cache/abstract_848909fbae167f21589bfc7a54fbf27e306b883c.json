{"abstract":"The “Impression” section of a radiology report is a critical basis for communication between radiologists and other physicians. Typically written by radiologists, this part is derived from the “Findings” section, which can be laborious and error-prone. Although deep-learning-based models, such as bidirectional encoder representation from transformers (BERT), have achieved promising results in automatic impression generation (AIG), such models often require substantial amounts of medical data and have poor generalization performance. Recently, large language models (LLMs) like Chat Generative Pre-trained Transformer (ChatGPT) have shown strong generalization capabilities and performance, but their performance in specific domains, such as radiology, remains under-investigated and potentially limited. To address this limitation, we propose ImpressionGPT, leveraging the contextual learning capabilities of LLMs through our dynamic prompt and iterative optimization algorithm to accomplish the AIG task. ImpressionGPT initially employs a small amount of domain-specific data to create a dynamic prompt, extracting contextual semantic information closely related to the test data. Subsequently, the iterative optimization algorithm automatically evaluates the output of LLMs and provides optimization suggestions, continuously refining the output results. The proposed ImpressionGPT model achieves superior performance of AIG task on both the Medical Information Mart for Intensive Care - Chest X-ray database (MIMIC-CXR) and Open Access Biomedical Image Search Engine (OpenI) datasets without requiring additional training data or fine-tuning the LLMs. This work presents a paradigm for localizing LLMs that can be applied in a wide range of similar application scenarios, bridging the gap between general-purpose LLMs and the specific language processing needs of various domains."}