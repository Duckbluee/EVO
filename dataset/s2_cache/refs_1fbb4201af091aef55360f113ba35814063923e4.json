{"references":[{"paperId":"3aaf88163e9e502daf5be57917470c30c63da6a6","externalIds":{"ArXiv":"2008.13015","DBLP":"journals/corr/abs-2008-13015","MAG":"3082881289","DOI":"10.1007/s11042-020-10382-x","CorpusId":221377169},"title":"Adaptive exploitation of pre-trained deep convolutional neural networks for robust visual tracking"},{"paperId":"842451bbece5958301283c9398139130643dcb73","externalIds":{"DBLP":"journals/corr/abs-2006-02597","MAG":"3033643005","ArXiv":"2006.02597","DOI":"10.1007/978-3-030-69532-3_36","CorpusId":219305183},"title":"COMET: Context-Aware IoU-Guided Network for Small Object Tracking"},{"paperId":"bc9679df3aa2632ad6615012a3154cc1f8f45403","externalIds":{"DBLP":"conf/cvpr/DuLZT20","MAG":"3035460038","DOI":"10.1109/cvpr42600.2020.00687","CorpusId":219963830},"title":"Correlation-Guided Attention for Corner Detection Based Visual Tracking"},{"paperId":"b03302d00dedd2ac8364ea41cd57a80df88d8b03","externalIds":{"MAG":"3035476980","DBLP":"conf/cvpr/GaoHL20","DOI":"10.1109/cvpr42600.2020.00741","CorpusId":219617542},"title":"Recursive Least-Squares Estimator-Aided Online Learning for Visual Tracking"},{"paperId":"c794eede1d0f4926dad822a1066f6ecdbba34e70","externalIds":{"DBLP":"conf/cvpr/ChenYZJXZJ20","MAG":"3035677743","DOI":"10.1109/cvpr42600.2020.01019","CorpusId":219630333},"title":"One-Shot Adversarial Attacks on Visual Tracking With Dual Attention"},{"paperId":"a45c6d3a6a765851f12797cd873c31b09ca75b80","externalIds":{"MAG":"3018195301","DBLP":"journals/tmm/LiFHZP21","DOI":"10.1109/TMM.2020.2990064","CorpusId":219004950},"title":"Intermittent Contextual Learning for Keyfilter-Aware UAV Object Tracking Using Deep Convolutional Feature"},{"paperId":"5eca15a355b2a9a1e80879e850afe49d3c398c53","externalIds":{"MAG":"3017087661","DBLP":"conf/cvpr/YuXHS20","ArXiv":"2004.06711","DOI":"10.1109/cvpr42600.2020.00676","CorpusId":215754230},"title":"Deformable Siamese Attention Networks for Visual Object Tracking"},{"paperId":"c2f098ad98aba65514f796d600d9bc920c623243","externalIds":{"DBLP":"journals/nca/Marvasti-ZadehG21","ArXiv":"2004.02933","MAG":"3016165628","DOI":"10.1007/s00521-020-05586-z","CorpusId":215238838},"title":"Efficient scale estimation methods using lightweight deep convolutional neural networks for visual tracking"},{"paperId":"dbb04a9b785f46e41f32165243e39bb75e7735e9","externalIds":{"ArXiv":"2004.02932","DBLP":"journals/corr/abs-2004-02932","MAG":"3015829703","CorpusId":215238859},"title":"Beyond Background-Aware Correlation Filters: Adaptive Context Modeling by Hand-Crafted and Deep RGB Features for Visual Tracking"},{"paperId":"2f37995ab4bd10172a1010ee8ed247278a4ba946","externalIds":{"DBLP":"journals/vc/Marvasti-ZadehG22","MAG":"3014173468","ArXiv":"2004.01382","DOI":"10.1007/s00371-021-02304-1","CorpusId":214794993},"title":"Effective Fusion of Deep Multitasking Representations for Robust Visual Tracking"},{"paperId":"af985dea540bd489397e7d28affa10f32a4d7167","externalIds":{"MAG":"3034617042","ArXiv":"2004.00830","DBLP":"journals/corr/abs-2004-00830","DOI":"10.1109/CVPR42600.2020.00632","CorpusId":214774780},"title":"Tracking by Instance Detection: A Meta-Learning Approach"},{"paperId":"e2e34b202363e4a46a14cd35fd4088d88b2e650e","externalIds":{"DBLP":"journals/tie/ChengZZZ20","MAG":"2943116006","DOI":"10.1109/TIE.2019.2913815","CorpusId":155242418},"title":"Visual Tracking via Auto-Encoder Pair Correlation Filter"},{"paperId":"96f149351f3bd932e8c79e1fb65207944410c518","externalIds":{"DBLP":"journals/tits/GaoJJG20","MAG":"2968127870","DOI":"10.1109/TITS.2019.2930337","CorpusId":202097053},"title":"Manifold Siamese Network: A Novel Visual Tracking ConvNet for Autonomous Vehicles"},{"paperId":"0619650ae0f698bcc38244a6858cc270df9dfaad","externalIds":{"DBLP":"journals/corr/abs-2003-12949","MAG":"3035466700","ArXiv":"2003.12949","DOI":"10.1109/CVPR42600.2020.01194","CorpusId":214714187},"title":"AutoTrack: Towards High-Performance Visual Tracking for UAV With Automatic Spatio-Temporal Regularization"},{"paperId":"6b6d31b022b7984a25fa9ee7fef64086ce7c464d","externalIds":{"MAG":"3013266062","DBLP":"journals/corr/abs-2003-12565","ArXiv":"2003.12565","DOI":"10.1109/cvpr42600.2020.00721","CorpusId":214693026},"title":"Probabilistic Regression for Visual Tracking"},{"paperId":"c9f8839c577746b75c25f76d3ce9ffbd46cc09ef","externalIds":{"MAG":"3034418285","DBLP":"conf/cvpr/YanWLY20","ArXiv":"2003.09595","DOI":"10.1109/CVPR42600.2020.00107","CorpusId":214611612},"title":"Cooling-Shrinking Attack: Blinding the Tracker With Imperceptible Noises"},{"paperId":"cce1fecc800d2782da638f3060d5b2e887739f74","externalIds":{"MAG":"3035571898","DBLP":"conf/cvpr/ChenZLZJ20","ArXiv":"2003.06761","DOI":"10.1109/cvpr42600.2020.00670","CorpusId":212725963},"title":"Siamese Box Adaptive Network for Visual Tracking"},{"paperId":"118b86a39eaf99a735130a12e2048105dfe7c3a6","externalIds":{"MAG":"3089861793","DBLP":"journals/corr/abs-2003-05326","ArXiv":"2003.05326","DOI":"10.1109/ICRA40945.2020.9197252","CorpusId":212657812},"title":"Training-Set Distillation for Real-Time UAV Object Tracking"},{"paperId":"9269b52994d8af23dc17dfbc225cd25c0902686c","externalIds":{"ArXiv":"2003.05218","DBLP":"journals/corr/abs-2003-05218","MAG":"3011843632","DOI":"10.1109/ICRA40945.2020.9196943","CorpusId":212657491},"title":"Keyfilter-Aware Real-Time UAV Object Tracking"},{"paperId":"b59e2c5e81a32781f3bbf88c0176df95c3a2f61c","externalIds":{"MAG":"2917610807","DBLP":"journals/tamd/WangZWY20","DOI":"10.1109/TCDS.2019.2900506","CorpusId":86788474},"title":"Memory Mechanisms for Discriminative Visual Tracking Algorithms With Deep Neural Networks"},{"paperId":"f7f5eb69fa79bf372dd468a0fb45e149bc6baef2","externalIds":{"DBLP":"conf/wacv/SongSU20","MAG":"3009969982","DOI":"10.1109/WACV45572.2020.9093613","CorpusId":214607549},"title":"Adaptive Aggregation of Arbitrary Online Trackers with a Regret Bound"},{"paperId":"5a1bf4170f4c2b1bc8e4bb70575b9cdf114fc934","externalIds":{"MAG":"3009281948","DBLP":"conf/wacv/ShuangHSC020","DOI":"10.1109/WACV45572.2020.9093517","CorpusId":214688391},"title":"Fine-Grained Motion Representation For Template-Free Visual Tracking"},{"paperId":"365244b73a1887fedc8d3b67ad0ca05300041893","externalIds":{"DBLP":"journals/sigpro/FuXLY20","MAG":"2977641159","DOI":"10.1016/j.sigpro.2019.107324","CorpusId":208017071},"title":"Surrounding-aware correlation filter for UAV tracking with selective spatial regularization"},{"paperId":"b205819fc48f3751138c0d23b8d0d0a8757686e8","externalIds":{"MAG":"3006062828","DBLP":"journals/nca/FuHLX20","DOI":"10.1007/s00521-020-04716-x","CorpusId":211067443},"title":"Robust multi-kernelized correlators for UAV tracking with adaptive context analysis and dynamic weighted filters"},{"paperId":"9e0f970e8667d512a0adffe66cd79b8216550c58","externalIds":{"MAG":"2906580494","DBLP":"journals/tcsv/HanWY20","DOI":"10.1109/TCSVT.2018.2888492","CorpusId":70213513},"title":"Adaptive Discriminative Deep Correlation Filter for Visual Object Tracking"},{"paperId":"a286e00f1927979e457eeeda4eabaef061a2a81b","externalIds":{"DBLP":"journals/tmm/ZhaKLZ20","MAG":"2950268230","DOI":"10.1109/TMM.2019.2922125","CorpusId":196205949},"title":"Deep Position-Sensitive Tracking"},{"paperId":"7633f6713119ad6a7b89786acb6c05e854a80cc8","externalIds":{"DBLP":"journals/tcsv/LiZCZC20","MAG":"2906516362","DOI":"10.1109/TCSVT.2018.2889457","CorpusId":58341840},"title":"Robust Visual Tracking via Hierarchical Particle Filter and Ensemble Deep Features"},{"paperId":"5664e24cacf3f6374c26b5597765099ee9537413","externalIds":{"DBLP":"journals/corr/abs-1912-08531","MAG":"2997896013","ArXiv":"1912.08531","DOI":"10.1609/AAAI.V34I07.6758","CorpusId":209404866},"title":"GlobalTrack: A Simple and Strong Baseline for Long-term Tracking"},{"paperId":"069ccdbab6ea6ca2d9c3b75c76360ca1e4e9a5e9","externalIds":{"DBLP":"conf/cvpr/VoigtlaenderLTL20","ArXiv":"1911.12836","MAG":"2990431089","DOI":"10.1109/cvpr42600.2020.00661","CorpusId":208512936},"title":"Siam R-CNN: Visual Tracking by Re-Detection"},{"paperId":"691c673ea67df5736ff17d86d27372f6298db38d","externalIds":{"MAG":"2989778648","ArXiv":"1911.08862","DBLP":"journals/corr/abs-1911-08862","DOI":"10.1109/cvpr42600.2020.00716","CorpusId":208175650},"title":"D3S – A Discriminative Single Shot Segmentation Tracker"},{"paperId":"c5faff3df88a076a2d339a56311c292d72dc3b32","externalIds":{"ArXiv":"1911.07959","MAG":"2991096577","DBLP":"journals/corr/abs-1911-07959","DOI":"10.1109/WACV48630.2021.00101","CorpusId":208158123},"title":"TracKlinic: Diagnosis of Challenge Factors in Visual Tracking"},{"paperId":"738165f33c50b059e87b14d8b4a129230e14eacd","externalIds":{"DBLP":"journals/corr/abs-1911-07241","ArXiv":"1911.07241","MAG":"2986265569","DOI":"10.1109/cvpr42600.2020.00630","CorpusId":208138555},"title":"SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking"},{"paperId":"0f8c3b653ff510e6f04a0195fa6aac91923bbffc","externalIds":{"DBLP":"journals/corr/abs-1910-10859","MAG":"3098582938","ArXiv":"1910.10859","DOI":"10.1109/TIP.2019.2940477","CorpusId":202689995,"PubMed":"31535994"},"title":"Aggregation Signature for Small Object Tracking"},{"paperId":"7d74c483561c985226d5c4ad498631f976ef681f","externalIds":{"MAG":"2903253065","DBLP":"journals/tase/ZhangSRL19","DOI":"10.1109/TASE.2018.2877499","CorpusId":58957263},"title":"Coarse-to-Fine UAV Target Tracking With Deep Reinforcement Learning"},{"paperId":"ae066f27f2edc1c51847ce4cb21b6e1a3db44fa2","externalIds":{"MAG":"2986235162","DBLP":"conf/iccv/HuangZH19","DOI":"10.1109/ICCV.2019.00410","CorpusId":208001827},"title":"Bridging the Gap Between Detection and Tracking: A Unified Approach"},{"paperId":"786577081e00d69eeac8e9612eaf2dad59765e73","externalIds":{"MAG":"2998027361","DBLP":"conf/iccvw/KristanBZRGBDDN19","DOI":"10.1109/ICCVW.2019.00276","CorpusId":207925044},"title":"The Seventh Visual Object Tracking VOT2019 Challenge Results"},{"paperId":"ef49671b06ae6657149ade58b86c3471c0a6357b","externalIds":{"MAG":"2995783658","DBLP":"conf/iccvw/TanL19","DOI":"10.1109/ICCVW.2019.00013","CorpusId":207895040},"title":"i-Siam: Improving Siamese Tracker with Distractors Suppression and Long-Term Strategies"},{"paperId":"47a58f8bec1d34004a7d7cf837e27a26de64f0f7","externalIds":{"MAG":"2972797657","DBLP":"journals/corr/abs-1909-06800","ArXiv":"1909.06800","DOI":"10.1109/ICCV.2019.00626","CorpusId":202578069},"title":"GradNet: Gradient-Guided Network for Visual Object Tracking"},{"paperId":"09b734072ad4f610478847c9cdc59a4a0c309b37","externalIds":{"DBLP":"journals/corr/abs-1909-01840","MAG":"2985509612","ArXiv":"1909.01840","DOI":"10.1109/ICCV.2019.00247","CorpusId":202539960},"title":"‘Skimming-Perusal’ Tracking: A Framework for Real-Time and Robust Long-Term Tracking"},{"paperId":"e03ec8474adfe2478a8594569c422501c1763a98","externalIds":{"ArXiv":"1909.00319","MAG":"3041795992","DBLP":"journals/corr/abs-1909-00319","DOI":"10.1109/ICCVW.2019.00026","CorpusId":202541492},"title":"Flow Guided Short-Term Trackers with Cascade Detection for Long-Term Tracking"},{"paperId":"770a74e86e7a39eec441d8af00e37329e247d2c8","externalIds":{"DBLP":"journals/corr/abs-1908-03701","ArXiv":"1908.03701","MAG":"2968578984","DOI":"10.1109/IROS40897.2019.8967674","CorpusId":199543536},"title":"Boundary Effect-Aware Visual Tracking for UAV with Online Enhanced Background Learning and Multi-Frame Consensus Verification"},{"paperId":"1b3a7e6ebd89a1fb03c992110952d7bddae3345a","externalIds":{"ArXiv":"1908.02231","DBLP":"conf/iccv/Huang0LLL19","MAG":"2964992886","DOI":"10.1109/ICCV.2019.00298","CorpusId":199453091},"title":"Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking"},{"paperId":"157ff6e216985911cc2f9775155d2a424ba2984b","externalIds":{"DBLP":"conf/iccv/ZhangGWDK19","MAG":"2987460522","ArXiv":"1908.00855","DOI":"10.1109/ICCV.2019.00411","CorpusId":199405431},"title":"Learning the Model Update for Siamese Trackers"},{"paperId":"7a96b5e56cd1a3964f22d0cb3a82eeddf331a5a5","externalIds":{"MAG":"2988310840","DBLP":"journals/corr/abs-1907-13242","ArXiv":"1907.13242","DOI":"10.1109/ICCV.2019.00804","CorpusId":199001006},"title":"Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking"},{"paperId":"e1cfc317da9268897cd8e9a594178ef63f6d5ddf","externalIds":{"DBLP":"conf/cvpr/Yang0HCC20","MAG":"3035257046","ArXiv":"1907.12006","DOI":"10.1109/cvpr42600.2020.00675","CorpusId":198967933},"title":"ROAM: Recurrently Optimizing Tracking Model"},{"paperId":"1ab3941a47c9c1aa4ddf7e7aa4ec28117fed0e03","externalIds":{"MAG":"2911996285","DBLP":"journals/ijon/LuNMY19","DOI":"10.1016/J.NEUCOM.2019.02.021","CorpusId":127287189},"title":"Learning transform-aware attentive network for object tracking"},{"paperId":"a85cceeded560c54b1d4b03df53c80aa93a562d5","externalIds":{"MAG":"2884930120","DBLP":"journals/tcsv/ZhaoWWT19","DOI":"10.1109/TCSVT.2018.2856540","CorpusId":69916863},"title":"Adversarial Deep Tracking"},{"paperId":"021d0c7013da519b508610064f264c76d768fdf1","externalIds":{"MAG":"2951339355","DBLP":"journals/tcsv/LiWSLPW19","DOI":"10.1109/TCSVT.2019.2923639","CorpusId":196212273},"title":"Real-Time Deep Tracking via Corrective Domain Adaptation"},{"paperId":"e5820233ea8abd27c81c0a83b1b782a9d4ca8db2","externalIds":{"MAG":"2955983623","DBLP":"conf/cvpr/Dai0LSL19","DOI":"10.1109/CVPR.2019.00480","CorpusId":198347261},"title":"Visual Tracking via Adaptive Spatially-Regularized Correlation Filters"},{"paperId":"53970ae69a73f547a56661fd25f6711746d277fb","externalIds":{"MAG":"2954137266","DBLP":"conf/cvpr/GaoZX19","DOI":"10.1109/CVPR.2019.00478","CorpusId":196700924},"title":"Graph Convolutional Tracking"},{"paperId":"e19ed7fe60638875d86e0284d7cd90766e26f7b1","externalIds":{"MAG":"3041754509","ArXiv":"1911.01668","DBLP":"journals/corr/abs-1911-01668","DOI":"10.1109/CVPR.2019.00593","CorpusId":192534743},"title":"ROI Pooled Correlation Filters for Visual Tracking"},{"paperId":"8e66c7e494476eb0dee846349df1bd705ceac6c3","externalIds":{"DBLP":"conf/cvpr/ChangLSSBHW0LRH19","MAG":"2983397630","ArXiv":"1911.02620","DOI":"10.1109/CVPR.2019.00895","CorpusId":198162846},"title":"Argoverse: 3D Tracking and Forecasting With Rich Maps"},{"paperId":"060239a69c0a975aaeb603630b40065acf3f8fde","externalIds":{"DBLP":"journals/tip/ZhongBLZF19","MAG":"2904531787","DOI":"10.1109/TIP.2018.2885238","CorpusId":54471994,"PubMed":"30530365"},"title":"Hierarchical Tracking by Reinforcement Learning-Based Searching and Coarse-to-Fine Verifying"},{"paperId":"2c8315ae713b3e27c6e9f291a158134d9c516166","externalIds":{"MAG":"3001584168","ArXiv":"1904.07220","DBLP":"journals/corr/abs-1904-07220","DOI":"10.1109/ICCV.2019.00628","CorpusId":118637813},"title":"Learning Discriminative Model Prediction for Tracking"},{"paperId":"503bafe063e410050c174fcc741e39b3b1e0eb22","externalIds":{"DBLP":"journals/corr/abs-1904-01772","MAG":"2951086918","ArXiv":"1904.01772","DOI":"10.1109/CVPR.2019.00146","CorpusId":102486909},"title":"Target-Aware Deep Tracking"},{"paperId":"8b6555c46a2d02e713dbd339e7ac7230ace5193f","externalIds":{"DBLP":"conf/cvpr/WangS0ZLL19","MAG":"2949357526","ArXiv":"1904.01828","DOI":"10.1109/CVPR.2019.00140","CorpusId":102487133},"title":"Unsupervised Deep Tracking"},{"paperId":"01ba7c8e78f145777ab7d9ebfe9a02729e624da4","externalIds":{"MAG":"2965236777","DOI":"10.1109/IranianCEE.2019.8786548","CorpusId":199490651},"title":"Rotation-Aware Discriminative Scale Space Tracking"},{"paperId":"511b6263795b8921e9f980b0ac7be5f6282337f6","externalIds":{"MAG":"2906772109","DBLP":"journals/ijon/TangLZHZ19","DOI":"10.1016/j.neucom.2018.12.035","CorpusId":67793052},"title":"Deep feature tracking based on interactive multiple model"},{"paperId":"a66c4c6ca597e5c61f4d8f60c5d695ffa6dd77bb","externalIds":{"DBLP":"journals/tip/GaoZX19","MAG":"2922332129","DOI":"10.1109/TIP.2019.2904434","CorpusId":78091135,"PubMed":"30872227"},"title":"SMART: Joint Sampling and Regression for Visual Tracking"},{"paperId":"64acdc8e9cf05d1ff42af86d216261c16362fd64","externalIds":{"MAG":"2903453900","DOI":"10.1109/JSEN.2018.2883593","CorpusId":59620627},"title":"Multi-Task Hierarchical Feature Learning for Real-Time Visual Tracking"},{"paperId":"9c92cec207554ce1f9608d5994eaaa2814933f2c","externalIds":{"MAG":"2895979306","DBLP":"journals/pr/ChenLSWYL19","DOI":"10.1016/j.patcog.2018.10.005","CorpusId":56487844},"title":"Multi attention module for visual tracking"},{"paperId":"059282edacac41b220f295b5ee1d376aa19871d8","externalIds":{"DBLP":"conf/cvpr/WangLXZ19","MAG":"2937749627","ArXiv":"1904.04452","DOI":"10.1109/CVPR.2019.00376","CorpusId":104291974},"title":"SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking"},{"paperId":"02fce4f407ef344bc6c78292126624c21fc45faa","externalIds":{"DBLP":"journals/tmm/HuMSSSP19","MAG":"2883108970","DOI":"10.1109/TMM.2018.2859831","CorpusId":59526182},"title":"Robust Object Tracking Using Manifold Regularized Convolutional Neural Networks"},{"paperId":"530c0e08362aceb66c226fa4379523820ef56ba3","externalIds":{"MAG":"2964423614","ArXiv":"1901.01660","DBLP":"conf/cvpr/ZhangP19","DOI":"10.1109/CVPR.2019.00472","CorpusId":57573771},"title":"Deeper and Wider Siamese Networks for Real-Time Visual Tracking"},{"paperId":"fec6fa9cc84a8885e396c584382a3f166674ba23","externalIds":{"DBLP":"journals/jvcir/LiWKXP19","MAG":"2901259746","DOI":"10.1016/J.JVCIR.2018.11.036","CorpusId":67753327},"title":"Learning target-aware correlation filters for visual tracking"},{"paperId":"d1a4135a2edd1af8a1e501109bbf7c2c720f10f8","externalIds":{"MAG":"2908174331","ArXiv":"1812.11703","DBLP":"journals/corr/abs-1812-11703","DOI":"10.1109/CVPR.2019.00441","CorpusId":57189581},"title":"SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks"},{"paperId":"f98be9a91dbf00b52a494720bd36be9c73a1210e","externalIds":{"DBLP":"conf/cvpr/FanL19","MAG":"2955747520","ArXiv":"1812.06148","DOI":"10.1109/CVPR.2019.00814","CorpusId":56305074},"title":"Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking"},{"paperId":"d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1","externalIds":{"MAG":"2955170442","ArXiv":"1812.05050","DBLP":"journals/corr/abs-1812-05050","DOI":"10.1109/CVPR.2019.00142","CorpusId":54475412},"title":"Fast Online Object Tracking and Segmentation: A Unifying Approach"},{"paperId":"d74169a8fd2f90a06480d1d583d0ae5e980ea951","externalIds":{"DBLP":"journals/corr/abs-1811-07628","MAG":"2901751835","ArXiv":"1811.07628","DOI":"10.1109/CVPR.2019.00479","CorpusId":53712235},"title":"ATOM: Accurate Tracking by Overlap Maximization"},{"paperId":"f7f8717963361dd1ab9b10862acc77d1a8898148","externalIds":{"ArXiv":"1811.03196","MAG":"2963794146","DBLP":"journals/tcsv/XieXHTZ20","DOI":"10.1109/TCSVT.2018.2889488","CorpusId":53207643},"title":"Correlation Filter Selection for Visual Tracking Using Reinforcement Learning"},{"paperId":"095336fe830166c63e3c7afdc89bf9f1c8260233","externalIds":{"MAG":"2962924865","ArXiv":"1811.02208","DBLP":"journals/corr/abs-1811-02208","DOI":"10.1007/978-3-030-20873-8_8","CorpusId":53236189},"title":"DSNet: Deep and Shallow Feature Learning for Efficient Visual Tracking"},{"paperId":"858ef81ea9558303a5d0b8cd57fc856036a9b68a","externalIds":{"MAG":"2905268474","DOI":"10.1109/GLOSIC.2018.8570061","CorpusId":54459943},"title":"Tracking of Moving Objects With Regeneration of Object Feature Points"},{"paperId":"9eb3584dc1193ea9192be8df6a3b57aebd3b8548","externalIds":{"MAG":"2898200825","DBLP":"journals/corr/abs-1810-11981","ArXiv":"1810.11981","DOI":"10.1109/TPAMI.2019.2957464","CorpusId":53102207,"PubMed":"31804928"},"title":"GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild"},{"paperId":"a8157f1d69979026ef78823e873a653a8600f8c9","externalIds":{"DBLP":"journals/spl/LiWKP18","MAG":"2896009640","DOI":"10.1109/LSP.2018.2877008","CorpusId":53626616},"title":"End-to-End Feature Integration for Correlation Filter Tracking With Channel Attention"},{"paperId":"914358f2703cf5b03b4516107ed1dfa868ab74f7","externalIds":{"MAG":"2963589976","DBLP":"journals/corr/abs-1810-05810","ArXiv":"1810.05810","DOI":"10.1007/978-3-030-20873-8_29","CorpusId":53113313},"title":"Efficient Multi-level Correlating for Visual Tracking"},{"paperId":"5c220558907b035bcbf61e3dab89c9128afae7f9","externalIds":{"MAG":"2890301062","ArXiv":"1810.03851","DBLP":"journals/corr/abs-1810-03851","CorpusId":52946129},"title":"Deep Attentive Tracking via Reciprocative Learning"},{"paperId":"a0e7d1add2b5b6454d80c62cf219f761bf477390","externalIds":{"DBLP":"conf/icip/0004XJS18","MAG":"2890472910","DOI":"10.1109/ICIP.2018.8451440","CorpusId":52191020},"title":"Generating Reliable Online Adaptive Templates for Visual Tracking"},{"paperId":"10bf437a339185b6f848270ef97c6342b61ddccf","externalIds":{"MAG":"2889607444","DBLP":"conf/icip/LinY18","DOI":"10.1109/ICIP.2018.8451826","CorpusId":52192258},"title":"Robust Visual Tracking in Low-Resolution Sequence"},{"paperId":"85a1ec62bbe3c781cafaeeb68662cfa76a4a3493","externalIds":{"DBLP":"conf/icip/MozhdehiRSM18","MAG":"2890381893","DOI":"10.1109/ICIP.2018.8451069","CorpusId":52192260},"title":"Deep Convolutional Particle Filter with Adaptive Correlation Maps for Visual Tracking"},{"paperId":"0e47a494cea9d18589639b0c2acf3b70cad7c835","externalIds":{"MAG":"2890730827","DBLP":"conf/icip/WangLLY18","DOI":"10.1109/ICIP.2018.8451324","CorpusId":52190500},"title":"Flow Guided Siamese Network for Visual Tracking"},{"paperId":"0f9e3fc917797ea0d43f0be34fc4690bcb3cd356","externalIds":{"DBLP":"conf/icip/CenJ18","MAG":"2890678738","DOI":"10.1109/ICIP.2018.8451102","CorpusId":52189492},"title":"Fully Convolutional Siamese Fusion Networks for Object Tracking"},{"paperId":"b73ae10a7b6a720c8710e5694c618385f7e04fbf","externalIds":{"MAG":"2889911734","DBLP":"conf/icip/DaiWYH18","DOI":"10.1109/ICIP.2018.8451332","CorpusId":52191940},"title":"Fusion of Template Matching and Foreground Detection for Robust Visual Tracking"},{"paperId":"b1c2cfaccb5ad1aadeac806a55821b74333a613a","externalIds":{"MAG":"2891962600","DBLP":"conf/icip/LiuL18","DOI":"10.1109/ICIP.2018.8451425","CorpusId":52186870},"title":"Integrating Multi-Level Convolutional Features for Correlation Filter Tracking"},{"paperId":"6d2658ed09d05101a15808a72d364f87a2046210","externalIds":{"DBLP":"conf/cbs/HaoZZLW18","MAG":"2910234817","DOI":"10.1109/CBS.2018.8612263","CorpusId":58674550},"title":"A Review of Target Tracking Algorithm Based on UAV"},{"paperId":"900ab48d25b44c076e31224b7befa503d9550c53","externalIds":{"MAG":"2954928776","DBLP":"journals/corr/abs-1809-07845","ArXiv":"1809.07845","DOI":"10.1109/CVPR.2019.00552","CorpusId":52350875},"title":"LaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking"},{"paperId":"3d372b63020c4d2c9510624f370b50d9f292bcde","externalIds":{"MAG":"2891378778","DBLP":"journals/corr/abs-1809-04320","ArXiv":"1809.04320","CorpusId":52196048},"title":"Learning regression and verification networks for long-term visual tracking"},{"paperId":"4b1965a54a064ac9145b1ce404fe33f0120c8ae3","externalIds":{"MAG":"2895588569","DBLP":"conf/eccv/ZhangWQWFL18","DOI":"10.1007/978-3-030-01240-3_22","CorpusId":52957957},"title":"Structured Siamese Network for Real-Time Visual Tracking"},{"paperId":"6b0422cb93bb3426ab480ffe2009ab16f5ee22ca","externalIds":{"MAG":"2895615633","DBLP":"conf/eccv/RenYLYZ18","DOI":"10.1007/978-3-030-01240-3_42","CorpusId":52954685},"title":"Deep Reinforcement Learning with Iterative Shift for Visual Tracking"},{"paperId":"fdb98f5a7015de0956ef8d4e468257dc3079b5e5","externalIds":{"MAG":"2894176037","DBLP":"conf/eccv/DongS18","DOI":"10.1007/978-3-030-01261-8_28","CorpusId":52959623},"title":"Triplet Loss in Siamese Network for Object Tracking"},{"paperId":"219e9a4527110baf1feb3df20db12064eeafdfb7","externalIds":{"DBLP":"conf/eccv/KristanLMFPZVBL18","MAG":"2913466142","DOI":"10.1007/978-3-030-11009-3_1","CorpusId":59222267},"title":"The Sixth Visual Object Tracking VOT2018 Challenge Results"},{"paperId":"ed84a17bd753d1ba9404131cff5186db4da6edd8","externalIds":{"MAG":"2912631173","DBLP":"conf/eccv/Rout0G18","DOI":"10.1007/978-3-030-11009-3_4","CorpusId":59159245},"title":"WAEF: Weighted Aggregation with Enhancement Filter for Visual Object Tracking"},{"paperId":"834baad9db5a1de1bfe993ff4a55a8a957eb9e0a","externalIds":{"MAG":"2913895053","DBLP":"conf/eccv/LeeCK18","DOI":"10.1007/978-3-030-11009-3_5","CorpusId":59158912},"title":"A Memory Model Based on the Siamese Network for Long-Term Tracking"},{"paperId":"bc10297534b275c87eac7297625e11509ef6f7b7","externalIds":{"MAG":"2912041066","DBLP":"conf/eccv/CheWLLZX18","DOI":"10.1007/978-3-030-11009-3_3","CorpusId":59159060},"title":"Channel Pruning for Visual Tracking"},{"paperId":"2088d93e7f4fa27b8498428d2ed64f144ab8cf3e","externalIds":{"DBLP":"conf/eccv/LuMNYRY18","MAG":"2897666265","DOI":"10.1007/978-3-030-01264-9_22","CorpusId":52036921},"title":"Deep Regression Tracking with Shrinkage Loss"},{"paperId":"29b263c42d4855ef2480eb516960e8d3a2902802","externalIds":{"DBLP":"conf/eccv/ChenWLWL18","MAG":"2894961023","DOI":"10.1007/978-3-030-01234-2_20","CorpusId":52952498},"title":"Real-Time 'Actor-Critic' Tracking"},{"paperId":"d867a1b599a5a99fa087d3c12a160ffb00dddfa7","externalIds":{"DBLP":"conf/eccv/Morimitsu18","MAG":"2914856999","DOI":"10.1007/978-3-030-11009-3_6","CorpusId":53697865},"title":"Multiple Context Features in Siamese Networks for Visual Object Tracking"},{"paperId":"73e7090d7ad8af42add824518772cd99d4048611","externalIds":{"MAG":"2911372736","DBLP":"conf/eccv/WenZDBLHLCLMNWW18","DOI":"10.1007/978-3-030-11021-5_28","CorpusId":59248943},"title":"VisDrone-SOT2018: The Vision Meets Drone Single-Object Tracking Challenge Results"},{"paperId":"3852738e4baa0a3bf57fb4e3d6d19435e764000e","externalIds":{"DBLP":"conf/eccv/ZhuWDBLHWNCLLMW18","MAG":"2913994632","DOI":"10.1007/978-3-030-11021-5_29","CorpusId":59249170},"title":"VisDrone-VDT2018: The Vision Meets Drone Video Detection and Tracking Challenge Results"},{"paperId":"cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad","externalIds":{"MAG":"2890447039","ArXiv":"1809.03327","DBLP":"journals/corr/abs-1809-03327","CorpusId":52181738},"title":"YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark"},{"paperId":"01f46bd91e053ce0c92af126bb87d7381a9fbe29","externalIds":{"DBLP":"conf/eccv/HeLTZ18","ArXiv":"1809.01368","MAG":"2950717291","DOI":"10.1007/978-3-030-11009-3_7","CorpusId":52165085},"title":"Towards a Better Match in Siamese Network Based Visual Object Tracker"},{"paperId":"d742fd19fe0dc8142e43705cb5b5fd166753b782","externalIds":{"DBLP":"journals/spic/DuLZT18","MAG":"2803146827","DOI":"10.1016/j.image.2018.05.013","CorpusId":51974816},"title":"Spatial-temporal adaptive feature weighted correlation filter for visual tracking"},{"paperId":"50003685fe0d72bd77eb675029da922f55b423bc","externalIds":{"MAG":"2953188310","DBLP":"conf/eccv/JungSBH18","ArXiv":"1808.08834","DOI":"10.1007/978-3-030-01225-0_6","CorpusId":52097928},"title":"Real-Time MDNet"},{"paperId":"776bc8955e801f6965e85b35d8e2dd6f2f1498ad","externalIds":{"MAG":"2886910176","DBLP":"journals/corr/abs-1808-06048","ArXiv":"1808.06048","DOI":"10.1007/978-3-030-01240-3_7","CorpusId":52045903},"title":"Distractor-aware Siamese Networks for Visual Object Tracking"},{"paperId":"77a2456c383443b372ebac692e146aa1bab80728","externalIds":{"DBLP":"journals/spic/CaoJZX18","MAG":"2800417485","DOI":"10.1016/J.IMAGE.2018.04.010","CorpusId":51969772},"title":"Learning spatio-temporal context via hierarchical features for visual tracking"},{"paperId":"7f75d4b462bd883f290461cdd8984f8cee6013ea","externalIds":{"MAG":"2886904239","DBLP":"conf/eccv/JiangLMXJ18","ArXiv":"1807.11590","DOI":"10.1007/978-3-030-01264-9_48","CorpusId":51888961},"title":"Acquisition of Localization Confidence for Accurate Object Detection"},{"paperId":"4b39e8494cf031b2b87c6bd5c65c2a2dfb02c531","externalIds":{"MAG":"2883782829","DBLP":"journals/iet-ipr/LiuJYCK18","DOI":"10.1049/iet-ipr.2018.5454","CorpusId":53014607},"title":"Occlusion-robust object tracking based on the confidence of online selected hierarchical features"},{"paperId":"58cee926e5d7b594d9973638c76b7c1639562c17","externalIds":{"MAG":"2895732080","DOI":"10.1109/MARSS.2018.8481231","CorpusId":52935478},"title":"Cell Tracking with Deep Learning and the Viterbi Algorithm"},{"paperId":"aa1679e90d060ada522c91d3171f73f5037a5337","externalIds":{"MAG":"2791697444","DBLP":"journals/ijon/BrunettiBTB18","DOI":"10.1016/j.neucom.2018.01.092","CorpusId":21707426},"title":"Computer vision and deep learning techniques for pedestrian detection and tracking: A survey"},{"paperId":"6683442ae358ae4261fdcde0164f83dd1ccd621b","externalIds":{"MAG":"2797812763","DBLP":"conf/cvpr/WangTXGHM18","DOI":"10.1109/CVPR.2018.00510","CorpusId":52061573},"title":"Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking"},{"paperId":"8a075b0ed920f650315020d1420231172fbe5ed2","externalIds":{"MAG":"2799148928","DBLP":"conf/cvpr/WangL0T18","DOI":"10.1109/CVPR.2018.00511","CorpusId":49476505},"title":"SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation"},{"paperId":"320d05db95ab42ade69294abe46cd1aca6aca602","externalIds":{"MAG":"2799058067","DBLP":"conf/cvpr/LiYWZH18","DOI":"10.1109/CVPR.2018.00935","CorpusId":52255840},"title":"High Performance Visual Tracking with Siamese Region Proposal Network"},{"paperId":"66b53fdbc752401f1a55986c0ea68acd463e5b5f","externalIds":{"DBLP":"conf/cvpr/DongSWL0P18","MAG":"2798520605","DOI":"10.1109/CVPR.2018.00061","CorpusId":52838265},"title":"Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning"},{"paperId":"9bdc71eacf7440bab8d2852f229da537498c9546","externalIds":{"DBLP":"journals/corr/abs-2012-12395","ArXiv":"2012.12395","MAG":"2798930779","DOI":"10.1109/CVPR.2018.00376","CorpusId":49366092},"title":"Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting with a Single Convolutional Net"},{"paperId":"a5278fc76eff08668bc1957b01b22eb627fa2c36","externalIds":{"DBLP":"conf/cvpr/WangZ0H0L18","MAG":"2798842862","DOI":"10.1109/CVPR.2018.00509","CorpusId":51993386},"title":"Multi-cue Correlation Filters for Robust Visual Tracking"},{"paperId":"1975bee228ac228df235d20777e32331bb21566d","externalIds":{"ArXiv":"1805.08982","DBLP":"journals/pr/LiLLZT19","MAG":"2958507350","DOI":"10.1016/J.PATCOG.2019.106977","CorpusId":43942930},"title":"RGB-T Object Tracking: Benchmark and Baseline"},{"paperId":"1855818c492d5f42dbe14814e4dd9b5733d54790","externalIds":{"MAG":"2804764393","DBLP":"journals/spl/PengLYK18","DOI":"10.1109/LSP.2018.2836360","CorpusId":46964620},"title":"Densely Connected Discriminative Correlation Filters for Visual Tracking"},{"paperId":"1fc9ec9246e40814063749f6821fc11106ecaae5","externalIds":{"DBLP":"journals/jvcir/GanLWK18","MAG":"2794707193","DOI":"10.1016/J.JVCIR.2018.03.016","CorpusId":13687335},"title":"Online object tracking via motion-guided convolutional neural network (MGNet)"},{"paperId":"d922b4f4076981bf91baa29131093bfda50a81ff","externalIds":{"DBLP":"journals/spic/KuaiWL18","MAG":"2791187890","DOI":"10.1016/J.IMAGE.2018.03.002","CorpusId":4947797},"title":"When correlation filters meet fully-convolutional Siamese networks for distractor-aware tracking"},{"paperId":"3f0da079ac950a4dfb699c41a90c087000e6ac38","externalIds":{"MAG":"2798770428","DBLP":"journals/corr/abs-1804-08965","ArXiv":"1804.08965","DOI":"10.1109/CVPR.2018.00058","CorpusId":5086087},"title":"Correlation Tracking via Joint Discrimination and Reliability Learning"},{"paperId":"3275944117b43cc44beebe7c82bffc13ec8cb0fa","externalIds":{"DBLP":"journals/corr/abs-1804-07056","MAG":"2798187154","ArXiv":"1804.07056","CorpusId":4991391},"title":"Now you see me: evaluating performance in long-term visual tracking"},{"paperId":"0eb1b75b98d4f4f69a5fb7669ad86d85cdd76848","externalIds":{"MAG":"2797257757","DBLP":"journals/corr/abs-1804-06833","ArXiv":"1804.06833","DOI":"10.1007/978-3-030-01216-8_30","CorpusId":4932842},"title":"Unveiling the Power of Deep Tracking"},{"paperId":"7cbad516a393ca808d6bb30e2b49cc82628af1e5","externalIds":{"MAG":"2950278217","DBLP":"journals/corr/abs-1804-04273","ArXiv":"1804.04273","DOI":"10.1109/CVPR.2018.00937","CorpusId":4803532},"title":"VITAL: VIsual Tracking via Adversarial Learning"},{"paperId":"e4a29c578af5067c0944c242b40531647d6ba5c6","externalIds":{"MAG":"2963634461","ArXiv":"1804.01771","DBLP":"conf/eccv/BurceanuL18","DOI":"10.1007/978-3-030-11009-3_9","CorpusId":4603031},"title":"Learning a Robust Society of Tracking Parts using Co-occurrence Constraints"},{"paperId":"26e2ca763087be09e3799ad294302aa91077942d","externalIds":{"MAG":"2767302379","DBLP":"journals/pr/LiWWL18","DOI":"10.1016/j.patcog.2017.11.007","CorpusId":29498806},"title":"Deep visual tracking: Review and experimental comparison"},{"paperId":"d56031beb07dc253eadc89ede2217c14b383f577","externalIds":{"DBLP":"journals/corr/abs-1803-10537","MAG":"2962959267","ArXiv":"1803.10537","DOI":"10.1109/CVPR.2018.00057","CorpusId":4319958},"title":"Context-Aware Deep Feature Compression for High-Speed Visual Tracking"},{"paperId":"8c11e517c2c028d63bc70c7d90c6b3d3ab805b1b","externalIds":{"DBLP":"conf/eccv/MullerBGAG18","ArXiv":"1803.10794","MAG":"2950006892","DOI":"10.1007/978-3-030-01246-5_19","CorpusId":4455970},"title":"TrackingNet: A Large-Scale Dataset and Benchmark for Object Tracking in the Wild"},{"paperId":"a213bbf9740854a276fdf71dad8f30cfbe3ea4d4","externalIds":{"ArXiv":"1804.00518","DBLP":"conf/eccv/DuQYYDLZHT18","MAG":"2950636517","DOI":"10.1007/978-3-030-01249-6_23","CorpusId":4560536},"title":"The Unmanned Aerial Vehicle Benchmark: Object Detection and Tracking"},{"paperId":"ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7","externalIds":{"MAG":"2794669410","DBLP":"conf/eccv/ValmadreBHTVSTG18","ArXiv":"1803.09502","DOI":"10.1007/978-3-030-01219-9_41","CorpusId":4305586},"title":"Long-term Tracking in the Wild: A Benchmark"},{"paperId":"9f45b55af027503fab557f55f70e81e43c6c1db7","externalIds":{"MAG":"2951286568","ArXiv":"1803.08679","DBLP":"journals/corr/abs-1803-08679","DOI":"10.1109/CVPR.2018.00515","CorpusId":4321186},"title":"Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking"},{"paperId":"9206bd299a8c058c5ea089e9b002235c7b974530","externalIds":{"DBLP":"journals/tip/GaoZYX18","MAG":"2790441826","DOI":"10.1109/TIP.2018.2813166","CorpusId":4568981,"PubMed":"29994065"},"title":"P2T: Part-to-Target Tracking via Deep Regression Learning"},{"paperId":"82b8146c62c621f0b3a36939a590ba2ffa450046","externalIds":{"DBLP":"journals/tnn/YunCYYC18","MAG":"2794109133","DOI":"10.1109/TNNLS.2018.2801826","CorpusId":21704120,"PubMed":"29771675"},"title":"Action-Driven Visual Object Tracking With Deep Reinforcement Learning"},{"paperId":"e5dedbbaa6f7111318a7381bc66d07f2eedc85d8","externalIds":{"MAG":"2801922425","DOI":"10.1109/INFOCT.2018.8356856","CorpusId":13713538},"title":"A novel strategy for kernel-based small target tracking against varying illumination with multiple features fusion"},{"paperId":"a3a4471e82260f573d240cc34aeff431cf236571","externalIds":{"MAG":"2787941778","ArXiv":"1802.08817","DBLP":"conf/cvpr/HeLTZ18","DOI":"10.1109/CVPR.2018.00508","CorpusId":3520436},"title":"A Twofold Siamese Network for Real-Time Object Tracking"},{"paperId":"5ae09141458cde3dfd7630f9c26b9b7894479b92","externalIds":{"ArXiv":"1802.03098","DBLP":"journals/corr/abs-1802-03098","MAG":"2787746963","CorpusId":41502497},"title":"Tracking Noisy Targets: A Review of Recent Object Tracking Approaches"},{"paperId":"911cf0e743c5af4029d37f1348b3717401922beb","externalIds":{"MAG":"2787237028","DBLP":"journals/mta/LuoYWW18","DOI":"10.1007/s11042-018-5728-8","CorpusId":3228558},"title":"Pedestrian tracking in surveillance video based on modified CNN"},{"paperId":"5f1141287c577f2e45f8c35a5fd30cfb91311257","externalIds":{"MAG":"2964186069","ArXiv":"1802.01483","DBLP":"conf/icml/LiGD18","CorpusId":3603048},"title":"Explicit Inductive Bias for Transfer Learning with Convolutional Networks"},{"paperId":"c37e16dd3b6ab6808b7f622addd27a494096f482","externalIds":{"MAG":"2953053233","ArXiv":"1801.10496","DBLP":"journals/corr/abs-1801-10496","DOI":"10.1109/TIP.2019.2904789","CorpusId":6139664,"PubMed":"30892205"},"title":"Parallel Tracking and Verifying"},{"paperId":"50c60583dc0ef09484358deab329f82ee22c2b66","externalIds":{"MAG":"2783173047","ArXiv":"1801.03049","DBLP":"journals/corr/abs-1801-03049","DOI":"10.1007/978-3-030-01219-9_35","CorpusId":4003481},"title":"Meta-Tracker: Fast and Robust Online Adaptation for Visual Object Trackers"},{"paperId":"3aa673abd49f0837ed2fbf5cffcada9ba6f48693","externalIds":{"ArXiv":"1801.01423","DBLP":"journals/corr/abs-1801-01423","MAG":"2963813679","CorpusId":2157345},"title":"Overcoming catastrophic forgetting with hard attention to the task"},{"paperId":"ee9596725d1db17f2b1e2207dd3ea260343bfe4f","externalIds":{"MAG":"2782436561","DBLP":"journals/sensors/LuoHF18","PubMedCentral":"5796336","DOI":"10.3390/s18010112","CorpusId":3498240,"PubMed":"29301318"},"title":"Underwater Acoustic Target Tracking: A Review"},{"paperId":"6cbc9a49e920231887604e3c3a018a9f2fdbd5e0","externalIds":{"MAG":"2947900225","DBLP":"conf/iccv/ChoiKL19","DOI":"10.1109/ICCV.2019.00100","CorpusId":173188328},"title":"Deep Meta Learning for Real-Time Target-Aware Visual Tracking"},{"paperId":"19d6b9725a59f4b624205829d5f03ac893ca1367","externalIds":{"DBLP":"journals/corr/abs-1712-01358","MAG":"2953565103","ArXiv":"1712.01358","DOI":"10.1007/978-3-030-20890-5_40","CorpusId":4100681},"title":"Long-Term Visual Object Tracking Benchmark"},{"paperId":"1131c53b9baaa740a4deef4c1282821b23d18687","externalIds":{"DBLP":"conf/iccvw/ZhuHZDH17","MAG":"2770266208","ArXiv":"1711.04661","DOI":"10.1109/ICCVW.2017.231","CorpusId":4727713},"title":"UCT: Learning Unified Convolutional Networks for Real-Time Visual Tracking"},{"paperId":"7ccbb845829234548bfa9b24c61297b4f0cd678e","externalIds":{"MAG":"2765505794","DBLP":"conf/cvpr/ZhuWZY18","ArXiv":"1711.01124","DOI":"10.1109/CVPR.2018.00064","CorpusId":3579521},"title":"End-to-End Flow Correlation Tracking with Spatial-Temporal Attention"},{"paperId":"c4345b74141c824caf0b44e6c9cadac273787d29","externalIds":{"MAG":"2768005784","DBLP":"conf/iccvw/RisseMWP17","DOI":"10.1109/ICCVW.2017.335","CorpusId":4728161},"title":"Visual Tracking of Small Animals in Cluttered Natural Environments Using a Freely Moving Camera"},{"paperId":"7b5be0cdec2a1b36cd8b61d161cff716b3594846","externalIds":{"PubMedCentral":"5777536","MAG":"2758694956","DOI":"10.1038/nmeth.4473","CorpusId":205427260,"PubMed":"29083403"},"title":"An Objective Comparison of Cell Tracking Algorithms"},{"paperId":"7574b7e5a75fdd338c27af5aeb77ab79460c4437","externalIds":{"MAG":"2776035257","DBLP":"conf/iccv/Guo0ZHWW17","DOI":"10.1109/ICCV.2017.196","CorpusId":8689055},"title":"Learning Dynamic Siamese Network for Visual Object Tracking"},{"paperId":"a9c800bcb05fa64910233cc01b860d41bc3b9dff","externalIds":{"MAG":"2776581970","DBLP":"conf/iccv/TengXWLFJ17","DOI":"10.1109/ICCV.2017.130","CorpusId":1762187},"title":"Robust Object Tracking Based on Temporal and Spatial Deep Networks"},{"paperId":"a102c524b2bdc3c1f9377a5ea079d47783d636c6","externalIds":{"DBLP":"conf/iccvw/HeFZDB17","MAG":"2768634781","DOI":"10.1109/ICCVW.2017.233","CorpusId":4756690},"title":"Correlation Filters with Weighted Convolution Responses"},{"paperId":"096710211d9e4eb77dc2d0f11a7ff818c8acc5ff","externalIds":{"MAG":"2752271432","DBLP":"journals/spl/GuoX17","DOI":"10.1109/LSP.2017.2749458","CorpusId":40569833},"title":"Deep Ensemble Tracking"},{"paperId":"53329e5c79c1128c7b252a12b182c472a3413bfa","externalIds":{"DBLP":"conf/iccvw/KristanLMFPZVHL17","MAG":"2917435394","DOI":"10.1109/ICCVW.2017.230","CorpusId":111386749},"title":"The Visual Object Tracking VOT2017 Challenge Results"},{"paperId":"650ff51384273e52bdc9f3d1d8a27a3910c9b446","externalIds":{"MAG":"2963571423","DBLP":"conf/iccvw/LiYLZZY17","ArXiv":"1710.02039","DOI":"10.1109/ICCVW.2017.234","CorpusId":4341649},"title":"Integrating Boundary and Center Correlation Filters for Visual Tracking with Aspect Ratio Variation"},{"paperId":"de10c2806f7c5dce2381435546d95435ea362e37","externalIds":{"MAG":"2514029627","DBLP":"journals/tcyb/ZhangS17","DOI":"10.1109/TCYB.2016.2588526","CorpusId":3409078,"PubMed":"27542188"},"title":"Visual Tracking With Convolutional Random Vector Functional Link Network"},{"paperId":"b8897e109ef6d81fa7dfb19fb65d03919c221656","externalIds":{"MAG":"2754738919","DBLP":"conf/icip/DaiWY17","DOI":"10.1109/ICIP.2017.8296961","CorpusId":3389814},"title":"Long-term object tracking based on siamese network"},{"paperId":"4d833043e1efc406e9d08196bc04e80da582395f","externalIds":{"DBLP":"conf/icip/KokulFSRP17","MAG":"2755780177","DOI":"10.1109/ICIP.2017.8296753","CorpusId":3484364},"title":"Gate connected convolutional neural network for object tracking"},{"paperId":"f24015a365ea2454391c285cd30b8ae723dbb05e","externalIds":{"MAG":"2790476930","DBLP":"conf/icip/WangLLPW17","DOI":"10.1109/ICIP.2017.8296363","CorpusId":3393944},"title":"Deep tracking with objectness"},{"paperId":"164f26c3064f9cc400befe52c920eaca33060b74","externalIds":{"DBLP":"journals/ijon/ZhangZHCK17","MAG":"2587403786","DOI":"10.1016/j.neucom.2016.10.073","CorpusId":35124206},"title":"Online object tracking based on CNN with spatial-temporal saliency guided sampling"},{"paperId":"76f4df26ff119388fd4dbb4603bcba0d0bf1a5f1","externalIds":{"DBLP":"conf/icip/XuMCC17","MAG":"2789536546","DOI":"10.1109/ICIP.2017.8296462","CorpusId":3456774},"title":"Siamese recurrent architecture for visual tracking"},{"paperId":"358ead99d9c9237a361929a2530b2d8526929c9b","externalIds":{"DBLP":"conf/icip/MozhdehiM17","MAG":"2791225467","DOI":"10.1109/ICIP.2017.8296963","CorpusId":3412424},"title":"Deep convolutional particle filter for visual tracking"},{"paperId":"b14d60dabe24938e8efe86d03444ed7bb4a4976d","externalIds":{"DBLP":"conf/icip/YangJWW17","MAG":"2791997040","DOI":"10.1109/ICIP.2017.8296746","CorpusId":3446678},"title":"Region-based fully convolutional siamese networks for robust real-time visual tracking"},{"paperId":"db5918831159c5500d78cf88599392bf0203945a","externalIds":{"MAG":"2791551176","DBLP":"conf/icip/AkokGKG17","DOI":"10.1109/ICIP.2017.8296966","CorpusId":3454148},"title":"Robust object tracking by interleaving variable rate color particle filtering and deep learning"},{"paperId":"db39754bde43c5555d7086261d1a6fd55af7de06","externalIds":{"ArXiv":"1708.03874","DBLP":"journals/corr/abs-1708-03874","MAG":"2951091420","DOI":"10.1109/ICCVW.2017.235","CorpusId":647942},"title":"Recurrent Filter Learning for Visual Tracking"},{"paperId":"3281c2fa244834400c970f33a20aa1fb0ca2f53d","externalIds":{"MAG":"2743941897","ArXiv":"1708.02973","DBLP":"journals/corr/abs-1708-02973","DOI":"10.1109/ICCV.2017.21","CorpusId":25011406},"title":"Learning Policies for Adaptive Tracking with Deep Feature Cascades"},{"paperId":"c2046fc4744a9d358ea7a8e9c21c92fd58df7a64","externalIds":{"MAG":"2949764466","ArXiv":"1708.00225","DBLP":"conf/iccv/SongMGZL017","DOI":"10.1109/ICCV.2017.279","CorpusId":1713491},"title":"CREST: Convolutional Residual Learning for Visual Tracking"},{"paperId":"fb49a45f5263e7c86aaa28b8e3ce839444698737","externalIds":{"MAG":"2949714673","DBLP":"conf/iccv/FanL17","ArXiv":"1708.00153","DOI":"10.1109/ICCV.2017.585","CorpusId":23893160},"title":"Parallel Tracking and Verifying: A Framework for Real-Time and High Accuracy Visual Tracking"},{"paperId":"f2c050fa106b2e6f27d32e21e75ecbdb0cc75f67","externalIds":{"DBLP":"conf/cvpr/ChoiCYFDC17","MAG":"2610871254","DOI":"10.1109/CVPR.2017.513","CorpusId":32367668},"title":"Attentional Correlation Filter Network for Adaptive Visual Tracking"},{"paperId":"142078e0715c5a430b4f89a2418251b9b8ce2fa3","externalIds":{"DBLP":"conf/cvpr/ZhangVSAM17","MAG":"2748261474","DOI":"10.1109/CVPR.2017.617","CorpusId":10603765},"title":"Robust Visual Tracking Using Oblique Random Forests"},{"paperId":"2bfba2bb4a1d30d25bcd65bcc664c644ed268ee1","externalIds":{"DBLP":"conf/cvpr/HanSA17","MAG":"2737572441","DOI":"10.1109/CVPR.2017.63","CorpusId":21042607},"title":"BranchOut: Regularization for Online Ensemble Tracking with Convolutional Neural Networks"},{"paperId":"a9607714002b5debc0cf7b96a3def0cc6a005198","externalIds":{"MAG":"2950976574","ArXiv":"1707.04991","DBLP":"conf/iccv/SupancicR17","DOI":"10.1109/ICCV.2017.43","CorpusId":13961372},"title":"Tracking as Online Decision-Making: Learning a Policy from Streaming Videos with Reinforcement Learning"},{"paperId":"f233c16a87d518bfe9f923ea7af48ed3eb6bb7d5","externalIds":{"MAG":"2950064029","DBLP":"journals/corr/MaHY017a","ArXiv":"1707.03816","DOI":"10.1109/TPAMI.2018.2865311","CorpusId":22947351,"PubMed":"30106709"},"title":"Robust Visual Tracking via Hierarchical Convolutional Features"},{"paperId":"7a078987c929b1aef72f4ca283dddef187c48132","externalIds":{"MAG":"3103989907","ArXiv":"1707.02309","DBLP":"journals/ijcv/MaHYY18","DOI":"10.1007/s11263-018-1076-4","CorpusId":4340068},"title":"Adaptive Correlation Filters with Long-Term and Short-Term Memory for Object Tracking"},{"paperId":"0a400fd7f0ee28694889baaa4faef150b6912dfa","externalIds":{"MAG":"2885238544","CorpusId":70327477},"title":"An In-Depth Analysis of Visual Tracking with Siamese Neural Networks"},{"paperId":"96dc41d3b004fd4c7f96b71b4e174beb3088b2bb","externalIds":{"MAG":"2738318237","DBLP":"conf/cvpr/YunCYYC17","DOI":"10.1109/CVPR.2017.148","CorpusId":19219023},"title":"Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning"},{"paperId":"d34ab5269af57e3f57c7b8e41ad5bb51b82cd49f","externalIds":{"MAG":"2742165450","DBLP":"conf/cvpr/ZhangX017","DOI":"10.1109/CVPR.2017.512","CorpusId":24234237},"title":"Multi-task Correlation Particle Filter for Robust Object Tracking"},{"paperId":"5028fccc09ca12e0a65df99dbb4e01c51d42dc7f","externalIds":{"DBLP":"conf/cvpr/YeoSHH17","MAG":"2734938207","DOI":"10.1109/CVPR.2017.62","CorpusId":30132037},"title":"Superpixel-Based Tracking-by-Segmentation Using Markov Chains"},{"paperId":"73bfe7a27e63a1308d667a3b6c2e5ba3c2a7c5bf","externalIds":{"MAG":"2673818281","ArXiv":"1706.07457","DBLP":"journals/corr/SunL017","DOI":"10.1109/CVPR.2018.00934","CorpusId":1665250},"title":"Learning Spatial-Aware Regressions for Visual Tracking"},{"paperId":"182732d0b604aedf16f2973f7be075b5017118ad","externalIds":{"MAG":"2621728955","DBLP":"journals/ejasp/HouWHMYH17","DOI":"10.1186/S13634-017-0482-Z","CorpusId":20143699},"title":"Human tracking over camera networks: a review"},{"paperId":"6c53ce986e620cb058865d4ebd6aaa9785a50bdc","externalIds":{"DBLP":"journals/cviu/ManafifardEM17","MAG":"2584665002","DOI":"10.1016/j.cviu.2017.02.002","CorpusId":24788299},"title":"A survey on player tracking in soccer videos"},{"paperId":"3bce27dd4e56224c84c2716e0d829b6e0e072120","externalIds":{"DBLP":"journals/corr/Cehovin17","ArXiv":"1705.04469","MAG":"2589631999","DOI":"10.1016/j.neucom.2017.02.036","CorpusId":28179381},"title":"TraX: The visual Tracking eXchange protocol and library"},{"paperId":"388d29f001411ff80650f80cf197afc440d98b51","externalIds":{"DBLP":"journals/tip/GundogduA18","ArXiv":"1704.06326","MAG":"3101525822","DOI":"10.1109/TIP.2018.2806280","CorpusId":3805125,"PubMed":"29994635"},"title":"Good Features to Correlate for Visual Tracking"},{"paperId":"000178cd12c8a6e5da8215b6365fae03c20fd18d","externalIds":{"ArXiv":"1704.06036","DBLP":"conf/cvpr/ValmadreBHVT17","MAG":"2962824803","DOI":"10.1109/CVPR.2017.531","CorpusId":10520310},"title":"End-to-End Representation Learning for Correlation Filter Based Tracking"},{"paperId":"5404718135548b01516a668e0c022c5cb22b422e","externalIds":{"MAG":"2605381261","DBLP":"journals/jcst/HuWGLM24","ArXiv":"1704.04057","DOI":"10.1007/s11390-023-3788-3","CorpusId":14444857},"title":"DCFNet: Discriminant Correlation Filters Network for Visual Tracking"},{"paperId":"552a06c09c49a91956e0bb3a69d7aae688dbcfd0","externalIds":{"MAG":"2579238278","DBLP":"journals/tip/GaoZYX17","DOI":"10.1109/TIP.2017.2656628","CorpusId":16402511,"PubMed":"28113343"},"title":"Deep Relative Tracking"},{"paperId":"2f62e40170265ffb1d0c79b6539d71457456880b","externalIds":{"MAG":"2550458994","DBLP":"journals/ivc/HeMGY17","DOI":"10.1016/j.imavis.2016.11.010","CorpusId":29746480},"title":"Cell tracking using deep neural networks with multi-task learning"},{"paperId":"703505a00579c0aa67712836acc41d94fa6d6edc","externalIds":{"MAG":"2605173812","DBLP":"journals/corr/GaloogahiFHRL17","ArXiv":"1703.05884","DOI":"10.1109/ICCV.2017.128","CorpusId":9857301},"title":"Need for Speed: A Benchmark for Higher Frame Rate Object Tracking"},{"paperId":"ece7625a346edbc5f6fab541c0c246ec06939121","externalIds":{"DBLP":"journals/corr/WangLH17","ArXiv":"1703.05020","MAG":"2951297236","DOI":"10.1109/CVPR.2017.510","CorpusId":3075532},"title":"Large Margin Object Tracking with Circulant Feature Maps"},{"paperId":"01c40508dcb6f8e9efcdefe49e22bc0ccaf8881c","externalIds":{"MAG":"2949607263","DBLP":"journals/corr/GaloogahiFL17","ArXiv":"1703.04590","DOI":"10.1109/ICCV.2017.129","CorpusId":15665411},"title":"Learning Background-Aware Correlation Filters for Visual Tracking"},{"paperId":"c889d6f98e6d79b89c3a6adf8a921f88fa6ba518","externalIds":{"MAG":"2604763608","DBLP":"journals/corr/FinnAL17","ArXiv":"1703.03400","CorpusId":6719686},"title":"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"},{"paperId":"4cbe61862bb95fc99293c24d6e02afcb50a05461","externalIds":{"DBLP":"journals/cviu/ChoiKL18","MAG":"2809375916","DOI":"10.1016/J.CVIU.2018.05.009","CorpusId":57375100},"title":"Real-time visual tracking by deep reinforced decision making"},{"paperId":"6ebc40a061433c24a3ea1f305bb6533b8f3dd5f4","externalIds":{"DBLP":"conf/aaai/LiY17","MAG":"2604701225","DOI":"10.1609/aaai.v31i1.11205","CorpusId":12949500},"title":"Visual Object Tracking for Unmanned Aerial Vehicles: A Benchmark and New Motion Models"},{"paperId":"991544f9333296a7d9e5b9751bca932bb68f54e1","externalIds":{"ArXiv":"1702.00824","MAG":"2592463526","DBLP":"journals/corr/RealSMPV17","DOI":"10.1109/CVPR.2017.789","CorpusId":7705765},"title":"YouTube-BoundingBoxes: A Large High-Precision Human-Annotated Data Set for Object Detection in Video"},{"paperId":"14b4127ef56f57eab19bb48d80ec169e7b1be944","externalIds":{"MAG":"2584265939","ArXiv":"1701.08936","DBLP":"journals/corr/ZhangMWW17","CorpusId":4308445},"title":"Deep Reinforcement Learning for Visual Object Tracking in Videos"},{"paperId":"572ecd0208e7c7b2ae0ba1a437dfc67eb8ea2458","externalIds":{"MAG":"2562852216","ArXiv":"1612.06053","DBLP":"journals/corr/ChiLL016","DOI":"10.1109/TIP.2017.2669880","CorpusId":16222565,"PubMed":"28212087"},"title":"Dual Deep Network for Visual Tracking"},{"paperId":"2a94c84383ee3de5e6211d43d16e7de387f68878","externalIds":{"ArXiv":"1612.03144","DBLP":"conf/cvpr/LinDGHHB17","MAG":"2565639579","DOI":"10.1109/CVPR.2017.106","CorpusId":10716717},"title":"Feature Pyramid Networks for Object Detection"},{"paperId":"2e7e3b4eb8bc0a7f29ca560b1cceb986a1dcd977","externalIds":{"MAG":"2576085163","ArXiv":"1612.06615","DBLP":"conf/icpr/GladhDKF16","DOI":"10.1109/ICPR.2016.7899807","CorpusId":12238230},"title":"Deep motion features for visual tracking"},{"paperId":"be991a3564b963e86b9529772e1f24ccaf987ad3","externalIds":{"MAG":"2609561199","DBLP":"conf/icpr/XiaoY16","DOI":"10.1109/ICPR.2016.7900048","CorpusId":36368641},"title":"Efficient tracking with distinctive target colors and silhouette"},{"paperId":"a87cc499cf101b3697cacc65094b4b6590e0d061","externalIds":{"MAG":"2557641257","ArXiv":"1611.09224","DBLP":"conf/cvpr/DanelljanBKF17","DOI":"10.1109/CVPR.2017.733","CorpusId":14958161},"title":"ECO: Efficient Convolution Operators for Tracking"},{"paperId":"8cc3651488e02d51fa5ae8d3563b346e9e370f5a","externalIds":{"DBLP":"journals/ijcv/LukezicVZMK18","MAG":"2781948176","ArXiv":"1611.08461","DOI":"10.1007/s11263-017-1061-3","CorpusId":47346364},"title":"Discriminative Correlation Filter Tracker with Channel and Spatial Reliability"},{"paperId":"bc4cfc075e406f9f5c621fe27a3e0002eec4a8b3","externalIds":{"DBLP":"journals/corr/FanL16a","MAG":"2556108308","ArXiv":"1611.06878","DOI":"10.1109/CVPRW.2017.275","CorpusId":6583681},"title":"SANet: Structure-Aware Network for Visual Tracking"},{"paperId":"de4ee92cfad3734ca820d004bc9ee75fc9dcfbf4","externalIds":{"DBLP":"conf/cvpr/LinMSR17","MAG":"2951402970","ArXiv":"1611.06612","DOI":"10.1109/CVPR.2017.549","CorpusId":5696978},"title":"RefineNet: Multi-path Refinement Networks for High-Resolution Semantic Segmentation"},{"paperId":"4f351f3718c6527c3d8121e22fe7a9c4f31bb5d9","externalIds":{"DBLP":"conf/itsc/GiraoAPN16","MAG":"2565096009","DOI":"10.1109/ITSC.2016.7795523","CorpusId":16213007},"title":"3D object tracking in driving environment: A short review and a benchmark dataset"},{"paperId":"6179ac06f1a8fd1ac6b693b02824948dff438d54","externalIds":{"MAG":"2916780012","DBLP":"conf/eccv/KristanLMFPCVHL16","DOI":"10.1007/978-3-319-48881-3_54","CorpusId":2519672},"title":"The Visual Object Tracking VOT2016 Challenge Results"},{"paperId":"27850781e39df9f750e05409b8072261124068e8","externalIds":{"MAG":"2518876086","DBLP":"conf/eccv/MuellerSG16","DOI":"10.1007/978-3-319-46448-0_27","CorpusId":10184155},"title":"A Benchmark and Simulator for UAV Tracking"},{"paperId":"ce8c76bfedc5d86faabf0d49dc42a4924f75876d","externalIds":{"DBLP":"journals/corr/DanelljanHKF16b","ArXiv":"1609.06141","MAG":"2520477759","DOI":"10.1109/TPAMI.2016.2609928","CorpusId":2889401,"PubMed":"27654137"},"title":"Discriminative Scale Space Tracking"},{"paperId":"0dd92d7a55bbab7c5d12ae3858a6baeb99b65e67","externalIds":{"MAG":"2513005088","DBLP":"journals/corr/NamBH16","ArXiv":"1608.07242","CorpusId":6195655},"title":"Modeling and Propagating CNNs in a Tree Structure for Visual Tracking"},{"paperId":"49a5aeefcb257ca92652acf4f875efbad5a2b00d","externalIds":{"DBLP":"journals/spl/MaXNY16","MAG":"2512452641","DOI":"10.1109/LSP.2016.2601691","CorpusId":16695472},"title":"When Correlation Filters Meet Convolutional Neural Networks for Visual Tracking"},{"paperId":"5fd235751a9a3e79cfd7599f5e8b4ce7d7baf801","externalIds":{"DBLP":"journals/corr/DanelljanRKF16","MAG":"2518013266","ArXiv":"1608.03773","DOI":"10.1007/978-3-319-46454-1_29","CorpusId":5650694},"title":"Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking"},{"paperId":"1fa76bab517403d346a2478ded68a0d89aa1a7b9","externalIds":{"MAG":"2601567076","DOI":"10.1109/SIPROCESS.2016.7888360","CorpusId":2776810},"title":"Making Bayesian tracking and matching by the BRISK interest points detector/descriptor cooperate for robust object tracking"},{"paperId":"29d1b9a6e6ff0a4216d10dd31376467d55e788a3","externalIds":{"MAG":"2470394683","DBLP":"conf/eccv/BertinettoVHVT16","ArXiv":"1606.09549","DOI":"10.1007/978-3-319-48881-3_56","CorpusId":14309034},"title":"Fully-Convolutional Siamese Networks for Object Tracking"},{"paperId":"35097ca8d9c8380d8d012a67b7b616f9d662f2fc","externalIds":{"MAG":"2473868734","DBLP":"conf/cvpr/QiZQYHL016","DOI":"10.1109/CVPR.2016.466","CorpusId":5648267},"title":"Hedged Deep Tracking"},{"paperId":"87283935f0eec5ddc0e5ad3062568df8eb89e7e0","externalIds":{"DBLP":"conf/cvpr/WangOWL16","MAG":"2470456807","DOI":"10.1109/CVPR.2016.153","CorpusId":17615903},"title":"STCT: Sequentially Training Convolutional Networks for Visual Tracking"},{"paperId":"1bb80ad79b9dafdbd68db40737cff3378b002e37","externalIds":{"DBLP":"conf/cvpr/ZhuPL16a","MAG":"2480631127","DOI":"10.1109/CVPRW.2016.160","CorpusId":5544457},"title":"Robust Visual Tracking with Deep Convolutional Neural Network Based Object Proposals on PETS"},{"paperId":"992efcca992733f4b170309fbdcd26219f1c0fbb","externalIds":{"MAG":"2469582947","DBLP":"journals/corr/DanelljanHKF16a","ArXiv":"1609.06118","DOI":"10.1109/CVPR.2016.159","CorpusId":6189154},"title":"Adaptive Decontamination of the Training Set: A Unified Formulation for Discriminative Visual Tracking"},{"paperId":"4f445f3e44f2f2ffb431cf1414c59ccba5a0b27d","externalIds":{"MAG":"2952558221","DBLP":"journals/corr/TaoGS16","ArXiv":"1605.05863","DOI":"10.1109/CVPR.2016.158","CorpusId":208232980},"title":"Siamese Instance Search for Tracking"},{"paperId":"3dc60732c1c08165c9d4e7b334ce66e511474bb2","externalIds":{"DBLP":"journals/corr/ChenT16","ArXiv":"1604.07507","MAG":"2951718719","DOI":"10.1109/TCSVT.2017.2757061","CorpusId":12856046},"title":"Once for All: A Two-Flow Convolutional Neural Network for Visual Tracking"},{"paperId":"5f0850ec47a17f22ba2611a5cb67a30cb02cf306","externalIds":{"MAG":"2964253307","ArXiv":"1604.01802","DBLP":"conf/eccv/HeldTS16","DOI":"10.1007/978-3-319-46448-0_45","CorpusId":15703426},"title":"Learning to Track at 100 FPS with Deep Regression Networks"},{"paperId":"91f2b2aeb7e65d0b673ed7e782488b3365027979","externalIds":{"MAG":"2066513826","DBLP":"journals/pami/LiL0YY16","DOI":"10.1109/TPAMI.2015.2417577","CorpusId":17749010,"PubMed":"26761738"},"title":"NUS-PRO: A New Visual Tracking Challenge"},{"paperId":"42bda24420044af5c743640dfc93fcf1835ba777","externalIds":{"DBLP":"journals/ijon/WuLGZL16","MAG":"2212435496","DOI":"10.1016/j.neucom.2015.10.064","CorpusId":39386806},"title":"Regional deep learning model for visual tracking"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0","externalIds":{"DBLP":"conf/eccv/LiuAESRFB16","MAG":"2193145675","ArXiv":"1512.02325","DOI":"10.1007/978-3-319-46448-0_2","CorpusId":2141740},"title":"SSD: Single Shot MultiBox Detector"},{"paperId":"bf94906f0d7a8ca9da5f6b86e2a476fde1a34dd0","externalIds":{"DBLP":"conf/iccv/WangOWL15","MAG":"2211629196","DOI":"10.1109/ICCV.2015.357","CorpusId":342957},"title":"Visual Tracking with Fully Convolutional Networks"},{"paperId":"5c8a6874011640981e4103d120957802fa28f004","externalIds":{"MAG":"2214352687","DBLP":"conf/iccv/MaHYY15","DOI":"10.1109/ICCV.2015.352","CorpusId":13028371},"title":"Hierarchical Convolutional Features for Visual Tracking"},{"paperId":"7f66ff8dd0313fc9c7d67be7ea5aecdda956657c","externalIds":{"MAG":"2210596465","DBLP":"conf/iccv/SonJPH15","DOI":"10.1109/ICCV.2015.350","CorpusId":18063910},"title":"Tracking-by-Segmentation with Online Gradient Boosting Decision Tree"},{"paperId":"09769e80cdf027db32a1fcb695a1aa0937214763","externalIds":{"DBLP":"journals/corr/DanelljanHKF16","ArXiv":"1608.05571","MAG":"1955741794","DOI":"10.1109/ICCV.2015.490","CorpusId":206770621},"title":"Learning Spatially Regularized Correlation Filters for Visual Tracking"},{"paperId":"15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d","externalIds":{"MAG":"2130026429","DBLP":"conf/iccvw/KristanMLFCFVHN15","DOI":"10.1109/ICCVW.2015.79","CorpusId":3710195},"title":"The Visual Object Tracking VOT2015 Challenge Results"},{"paperId":"311bc4e48838d8e5ef619df3ce0bc598aba788a1","externalIds":{"DBLP":"conf/iccvw/DanelljanHKF15","MAG":"2244956674","DOI":"10.1109/ICCVW.2015.84","CorpusId":1511942},"title":"Convolutional Features for Correlation Filter Based Visual Tracking"},{"paperId":"2ce63d77eecc35faef85a3b752a314c93a077ac9","externalIds":{"DBLP":"journals/corr/NamH15","ArXiv":"1510.07945","MAG":"2950410377","DOI":"10.1109/CVPR.2016.465","CorpusId":973101},"title":"Learning Multi-domain Convolutional Neural Networks for Visual Tracking"},{"paperId":"4ff486644be5e451784d6ae83f8073c8320fa974","externalIds":{"MAG":"2249578758","DBLP":"conf/smc/ZhangS15","DOI":"10.1109/SMC.2015.362","CorpusId":9255939},"title":"Visual Tracking with Convolutional Neural Network"},{"paperId":"47b5e4d564f36bf322c14893b51ae4ecf782b53b","externalIds":{"DBLP":"journals/tip/LiangBL15","MAG":"1915785815","DOI":"10.1109/TIP.2015.2482905","CorpusId":6094550,"PubMed":"26415202"},"title":"Encoding color information for visual tracking: Algorithms and benchmark"},{"paperId":"c4c45661501c16064eead6e5d37dcb80d41c7a78","externalIds":{"MAG":"2158592639","DBLP":"journals/pami/WuLY15","DOI":"10.1109/TPAMI.2014.2388226","CorpusId":15287463,"PubMed":"26353130"},"title":"Object Tracking Benchmark"},{"paperId":"1fcdbc996c2a08ff9e0c2de7ff8c3cdabff47884","externalIds":{"DBLP":"journals/arobots/RobinL16","MAG":"1126974217","DOI":"10.1007/s10514-015-9491-7","CorpusId":7271501},"title":"Multi-robot target detection and tracking: taxonomy and survey"},{"paperId":"ec18afedf1c7c1389c1f2d3a7f332c44b113da04","externalIds":{"MAG":"1904248166","DBLP":"conf/cvpr/WenDLLY15","DOI":"10.1109/CVPR.2015.7298835","CorpusId":14946436},"title":"JOTS: Joint Online Tracking and Segmentation"},{"paperId":"0c7c61e2d85081bc4c63556f41d7bc71fdf0f5ac","externalIds":{"MAG":"2158827467","ArXiv":"1503.01313","DBLP":"journals/pami/KristanMLVPFNPC16","DOI":"10.1109/TPAMI.2016.2516982","CorpusId":1118174,"PubMed":"26766217"},"title":"A Novel Performance Evaluation Methodology for Single-Target Trackers"},{"paperId":"084bd219dd239dc4c9a02621a5333d3bc1446566","externalIds":{"MAG":"3098217967","DBLP":"journals/corr/LiLP15","ArXiv":"1503.00072","DOI":"10.1109/TIP.2015.2510583","CorpusId":1892112,"PubMed":"26841390"},"title":"DeepTrack: Learning Discriminative Feature Representations Online for Robust Visual Tracking"},{"paperId":"c46b08850b9c458704a3ca69172e6a0d40a6cb7f","externalIds":{"MAG":"2951157758","DBLP":"journals/corr/HongYKH15","ArXiv":"1502.06796","CorpusId":7993679},"title":"Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network"},{"paperId":"9cf3c67529085d31c646091b97be1a1e3dc191f2","externalIds":{"MAG":"2280226538","DBLP":"journals/tip/ZhangL0Y16","DOI":"10.1109/TIP.2016.2531283","CorpusId":17704601,"PubMed":"26890870"},"title":"Robust Visual Tracking via Convolutional Networks Without Training"},{"paperId":"0bde8d9367d1004c7396dd69cb27ed97dc2f8d77","externalIds":{"DBLP":"conf/mm/VedaldiL15","MAG":"2953066166","ArXiv":"1412.4564","DOI":"10.1145/2733373.2807412","CorpusId":207224096},"title":"MatConvNet: Convolutional Neural Networks for MATLAB"},{"paperId":"e15cf50aa89fee8535703b9f9512fca5bfc43327","externalIds":{"DBLP":"journals/corr/SzegedyLJSRAEVR14","MAG":"2097117768","ArXiv":"1409.4842","DOI":"10.1109/CVPR.2015.7298594","CorpusId":206592484},"title":"Going deeper with convolutions"},{"paperId":"3c74b636c0f74c1a0cbbd6e165c2760264044971","externalIds":{"MAG":"2186330282","DBLP":"conf/eccv/KristanPLMCNVFL14","DOI":"10.1007/978-3-319-16181-5_14","CorpusId":14284153},"title":"The Visual Object Tracking VOT2014 Challenge Results"},{"paperId":"eb42cf88027de515750f230b23b1a057dc782108","externalIds":{"MAG":"2949429431","ArXiv":"1409.1556","DBLP":"journals/corr/SimonyanZ14a","CorpusId":14124313},"title":"Very Deep Convolutional Networks for Large-Scale Image Recognition"},{"paperId":"1b3a107739e7f7e05c50999a3d79b8225746f662","externalIds":{"MAG":"2069332137","DBLP":"conf/bmvc/LiLP14","DOI":"10.5244/C.28.56","CorpusId":18194897},"title":"DeepTrack: Learning Discriminative Feature Representations by Convolutional Neural Networks for Visual Tracking"},{"paperId":"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd","externalIds":{"ArXiv":"1409.0575","DBLP":"journals/corr/RussakovskyDSKSMHKKBBF14","MAG":"2546241758","DOI":"10.1007/s11263-015-0816-y","CorpusId":2930547},"title":"ImageNet Large Scale Visual Recognition Challenge"},{"paperId":"c6b19b0acace2add1d8a2830e0520135d7894c9b","externalIds":{"MAG":"1976033797","DBLP":"journals/tsmc/BruniV14","DOI":"10.1109/TSMC.2014.2331217","CorpusId":9087044},"title":"An Improvement of Kernel-Based Object Tracking Based on Human Perception"},{"paperId":"14d9be7962a4ec5a6e55755f4c7588ea00793652","externalIds":{"MAG":"2950159980","DBLP":"journals/corr/ChatfieldSVZ14","ArXiv":"1405.3531","DOI":"10.5244/C.28.6","CorpusId":7204540},"title":"Return of the Devil in the Details: Delving Deep into Convolutional Nets"},{"paperId":"65c9b4b1d49f46b3f8f64a5f617acfc14f85d031","externalIds":{"DBLP":"journals/pami/HenriquesC0B15","ArXiv":"1404.7584","MAG":"2154889144","DOI":"10.1109/TPAMI.2014.2345390","CorpusId":5378407,"PubMed":"26353263"},"title":"High-Speed Tracking with Kernelized Correlation Filters"},{"paperId":"448ff117f216bba80080ad56851d7dc6bb5e22bd","externalIds":{"MAG":"2074143295","DBLP":"conf/wacv/CehovinKL14","DOI":"10.1109/WACV.2014.6836055","CorpusId":18230212},"title":"Is my new tracker really better than yours?"},{"paperId":"e0eab2d6d2408cf9dd33dccd0c1271266fc0ec83","externalIds":{"DBLP":"journals/tcsv/KimKLPK14","MAG":"2069994574","DOI":"10.1109/TCSVT.2014.2305514","CorpusId":10005603},"title":"Kernel-Based Structural Binary Pattern Tracking"},{"paperId":"4b1a47709d0546e5bc614bf9a521c550e6881d04","externalIds":{"MAG":"2915935370","DBLP":"conf/iccvw/KristanPLMPCNFV13","DOI":"10.1109/ICCVW.2013.20","CorpusId":263883845},"title":"The Visual Object Tracking VOT2013 Challenge Results"},{"paperId":"79b949d9b35c3f51dd20fb5c746cc81fc87147eb","externalIds":{"MAG":"2115579991","DBLP":"journals/ijrr/GeigerLSU13","DOI":"10.1177/0278364913491297","CorpusId":9455111},"title":"Vision meets robotics: The KITTI dataset"},{"paperId":"bfba194dfd9c7c27683082aa8331adc4c5963a0d","externalIds":{"MAG":"2089961441","DBLP":"conf/cvpr/WuLY13","DOI":"10.1109/CVPR.2013.312","CorpusId":1660289},"title":"Online Object Tracking: A Benchmark"},{"paperId":"506f628df107dc62abc4acbe403fe9dfbe06684a","externalIds":{"MAG":"1984914017","DBLP":"journals/corr/abs-1303-4803","ArXiv":"1303.4803","DOI":"10.1145/2508037.2508039","CorpusId":10355303},"title":"A survey of appearance models in visual object tracking"},{"paperId":"abd1c342495432171beb7ca8fd9551ef13cbd0ff","externalIds":{"DBLP":"conf/nips/KrizhevskySH12","MAG":"2618530766","DOI":"10.1145/3065386","CorpusId":195908774},"title":"ImageNet classification with deep convolutional neural networks"},{"paperId":"2bcf2bd59219d89f335cbc8d1dd4f431076b4c4c","externalIds":{"MAG":"2038943746","DBLP":"journals/ijon/YangSZWS11","DOI":"10.1016/j.neucom.2011.07.024","CorpusId":4338802},"title":"Recent advances and trends in visual tracking: A review"},{"paperId":"873d00882907388ca00e6966310951c338195b19","externalIds":{"MAG":"1968557510","DBLP":"conf/ipin/KlopschitzSSR10","DOI":"10.1109/IPIN.2010.5648274","CorpusId":6262101},"title":"Visual tracking for Augmented Reality"},{"paperId":"70c3c9b9a40ca55264e454586dca2a6cf416f6e0","externalIds":{"MAG":"1964846093","DBLP":"conf/cvpr/BolmeBDL10","DOI":"10.1109/CVPR.2010.5539960","CorpusId":2451356},"title":"Visual object tracking using adaptive correlation filters"},{"paperId":"65a7aca24d6358b3e57368688856a10833ecd062","externalIds":{"DBLP":"conf/icip/BoudoukhLR09","MAG":"2109489741","DOI":"10.1109/ICIP.2009.5414280","CorpusId":16953505},"title":"Visual tracking of object silhouettes"},{"paperId":"2a38768dabcd02539265c065a4d7ac445309ae96","externalIds":{"MAG":"2145201922","DBLP":"conf/cvpr/WeijerSV07","DOI":"10.1109/CVPR.2007.383218","CorpusId":2852002},"title":"Learning Color Names from Real-World Images"},{"paperId":"caa0fd34e50bb417fae3ee32f667e78fe5b198bc","externalIds":{"MAG":"1995903777","DBLP":"journals/csur/YilmazJS06","DOI":"10.1145/1177352.1177355","CorpusId":11962297},"title":"Object tracking: A survey"},{"paperId":"e8b12467bdc20bde976750b8a28decdb33246d1d","externalIds":{"MAG":"2161969291","DBLP":"conf/cvpr/DalalT05","DOI":"10.1109/CVPR.2005.177","CorpusId":206590483},"title":"Histograms of oriented gradients for human detection"},{"paperId":"68c03788224000794d5491ab459be0b2a2c38677","externalIds":{"MAG":"2081580037","DBLP":"conf/naacl/Miller92","ACL":"H92-1116","DOI":"10.1145/219717.219748","CorpusId":1671874},"title":"WordNet: A Lexical Database for English"},{"paperId":"7d25ec83e40928700e078057d9b61e7012687d9e","externalIds":{"MAG":"3082755608","DBLP":"conf/eccv/KulhariaCATT20","DOI":"10.1007/978-3-030-58583-9_18","CorpusId":221134166},"title":"Box2Seg: Attention Weighted Loss and Discriminative Feature Learning for Weakly Supervised Segmentation"},{"paperId":"62086fbddce3bafa052232742bc047eccb184d1d","externalIds":{"MAG":"2971339032","DBLP":"conf/nips/ChenWFLW19","CorpusId":202783962},"title":"Catastrophic Forgetting Meets Negative Transfer: Batch Spectral Shrinkage for Safe Transfer Learning"},{"paperId":"70eb84c3f8968a5285884b778adc6b517b90d653","externalIds":{"DBLP":"conf/bmvc/MaBW18","MAG":"2892995887","CorpusId":52289364},"title":"Multi-Scale Recurrent Tracking via Pyramid Recurrent Network and Optical Flow"},{"paperId":"73197b136f9c8bc0e6568efde0b805888046ad8e","externalIds":{"MAG":"2892385803","DBLP":"conf/bmvc/LiCW18","CorpusId":52285816},"title":"BUAA-PRO: A Tracking Dataset with Pixel-Level Annotation"},{"paperId":"235bda432a3b1add4fd56d2ad071eae8e96077c5","externalIds":{"MAG":"2894149753","DBLP":"conf/bmvc/JiangZZY018","CorpusId":52283100},"title":"Deep Collaborative Tracking Networks"},{"paperId":"80efbeca0f3250fe99a899e1122583eeacd3ddc2","externalIds":{"MAG":"2770189358","DBLP":"journals/tits/DingCZHL18","DOI":"10.1109/TITS.2017.2774778","CorpusId":25467807},"title":"Real-Time Scalable Visual Tracking via Quadrangle Kernelized Correlation Filters"},{"paperId":"703f8fb5aefdc684c2ef7794a47bbd3bfabca628","externalIds":{"MAG":"2519007024","DBLP":"journals/mia/BougetASJ17","DOI":"10.1016/j.media.2016.09.003","CorpusId":206870493,"PubMed":"27744253"},"title":"Vision‐based and marker‐less surgical tool detection and tracking: a review of the literature"},{"paperId":"f216444d4f2959b4520c61d20003fa30a199670a","externalIds":{"MAG":"3091905774","CorpusId":13874643},"title":"Siamese Neural Networks for One-Shot Image Recognition"},{"paperId":"5648597dc65a3e1fdc6d8e0aeccbf9bf6fe82dcb","externalIds":{"CorpusId":6795574},"title":"Visual Tracking: an Experimental Survey"},{"paperId":"ac4d4ff147c53d8ce35e1d094dd8bf341c094fef","externalIds":{"MAG":"2509173122","CorpusId":3539576},"title":"Adaptive Visual Face Tracking for an Autonomous Robot"},{"paperId":"0b9548474bf379e761dac25853556ab8158ff62b","externalIds":{"MAG":"101998584","DOI":"10.1007/978-3-540-78502-6_12","CorpusId":107362328},"title":"Vision-Based Tracking for Mobile Augmented Reality"}]}