{"references":[{"paperId":"d00735241af700d21762d2f3ca00d920241a15a4","externalIds":{"DBLP":"journals/corr/abs-2309-01219","ArXiv":"2309.01219","DOI":"10.1162/coli.a.16","CorpusId":261530162},"title":"Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models"},{"paperId":"eee548fbd0b9dd954c692fbd8880e80d5f077bd7","externalIds":{"ArXiv":"2308.11764","DBLP":"journals/corr/abs-2308-11764","DOI":"10.48550/arXiv.2308.11764","CorpusId":261076218},"title":"Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models"},{"paperId":"658cd67a91da86cf451e6f1b015f762b56015172","externalIds":{"DBLP":"conf/aaai/GunjalYB24","ArXiv":"2308.06394","DOI":"10.48550/arXiv.2308.06394","CorpusId":260887222},"title":"Detecting and Preventing Hallucinations in Large Vision Language Models"},{"paperId":"ce9c0935c074a0ca8769f13fd4e8651cee263112","externalIds":{"DBLP":"conf/ismir/DohCLN23","ArXiv":"2307.16372","DOI":"10.48550/arXiv.2307.16372","CorpusId":260334763},"title":"LP-MusicCaps: LLM-Based Pseudo Music Captioning"},{"paperId":"3b0792f6d7f6aa6aadd316e73943116afef2979b","externalIds":{"DBLP":"conf/conll/PalUS23","ACL":"2023.conll-1.21","ArXiv":"2307.15343","DOI":"10.48550/arXiv.2307.15343","CorpusId":260316324},"title":"Med-HALT: Medical Domain Hallucination Test for Large Language Models"},{"paperId":"a08b9d6fb0543ed92e0f0b4ce101e57228ceb6bf","externalIds":{"ArXiv":"2307.12168","DBLP":"conf/iccv/WuHH23","DOI":"10.1109/ICCV51070.2023.01478","CorpusId":260125675},"title":"Hallucination Improves the Performance of Unsupervised Visual Representation Learning"},{"paperId":"7e7d16f603ba848542abdbe4151fa3112f26bd72","externalIds":{"DBLP":"journals/corr/abs-2307-08629","ArXiv":"2307.08629","DOI":"10.48550/arXiv.2307.08629","CorpusId":259937606},"title":"Deficiency-Aware Masked Transformer for Video Inpainting"},{"paperId":"1827dd28ef866eaeb929ddf4bcfa492880aba4c7","externalIds":{"DBLP":"journals/corr/abs-2307-03987","ArXiv":"2307.03987","DOI":"10.48550/arXiv.2307.03987","CorpusId":263699899},"title":"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation"},{"paperId":"78eca0064ec7779d131cbaac49c2d1a023426871","externalIds":{"ArXiv":"2307.02185","DBLP":"journals/corr/abs-2307-02185","DOI":"10.48550/arXiv.2307.02185","CorpusId":259342641},"title":"Citation: A Key to Building Responsible and Accountable Large Language Models"},{"paperId":"228aee5393e7a11e018bbef940fea1c2816b6ec4","externalIds":{"ArXiv":"2306.16092","CorpusId":259274889},"title":"Chatlaw: A Multi-Agent Collaborative Legal Assistant with Knowledge Graph Enhanced Mixture-of-Experts Large Language Model"},{"paperId":"44d74b0d77b4056ddd4c6611a76711c8bab2e0a7","externalIds":{"DBLP":"conf/icaa2/JhaJLBVN23","DOI":"10.1109/ICAA58325.2023.00029","CorpusId":260810131},"title":"Dehallucinating Large Language Models Using Formal Methods Guided Iterative Prompting"},{"paperId":"3dbbe6909d7b53dd49e059c7f61a3613045a8db0","externalIds":{"DBLP":"conf/iclr/MundlerHJV24","ArXiv":"2305.15852","DOI":"10.48550/arXiv.2305.15852","CorpusId":258887694},"title":"Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation"},{"paperId":"7db7653c581d7823cb9c328f2d742ec70d7a0ce4","externalIds":{"DBLP":"journals/corr/abs-2305-14908","ArXiv":"2305.14908","DOI":"10.48550/arXiv.2305.14908","CorpusId":258865339},"title":"PURR: Efficiently Editing Language Model Hallucinations by Denoising Language Model Corruptions"},{"paperId":"62b322b0bead56d6a252a2e24de499ea8385ad7f","externalIds":{"DBLP":"journals/corr/abs-2305-13669","DOI":"10.48550/arXiv.2305.13669","CorpusId":258840979},"title":"Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment"},{"paperId":"2b2591c151efc43e8836a5a6d17e44c04bb68260","externalIds":{"ArXiv":"2305.14224","DBLP":"conf/emnlp/PfeifferPNWRR23","DOI":"10.48550/arXiv.2305.14224","CorpusId":258841429},"title":"mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations"},{"paperId":"7bf902fb94a577d15293ac4f90d8967163850fb1","externalIds":{"DBLP":"journals/corr/abs-2305-13903","DOI":"10.48550/arXiv.2305.13903","CorpusId":258841347},"title":"Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction"},{"paperId":"2c67ee597ed38f43ec0f123a3f1cce38cbd3b5b4","externalIds":{"DBLP":"journals/corr/abs-2305-14552","ArXiv":"2305.14552","DOI":"10.48550/arXiv.2305.14552","CorpusId":258865517},"title":"Sources of Hallucination by Large Language Models on Inference Tasks"},{"paperId":"6825ba09383bc758f9a2feaebabe35a6cd4adc4c","externalIds":{"DBLP":"conf/icml/ZhangPMLS24","ArXiv":"2305.13534","DOI":"10.48550/arXiv.2305.13534","CorpusId":258841857},"title":"How Language Model Hallucinations Can Snowball"},{"paperId":"206400aba5f12f734cdd2e4ab48ef6014ea60773","externalIds":{"DBLP":"journals/corr/abs-2305-10355","ArXiv":"2305.10355","DOI":"10.48550/arXiv.2305.10355","CorpusId":258740697},"title":"Evaluating Object Hallucination in Large Vision-Language Models"},{"paperId":"d48cb91b9e555194f7494c4d4bb9815021d3ee45","externalIds":{"DBLP":"journals/corr/abs-2305-06355","ArXiv":"2305.06355","DOI":"10.1007/s11432-024-4321-9","CorpusId":258588306},"title":"VideoChat: chat-centric video understanding"},{"paperId":"f2b34c5bc6b20353aa531f860aefeadf8d96e3be","externalIds":{"ArXiv":"2304.14406","DBLP":"conf/cvpr/KulalBA0YLES23","DOI":"10.1109/CVPR52729.2023.01639","CorpusId":258352521},"title":"Putting People in Their Place: Affordance-Aware Human Insertion into Scenes"},{"paperId":"f406aceba4f29cc7cfbe7edb2f52f01374486589","externalIds":{"ArXiv":"2304.13734","DBLP":"journals/corr/abs-2304-13734","DOI":"10.18653/v1/2023.findings-emnlp.68","CorpusId":258352729},"title":"The Internal State of an LLM Knows When its Lying"},{"paperId":"7c1707db9aafd209aa93db3251e7ebd593d55876","externalIds":{"DBLP":"conf/emnlp/ManakulLG23","ArXiv":"2303.08896","DOI":"10.48550/arXiv.2303.08896","CorpusId":257557820},"title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"},{"paperId":"01bc871c0ecb7f586e54b9f67d2e50e08cbedf3d","externalIds":{"DBLP":"conf/emnlp/Liu023","ArXiv":"2303.02961","DOI":"10.48550/arXiv.2303.02961","CorpusId":257364802},"title":"Models See Hallucinations: Evaluating the Factuality in Video Captioning"},{"paperId":"e5c72b92c48d68594b290c84a8904da7c8335554","externalIds":{"ArXiv":"2302.12813","DBLP":"journals/corr/abs-2302-12813","DOI":"10.48550/arXiv.2302.12813","CorpusId":257205781},"title":"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"},{"paperId":"66242baf48b0f6b828e7547ac39ffaa5e1b2cb3e","externalIds":{"ArXiv":"2210.08726","DBLP":"conf/acl/GaoDPCCFZLLJG23","ACL":"2023.acl-long.910","DOI":"10.18653/v1/2023.acl-long.910","CorpusId":254247260},"title":"RARR: Researching and Revising What Language Models Say, Using Language Models"},{"paperId":"7cfbd36c0043098589cbaf18dca2b41d8dc24abe","externalIds":{"DBLP":"conf/eacl/DaiLJSF23","ACL":"2023.eacl-main.156","ArXiv":"2210.07688","DOI":"10.48550/arXiv.2210.07688","CorpusId":252907639},"title":"Plausible May Not Be Faithful: Probing Object Hallucination in Vision-Language Pre-training"},{"paperId":"3def68bd0f856886d34272840a7f81588f2bc082","externalIds":{"DBLP":"journals/corr/abs-2202-03629","ArXiv":"2202.03629","DOI":"10.1145/3571730","CorpusId":246652372},"title":"Survey of Hallucination in Natural Language Generation"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","externalIds":{"ArXiv":"2112.10752","DBLP":"journals/corr/abs-2112-10752","DOI":"10.1109/CVPR52688.2022.01042","CorpusId":245335280},"title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2","externalIds":{"DBLP":"journals/corr/abs-2108-07258","ArXiv":"2108.07258","CorpusId":237091588},"title":"On the Opportunities and Risks of Foundation Models"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"4921243268c81d0d6db99053a9d004852225a622","externalIds":{"MAG":"2962735233","DBLP":"conf/emnlp/RohrbachHBDS18","ArXiv":"1809.02156","ACL":"D18-1437","DOI":"10.18653/v1/D18-1437","CorpusId":52176506},"title":"Object Hallucination in Image Captioning"},{"paperId":"96dd1fc39a368d23291816d57763bc6eb4f7b8d6","externalIds":{"MAG":"2963916161","DBLP":"journals/corr/KrishnaHRLN17","ArXiv":"1705.00754","DOI":"10.1109/ICCV.2017.83","CorpusId":1026139},"title":"Dense-Captioning Events in Videos"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","externalIds":{"ArXiv":"1405.0312","DBLP":"conf/eccv/LinMBHPRDZ14","MAG":"2952122856","DOI":"10.1007/978-3-319-10602-1_48","CorpusId":14113767},"title":"Microsoft COCO: Common Objects in Context"},{"paperId":"66c8e96397e9188f4cb88d41556a3f7924a517a7","externalIds":{"MAG":"2406334966","DOI":"10.1177/000313480707300709","CorpusId":46396666,"PubMed":"17674941"},"title":"Severe Sepsis Attributable to Community-Associated Methicillin-Resistant Staphylococcus aureus: An Emerging Fatal Problem"},{"paperId":"80fd20e175f83a699258b8780cf365418d1538b0","externalIds":{"DBLP":"journals/corr/abs-2305-13269","DOI":"10.48550/arXiv.2305.13269","CorpusId":258833025},"title":"Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases"},{"paperId":"13697bc3e4047683ed8375845783b7f2ab590f37","externalIds":{"CorpusId":268726981},"title":"Audio-Journey: Efficient Visual+LLM-aided Audio Encodec Diffusion"}]}