{"references":[{"paperId":"73af7be98aef3f9a91e771642428d37d66754db3","externalIds":{"ArXiv":"2312.04737","DBLP":"conf/kdd/0006SYL25","DOI":"10.1145/3711896.3736922","CorpusId":266149673},"title":"Efficient End-to-end Language Model Fine-tuning on Graphs"},{"paperId":"d2ecb191cb037c96d4c2ad0a47a49ba82b701285","externalIds":{"DBLP":"conf/nips/TanZL0023","CorpusId":265216566,"PubMed":"39130614"},"title":"WalkLM: A Uniform Language Model Fine-tuning Framework for Attributed Graph Embedding"},{"paperId":"2b3554a8fea6f123fc04bd3e120f2293f227e1b2","externalIds":{"ArXiv":"2311.16208","DBLP":"journals/corr/abs-2311-16208","DOI":"10.48550/arXiv.2311.16208","CorpusId":265466509},"title":"InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery"},{"paperId":"a7f801222c4d053c1ac49fb91ce3a4f750e8343b","externalIds":{"ArXiv":"2311.09862","DBLP":"conf/naacl/DasGSK24","DOI":"10.48550/arXiv.2311.09862","CorpusId":265221466},"title":"Which Modality should I use - Text, Motif, or Image? : Understanding Graphs with Large Language Models"},{"paperId":"5aa3b1009955ce2c8f896e0d5e94e06155ef1e43","externalIds":{"ArXiv":"2311.00423","DBLP":"journals/corr/abs-2311-00423","DOI":"10.1145/3616855.3635853","CorpusId":264832979},"title":"LLMRec: Large Language Models with Graph Augmentation for Recommendation"},{"paperId":"7a922abcda328f9333c5a3819ade8917b98f08c9","externalIds":{"DBLP":"journals/corr/abs-2310-18152","ArXiv":"2310.18152","DOI":"10.48550/arXiv.2310.18152","CorpusId":264555213},"title":"Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs"},{"paperId":"4829b73a47be18f73e9e8d90f3c23c8f84d0fccb","externalIds":{"ArXiv":"2310.15950","DBLP":"conf/www/RenWXSCWY024","DOI":"10.1145/3589334.3645458","CorpusId":264439548},"title":"Representation Learning with Large Language Models for Recommendation"},{"paperId":"76d10a049d39267a4ff79a38e30555d3a5a525c4","externalIds":{"DBLP":"journals/corr/abs-2310-15109","ArXiv":"2310.15109","DOI":"10.48550/arXiv.2310.15109","CorpusId":264436636},"title":"GRENADE: Graph-Centric Language Model for Self-Supervised Representation Learning on Text-Attributed Graphs"},{"paperId":"e391d266b0d43475567f59efeaeabc884a48abd0","externalIds":{"ArXiv":"2310.13590","DBLP":"conf/emnlp/Shi0ZL023","DOI":"10.48550/arXiv.2310.13590","CorpusId":264406019},"title":"ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction"},{"paperId":"45872b94798c3125abfb185b7926689c5e767763","externalIds":{"DBLP":"conf/sigir/Tang00SSCY024","ArXiv":"2310.13023","DOI":"10.1145/3626772.3657775","CorpusId":264405943},"title":"GraphGPT: Graph Instruction Tuning for Large Language Models"},{"paperId":"25738c43c0c4788d803981eaf5d397691aba0958","externalIds":{"ArXiv":"2310.12798","DBLP":"journals/corr/abs-2310-12798","DOI":"10.48550/arXiv.2310.12798","CorpusId":264306303},"title":"MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter"},{"paperId":"c4fa9c1e53e7818ad11c9e656869c3f35b6b2c69","externalIds":{"DBLP":"journals/corr/abs-2310-12580","ArXiv":"2310.12580","DOI":"10.48550/arXiv.2310.12580","CorpusId":264305676},"title":"Pretraining Language Models with Text-Attributed Heterogeneous Graphs"},{"paperId":"6912a12f3710bf4bbdfd9f55f90311426fc1c32c","externalIds":{"ArXiv":"2310.11829","DBLP":"journals/pami/LiuYLCLZBFSYS25","DOI":"10.1109/TPAMI.2025.3548729","CorpusId":264288909,"PubMed":"40048343"},"title":"Graph Foundation Models: Concepts, Opportunities and Challenges"},{"paperId":"4f63c5a89c7299a864c6c48aa1844fb0fe8c9437","externalIds":{"ArXiv":"2310.10844","DBLP":"journals/corr/abs-2310-10844","DOI":"10.48550/arXiv.2310.10844","CorpusId":264172191},"title":"Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks"},{"paperId":"04ab0af17cb5af36966d5e27cca713aafa55ec91","externalIds":{"DBLP":"conf/aaai/0001RG0LZ25","ArXiv":"2310.09872","DOI":"10.1609/aaai.v39i12.33428","CorpusId":264146054},"title":"Leveraging Large Language Models for Node Generation in Few-Shot Learning on Text-Attributed Graphs"},{"paperId":"062fab31d30478b57457c8b7a94d7467f5bd770c","externalIds":{"ArXiv":"2310.05845","DBLP":"journals/corr/abs-2310-05845","DOI":"10.48550/arXiv.2310.05845","CorpusId":263830019},"title":"GraphLLM: Boosting Graph Reasoning Ability of Large Language Model"},{"paperId":"4d1bcfb754dcd14fd312356021d9e332d3d3b18f","externalIds":{"DBLP":"journals/corr/abs-2310-04668","ArXiv":"2310.04668","DOI":"10.48550/arXiv.2310.04668","CorpusId":263829256},"title":"Label-free Node Classification on Graphs with Large Language Models (LLMS)"},{"paperId":"4ae7c4decd1df71c466f19d66d69b555945098c4","externalIds":{"DBLP":"journals/corr/abs-2310-04944","ArXiv":"2310.04944","DOI":"10.48550/arXiv.2310.04944","CorpusId":263831119},"title":"Beyond Text: A Deep Dive into Large Language Models' Ability on Understanding Graph Data"},{"paperId":"9283b8c7e6ad6ae86be059a26595de0d7a427a10","externalIds":{"ArXiv":"2310.04560","DBLP":"journals/corr/abs-2310-04560","DOI":"10.48550/arXiv.2310.04560","CorpusId":263829977},"title":"Talk like a Graph: Encoding Graphs for Large Language Models"},{"paperId":"55367fbade73f96181ffcf52169d0471d4c014a2","externalIds":{"DBLP":"journals/corr/abs-2310-01089","ArXiv":"2310.01089","DOI":"10.48550/arXiv.2310.01089","CorpusId":263605738},"title":"GraphText: Graph Reasoning in Text Space"},{"paperId":"ab22d54dd13876d25c6c8f46c40fb9ac41c61ec5","externalIds":{"DBLP":"journals/corr/abs-2310-00149","ArXiv":"2310.00149","DOI":"10.48550/arXiv.2310.00149","CorpusId":265871676},"title":"One for All: Towards Training One Graph Model for All Classification Tasks"},{"paperId":"1081b62f3eea92c87eb024ce80cb9e5d16113057","externalIds":{"DBLP":"conf/sigir/Zhu0IKF24","ArXiv":"2309.13885","DOI":"10.1145/3626772.3657978","CorpusId":260853042},"title":"TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning"},{"paperId":"be0faf7c69103c10dccc6181ef3c9ee8ead38d74","externalIds":{"ArXiv":"2309.02848","DBLP":"journals/corr/abs-2309-02848","DOI":"10.48550/arXiv.2309.02848","CorpusId":261556793},"title":"Prompt-based Node Feature Extractor for Few-shot Learning on Text-Attributed Graphs"},{"paperId":"26089bdfdbca1e6eaaceca71e3116b715bec6d47","externalIds":{"DBLP":"journals/corr/abs-2309-01029","ArXiv":"2309.01029","DOI":"10.1145/3639372","CorpusId":261530292},"title":"Explainability for Large Language Models: A Survey"},{"paperId":"927fc7652e033c9eb17296df087e3e6491112bb0","externalIds":{"DBLP":"journals/corr/abs-2308-11224","ArXiv":"2308.11224","DOI":"10.48550/arXiv.2308.11224","CorpusId":261064686},"title":"Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis"},{"paperId":"8d65b5940a4dbed8c18e02ca35e3a9d7a14ea76b","externalIds":{"ArXiv":"2308.07134","DBLP":"conf/eacl/YeZWXZ24","ACL":"2024.findings-eacl.132","DOI":"10.18653/v1/2024.findings-eacl.132","CorpusId":260887732},"title":"Language is All a Graph Needs"},{"paperId":"2e3dcf5a5d58ac210d0d87e9f918540a8373211a","externalIds":{"DBLP":"journals/corr/abs-2308-06911","ArXiv":"2308.06911","DOI":"10.1016/j.compbiomed.2024.108073","CorpusId":260887406,"PubMed":"38359660"},"title":"GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text"},{"paperId":"303b7d0a81395562e3a46578a89d6821ce564a8b","externalIds":{"ArXiv":"2308.02565","DBLP":"journals/corr/abs-2308-02565","DOI":"10.48550/arXiv.2308.02565","CorpusId":260681726},"title":"SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning"},{"paperId":"1b2bd46bd395650675a670e2361c4f967eea8fdd","externalIds":{"ArXiv":"2307.10230","DBLP":"journals/corr/abs-2307-10230","DOI":"10.1109/TKDE.2024.3440068","CorpusId":259991036},"title":"Prompt Tuning on Graph-Augmented Low-Resource Text Classification"},{"paperId":"1212b1e44f7611d2017b246fd3d8e9c973c9d937","externalIds":{"DBLP":"journals/corr/abs-2307-07443","ArXiv":"2307.07443","DOI":"10.48550/arXiv.2307.07443","CorpusId":259924688},"title":"Can Large Language Models Empower Molecular Property Prediction?"},{"paperId":"105669ec59a58fb2d4dd3021a984af33c227c5ab","externalIds":{"DBLP":"journals/sigkdd/ChenMLJWWWYFLT23","ArXiv":"2307.03393","DOI":"10.1145/3655103.3655110","CorpusId":259375824},"title":"Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs"},{"paperId":"80c698688bb4488beaceaab5c64f701a946cb7ae","externalIds":{"DBLP":"journals/corr/abs-2307-01504","ArXiv":"2307.01504","DOI":"10.1145/3580305.3599256","CorpusId":259341605},"title":"All in One: Multi-Task Prompting for Graph Neural Networks"},{"paperId":"3090d5ef973e34e054ed520a118b2df8b16a5702","externalIds":{"DBLP":"journals/corr/abs-2306-02592","ArXiv":"2306.02592","DOI":"10.1145/3580305.3599833","CorpusId":259257650,"PubMed":"38375450"},"title":"Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help Multiple Graph Applications"},{"paperId":"5d321194696f1f75cf9da045e6022b2f20ba5b9c","externalIds":{"DBLP":"journals/corr/abs-2306-02858","ArXiv":"2306.02858","DOI":"10.48550/arXiv.2306.02858","CorpusId":259075356},"title":"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding"},{"paperId":"119a3ed0898499fce0ce6af6958d566d82390ba5","externalIds":{"ArXiv":"2306.13089","DBLP":"conf/nips/ZhaoLMXFDKL23","DOI":"10.1101/2023.05.30.542904","CorpusId":259077070},"title":"GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning"},{"paperId":"2b967d82b25088566980aaaf5a7062d90b2fb14f","externalIds":{"DBLP":"journals/corr/abs-2305-15066","ArXiv":"2305.15066","CorpusId":258865990},"title":"GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking"},{"paperId":"452dac53963afe5599c484136e200498763f750b","externalIds":{"DBLP":"journals/corr/abs-2305-14321","ArXiv":"2305.14321","ACL":"2024.textgraphs-1.2","DOI":"10.48550/arXiv.2305.14321","CorpusId":258841509},"title":"ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and Text Embeddings"},{"paperId":"3a755f8dcc9af9304c2cbd3a00e42e66feec1d5d","externalIds":{"ArXiv":"2305.12268","DBLP":"journals/corr/abs-2305-12268","ACL":"2023.acl-long.387","DOI":"10.48550/arXiv.2305.12268","CorpusId":258832995},"title":"Patton: Language Model Pretraining on Text-Rich Networks"},{"paperId":"df2beaae63e4d68ef8e762bcd4704c9f11f856d9","externalIds":{"DBLP":"journals/corr/abs-2305-10037","ArXiv":"2305.10037","DOI":"10.48550/arXiv.2305.10037","CorpusId":258740923},"title":"Can Language Models Solve Graph Problems in Natural Language?"},{"paperId":"131c6f328c11706de2c43cd16e0b7c5d5e610b6a","externalIds":{"DBLP":"journals/corr/abs-2304-13712","ArXiv":"2304.13712","DOI":"10.1145/3649506","CorpusId":258331833},"title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"},{"paperId":"51484cf02592a3551f944b7c6bf94fe902c0aa66","externalIds":{"DBLP":"conf/pkdd/MavromatisIWZAMZFK23","ArXiv":"2304.10668","DOI":"10.48550/arXiv.2304.10668","CorpusId":258291779},"title":"Train Your Own GNN Teacher: Graph-Aware Distillation on Textual Graphs"},{"paperId":"5278a8eb2ba2429d4029745caf4e661080073c81","externalIds":{"DBLP":"conf/uist/ParkOCMLB23","ArXiv":"2304.03442","DOI":"10.1145/3586183.3606763","CorpusId":258040990},"title":"Generative Agents: Interactive Simulacra of Human Behavior"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"a757999ed260d7bc45484dc6b4456bf33fe6f679","externalIds":{"ArXiv":"2303.16199","DBLP":"journals/corr/abs-2303-16199","DOI":"10.48550/arXiv.2303.16199","CorpusId":257771811},"title":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"},{"paperId":"7d40189f3fa56728b8d210628e98fc204961778f","externalIds":{"ArXiv":"2303.12767","DBLP":"journals/corr/abs-2303-12767","ACL":"2023.trustnlp-1.5","DOI":"10.18653/v1/2023.trustnlp-1.5","CorpusId":257663514},"title":"Can we trust the evaluation on ChatGPT?"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"355cf4ef8c666898ceed76ea7950c3df176900fc","externalIds":{"DBLP":"conf/wsdm/TanL0CL0H23","DOI":"10.1145/3539597.3570404","CorpusId":257079694},"title":"S2GAE: Self-Supervised Graph Autoencoders are Generalizable Learners with Graph Masking"},{"paperId":"3f5b31c4f7350dc88002c121aecbdc82f86eb5bb","externalIds":{"DBLP":"journals/corr/abs-2301-12597","ArXiv":"2301.12597","DOI":"10.48550/arXiv.2301.12597","CorpusId":256390509},"title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"},{"paperId":"62c9fdb7b1820c849a407a6b1e4e2ea190336459","externalIds":{"ArXiv":"2212.11440","DBLP":"journals/tkde/SunCLLCXY23","DOI":"10.1109/TKDE.2023.3235312","CorpusId":254974166},"title":"Self-Supervised Hypergraph Representation Learning for Sociological Analysis"},{"paperId":"958bb3831589246fe5b6b58cf99e3b65c58d027f","externalIds":{"DBLP":"journals/natmi/LiuNWLQLTXA23","ArXiv":"2212.10789","DOI":"10.1038/s42256-023-00759-6","CorpusId":254926709},"title":"Multi-modal molecule structure–text model for text-based retrieval and editing"},{"paperId":"7d645a3fd276918374fd9483fd675c28e46506d1","externalIds":{"DBLP":"journals/corr/abs-2211-09085","ArXiv":"2211.09085","CorpusId":253553203},"title":"Galactica: A Large Language Model for Science"},{"paperId":"8bb37e8ae7dd6fa8cab2407f63a61f697152717f","externalIds":{"ArXiv":"2210.14709","DBLP":"journals/corr/abs-2210-14709","DOI":"10.48550/arXiv.2210.14709","CorpusId":253117079},"title":"Learning on Large-scale Text-attributed Graphs via Variational Inference"},{"paperId":"ed38c6b157c11476939c426ec6871c926f2f3524","externalIds":{"ArXiv":"2210.12353","DBLP":"journals/corr/abs-2210-12353","DOI":"10.48550/arXiv.2210.12353","CorpusId":253098700},"title":"Leveraging Large Language Models for Multiple Choice Question Answering"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"1d26c947406173145a4665dd7ab255e03494ea28","externalIds":{"DBLP":"journals/corr/abs-2210-02414","ArXiv":"2210.02414","DOI":"10.48550/arXiv.2210.02414","CorpusId":252715691},"title":"GLM-130B: An Open Bilingual Pre-trained Model"},{"paperId":"1c7a4e8d9f4fcf19a5d1caa078c66ca39cb75dd2","externalIds":{"ArXiv":"2209.05481","DBLP":"journals/corr/abs-2209-05481","DOI":"10.48550/arXiv.2209.05481","CorpusId":252212175},"title":"A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language"},{"paperId":"e60ad3d4ed3273af6a94745689783b83f59c8b4a","externalIds":{"DBLP":"conf/kdd/SunZHWW22","DOI":"10.1145/3534678.3539249","CorpusId":251518260},"title":"GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks"},{"paperId":"1497a56aa25a385e1d60e6a9c2fa60aa7bd17edd","externalIds":{"ArXiv":"2206.12933","DBLP":"conf/aaai/Cheng0LT23","DOI":"10.1609/aaai.v37i6.25870","CorpusId":254044757},"title":"Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning"},{"paperId":"f7a3d9bcf052f2b4ef7d59dcca4013ea11081d0f","externalIds":{"DBLP":"conf/nips/DwivediRGPWLB22","ArXiv":"2206.08164","DOI":"10.48550/arXiv.2206.08164","CorpusId":249712241},"title":"Long Range Graph Benchmark"},{"paperId":"dac3a172b504f4e33c029655e9befb3386e5f63a","externalIds":{"DBLP":"journals/corr/abs-2206-07682","ArXiv":"2206.07682","DOI":"10.48550/arXiv.2206.07682","CorpusId":249674500},"title":"Emergent Abilities of Large Language Models"},{"paperId":"b161c4aaddd2983a9d4d5a240bd5ffa84b36c4e7","externalIds":{"DBLP":"journals/corr/abs-2205-10803","ArXiv":"2205.10803","DOI":"10.1145/3534678.3539321","CorpusId":248987361},"title":"GraphMAE: Self-Supervised Masked Graph Autoencoders"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"da18398274bec87d3568acfd6aba6977be7ba6b8","externalIds":{"ArXiv":"2201.05867","DBLP":"journals/corr/abs-2201-05867","CorpusId":246016155},"title":"Transferability in Deep Learning: A Survey"},{"paperId":"259cbc1492c51d985bdafb67e48fa170471ee446","externalIds":{"DBLP":"conf/iclr/ChienCHYZMD22","ArXiv":"2111.00064","CorpusId":240354406},"title":"Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction"},{"paperId":"bf713a9595edc9f8c4d240a08f2b5b01efbf1eb2","externalIds":{"ArXiv":"2105.02605","DBLP":"conf/nips/YangLXLLASSX21","CorpusId":238227259},"title":"GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"0d67d3ddca1c4e370eaf1e99ec674f612c39c66c","externalIds":{"DBLP":"journals/corr/abs-2010-14945","MAG":"3095746859","ArXiv":"2010.14945","DOI":"10.1145/3442381.3449802","CorpusId":225094367},"title":"Graph Contrastive Learning with Adaptive Augmentation"},{"paperId":"76c124786ccf4263e6403a15a8e350ac28be4e65","externalIds":{"MAG":"3102419180","ArXiv":"2010.13902","DBLP":"journals/corr/abs-2010-13902","CorpusId":225076220},"title":"Graph Contrastive Learning with Augmentations"},{"paperId":"1ef493a358cae89e8d5474574b4c7fdddbe00570","externalIds":{"DBLP":"journals/corr/abs-2008-06274","ArXiv":"2008.06274","MAG":"3049697419","CorpusId":221135782},"title":"Graph-based Modeling of Online Communities for Fake News Detection"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"597bd2e45427563cdf025e53a3239006aa364cfc","externalIds":{"MAG":"3021975806","ArXiv":"2005.00687","DBLP":"journals/corr/abs-2005-00687","CorpusId":218487328},"title":"Open Graph Benchmark: Datasets for Machine Learning on Graphs"},{"paperId":"f420663fe8c69ed5ea5236201a1f4c734cd145a7","externalIds":{"DBLP":"conf/aaai/SongLGW20","MAG":"2996847713","DOI":"10.1609/AAAI.V34I01.5438","CorpusId":214274349},"title":"Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting"},{"paperId":"43f2ad297941db230c089ba353efc3f281ab678c","externalIds":{"MAG":"3033156098","CorpusId":226096901},"title":"5分で分かる!? 有名論文ナナメ読み：Jacob Devlin et al. : BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"3024f58826a5bce3378af94f677e8fb90cbb49e0","externalIds":{"DBLP":"journals/corr/abs-2002-02126","MAG":"3045200674","ArXiv":"2002.02126","DOI":"10.1145/3397271.3401063","CorpusId":211043589},"title":"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation"},{"paperId":"845b4941d8c016aa5f8967da2f86d38ef6c18fa3","externalIds":{"DBLP":"journals/corr/abs-2002-00388","MAG":"3003265726","ArXiv":"2002.00388","DOI":"10.1109/TNNLS.2021.3070843","CorpusId":211010433,"PubMed":"33900922"},"title":"A Survey on Knowledge Graphs: Representation, Acquisition, and Applications"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"156d217b0a911af97fa1b5a71dc909ccef7a8028","externalIds":{"ACL":"D19-1371","DBLP":"conf/emnlp/BeltagyLC19","MAG":"2973154071","ArXiv":"1903.10676","DOI":"10.18653/v1/D19-1371","CorpusId":202558505},"title":"SciBERT: A Pretrained Language Model for Scientific Text"},{"paperId":"62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9","externalIds":{"MAG":"2950468517","ArXiv":"1810.00826","DBLP":"journals/corr/abs-1810-00826","CorpusId":52895589},"title":"How Powerful are Graph Neural Networks?"},{"paperId":"b227f3e4c0dc96e5ac5426b85485a70f2175a205","externalIds":{"MAG":"2842511635","DBLP":"journals/corr/abs-1807-03748","ArXiv":"1807.03748","CorpusId":49670925},"title":"Representation Learning with Contrastive Predictive Coding"},{"paperId":"33998aff64ce51df8dee45989cdca4b6b1329ec4","externalIds":{"DBLP":"journals/corr/abs-1710-10903","ArXiv":"1710.10903","MAG":"2766453196","DOI":"10.17863/CAM.48429","CorpusId":3292002},"title":"Graph Attention Networks"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"6b7d6e6416343b2a122f8416e69059ce919026ef","externalIds":{"DBLP":"conf/nips/HamiltonYL17","MAG":"2952779545","ArXiv":"1706.02216","CorpusId":4755450},"title":"Inductive Representation Learning on Large Graphs"},{"paperId":"d0ab11de3077490c80a08abd0fb8827bac84c454","externalIds":{"MAG":"2949858440","ArXiv":"1703.00564","DBLP":"journals/corr/WuRFGGPLP17","PubMedCentral":"5868307","DOI":"10.1039/c7sc02664a","CorpusId":217680306,"PubMed":"29629118"},"title":"MoleculeNet: a benchmark for molecular machine learning"},{"paperId":"36eff562f65125511b5dfab68ce7f7a943c27478","externalIds":{"ArXiv":"1609.02907","MAG":"2519887557","DBLP":"journals/corr/KipfW16","CorpusId":3144218},"title":"Semi-Supervised Classification with Graph Convolutional Networks"},{"paperId":"3d846cb01f6a975554035d2210b578ca61344b22","externalIds":{"MAG":"2315403234","ArXiv":"1603.08861","DBLP":"journals/corr/YangCS16","CorpusId":7008752},"title":"Revisiting Semi-Supervised Learning with Graph Embeddings"},{"paperId":"87f40e6f3022adbc1f1905e3e506abad05a9964f","externalIds":{"ArXiv":"1310.4546","MAG":"2950133940","DBLP":"conf/nips/MikolovSCCD13","CorpusId":16447573},"title":"Distributed Representations of Words and Phrases and their Compositionality"},{"paperId":"45c1d83775038164894078a9f7061f56bc12470d","externalIds":{"MAG":"2127553917","DBLP":"journals/nar/WangXSZWB09","PubMedCentral":"2703903","DOI":"10.1093/nar/gkp456","CorpusId":477760,"PubMed":"19498078"},"title":"PubChem: a public information system for analyzing bioactivities of small molecules"},{"paperId":"43d2ed5c3c55c1100450cd74dc1031afa24d37b2","externalIds":{"MAG":"2403788960","DBLP":"journals/aim/SenNBGGE08","DOI":"10.1201/b17320-16","CorpusId":62016134},"title":"Collective Classification in Network Data"},{"paperId":"e50a316f97c9a405aa000d883a633bd5707f1a34","externalIds":{"MAG":"1978394996","DBLP":"journals/ipm/SaltonB88","DOI":"10.1016/0306-4573(88)90021-0","CorpusId":7725217},"title":"Term-Weighting Approaches in Automatic Text Retrieval"},{"paperId":"f01281b125128435ad134230c6a41cc55808eaac","externalIds":{"DBLP":"journals/corr/abs-2309-16595","DOI":"10.48550/arXiv.2309.16595","CorpusId":263135565},"title":"Can LLMs Effectively Leverage Graph Structural Information: When and Why"},{"paperId":"0b8265a63570d08d8d84aeacbec5495611ae3312","externalIds":{"DBLP":"journals/corr/abs-2310-01436","DOI":"10.48550/arXiv.2310.01436","CorpusId":263608402},"title":"Graph Neural Architecture Search with GPT-4"},{"paperId":"a5cec58c2525b6f5b011d2170bf37a67b42d1fbb","externalIds":{"DBLP":"journals/corr/abs-2308-14522","DOI":"10.48550/arXiv.2308.14522","CorpusId":271709079},"title":"Large Graph Models: A Perspective"},{"paperId":"edc11420b3f2aa6638d78cceb3b12778fe07bb85","externalIds":{"CorpusId":271293795},"title":"ChemCrow: Augmenting large-language models with chemistry tools"},{"paperId":"0e87f4c721c2a5302e9cf7e2b3a6ceacfaceb469","externalIds":{"DBLP":"journals/corr/abs-2310-17110","DOI":"10.48550/arXiv.2310.17110","CorpusId":271710643},"title":"LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?"},{"paperId":"57651d65078818821234d13544ac1f29858dcd67","externalIds":{"ACL":"2021.emnlp-main.47","DBLP":"conf/emnlp/EdwardsZJ21","DOI":"10.18653/v1/2021.emnlp-main.47","CorpusId":243865204},"title":"Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries"},{"paperId":"53d8b356551a2361020a948f64454a6d599af69f","externalIds":{"DBLP":"conf/acl/LiL20","ACL":"2021.acl-long.353","ArXiv":"2101.00190","DOI":"10.18653/v1/2021.acl-long.353","CorpusId":230433941},"title":"Prefix-Tuning: Optimizing Continuous Prompts for Generation"},{"paperId":"acf87283fa8ae426f1a4987b345b401bf2913f61","externalIds":{"DBLP":"conf/nips/YingCLZKHSL21","CorpusId":265104899},"title":"Do Transformers Really Perform Badly for Graph Representation?"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"0c0a778e6fdf7e36b1750c533dcc916f86608607","externalIds":{"MAG":"2527310337","DBLP":"journals/tkde/XunJGZ17","DOI":"10.1109/TKDE.2016.2614508","CorpusId":13490401},"title":"A Survey on Context Learning"},{"paperId":"414cb3c6cede070ab2c18d236895277d9c171828","externalIds":{"DBLP":"reference/crc/BrandesELP13","MAG":"2171502901","DOI":"10.1201/b15385-19","CorpusId":142947},"title":"Graph Markup Language (GraphML)"},{"paperId":"b030b1b1ca06e8b08f12bb695fbe0da4234e1c54","externalIds":{"DOI":"10.1016/b0-12-227410-5/00410-5","CorpusId":5555641},"title":"Mathematical Logic"}]}