{"references":[{"paperId":"66a24844055349327c52433141d1d1b094aae4b0","externalIds":{"MAG":"2963495269","DBLP":"conf/icml/YinCRB19","ArXiv":"1806.05358","CorpusId":49208440},"title":"Defending Against Saddle Point Attack in Byzantine-Robust Distributed Learning"},{"paperId":"0a4230af7869cf63159a444510627b4f91e38eed","externalIds":{"MAG":"2946633206","DBLP":"conf/icml/XieKG19","CorpusId":159041074},"title":"Zeno: Distributed Stochastic Gradient Descent with Suspicion-based Fault-tolerance"},{"paperId":"f21b48d62e9bbeae34d6a552fa2bafd62af25c99","externalIds":{"MAG":"2804165311","ArXiv":"1805.10032","DBLP":"journals/corr/abs-1805-10032","CorpusId":44066866},"title":"Zeno: Byzantine-suspicious stochastic gradient descent"},{"paperId":"ccf18d7ead5402dfcf3f2775b40bc78a9a27087f","externalIds":{"MAG":"2963773265","DBLP":"journals/corr/abs-1805-09965","ArXiv":"1805.09965","CorpusId":44061071},"title":"LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning"},{"paperId":"87bf168f93923407b11c771b462780ffadddef8a","externalIds":{"DBLP":"journals/corr/abs-1805-09682","MAG":"2804948787","ArXiv":"1805.09682","CorpusId":43926230},"title":"Phocas: dimensional Byzantine-resilient stochastic gradient descent"},{"paperId":"28cec9ccb6d9faaae8808845f132a277937e9dfd","externalIds":{"MAG":"2798551148","ArXiv":"1804.10140","DBLP":"journals/corr/abs-1804-10140","CorpusId":13747984},"title":"Securing Distributed Machine Learning in High Dimensions"},{"paperId":"31f8806397907e197ca1d3676f598fd197087ad6","externalIds":{"MAG":"2964261056","ArXiv":"1803.09877","DBLP":"conf/icml/ChenWCP18","CorpusId":49397275},"title":"DRACO: Byzantine-resilient Distributed Training via Redundant Gradients"},{"paperId":"293346ebd2285e3ecbb297a2773830dddc4c0a34","externalIds":{"MAG":"2789903762","DBLP":"journals/corr/abs-1803-08917","ArXiv":"1803.08917","CorpusId":4312831},"title":"Byzantine Stochastic Gradient Descent"},{"paperId":"5ad1cfdc40f58c5ee078496312798f784fc80801","externalIds":{"DBLP":"journals/corr/abs-1803-01498","ArXiv":"1803.01498","MAG":"2951502311","CorpusId":3708326},"title":"Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates"},{"paperId":"b8167db77296f9557328f0fb6d7fe3c044d1043a","externalIds":{"ArXiv":"1802.10116","MAG":"2788308444","DBLP":"journals/corr/abs-1802-10116","CorpusId":3630046},"title":"Generalized Byzantine-tolerant SGD"},{"paperId":"34c303f5609b8d553c2114c0fb4c99393346a185","externalIds":{"DBLP":"conf/sigmetrics/ChenSX18","MAG":"2614254310","DOI":"10.1145/3219617.3219655","CorpusId":7265349},"title":"Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent"},{"paperId":"9583ac53a19cdf0db81fef6eb0b63e66adbe2324","externalIds":{"MAG":"2752689052","DBLP":"conf/nips/BlanchardMGS17","CorpusId":28527385},"title":"Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent"},{"paperId":"99e4bb3b33c337d0546954bc2cf7117a5a16d5ce","externalIds":{"MAG":"2783291400","DBLP":"conf/cdc/LiuNTL17","DOI":"10.1109/CDC.2017.8264668","CorpusId":20138721},"title":"Asynchronous periodic event-triggered coordination of multi-agent systems"},{"paperId":"276194e96ebd620b5cff35a9168bdda39a0be57b","externalIds":{"MAG":"2951372312","DBLP":"conf/nips/SmithCST17","ArXiv":"1705.10467","CorpusId":3586416},"title":"Federated Multi-Task Learning"},{"paperId":"c756b4362f073619aa0eeb725213411a69928730","externalIds":{"DBLP":"journals/tac/Ben-AmeurBJ16","MAG":"2403871130","DOI":"10.1109/TAC.2015.2471755","CorpusId":9107848},"title":"Robust Distributed Consensus Using Total Variation"},{"paperId":"5085517ab5803c3ab2bc6fa984e10e541a5f2f37","externalIds":{"MAG":"2913453460","DBLP":"journals/cn/SicariRGC15","DOI":"10.1016/j.comnet.2014.11.008","CorpusId":13835959},"title":"Security, privacy and trust in Internet of Things: The road ahead"},{"paperId":"04ca5de59edbdd49a9c0502c58331524d220bc8c","externalIds":{"MAG":"2127941149","DBLP":"conf/nips/LiASY14","CorpusId":2235165},"title":"Communication Efficient Distributed Machine Learning with the Parameter Server"},{"paperId":"f244da7263ef3e5c25a7780c7c2f32ca07a25d12","externalIds":{"DBLP":"books/sp/Nesterov04","MAG":"2124541940","CorpusId":62288331},"title":"Introductory Lectures on Convex Optimization - A Basic Course"},{"paperId":"2e6a19158ba2c695494edbca0cd9ccabace0f03d","externalIds":{"DBLP":"journals/tsp/ShiLYWY14","MAG":"2123705108","ArXiv":"1307.5561","DOI":"10.1109/TSP.2014.2304432","CorpusId":5642927},"title":"On the Linear Convergence of the ADMM in Decentralized Consensus Optimization"},{"paperId":"3127190433230b3dc1abd0680bb58dced4bcd90e","externalIds":{"DBLP":"conf/nips/DeanCMCDLMRSTYN12","MAG":"2168231600","CorpusId":372467},"title":"Large Scale Distributed Deep Networks"},{"paperId":"d93fc37dc0c89ecf71844494bdfb0105e4539b06","externalIds":{"DBLP":"journals/anor/WeiszfeldP09","MAG":"2161669108","DOI":"10.1007/S10479-008-0352-Z","CorpusId":21000317},"title":"On the point for which the sum of the distances to n given points is minimum"},{"paperId":"da0877799c8daab985853c0aeed7c04f987bad4a","externalIds":{"MAG":"1992208280","DBLP":"journals/siamjo/NemirovskiJLS09","DOI":"10.1137/070704277","CorpusId":268069803},"title":"Robust Stochastic Approximation Approach to Stochastic Programming"},{"paperId":"fbc6562814e08e416e28a268ce7beeaa3d0708c8","externalIds":{"MAG":"114517082","DBLP":"conf/compstat/Bottou10","DOI":"10.1007/978-3-7908-2604-3_16","CorpusId":115963355},"title":"Large-Scale Machine Learning with Stochastic Gradient Descent"},{"paperId":"79fa5e51a519d30a19b3fd3accfa580cbd556b33","externalIds":{"DBLP":"conf/wdag/1992","DOI":"10.1007/3-540-56188-9","CorpusId":4312},"title":"Distributed Algorithms"}]}