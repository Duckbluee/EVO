{"references":[{"paperId":"bc2ddba47a9d6b378abd8a8584849f3e4c410f24","externalIds":{"DBLP":"journals/corr/abs-2410-18072","ArXiv":"2410.18072","DOI":"10.48550/arXiv.2410.18072","CorpusId":273532769},"title":"WorldSimBench: Towards Video Generation Models as World Simulators"},{"paperId":"e3116a5d5784392d9190ca35997f65a252291032","externalIds":{"ArXiv":"2405.01534","DBLP":"conf/iclr/DalalCCS24","DOI":"10.48550/arXiv.2405.01534","CorpusId":269502645},"title":"Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks"},{"paperId":"f9143d68be6475cac4d5d2096edcf1691c8f0356","externalIds":{"DBLP":"conf/fat/KimLVBV24","ArXiv":"2405.00623","DOI":"10.1145/3630106.3658941","CorpusId":269484145},"title":"\"I'm Not Sure, But...\": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust"},{"paperId":"59982844ae41696577f3fe4c396a8569f7d0fbd3","externalIds":{"DBLP":"journals/pacmse/VirkDA25","ArXiv":"2404.19318","DOI":"10.1145/3729400","CorpusId":269456957},"title":"Calibration of Large Language Models on Code Summarization"},{"paperId":"73c7426559030bf7ef1ec525f99223b670a76fe6","externalIds":{"ArXiv":"2404.03514","DBLP":"conf/coling/HuangXWXYM025","CorpusId":268889926},"title":"Embedding-Informed Adaptive Retrieval-Augmented Generation of Large Language Models"},{"paperId":"4e15901eaaaa9a9c2c30f64e05054ce6f5cdaa97","externalIds":{"ArXiv":"2404.02649","DBLP":"journals/corr/abs-2404-02649","DOI":"10.48550/arXiv.2404.02649","CorpusId":268875784},"title":"On the Importance of Uncertainty in Decision-Making with Large Language Models"},{"paperId":"59325da69a3d47a30becc723000b2a44a3c9dbcd","externalIds":{"DOI":"10.1016/s2589-7500(24)00061-x","CorpusId":269343833,"PubMed":"38658283"},"title":"Ethical and regulatory challenges of large language models in medicine."},{"paperId":"4af6b20591bc58bbadcec42e4dfa53ab8f4ceef2","externalIds":{"ArXiv":"2404.00573","DBLP":"conf/chi/HouTM24","DOI":"10.1145/3613905.3650839","CorpusId":268819055},"title":"\"My agent understands me better\": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents"},{"paperId":"00dc72c6c0072f2e41e42849d63d1827c303524e","externalIds":{"DBLP":"journals/corr/abs-2403-19369","ArXiv":"2403.19369","DOI":"10.48550/arXiv.2403.19369","CorpusId":268733265},"title":"RAIL: Robot Affordance Imagination with Large Language Models"},{"paperId":"8e68b5d1808349fd53c372c0d952b6ebea9d7b9e","externalIds":{"DBLP":"conf/iclr/ZhouSLSWW24","ArXiv":"2403.18120","CorpusId":268724184},"title":"Don't Trust: Verify - Grounding LLM Quantitative Reasoning with Autoformalization"},{"paperId":"6b2a62056f6b67370bf832bbaf1769e9edbf961a","externalIds":{"ArXiv":"2405.00693","CorpusId":269502160},"title":"Leveraging Large Language Models in Human-Robot Interaction: A Critical Analysis of Potential and Pitfalls"},{"paperId":"f96c102bcbb8395bbd380a2d711941f2691c3421","externalIds":{"DBLP":"journals/corr/abs-2404-00019","ArXiv":"2404.00019","DOI":"10.1145/3714478","CorpusId":268819452},"title":"Advancing Explainable Autonomous Vehicle Systems: A Comprehensive Review and Research Roadmap"},{"paperId":"e42e4c6f3834ae8c8caa91baef3c5b67cb011053","externalIds":{"ArXiv":"2403.13198","DBLP":"conf/iros/MullenM25","DOI":"10.1109/IROS60139.2025.11245905","CorpusId":268536769},"title":"LBAP: Improved Uncertainty Alignment of LLM Planners using Bayesian Inference"},{"paperId":"f213d0cb84b6afca9a4d5722081ba3052e7e89bc","externalIds":{"DBLP":"journals/corr/abs-2403-12910","ArXiv":"2403.12910","DOI":"10.48550/arXiv.2403.12910","CorpusId":268532135},"title":"Yell At Your Robot: Improving On-the-Fly from Language Corrections"},{"paperId":"32656886c8137f506f1bbc5e8eee63a38e18f191","externalIds":{"ArXiv":"2403.10700","DBLP":"conf/iros/TaioliRCNBFC024","DOI":"10.1109/IROS58592.2024.10801822","CorpusId":268512756},"title":"Mind the Error! Detection and Localization of Instruction Errors in Vision-and-Language Navigation"},{"paperId":"7c0cc7f7efba81ba78b4d9ff21282def690514e8","externalIds":{"DBLP":"journals/corr/abs-2404-10179","ArXiv":"2404.10179","DOI":"10.48550/arXiv.2404.10179","CorpusId":268524153},"title":"Scaling Instructable Agents Across Many Simulated Worlds"},{"paperId":"030522cc114b93ec6cec078697caf241c407c4ce","externalIds":{"ArXiv":"2403.07506","DBLP":"journals/corr/abs-2403-07506","DOI":"10.48550/arXiv.2403.07506","CorpusId":268364103},"title":"Robustness, Security, Privacy, Explainability, Efficiency, and Usability of Large Language Models for Code"},{"paperId":"b232f468de0b1d4ff1c2dfe5dbb03ec093160c48","externalIds":{"ArXiv":"2403.06634","DBLP":"journals/corr/abs-2403-06634","DOI":"10.48550/arXiv.2403.06634","CorpusId":268357903},"title":"Stealing Part of a Production Language Model"},{"paperId":"24b6b70e1b1525535155cc9fa66dfd9d5d42d6b5","externalIds":{"ArXiv":"2403.06710","DBLP":"conf/chi/LeiserELKMSS24","DOI":"10.1145/3613904.3642428","CorpusId":268358769},"title":"HILL: A Hallucination Identifier for Large Language Models"},{"paperId":"3d990f84442e113831b83313de7453a2afa13930","externalIds":{"DBLP":"journals/corr/abs-2403-03699","ArXiv":"2403.03699","DOI":"10.48550/arXiv.2403.03699","CorpusId":268253250},"title":"Model Parallelism on Distributed Infrastructure: A Literature Review from Theory to LLM Case-Studies"},{"paperId":"95dad62c52800600e571b4197314578fd441ca28","externalIds":{"DBLP":"journals/corr/abs-2403-03101","ArXiv":"2403.03101","DOI":"10.48550/arXiv.2403.03101","CorpusId":268248897},"title":"KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents"},{"paperId":"8ba57771dd6345821a0cbe83c4c7eb50f66b7b65","externalIds":{"ArXiv":"2403.04783","DBLP":"journals/corr/abs-2403-04783","DOI":"10.48550/arXiv.2403.04783","CorpusId":268297202},"title":"AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks"},{"paperId":"15a04a2796503bead606dfbd47b9d7e5dbfc58b6","externalIds":{"ArXiv":"2402.19166","DBLP":"conf/atal/HuntGS24","DOI":"10.48550/arXiv.2402.19166","CorpusId":268063195},"title":"Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination"},{"paperId":"5aa4e4d90cac81f8ec7001ae25356d75f02efbb1","externalIds":{"ArXiv":"2402.18041","DBLP":"journals/corr/abs-2402-18041","DOI":"10.48550/arXiv.2402.18041","CorpusId":268041439},"title":"Datasets for Large Language Models: A Comprehensive Survey"},{"paperId":"1cef01ab4db546659f42de237a54dd510f9906cb","externalIds":{"DBLP":"journals/corr/abs-2402-18649","ArXiv":"2402.18649","DOI":"10.48550/arXiv.2402.18649","CorpusId":268063870},"title":"A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems"},{"paperId":"5c05b129216e187bcf3499834759b9f23e0ad89a","externalIds":{"ArXiv":"2402.17930","DBLP":"conf/atal/Zhi-XuanY0T24","DOI":"10.48550/arXiv.2402.17930","CorpusId":268041272},"title":"Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning"},{"paperId":"2643f3500bcfde6fef0b885b7f230a36684aa608","externalIds":{"ArXiv":"2402.16569","DBLP":"journals/corr/abs-2402-16569","DOI":"10.48550/arXiv.2402.16569","CorpusId":268032818},"title":"Pretrained Visual Uncertainties"},{"paperId":"924908d316b575e3c7ada549620c2616b86f5054","externalIds":{"ArXiv":"2402.15368","DBLP":"journals/ral/WangHK25","DOI":"10.1109/LRA.2024.3504233","CorpusId":267897940},"title":"Probabilistically Correct Language-Based Multi-Robot Planning Using Conformal Prediction"},{"paperId":"7f254928af6718c80224199e9cd915e7372ac54d","externalIds":{"ArXiv":"2402.10828","DBLP":"conf/rss/YuanSOZ0KG24","DOI":"10.48550/arXiv.2402.10828","CorpusId":267740546},"title":"RAG-Driver: Generalisable Driving Explanations with Retrieval-Augmented In-Context Learning in Multi-Modal Large Language Model"},{"paperId":"817f5a9504e59a6afc83cc745dff758f59e0b0a4","externalIds":{"DBLP":"journals/corr/abs-2402-10790","ArXiv":"2402.10790","DOI":"10.48550/arXiv.2402.10790","CorpusId":267740348},"title":"In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs Miss"},{"paperId":"9b204030b6baa4f8913595b4582dfc10dba8ba31","externalIds":{"ArXiv":"2402.09733","DBLP":"journals/corr/abs-2402-09733","DOI":"10.48550/arXiv.2402.09733","CorpusId":267682191},"title":"Do LLMs Know about Hallucination? An Empirical Investigation of LLM's Hidden States"},{"paperId":"0ebad08c67e9bb775bd0bd7a0c5acf7555679c2d","externalIds":{"ArXiv":"2402.08546","DBLP":"journals/corr/abs-2402-08546","DOI":"10.1002/adrr.202500072","CorpusId":267637064},"title":"Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback"},{"paperId":"f5e7e22036c3fe7d6660eee90642f716c3b303f5","externalIds":{"DBLP":"conf/uss/ChenPS025","ArXiv":"2402.06363","DOI":"10.48550/arXiv.2402.06363","CorpusId":267616771},"title":"StruQ: Defending Against Prompt Injection with Structured Queries"},{"paperId":"a1f76db91c0debcf93ae9889736bce8470902113","externalIds":{"DBLP":"journals/corr/abs-2402-06196","ArXiv":"2402.06196","DOI":"10.48550/arXiv.2402.06196","CorpusId":267617032},"title":"Large Language Models: A Survey"},{"paperId":"7ceefa6766418966a12a04d282967258e5cd1267","externalIds":{"DBLP":"journals/corr/abs-2402-05188","ArXiv":"2402.05188","DOI":"10.48550/arXiv.2402.05188","CorpusId":267547747},"title":"InCoRo: In-Context Learning for Robotics Control with Feedback Loops"},{"paperId":"7baaaa623d2c3011a52e2bb515e030825fa6e36c","externalIds":{"DBLP":"conf/icann/LiZL24","ArXiv":"2402.04978","DOI":"10.48550/arXiv.2402.04978","CorpusId":267523228},"title":"An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration"},{"paperId":"8e6d1e76f5090baa1b170d2f250523e06d82cb4a","externalIds":{"ArXiv":"2402.04206","DBLP":"journals/corr/abs-2402-04206","DOI":"10.48550/arXiv.2402.04206","CorpusId":267500082},"title":"Explaining Autonomy: Enhancing Human-Robot Interaction through Explanation Generation with Large Language Models"},{"paperId":"4b1278b2266ce5009e70f2efe85ccff87350de9c","externalIds":{"ArXiv":"2402.02651","DBLP":"journals/tmlr/ChenMKL25","DOI":"10.48550/arXiv.2402.02651","CorpusId":267412750},"title":"Vision-Language Models Provide Promptable Representations for Reinforcement Learning"},{"paperId":"6d1ef839db3d637977392f4a7046c26bfea37d46","externalIds":{"DBLP":"journals/corr/abs-2402-03578","ArXiv":"2402.03578","DOI":"10.48550/arXiv.2402.03578","CorpusId":267499950},"title":"LLM Multi-Agent Systems: Challenges and Open Problems"},{"paperId":"6e2704025046be6dc29b71339994422f9a9cacf1","externalIds":{"DBLP":"journals/corr/abs-2402-01822","ArXiv":"2402.01822","DOI":"10.48550/arXiv.2402.01822","CorpusId":267412893},"title":"Building Guardrails for Large Language Models"},{"paperId":"25cee84e3a1541697a7c97443d7526574127c344","externalIds":{"ArXiv":"2402.00367","DBLP":"journals/corr/abs-2402-00367","DOI":"10.48550/arXiv.2402.00367","CorpusId":267365203},"title":"Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration"},{"paperId":"2751de08d6dbec07f53808231c016e96b075b06c","externalIds":{"ArXiv":"2401.15449","ACL":"2024.knowledgenlp-1.4","DBLP":"journals/corr/abs-2401-15449","DOI":"10.48550/arXiv.2401.15449","CorpusId":267312028},"title":"Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for Hallucination Mitigation"},{"paperId":"48fd140ea0f625471cb1018cbd743dc13eb7fca3","externalIds":{"DBLP":"conf/acl/HanBS24","ArXiv":"2401.14016","DOI":"10.48550/arXiv.2401.14016","CorpusId":267211955},"title":"Towards Uncertainty-Aware Language Agent"},{"paperId":"3cd81b0123b5f8477f6b5777681030ef6b05dd46","externalIds":{"ArXiv":"2401.13136","DBLP":"conf/acl/ShenTCCZXZKK24","DOI":"10.48550/arXiv.2401.13136","CorpusId":267200158},"title":"The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts"},{"paperId":"948c9d605a77d9d3c3959efecaa69d97b4d9a1de","externalIds":{"ArXiv":"2401.12963","DBLP":"journals/corr/abs-2401-12963","DOI":"10.48550/arXiv.2401.12963","CorpusId":266906759},"title":"AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents"},{"paperId":"848139f931c39a59d59203eea73f941b5767f419","externalIds":{"DBLP":"journals/corr/abs-2401-11838","ArXiv":"2401.11838","DOI":"10.1145/3610978.3640723","CorpusId":267069080},"title":"The Conversation is the Command: Interacting with Real-World Autonomous Robots Through Natural Language"},{"paperId":"5cd671efa2af8456c615c5faf54d1be4950f3819","externalIds":{"ArXiv":"2401.11817","DBLP":"journals/corr/abs-2401-11817","DOI":"10.48550/arXiv.2401.11817","CorpusId":267069207},"title":"Hallucination is Inevitable: An Innate Limitation of Large Language Models"},{"paperId":"8f070e301979732e0dd73f6aa6170309cf73aa7d","externalIds":{"DBLP":"journals/corr/abs-2402-01680","ArXiv":"2402.01680","DOI":"10.48550/arXiv.2402.01680","CorpusId":267412980},"title":"Large Language Model based Multi-Agents: A Survey of Progress and Challenges"},{"paperId":"f9863e1cb5ab60b0ad2892b0d003ffb2308ff187","externalIds":{"DBLP":"journals/corr/abs-2401-10862","ACL":"2024.blackboxnlp-1.26","ArXiv":"2401.10862","DOI":"10.48550/arXiv.2401.10862","CorpusId":267060803},"title":"Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning"},{"paperId":"0e0ea3593dda3039cb93d2ec795a87420006ec08","externalIds":{"ArXiv":"2401.10019","DBLP":"conf/emnlp/Yuan0DW0XXZ000L24","DOI":"10.48550/arXiv.2401.10019","CorpusId":267034935},"title":"R-Judge: Benchmarking Safety Risk Awareness for LLM Agents"},{"paperId":"cb9533e6e0f91f74b8af0cb411a47f1d2fa556ba","externalIds":{"ArXiv":"2401.08461","DBLP":"journals/corr/abs-2401-08461","DOI":"10.48550/arXiv.2401.08461","CorpusId":267027742},"title":"Decentralised Emergence of Robust and Adaptive Linguistic Conventions in Populations of Autonomous Agents Grounded in Continuous Worlds"},{"paperId":"8223f81e8cc126b83d2774fe2da19ead290c144d","externalIds":{"DBLP":"journals/corr/abs-2401-05033","ArXiv":"2401.05033","DOI":"10.48550/arXiv.2401.05033","CorpusId":266902624},"title":"Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk"},{"paperId":"fb4dc0178e5d7347b1615c48caf05347b6e5eb48","externalIds":{"DBLP":"journals/corr/abs-2401-05561","ArXiv":"2401.05561","DOI":"10.48550/arXiv.2401.05561","CorpusId":266933236},"title":"TrustLLM: Trustworthiness in Large Language Models"},{"paperId":"39e0bf77300bb6df8716ce83eb8a3f6a5e3d6b20","externalIds":{"DBLP":"conf/iclr/0002ZLEP0MFSLP24","ArXiv":"2401.04398","DOI":"10.48550/arXiv.2401.04398","CorpusId":266899992},"title":"Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"},{"paperId":"25544d4daf34b0c49844a1f68fd628420297cbcb","externalIds":{"ArXiv":"2401.03701","DBLP":"journals/corr/abs-2401-03701","DOI":"10.48550/arXiv.2401.03701","CorpusId":266844177},"title":"ExTraCT - Explainable Trajectory Corrections from language inputs using Textual description of features"},{"paperId":"460ad9ab0ccf5c97583235d313f1b1cd9c4e247a","externalIds":{"DBLP":"conf/icra/WenZZLXCSPLFT24","ArXiv":"2401.02814","DOI":"10.1109/ICRA57147.2024.10609992","CorpusId":266818502},"title":"Object-Centric Instruction Augmentation for Robotic Manipulation"},{"paperId":"d4656bba3a424a25fcd9e1fbf3966f080ace9c2f","externalIds":{"DBLP":"journals/corr/abs-2401-01312","ArXiv":"2401.01312","DOI":"10.48550/arXiv.2401.01312","CorpusId":266725580},"title":"LLM Harmony: Multi-Agent Communication for Problem Solving"},{"paperId":"5272acad9e4201e93dabe3fd99bd7ead9b1a544d","externalIds":{"DBLP":"journals/corr/abs-2401-01313","ArXiv":"2401.01313","DOI":"10.48550/arXiv.2401.01313","CorpusId":266725532},"title":"A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"},{"paperId":"2c9bdb69274cc4baf7d9df8ebfc86fc6bf35d0f1","externalIds":{"DBLP":"conf/wacv/ParkLKCPCLK24","DOI":"10.1109/WACVW60836.2024.00107","CorpusId":269191004},"title":"VLAAD: Vision and Language Assistant for Autonomous Driving"},{"paperId":"0553ff6d10a8dd377d6d0c171f8612231b7211a2","externalIds":{"DBLP":"journals/tiv/CuiHZLWSLWK24","DOI":"10.1109/TIV.2023.3327715","CorpusId":264534614},"title":"DriveLLM: Charting the Path Toward Full Autonomous Driving With Large Language Models"},{"paperId":"237b0cf9d78f4a52274b868656ad011f599aeb26","externalIds":{"DBLP":"journals/corr/abs-2401-00125","ArXiv":"2401.00125","DOI":"10.48550/arXiv.2401.00125","CorpusId":266693892},"title":"LLM-Assist: Enhancing Closed-Loop Planning with Language-Based Reasoning"},{"paperId":"46f9f7b8f88f72e12cbdb21e3311f995eb6e65c5","externalIds":{"ArXiv":"2312.10997","DBLP":"journals/corr/abs-2312-10997","CorpusId":266359151},"title":"Retrieval-Augmented Generation for Large Language Models: A Survey"},{"paperId":"98035acf98e823c07138aea711d02db76b663d38","externalIds":{"DBLP":"journals/corr/abs-2312-09348","ArXiv":"2312.09348","DOI":"10.48550/arXiv.2312.09348","CorpusId":266335650},"title":"LLM-MARS: Large Language Model for Behavior Tree Generation and NLP-enhanced Dialogue in Multi-Agent Robot Systems"},{"paperId":"d32ba88571141ed0ebe7aeefbaa4ccaf8cda7be3","externalIds":{"PubMedCentral":"10794145","DBLP":"journals/nature/RomeraParedesBNBKDREWFKF24","DOI":"10.1038/s41586-023-06924-6","CorpusId":266223700,"PubMed":"38096900"},"title":"Mathematical discoveries from program search with large language models"},{"paperId":"383c598625110e0a4c60da4db10a838ef822fbcf","externalIds":{"ArXiv":"2312.02003","DBLP":"journals/corr/abs-2312-02003","DOI":"10.1016/j.hcc.2024.100211","CorpusId":265609409},"title":"A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly"},{"paperId":"451539c0d0f5f5785ff58d09ca5e67a5f129f9de","externalIds":{"ArXiv":"2311.12320","DBLP":"journals/corr/abs-2311-12320","DOI":"10.1109/WACVW60836.2024.00106","CorpusId":265308931},"title":"A Survey on Multimodal Large Language Models for Autonomous Driving"},{"paperId":"7d884f1ff991eb9fff7bf31fa006196e58934b8a","externalIds":{"ArXiv":"2311.11183","DBLP":"journals/ral/HuLSSFMGB24","DOI":"10.1109/LRA.2024.3360020","CorpusId":265294597},"title":"Deploying and Evaluating LLMs to Program Service Mobile Robots"},{"paperId":"e92e8ff1becb9a9e4a7dd09878eaacb2a62ffb6b","externalIds":{"ArXiv":"2311.09096","DBLP":"conf/acl/ZhangYKMWH24","DOI":"10.48550/arXiv.2311.09096","CorpusId":265212812},"title":"Defending Large Language Models Against Jailbreaking Attacks Through Goal Prioritization"},{"paperId":"024646623aa733df2bb752aa3bb3e76d691cab11","externalIds":{"ArXiv":"2311.09247","DBLP":"journals/corr/abs-2311-09247","DOI":"10.48550/arXiv.2311.09247","CorpusId":265220802},"title":"Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks"},{"paperId":"d3367dc9a7a1d7ae70a06eadc02b2430f4529f7c","externalIds":{"DBLP":"journals/corr/abs-2311-07226","ArXiv":"2311.07226","DOI":"10.48550/arXiv.2311.07226","CorpusId":265149884},"title":"Large Language Models for Robotics: A Survey"},{"paperId":"964f3d5e21f33de98c66015f3a5aab8369db8796","externalIds":{"DOI":"10.1126/science.adm8175","CorpusId":265103674,"PubMed":"37943939"},"title":"AI's challenge of understanding the world."},{"paperId":"1ba3adf8f2049e672c0b8786c18a1f2ffcd21fa0","externalIds":{"ArXiv":"2311.01977","DBLP":"journals/corr/abs-2311-01977","DOI":"10.48550/arXiv.2311.01977","CorpusId":265018996},"title":"RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches"},{"paperId":"01d9bdf230442f6460127def244fb0ef06b47b8b","externalIds":{"ArXiv":"2311.00967","DBLP":"conf/icra/ShiraiBH0TKTUM24","DOI":"10.1109/ICRA57147.2024.10611112","CorpusId":264935138},"title":"Vision-Language Interpreter for Robot Task Planning"},{"paperId":"a2f44031dfa55f6da176955bcc37aac726de3a00","externalIds":{"DBLP":"journals/corr/abs-2310-20587","ArXiv":"2310.20587","DOI":"10.48550/arXiv.2310.20587","CorpusId":264802494},"title":"Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning"},{"paperId":"8e3d701b767213062edda831e7deef010e48c9fd","externalIds":{"DBLP":"journals/arobots/YoshikawaSDAJKLZXKASG23","DOI":"10.1007/s10514-023-10136-2","CorpusId":264498447},"title":"Large language models for chemistry robotics"},{"paperId":"fac468032e0c38ea10dfb95ba6cdeac51a473050","externalIds":{"ArXiv":"2407.04121","DBLP":"conf/cikm/ChenFYWFL0LX23","DOI":"10.1145/3583780.3614905","CorpusId":264350686},"title":"Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models"},{"paperId":"6ca16c1c2c60ceda87242c8f8e522d12cc4a13bc","externalIds":{"DBLP":"journals/corr/abs-2310-12931","ArXiv":"2310.12931","DOI":"10.48550/arXiv.2310.12931","CorpusId":264306288},"title":"Eureka: Human-Level Reward Design via Coding Large Language Models"},{"paperId":"b24a191abe87ac6cb159711a56d658c75c22ecec","externalIds":{"DBLP":"conf/iclr/DuYFXWISYATKZT24","ArXiv":"2310.10625","DOI":"10.48550/arXiv.2310.10625","CorpusId":264172935},"title":"Video Language Planning"},{"paperId":"e17c58d7a48b6b811df023484161a3b9c03e0d6b","externalIds":{"DBLP":"journals/corr/abs-2310-10701","ArXiv":"2310.10701","DOI":"10.18653/v1/2023.emnlp-main.13","CorpusId":264172518},"title":"Theory of Mind for Multi-Agent Collaboration via Large Language Models"},{"paperId":"9a73effed8775962c86587feb0f9ef841fa2ff4c","externalIds":{"DBLP":"journals/corr/abs-2310-09454","ArXiv":"2310.09454","DOI":"10.48550/arXiv.2310.09454","CorpusId":264146113},"title":"LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents"},{"paperId":"aa9aa1c315cb2a0c1759d82fb3d4b4506c2dbb7c","externalIds":{"DBLP":"conf/emnlp/MeiLW23","ArXiv":"2310.09624","DOI":"10.48550/arXiv.2310.09624","CorpusId":264146213},"title":"ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models"},{"paperId":"ef7d31137ef06c5be8c2824ecc5af6ce3358cc8f","externalIds":{"DBLP":"journals/corr/abs-2310-08864","ArXiv":"2310.08864","DOI":"10.1109/ICRA57147.2024.10611477","CorpusId":263626099},"title":"Open X-Embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration0"},{"paperId":"84b7c486c56bd3880cb8eb01de9ae90ba3ebdaed","externalIds":{"ArXiv":"2310.02949","DBLP":"journals/corr/abs-2310-02949","DOI":"10.48550/arXiv.2310.02949","CorpusId":263620436},"title":"Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models"},{"paperId":"f01ff5acf9e086030c01beda6f433f99013ebbd4","externalIds":{"DBLP":"conf/icra/ChenSHKWBMS24","ArXiv":"2310.01957","DOI":"10.1109/ICRA57147.2024.10611018","CorpusId":263608168},"title":"Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving"},{"paperId":"9fcdbfdf28245010c875ce85502351fe05c04b49","externalIds":{"ArXiv":"2310.02124","DBLP":"journals/corr/abs-2310-02124","DOI":"10.48550/arXiv.2310.02124","CorpusId":263608682},"title":"Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View"},{"paperId":"97f173e67ef937f3318f1ef41ae9fdd6a521de97","externalIds":{"DBLP":"journals/corr/abs-2310-01361","ArXiv":"2310.01361","DOI":"10.48550/arXiv.2310.01361","CorpusId":263605851},"title":"GenSim: Generating Robotic Simulation Tasks via Large Language Models"},{"paperId":"ccd6f8b6544f112de632e49bfbe592a0a654537d","externalIds":{"ArXiv":"2310.01412","DBLP":"journals/ral/XuZXZGWLZ24","DOI":"10.1109/LRA.2024.3440097","CorpusId":263605524},"title":"DriveGPT4: Interpretable End-to-End Autonomous Driving Via Large Language Model"},{"paperId":"93c525267e93c78309a5b28a3eb0780704125744","externalIds":{"ArXiv":"2310.00754","DBLP":"conf/iclr/ZhouCYZDFBY24","DOI":"10.48550/arXiv.2310.00754","CorpusId":263334335},"title":"Analyzing and Mitigating Object Hallucination in Large Vision-Language Models"},{"paperId":"f4c2b23fc463867f6c54e82fac0ccbb6617c5324","externalIds":{"DOI":"10.1016/j.birob.2023.100131","CorpusId":264564300},"title":"Large language models for human-robot interaction: A review"},{"paperId":"0ace4a1d304649d6b48f12104855bcda1fa76d54","externalIds":{"DBLP":"journals/corr/abs-2310-00710","ArXiv":"2310.00710","DOI":"10.48550/arXiv.2310.00710","CorpusId":263334479},"title":"How well does LLM generate security tests?"},{"paperId":"f875c2de4a3ccee670cc76a81b1dfd111bd40f64","externalIds":{"DBLP":"journals/ai/BrowningL23","DOI":"10.1016/j.artint.2023.104031","CorpusId":263820570},"title":"Language, common sense, and the Winograd schema challenge"},{"paperId":"0b9ab24684d275c355248c54bcac5d44cf6b1999","externalIds":{"DBLP":"conf/iros/ShekWSBZMTB24","ArXiv":"2310.00481","DOI":"10.1109/IROS58592.2024.10802075","CorpusId":263334543},"title":"LANCAR: Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments"},{"paperId":"174a3290ff0040e0f6a7a0b43bcd752c456350a0","externalIds":{"DBLP":"conf/icra/GuKMJSARPECGMTT24","ArXiv":"2309.16650","DOI":"10.1109/ICRA57147.2024.10610243","CorpusId":263134620},"title":"ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning"},{"paperId":"3cbfe152220de84ecf8059fa50c47587a3134c86","externalIds":{"DBLP":"conf/iclr/WenF0C0CDS0024","ArXiv":"2309.16292","DOI":"10.48550/arXiv.2309.16292","CorpusId":263136146},"title":"DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models"},{"paperId":"0a893657e00fe8ecfadcc65c63bf293e70cb1564","externalIds":{"DBLP":"journals/corr/abs-2309-15817","ArXiv":"2309.15817","DOI":"10.48550/arXiv.2309.15817","CorpusId":262944419},"title":"Identifying the Risks of LM Agents with an LM-Emulated Sandbox"},{"paperId":"482665786ce1956fb9ea4b694d2d8e8cf92276fa","externalIds":{"ArXiv":"2309.10228","DBLP":"conf/wacv/CuiMCYW24","DOI":"10.1109/WACVW60836.2024.00101","CorpusId":262054629},"title":"Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles"},{"paperId":"2591e780b07de962933490792c02025734a24a94","externalIds":{"DBLP":"journals/corr/abs-2309-10346","ArXiv":"2309.10346","DOI":"10.48550/arXiv.2309.10346","CorpusId":261945134},"title":"Explaining Agent Behavior with Large Language Models"},{"paperId":"9799436d3bcf04185c224543bf27737103c35154","externalIds":{"ArXiv":"2309.10092","DBLP":"journals/corr/abs-2309-10092","DOI":"10.1145/3769111","CorpusId":262054964},"title":"Conformal Temporal Logic Planning using Large Language Models"},{"paperId":"755853c6b30f5a186131e23a63c68a3f2737068e","externalIds":{"ArXiv":"2309.10062","DBLP":"conf/iros/KannanVM24","DOI":"10.1109/IROS58592.2024.10802322","CorpusId":262055166},"title":"SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models"},{"paperId":"ee2e0077ec46704f2cb930958c9bf3739a904227","externalIds":{"DBLP":"conf/icra/YangRST24","ArXiv":"2309.09919","DOI":"10.1109/ICRA57147.2024.10611447","CorpusId":262044464},"title":"Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents"},{"paperId":"cd29c25c489562b409a60f83365f93f33ee1a0a1","externalIds":{"DBLP":"journals/corr/abs-2309-14348","ArXiv":"2309.14348","DOI":"10.48550/arXiv.2309.14348","CorpusId":262827619},"title":"Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM"},{"paperId":"b70075b496c1f519093884945be5670c32cbceed","externalIds":{"DBLP":"conf/cdc/WangZCS24","ArXiv":"2309.09969","DOI":"10.1109/CDC56724.2024.10885862","CorpusId":262044060},"title":"Prompt a Robot to Walk with Large Language Models"},{"paperId":"d7d712e507c1c6273b05c773c825a668c5cf1504","externalIds":{"DBLP":"conf/naacl/GongHMNDZTFGV24","ArXiv":"2309.09971","DOI":"10.48550/arXiv.2309.09971","CorpusId":261898118},"title":"MindAgent: Emergent Gaming Interaction"},{"paperId":"8035a247980cb18abf2bb7b9d96e7d4c63622ef2","externalIds":{"ArXiv":"2309.10103","DBLP":"journals/corr/abs-2309-10103","DOI":"10.48550/arXiv.2309.10103","CorpusId":261945162},"title":"Reasoning about the Unseen for Efficient Outdoor Object Navigation"},{"paperId":"a4c921bdef167ae54cc3a40643e6e3ed13d49a61","externalIds":{"DBLP":"conf/iclr/0001SARJH024","ArXiv":"2309.07875","DOI":"10.48550/arXiv.2309.07875","CorpusId":261823321},"title":"Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions"},{"paperId":"b05d5ae30174f9c9a4b51660d15370f113dc9c40","externalIds":{"DBLP":"conf/iros/NiDTZXHWZ24","ArXiv":"2309.07726","DOI":"10.1109/IROS58592.2024.10801291","CorpusId":261822945},"title":"GRID: Scene-Graph-based Instruction-driven Robotic Task Planning"},{"paperId":"71bc0c97c20fffce796a355b16bd202987260029","externalIds":{"ArXiv":"2309.05922","DBLP":"journals/corr/abs-2309-05922","DOI":"10.48550/arXiv.2309.05922","CorpusId":261696947},"title":"A Survey of Hallucination in Large Foundation Models"},{"paperId":"807abb9c185ce233e2c8a2fcee49be851a1c968f","externalIds":{"DBLP":"journals/corr/abs-2309-04316","PubMedCentral":"11499633","ArXiv":"2309.04316","DOI":"10.3389/frobt.2024.1455375","CorpusId":261660596,"PubMed":"39449715"},"title":"Incremental learning of humanoid robot behavior from natural interaction and large language models"},{"paperId":"67c09c9f93aa91f2419f2b348e1545bc2c115e71","externalIds":{"DBLP":"journals/corr/abs-2309-02721","ArXiv":"2309.02721","DOI":"10.48550/arXiv.2309.02721","CorpusId":261557194},"title":"Gesture-Informed Robot Assistance via Foundation Models"},{"paperId":"26089bdfdbca1e6eaaceca71e3116b715bec6d47","externalIds":{"DBLP":"journals/corr/abs-2309-01029","ArXiv":"2309.01029","DOI":"10.1145/3639372","CorpusId":261530292},"title":"Explainability for Large Language Models: A Survey"},{"paperId":"bf0008d1b521be0c96bb34e8de78dd404ad37099","externalIds":{"DBLP":"journals/corr/abs-2308-15684","ArXiv":"2308.15684","DOI":"10.1109/SII58957.2024.10417267","CorpusId":261339591},"title":"Interactively Robot Action Planning with Uncertainty Analysis and Active Questioning by Large Language Model"},{"paperId":"83c3ddd2e56152c8361bfad7d0522a03aa4de6c2","externalIds":{"ArXiv":"2308.14972","DBLP":"journals/corr/abs-2308-14972","DOI":"10.48550/arXiv.2308.14972","CorpusId":261277182},"title":"LLM-Based Human-Robot Collaboration Framework for Manipulation Tasks"},{"paperId":"28c6ac721f54544162865f41c5692e70d61bccab","externalIds":{"DBLP":"journals/fcsc/WangMFZYZCTCLZWW24","ArXiv":"2308.11432","DOI":"10.1007/s11704-024-40231-1","CorpusId":261064713},"title":"A survey on large language model based autonomous agents"},{"paperId":"9fbde8d0315f52e598c5b4a1409ed2aee215ace9","externalIds":{"DBLP":"conf/aaai/ZhangYHWLSZZLZC24","ArXiv":"2308.11339","DOI":"10.1609/aaai.v38i16.29710","CorpusId":261064959},"title":"ProAgent: Building Proactive Cooperative Agents with Large Language Models"},{"paperId":"ad97671a924a9b3a060fee857e561f140ec79dd7","externalIds":{"DBLP":"conf/iclr/ChenSZ0YCYLHQQC24","ArXiv":"2308.10848","DOI":"10.48550/arXiv.2308.10848","CorpusId":261048935},"title":"AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents"},{"paperId":"aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3","externalIds":{"DBLP":"conf/aaai/BestaBKGPGGLNNH24","ArXiv":"2308.09687","DOI":"10.1609/aaai.v38i16.29720","CorpusId":261030303},"title":"Graph of Thoughts: Solving Elaborate Problems with Large Language Models"},{"paperId":"ec58a564fdda29e6a9a0a7bab5eeb4c290f716d7","externalIds":{"ArXiv":"2308.07201","DBLP":"journals/corr/abs-2308-07201","DOI":"10.48550/arXiv.2308.07201","CorpusId":260887105},"title":"ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"},{"paperId":"978d2112bef740aae960b2f948821d190dab175e","externalIds":{"DOI":"10.3390/cmsf2023008068","CorpusId":260847150},"title":"Are Large Language Models Intelligent? Are Humans?"},{"paperId":"0476750c048abe336b9a24dbfa60b975bf0834c1","externalIds":{"DBLP":"journals/corr/abs-2308-03983","ArXiv":"2308.03983","DOI":"10.48550/arXiv.2308.03983","CorpusId":260704453},"title":"SimplyRetrieve: A Private and Lightweight Retrieval-Centric Generative AI Tool"},{"paperId":"81b10e64133e775dab53153cc82277d276efe1f7","externalIds":{"DBLP":"conf/iclr/YaoHNLFXNC0AXMW24","ArXiv":"2308.02151","DOI":"10.48550/arXiv.2308.02151","CorpusId":260611249},"title":"Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"},{"paperId":"703035b483c181953de1b55b5fd59cd4cd4cf211","externalIds":{"DBLP":"journals/corr/abs-2308-00352","ArXiv":"2308.00352","DOI":"10.48550/arXiv.2308.00352","CorpusId":260351380},"title":"MetaGPT: Meta Programming for Multi-Agent Collaborative Framework"},{"paperId":"0bfc804e31eecfd77f45e4ee7f4d629fffdcd628","externalIds":{"DBLP":"journals/corr/abs-2307-16789","ArXiv":"2307.16789","DOI":"10.48550/arXiv.2307.16789","CorpusId":260334759},"title":"ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"},{"paperId":"38939304bb760473141c2aca0305e44fbe04e6e8","externalIds":{"ArXiv":"2307.15818","DBLP":"conf/corl/ZitkovichYXXXXW23","DOI":"10.48550/arXiv.2307.15818","CorpusId":260293142},"title":"RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control"},{"paperId":"af6d0ba799213cbbcbfceb1fb9b78d2858486308","externalIds":{"DBLP":"journals/corr/abs-2307-14535","ArXiv":"2307.14535","DOI":"10.48550/arXiv.2307.14535","CorpusId":260203080},"title":"Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition"},{"paperId":"59a4602b9613444df53de6323339f84cc75045c4","externalIds":{"ArXiv":"2307.11865","DBLP":"conf/icra/RivkinKHBD24","DOI":"10.1109/ICRA57147.2024.10610072","CorpusId":260125004},"title":"CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots"},{"paperId":"05d5e6dba2b49c55433b548c84e14547729f0fe0","externalIds":{"DBLP":"journals/corr/abs-2307-10690","ArXiv":"2307.10690","DOI":"10.48550/arXiv.2307.10690","CorpusId":259991866},"title":"Bridging Intelligence and Instinct: A New Control Paradigm for Autonomous Robots"},{"paperId":"67188a50e1d8a601896f1217451b99f646af4ac8","externalIds":{"ArXiv":"2307.09668","DBLP":"journals/corr/abs-2307-09668","DOI":"10.48550/arXiv.2307.09668","CorpusId":259311695},"title":"Towards A Unified Agent with Foundation Models"},{"paperId":"94ce1d5924e05e8d75e43ce70044293ddcef850a","externalIds":{"DOI":"10.1038/s41591-023-02448-8","CorpusId":259947046,"PubMed":"37460753"},"title":"Large language models in medicine"},{"paperId":"1cd8373490efc2d74c2796f4b2aa27c7d4415ec9","externalIds":{"DBLP":"conf/corl/HuangWZL0023","ArXiv":"2307.05973","DOI":"10.48550/arXiv.2307.05973","CorpusId":259837330},"title":"VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models"},{"paperId":"3843469976bd895851bfa08c8208350745bf649f","externalIds":{"DBLP":"conf/corl/RanaHGA0S23","ArXiv":"2307.06135","DOI":"10.48550/arXiv.2307.06135","CorpusId":259837542},"title":"SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning"},{"paperId":"1f9822022f586e375461660db792f23e891c7123","externalIds":{"DBLP":"journals/corr/abs-2307-06187","ArXiv":"2307.06187","DOI":"10.1109/ACSOS-C58168.2023.00048","CorpusId":259836864},"title":"Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems"},{"paperId":"c5d18dbb92d0cd5393baa1e69de33d6922ac3e57","externalIds":{"DBLP":"conf/icra/MandiJS24","ArXiv":"2307.04738","DOI":"10.1109/ICRA57147.2024.10610855","CorpusId":259501567},"title":"RoCo: Dialectic Multi-Robot Collaboration with Large Language Models"},{"paperId":"92930ed3560ea6c86d53cf52158bc793b089054d","externalIds":{"ArXiv":"2307.04657","DBLP":"conf/nips/JiLDPZB0SW023","DOI":"10.48550/arXiv.2307.04657","CorpusId":259501579},"title":"BeaverTails: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset"},{"paperId":"0893549771094fac547432cb4f84e9605c911a86","externalIds":{"PubMedCentral":"10326069","DBLP":"journals/npjdm/MeskoT23","DOI":"10.1038/s41746-023-00873-0","CorpusId":259357970,"PubMed":"37414860"},"title":"The imperative for regulatory oversight of large language models (or generative AI) in healthcare"},{"paperId":"587352c3b95c90de6d37f061c8e117f42be0b575","externalIds":{"DBLP":"journals/corr/abs-2307-02485","ArXiv":"2307.02485","DOI":"10.48550/arXiv.2307.02485","CorpusId":259342833},"title":"Building Cooperative Embodied Agents Modularly with Large Language Models"},{"paperId":"d1500f1dbd62e26ef0753f31e845078f58479968","externalIds":{"ArXiv":"2307.01928","DBLP":"conf/corl/RenDBSTBXTXVXSZ23","DOI":"10.48550/arXiv.2307.01928","CorpusId":259342058},"title":"Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners"},{"paperId":"df710c46594c04fb59ef9a93d3b4e1cb387a1b2b","externalIds":{"DBLP":"journals/corr/abs-2307-01848","ArXiv":"2307.01848","DOI":"10.48550/arXiv.2307.01848","CorpusId":259342896},"title":"Embodied Task Planning with Large Language Models"},{"paperId":"942130a875ccfe55a4c60c27c636f693e25cb13d","externalIds":{"DBLP":"journals/corr/abs-2307-00184","ArXiv":"2307.00184","DOI":"10.48550/arXiv.2307.00184","CorpusId":259317218},"title":"Personality Traits in Large Language Models"},{"paperId":"03251361c1d67c6b5badffc7059fdd7fbfea1fed","externalIds":{"DBLP":"journals/corr/abs-2306-17840","ArXiv":"2306.17840","DOI":"10.1109/ICRA57147.2024.10610634","CorpusId":259309028},"title":"Statler: State-Maintaining Language Models for Embodied Reasoning"},{"paperId":"d9823ffa34f865fb1d0adef95d64a0c352ae125f","externalIds":{"DBLP":"journals/corr/abs-2306-15724","ArXiv":"2306.15724","DOI":"10.48550/arXiv.2306.15724","CorpusId":259274760},"title":"REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction"},{"paperId":"6395e31dfcbce38ac574565ed4134297ebb61ef2","externalIds":{"DOI":"10.3390/electronics12132814","CorpusId":259723320},"title":"LLM-Informed Multi-Armed Bandit Strategies for Non-Stationary Environments"},{"paperId":"704f28c4c0a8e8264c2dae8922b0a3be84de2954","externalIds":{"ArXiv":"2306.14027","DBLP":"journals/tifs/KandePTDTKR24","DOI":"10.1109/TIFS.2024.3372809","CorpusId":259251452},"title":"(Security) Assertions by Large Language Models"},{"paperId":"7d22ad3573101337bca2091fb0114b377c4f3db6","externalIds":{"DBLP":"journals/corr/abs-2306-11695","ArXiv":"2306.11695","DOI":"10.48550/arXiv.2306.11695","CorpusId":259203115},"title":"A Simple and Effective Pruning Approach for Large Language Models"},{"paperId":"94bcf0390d5acb1b92323bd15cc1dc311314122c","externalIds":{"DBLP":"conf/corl/0003GFKLACEHHIX23","ArXiv":"2306.08647","DOI":"10.48550/arXiv.2306.08647","CorpusId":259164906},"title":"Language to Rewards for Robotic Skill Synthesis"},{"paperId":"1fc21645ccc8e99eb8162e5f91407148b7f77e3d","externalIds":{"DBLP":"journals/corr/abs-2306-07580","ArXiv":"2306.07580","DOI":"10.48550/arXiv.2306.07580","CorpusId":259144814},"title":"SayTap: Language to Quadrupedal Locomotion"},{"paperId":"60e6e3767c36bf9e16b58b7221c5712b4d3d5293","externalIds":{"DBLP":"conf/nips/ZhangCZXZ023","ArXiv":"2306.07929","CorpusId":259145016},"title":"Large Language Models Are Semi-Parametric Reinforcement Learning Agents"},{"paperId":"db4cf9f6a653d5c15973e836c800ea47743251ae","externalIds":{"DBLP":"journals/corr/abs-2306-05499","ArXiv":"2306.05499","DOI":"10.48550/arXiv.2306.05499","CorpusId":259129807},"title":"Prompt Injection attack against LLM-integrated Applications"},{"paperId":"98cfd7b1b29453c4e82536f5afdc6ddc58bbb1b3","externalIds":{"DBLP":"journals/corr/abs-2306-03310","ArXiv":"2306.03310","DOI":"10.48550/arXiv.2306.03310","CorpusId":259089508},"title":"LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning"},{"paperId":"484c508bfad5d335f8a87cf62027fd38cf87f234","externalIds":{"DBLP":"journals/robotics/TaesiAP23","DOI":"10.3390/robotics12030079","CorpusId":259228454},"title":"COBOT Applications - Recent Advances and Challenges"},{"paperId":"73b2dee720ebc9014dfe57d9b73da60ca7645c86","externalIds":{"DBLP":"journals/corr/abs-2305-19352","ArXiv":"2305.19352","DOI":"10.1109/FLLM63129.2024.10852491","CorpusId":258987995},"title":"LLM-BRAIn: AI-driven Fast Generation of Robot Behaviour Tree based on Large Language Model"},{"paperId":"80be1426825288ff876acb8cc0babcc6629fa644","externalIds":{"ArXiv":"2305.18898","DBLP":"journals/corr/abs-2305-18898","DOI":"10.48550/arXiv.2305.18898","CorpusId":258967880},"title":"AlphaBlock: Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation"},{"paperId":"d2bf230a0229a98066b47f8635ec0b45e26b86e1","externalIds":{"DBLP":"journals/corr/abs-2305-16925","ArXiv":"2305.16925","DOI":"10.48550/arXiv.2305.16925","CorpusId":258947447},"title":"How To Not Train Your Dragon: Training-free Embodied Object Goal Navigation with Semantic Frontiers"},{"paperId":"f197bf0fc2f228483f6af3285000d54d8d97f9eb","externalIds":{"ArXiv":"2305.16291","DBLP":"journals/tmlr/WangX0MXZFA24","DOI":"10.48550/arXiv.2305.16291","CorpusId":258887849},"title":"Voyager: An Open-Ended Embodied Agent with Large Language Models"},{"paperId":"c695c4e68561347564ea0daa50dc339dff73d8c5","externalIds":{"DBLP":"journals/corr/abs-2305-17144","ArXiv":"2305.17144","DOI":"10.48550/arXiv.2305.17144","CorpusId":258959262},"title":"Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory"},{"paperId":"4f601b4e561557c7a0bd5a741a54cabaec7dc70e","externalIds":{"ArXiv":"2305.14909","DBLP":"journals/corr/abs-2305-14909","DOI":"10.48550/arXiv.2305.14909","CorpusId":258865907},"title":"Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning"},{"paperId":"4780d0a027c5c5a8e01d7cf697f6296880ffc945","externalIds":{"ArXiv":"2305.14325","DBLP":"journals/corr/abs-2305-14325","DOI":"10.48550/arXiv.2305.14325","CorpusId":258841118},"title":"Improving Factuality and Reasoning in Language Models through Multiagent Debate"},{"paperId":"90027ca7802645671a69b00b65e1fa94e6b63544","externalIds":{"ArXiv":"2305.18323","DBLP":"journals/corr/abs-2305-18323","DOI":"10.48550/arXiv.2305.18323","CorpusId":258967566},"title":"ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models"},{"paperId":"b3bba15f000000a6d3b5808f798a9fe7629fa499","externalIds":{"DBLP":"journals/corr/abs-2305-11014","ArXiv":"2305.11014","DOI":"10.48550/arXiv.2305.11014","CorpusId":258762760},"title":"Generalized Planning in PDDL Domains with Pretrained Large Language Models"},{"paperId":"6f821d75968bc8de070af3ce5aa7f57bc031fafb","externalIds":{"DBLP":"conf/nips/XiangTGSWYH23","ArXiv":"2305.10626","DOI":"10.48550/arXiv.2305.10626","CorpusId":258762577},"title":"Language Models Meet World Models: Embodied Experiences Enhance Language Models"},{"paperId":"c3a59e1e405e7c28319e5a1c5b5241f9b340cf63","externalIds":{"DBLP":"journals/corr/abs-2305-10250","ArXiv":"2305.10250","DOI":"10.48550/arXiv.2305.10250","CorpusId":258741194},"title":"MemoryBank: Enhancing Large Language Models with Long-Term Memory"},{"paperId":"2e6b6de08f459e2165b11ed8d2103916966b0fcf","externalIds":{"ArXiv":"2305.10142","DBLP":"journals/corr/abs-2305-10142","DOI":"10.48550/arXiv.2305.10142","CorpusId":258740978},"title":"Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback"},{"paperId":"2f3822eb380b5e753a6d579f31dfc3ec4c4a0820","externalIds":{"ArXiv":"2305.10601","DBLP":"journals/corr/abs-2305-10601","DOI":"10.48550/arXiv.2305.10601","CorpusId":258762525},"title":"Tree of Thoughts: Deliberate Problem Solving with Large Language Models"},{"paperId":"ec56f49bef8925dc8931cc261ab3aca4dd36ad2d","externalIds":{"DBLP":"journals/corr/abs-2305-09067","ArXiv":"2305.09067","DOI":"10.48550/arXiv.2305.09067","CorpusId":258715201},"title":"SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting"},{"paperId":"e7a4e987dc250ac6a016ee2011bc7a552cfa8e8a","externalIds":{"ArXiv":"2305.05658","DBLP":"journals/arobots/WuAKLZSBRF23","DOI":"10.1007/s10514-023-10139-z","CorpusId":258564887},"title":"TidyBot: Personalized Robot Assistance with Large Language Models"},{"paperId":"5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f","externalIds":{"DBLP":"journals/corr/abs-2305-02412","ArXiv":"2305.02412","DOI":"10.48550/arXiv.2305.02412","CorpusId":258480064},"title":"Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents"},{"paperId":"ed7ac159eb1850491a812b074cf37157600c5b13","externalIds":{"DBLP":"journals/natmi/MannENDMBHKPRTRMS23","DOI":"10.1038/s42256-023-00653-1","CorpusId":258519213},"title":"Generative AI entails a credit–blame asymmetry"},{"paperId":"049af20e556a81ea56755c7f893340336aca3088","externalIds":{"DBLP":"conf/hais/SantamartaFSHGL23","ArXiv":"2304.14844","DOI":"10.1007/978-3-031-40725-3_45","CorpusId":258418212},"title":"Using Large Language Models for Interpreting Autonomous Robots Behaviors"},{"paperId":"131c6f328c11706de2c43cd16e0b7c5d5e610b6a","externalIds":{"DBLP":"journals/corr/abs-2304-13712","ArXiv":"2304.13712","DOI":"10.1145/3649506","CorpusId":258331833},"title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"},{"paperId":"51601d554d04c89ae71efe1e66c1d67ef44bec71","externalIds":{"DBLP":"journals/corr/abs-2304-12958","ArXiv":"2304.12958","DOI":"10.1109/ICDL55364.2023.10364407","CorpusId":258309200},"title":"A Closer Look at Reward Decomposition for High-Level Robotic Explanations"},{"paperId":"bd05f81167ca3f77460f4a1da3bf5ade9febb15b","externalIds":{"DBLP":"conf/icml/HuS23","ArXiv":"2304.07297","DOI":"10.48550/arXiv.2304.07297","CorpusId":258179085},"title":"Language Instructed Reinforcement Learning for Human-AI Coordination"},{"paperId":"5278a8eb2ba2429d4029745caf4e661080073c81","externalIds":{"DBLP":"conf/uist/ParkOCMLB23","ArXiv":"2304.03442","DOI":"10.1145/3586183.3606763","CorpusId":258040990},"title":"Generative Agents: Interactive Simulacra of Human Behavior"},{"paperId":"a98862ffe4c18634a67a3df8a965a35e5e0d7ec8","externalIds":{"DOI":"10.1016/j.lindif.2023.102274","CorpusId":257445349},"title":"ChatGPT for good? On opportunities and challenges of large language models for education"},{"paperId":"06e5828341aa3926e1d839039363b0673b9461cc","externalIds":{"ArXiv":"2303.14100","DBLP":"journals/corr/abs-2303-14100","DOI":"10.48550/arXiv.2303.14100","CorpusId":257757298},"title":"Errors are Useful Prompts: Instruction Guided Task Programming with Verifier-Assisted Iterative Prompting"},{"paperId":"8f2d4758e6d525509ae36bb30224dc9259027e6b","externalIds":{"DBLP":"journals/arobots/LinAMPB23","ArXiv":"2303.12153","DOI":"10.1007/s10514-023-10131-7","CorpusId":257663442},"title":"Text2Motion: from natural language instructions to feasible plans"},{"paperId":"0671fd553dd670a4e820553a974bc48040ba0819","externalIds":{"DBLP":"conf/nips/ShinnCGNY23","ArXiv":"2303.11366","CorpusId":258833055},"title":"Reflexion: language agents with verbal reinforcement learning"},{"paperId":"e4be613cc875e61b8c1c6c60d958f1c20d12d6c0","externalIds":{"ArXiv":"2303.06247","DBLP":"conf/iros/Ding0P023","DOI":"10.1109/IROS55552.2023.10342169","CorpusId":257496672},"title":"Task and Motion Planning with Large Language Models for Object Rearrangement"},{"paperId":"407b9e9478ba6bff43ce4b20e8b6cb2b303477d2","externalIds":{"ArXiv":"2303.05510","DBLP":"conf/iclr/ZhangCSDTG23","DOI":"10.48550/arXiv.2303.05510","CorpusId":257427177},"title":"Planning with Large Language Models for Code Generation"},{"paperId":"32524aa3ae8522542753ed7e6f4cca3970e4acab","externalIds":{"ArXiv":"2303.03480","DBLP":"journals/ral/DorbalaMM24","DOI":"10.1109/LRA.2023.3346800","CorpusId":257378363},"title":"Can an Embodied Agent Find Your “Cat-shaped Mug”? LLM-Based Zero-Shot Object Navigation"},{"paperId":"38fe8f324d2162e63a967a9ac6648974fc4c66f3","externalIds":{"ArXiv":"2303.03378","DBLP":"journals/corr/abs-2303-03378","DOI":"10.48550/arXiv.2303.03378","CorpusId":257364842},"title":"PaLM-E: An Embodied Multimodal Language Model"},{"paperId":"5d8a0a5c4a5ecdce0ff293d479803bc976ea2b0b","externalIds":{"ArXiv":"2303.00855","DBLP":"conf/nips/HuangXSDZLFMLHI23","CorpusId":266173978},"title":"Grounded Decoding: Guiding Text Generation with Grounded Models for Embodied Agents"},{"paperId":"9d3cbe8d25c8f093714f6e5cfaf5a9e8f2f938e9","externalIds":{"DBLP":"conf/aaaiss/0007L23","ArXiv":"2302.12927","DOI":"10.48550/arXiv.2302.12927","CorpusId":257219432},"title":"Robot Behavior-Tree-Based Task Generation with Large Language Models"},{"paperId":"705e49afd92130f2bc1e0d4d0b1f6cb14e88803f","externalIds":{"DBLP":"conf/ccs/AbdelnabiGMEHF23","ArXiv":"2302.12173","DOI":"10.1145/3605764.3623985","CorpusId":258546941},"title":"Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection"},{"paperId":"e701e4c02a32da186d25b08373ada12d83b73b3d","externalIds":{"DBLP":"conf/rss/YuXTSWBSTMPHIX23","ArXiv":"2302.11550","DOI":"10.48550/arXiv.2302.11550","CorpusId":257079001},"title":"Scaling Robot Learning with Semantically Imagined Experience"},{"paperId":"53d128ea815bcc0526856eb5a9c42cc977cb36a7","externalIds":{"DBLP":"journals/corr/abs-2302-04761","ArXiv":"2302.04761","DOI":"10.48550/arXiv.2302.04761","CorpusId":256697342},"title":"Toolformer: Language Models Can Teach Themselves to Use Tools"},{"paperId":"102e4c860e39a2bfd7bf3f03b9ad69aac7bf3b5f","externalIds":{"ArXiv":"2302.00763","DBLP":"journals/corr/abs-2302-00763","DOI":"10.48550/arXiv.2302.00763","CorpusId":253180684},"title":"Collaborating with language models for embodied reasoning"},{"paperId":"2d4cc999cf1a4202849ae09d0972660800c14eb4","externalIds":{"DBLP":"journals/corr/abs-2301-07150","ArXiv":"2301.07150","DOI":"10.1109/ICRA48891.2023.10160668","CorpusId":255998421},"title":"Embodied Agents for Efficient Exploration and Smart Scene Description"},{"paperId":"492987781038027ccf869b6992f48eb14022bac2","externalIds":{"ArXiv":"2301.02555","DBLP":"journals/corr/abs-2301-02555","DOI":"10.1145/3568162.3578623","CorpusId":255341638},"title":"No, to the Right: Online Language Corrections for Robotic Manipulation via Shared Autonomy"},{"paperId":"2cd72e71299c5d62d5cdb1164df5236172d418c4","externalIds":{"DBLP":"journals/corr/abs-2301-00355","ArXiv":"2301.00355","DOI":"10.48550/arXiv.2301.00355","CorpusId":253306024},"title":"Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits"},{"paperId":"e65b346d442e9962a4276dc1c1af2956d9d5f1eb","externalIds":{"DBLP":"journals/corr/abs-2212-10560","ArXiv":"2212.10560","ACL":"2023.acl-long.754","DOI":"10.48550/arXiv.2212.10560","CorpusId":254877310},"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions"},{"paperId":"fd1cf28a2b8caf2fe29af5e7fa9191cecfedf84d","externalIds":{"ArXiv":"2212.06817","DBLP":"conf/rss/BrohanBCCDFGHHH23","DOI":"10.48550/arXiv.2212.06817","CorpusId":254591260},"title":"RT-1: Robotics Transformer for Real-World Control at Scale"},{"paperId":"8ee45aeb7c97e3346cc62f216f673b91277ac718","externalIds":{"DBLP":"conf/iccv/SongSWCW023","ArXiv":"2212.04088","DOI":"10.1109/ICCV51070.2023.00280","CorpusId":254408960},"title":"LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models"},{"paperId":"ee0bafc81f864bd013bfad6a96494720d6445c3d","externalIds":{"DBLP":"journals/ais/YazdanpanahGSDJNR23","DOI":"10.1007/s00146-022-01607-8","CorpusId":254357010},"title":"Reasoning about responsibility in autonomous systems: challenges and opportunities"},{"paperId":"0e34addae55a571d7efd3a5e2543e86dd7d41a83","externalIds":{"DBLP":"journals/corr/abs-2210-06407","ArXiv":"2210.06407","DOI":"10.48550/arXiv.2210.06407","CorpusId":252846090},"title":"Interactive Language: Talking to Robots in Real Time"},{"paperId":"c305ab1bdba79442bec72ec7f5c5ee7c49c2a566","externalIds":{"DBLP":"journals/corr/abs-2210-05714","ArXiv":"2210.05714","DOI":"10.1109/ICRA48891.2023.10160969","CorpusId":252846548},"title":"Visual Language Maps for Robot Navigation"},{"paperId":"2cb97b2bb6ab2eb17add9ffe69d5cbeaca2b29c8","externalIds":{"DBLP":"journals/corr/abs-2210-05359","ArXiv":"2210.05359","DOI":"10.48550/arXiv.2210.05359","CorpusId":252815535},"title":"Mind's Eye: Grounded Language Model Reasoning through Simulation"},{"paperId":"4fd4e392fb39124744bdfbb6d71ae2030be5132e","externalIds":{"DBLP":"journals/corr/abs-2210-02438","ArXiv":"2210.02438","DOI":"10.1109/LRA.2023.3272516","CorpusId":252715865},"title":"DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics"},{"paperId":"c03fa01fbb9c77fe3d10609ba5f1dee33a723867","externalIds":{"DBLP":"journals/corr/abs-2209-11302","ArXiv":"2209.11302","DOI":"10.1109/ICRA48891.2023.10161317","CorpusId":252519594},"title":"ProgPrompt: Generating Situated Robot Task Plans using Large Language Models"},{"paperId":"91deaf9d324c8feafc189da0da03e60a60287bca","externalIds":{"ArXiv":"2209.07753","DBLP":"conf/icra/LiangHXXHIFZ23","DOI":"10.1109/ICRA48891.2023.10160591","CorpusId":252355542},"title":"Code as Policies: Language Model Programs for Embodied Control"},{"paperId":"d1ad1bfa0bb76002b10e7f211b937842baeb28d9","externalIds":{"ArXiv":"2209.04924","DBLP":"journals/corr/abs-2209-04924","DOI":"10.1109/ICRA48891.2023.10160626","CorpusId":252200224},"title":"Meta-Reinforcement Learning via Language Instructions"},{"paperId":"961a1772f3b90d9dffd2b571c6996007a1d0ccd1","externalIds":{"DBLP":"journals/corr/abs-2208-13266","ArXiv":"2208.13266","DOI":"10.48550/arXiv.2208.13266","CorpusId":251903775},"title":"JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents"},{"paperId":"97e6b89f8f256289b01b9f31799d957db81f2d4e","externalIds":{"DBLP":"conf/icra/BuckerFHKMVB23","ArXiv":"2208.02918","DOI":"10.1109/ICRA48891.2023.10161068","CorpusId":251371492},"title":"LATTE: LAnguage Trajectory TransformEr"},{"paperId":"d697b440dd0e65a05fe027e4c0ea85f62dcba033","externalIds":{"DBLP":"journals/patterns/LievinHMW24","ArXiv":"2207.08143","PubMedCentral":"10935498","DOI":"10.1016/j.patter.2024.100943","CorpusId":250627547,"PubMed":"38487804"},"title":"Can large language models reason about medical questions?"},{"paperId":"f3cf71c51b882fe3111d71c4bf104297d38197f8","externalIds":{"ArXiv":"2207.05608","DBLP":"conf/corl/HuangXXCLFZTMCS22","DOI":"10.48550/arXiv.2207.05608","CorpusId":250451569},"title":"Inner Monologue: Embodied Reasoning through Planning with Language Models"},{"paperId":"cdf54c147434c83a4a380916b6c1279b0ca19fc2","externalIds":{"ArXiv":"2207.04429","DBLP":"conf/corl/ShahOIL22","DOI":"10.48550/arXiv.2207.04429","CorpusId":250426345},"title":"LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action"},{"paperId":"52bf81fbb080357669d04631a3fa9b0b81043bac","externalIds":{"ArXiv":"2206.11421","DBLP":"journals/corr/abs-2206-11421","DOI":"10.1145/3624699","CorpusId":249953749},"title":"On Specifying for Trustworthiness"},{"paperId":"e850d4c0dad3aee3b8b40be5e5d5e5c31354d8cc","externalIds":{"ArXiv":"2206.10498","DBLP":"conf/nips/ValmeekamMHSK23","CorpusId":249889477},"title":"PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change"},{"paperId":"5922f437512158970c417f4413bface021df5f78","externalIds":{"DBLP":"journals/corr/abs-2205-06175","ArXiv":"2205.06175","DOI":"10.48550/arXiv.2205.06175","CorpusId":248722148},"title":"A Generalist Agent"},{"paperId":"a8e510680ecbf5ad1fa32a486b3135f9886a6c2f","externalIds":{"DBLP":"journals/corr/abs-2205-00176","ArXiv":"2205.00176","ACL":"2022.naacl-main.155","DOI":"10.48550/arXiv.2205.00176","CorpusId":248496216},"title":"Building a Role Specified Open-Domain Dialogue System Leveraging Large-Scale Language Models"},{"paperId":"cb5e3f085caefd1f3d5e08637ab55d39e61234fc","externalIds":{"DBLP":"conf/corl/IchterBCFHHHIIJ22","ArXiv":"2204.01691","CorpusId":247939706},"title":"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"},{"paperId":"ada81a4de88a6ce474df2e2446ad11fea480616e","externalIds":{"ArXiv":"2204.00598","DBLP":"journals/corr/abs-2204-00598","CorpusId":247922520},"title":"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"},{"paperId":"34e0bf5ad047e2b8d908123107d77ce6bca704ad","externalIds":{"DBLP":"conf/hri/Dogan0L22","DOI":"10.1109/HRI53351.2022.9889368","CorpusId":247619327},"title":"Asking Follow-Up Clarifications to Resolve Ambiguities in Human-Robot Conversation"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"b32a6f6ef7dd775e0f876b4713ceccebc56e651e","externalIds":{"DBLP":"journals/corr/abs-2202-13169","ArXiv":"2202.13169","DOI":"10.1145/3520312.3534862","CorpusId":247158549},"title":"A systematic evaluation of large language models of code"},{"paperId":"0e931f497172ab0c3017c81af58156b3fa52888f","externalIds":{"DBLP":"journals/thri/SchneidersCKRS22","DOI":"10.1145/3488242","CorpusId":247617547},"title":"Non-Dyadic Interaction: A Literature Review of 15 Years of Human-Robot Interaction Conference Publications"},{"paperId":"aa7ed7e04182d0588bb53376e472afb59e236c36","externalIds":{"ArXiv":"2202.01875","DBLP":"journals/corr/abs-2202-01875","CorpusId":246607834},"title":"Rethinking Explainability as a Dialogue: A Practitioner's Perspective"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"b3848d32f7294ec708627897833c4097eb4d8778","externalIds":{"DBLP":"journals/corr/abs-2201-08239","ArXiv":"2201.08239","CorpusId":246063428},"title":"LaMDA: Language Models for Dialog Applications"},{"paperId":"92a8f7f09f3705cb5a6009a42220a6f01ea084e8","externalIds":{"DBLP":"journals/corr/abs-2201-07207","ArXiv":"2201.07207","CorpusId":246035276},"title":"Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents"},{"paperId":"3e906906d475c73b6d8ce24ac5ebdac9979fd01b","externalIds":{"DBLP":"journals/pami/SelvaJENMC23","ArXiv":"2201.05991","DOI":"10.1109/TPAMI.2023.3243465","CorpusId":246015436,"PubMed":"37022830"},"title":"Video Transformers: A Survey"},{"paperId":"bfba05093314e52317536b6cfc8b7fded8371e02","externalIds":{"ArXiv":"2111.03205","DBLP":"journals/corr/abs-2111-03205","CorpusId":243832934},"title":"LILA: Language-Informed Latent Actions"},{"paperId":"7b8ef4337eeca9c5b047ed2d30590c22485c65ff","externalIds":{"DBLP":"journals/ijmms/KoppBK22","DOI":"10.1016/j.ijhcs.2021.102730","CorpusId":243948197},"title":"How Linguistic Framing Affects Factory Workers' Initial Trust in Collaborative Robots: The Interplay Between Anthropomorphism and Technological Replacement"},{"paperId":"6ec6fa4e34200e13d80ee79b95d1cc6ec0f6b424","externalIds":{"DBLP":"journals/corr/abs-2110-00534","ArXiv":"2110.00534","DOI":"10.1609/aaai.v36i2.20097","CorpusId":238253352},"title":"TEACh: Task-driven Embodied Agents that Chat"},{"paperId":"e6ec02efa420a297e0072585254bff871563cbf8","externalIds":{"DBLP":"journals/thri/HanPY21","DOI":"10.1145/3469652","CorpusId":237518349},"title":"The Need for Verbal Robot Explanations and How People Would Like a Robot to Explain Itself"},{"paperId":"20e6909ce6c5f12b61e5c9022d97134137360273","externalIds":{"DBLP":"conf/corl/NairM0ISF21","ArXiv":"2109.01115","CorpusId":237385309},"title":"Learning Language-Conditioned Robot Behavior from Offline Data and Crowd-Sourced Annotation"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"041c4a3932eae3931d90b1a0fc033cf5f491c267","externalIds":{"MAG":"3171850892","DBLP":"conf/naacl/XuJLBWD21","ACL":"2021.naacl-main.235","DOI":"10.18653/V1/2021.NAACL-MAIN.235","CorpusId":235097625},"title":"Bot-Adversarial Dialogue for Safe Conversational Agents"},{"paperId":"7d70e49d027634e5a070096b2735dee90ab36d26","externalIds":{"ArXiv":"2104.09025","DBLP":"journals/corr/abs-2104-09025","DOI":"10.1109/HUMANOIDS47582.2021.9555782","CorpusId":233296675},"title":"The MIT Humanoid Robot: Design, Motion Planning, and Control For Acrobatic Behaviors"},{"paperId":"bb44857cac3dd7fd0fdb58527886d74e0c7a55b9","externalIds":{"DBLP":"journals/ral/LiuXS21","DOI":"10.1109/LRA.2021.3056373","CorpusId":231704288},"title":"A Lifelong Learning Approach to Mobile Robot Navigation"},{"paperId":"cdbb860418769f2c789695618df437539423f7b2","externalIds":{"DBLP":"conf/hri/IrfanRSPG22","DOI":"10.1145/3434074.3444881","CorpusId":232136609},"title":"Lifelong Learning and Personalization in Long-Term Human-Robot Interaction (LEAP-HRI)"},{"paperId":"2cd605106b88c85d7d8b865b1ef0f8c8293debf1","externalIds":{"ArXiv":"2102.12092","DBLP":"conf/icml/RameshPGGVRCS21","MAG":"3170016573","CorpusId":232035663},"title":"Zero-Shot Text-to-Image Generation"},{"paperId":"fcfc9648561a221750b8085790ad9ba1bebb1800","externalIds":{"ArXiv":"2102.00894","ACL":"2021.eacl-main.284","DBLP":"conf/eacl/KassnerDS21","DOI":"10.18653/v1/2021.eacl-main.284","CorpusId":231740666},"title":"Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models"},{"paperId":"1e46c6970d1b3f4f3f9df4c3598f24939e712b2e","externalIds":{"DBLP":"journals/corr/abs-2101-01625","ArXiv":"2101.01625","DOI":"10.1145/3434073.3444657","CorpusId":230523843},"title":"Explainable AI for Robot Failures: Generating Explanations that Improve User Assistance in Fault Recovery"},{"paperId":"191f2a22c3cd2bcebdb3c2f5ac354e2a464e0931","externalIds":{"DBLP":"journals/corr/abs-2010-12639","ArXiv":"2010.12639","MAG":"3093582851","CorpusId":225067813},"title":"The RobotSlang Benchmark: Dialog-guided Robot Localization and Navigation"},{"paperId":"81cac40cd4e20f1fd3c6be7fd3e572d999e4b230","externalIds":{"MAG":"3086312048","DBLP":"journals/systems/Jordanous20","DOI":"10.3390/systems8030031","CorpusId":221802114},"title":"Intelligence without Representation: A Historical Perspective"},{"paperId":"0887910d5a0f5c7d0e1093db8b4fe75235faaf0e","externalIds":{"DOI":"10.1093/oso/9780199828098.003.0024","CorpusId":243129092},"title":"Relations Between Language and Thought"},{"paperId":"da83a77dc3432128534fc6aafcfb8789ebea72b5","externalIds":{"MAG":"3035305488","DBLP":"conf/ijcai/MirskyMWYS20","DOI":"10.24963/ijcai.2020/36","CorpusId":220483028},"title":"A Penny for Your Thoughts: The Value of Communication in Ad Hoc Teamwork"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"01203341a8b5b7df21dec5359afe8cc388786ebf","externalIds":{"MAG":"3012990076","ACL":"2020.lrec-1.297","DBLP":"conf/lrec/GuoDVA20","CorpusId":214733361},"title":"Wiki-40B: Multilingual Language Model Dataset"},{"paperId":"8946c35672fdc04174fe36b5d479756b98280fe9","externalIds":{"DBLP":"journals/jair/ThomasonPSWJYHS20","MAG":"3008329436","DOI":"10.1613/jair.1.11485","CorpusId":215807853},"title":"Jointly Improving Parsing and Perception for Natural Language Commands through Human-Robot Dialog"},{"paperId":"7f1e602a44b56b9853fcc2063df9593e7b79ba22","externalIds":{"MAG":"2987644081","ArXiv":"1911.05268","DBLP":"journals/corr/abs-1911-05268","CorpusId":207930466},"title":"Adversarial Examples in Modern Machine Learning: A Review"},{"paperId":"c8c30a424f09d6ec8363071786821b6ae9fe4354","externalIds":{"MAG":"2977683283","DBLP":"conf/chira/BergmanJGS19","DOI":"10.5220/0008363201910198","CorpusId":204754496},"title":"Human-cobot Teams: Exploring Design Principles and Behaviour Models to Facilitate the Understanding of Non-verbal Communication from Cobots"},{"paperId":"93d63ec754f29fa22572615320afe0521f7ec66d","externalIds":{"DBLP":"journals/corr/abs-1908-10084","MAG":"2970641574","ArXiv":"1908.10084","ACL":"D19-1410","DOI":"10.18653/v1/D19-1410","CorpusId":201646309},"title":"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"},{"paperId":"e3adfc4de6e65ffb8e179790c5693aac0af2cfff","externalIds":{"MAG":"2979372603","ACL":"W19-5912","DBLP":"conf/sigdial/PapangelisWMT19","ArXiv":"1907.05507","DOI":"10.18653/v1/W19-5912","CorpusId":196471395},"title":"Collaborative Multi-Agent Dialogue Model Training Via Reinforcement Learning"},{"paperId":"97b446e2ec3b402ea104421dab5eb4b99a21e42a","externalIds":{"ArXiv":"1906.05684","MAG":"2951073610","DBLP":"journals/corr/abs-1906-05684","DOI":"10.5281/zenodo.3240529","CorpusId":199512916},"title":"Understanding artificial intelligence ethics and safety"},{"paperId":"9fa5fb853bf6639abbbbf570ffecb7b5e3e2885d","externalIds":{"DBLP":"journals/ras/ZaatariMLU19","MAG":"2922464707","DOI":"10.1016/J.ROBOT.2019.03.003","CorpusId":88500576},"title":"Cobot programming for collaborative industrial tasks: An overview"},{"paperId":"e0f7763c0da21ea3180165fa09be97cf5c62d40e","externalIds":{"MAG":"2963641083","DBLP":"journals/aamas/RosenfeldR19","ArXiv":"1904.08123","DOI":"10.1007/s10458-019-09408-y","CorpusId":118687946},"title":"Explainability in human–agent systems"},{"paperId":"c41a11c0e9b8b92b4faaf97749841170b760760a","externalIds":{"DBLP":"journals/corr/abs-1904-01766","ArXiv":"1904.01766","MAG":"2981851019","DOI":"10.1109/ICCV.2019.00756","CorpusId":102483628},"title":"VideoBERT: A Joint Model for Video and Language Representation Learning"},{"paperId":"b0b96270a9bbeb9f3ec040e70114d565fbcaaed9","externalIds":{"DBLP":"journals/corr/abs-1901-05415","ArXiv":"1901.05415","MAG":"2951998460","ACL":"P19-1358","DOI":"10.18653/v1/P19-1358","CorpusId":58007087},"title":"Learning from Dialogue after Deployment: Feed Yourself, Chatbot!"},{"paperId":"eceb7897a08dbd8e02e9b81da36610d931daab19","externalIds":{"DBLP":"conf/ro-man/GongZ18","MAG":"2899824181","DOI":"10.1109/ROMAN.2018.8525675","CorpusId":51842740},"title":"Behavior Explanation as Intention Signaling in Human-Robot Teaming"},{"paperId":"78f548cb0d60ecc897265b1540a6e87de0f888b9","externalIds":{"MAG":"2794708857","DBLP":"conf/taros/AbioyePTSR18","DOI":"10.1007/978-3-319-96728-8_36","CorpusId":51867710},"title":"The Multimodal Speech and Visual Gesture (mSVG) Control Model for a Practical Patrol, Search, and Rescue Aerobot"},{"paperId":"cd43b82f0793f048d16d704c9eed9451252a0589","externalIds":{"DBLP":"journals/ram/MakriniEBVKJSCR18","MAG":"2804659270","DOI":"10.1109/MRA.2018.2815947","CorpusId":49191365},"title":"Working with Walt: How a Cobot Was Developed and Inserted on an Auto Assembly Line"},{"paperId":"d6b4db3309aad15ca6d379e905d9c9a4cbd77311","externalIds":{"MAG":"2804421475","DOI":"10.1080/08998280.2018.1457879","CorpusId":49215839,"PubMed":"29904320"},"title":"Facilitators and barriers to ad hoc team performance"},{"paperId":"5a5a1d666e4b7b933bc5aafbbadf179bc447ee67","externalIds":{"ArXiv":"1805.00899","MAG":"2798877128","DBLP":"journals/corr/abs-1805-00899","CorpusId":22050710},"title":"AI safety via debate"},{"paperId":"32614c3ffebdb97544a4c08b065eafb42c6cc1f5","externalIds":{"ArXiv":"1803.02088","DBLP":"journals/corr/abs-1803-02088","MAG":"2964031064","CorpusId":3742529},"title":"Explain Yourself: A Natural Language Interface for Scrutable Autonomous Robots"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"8fab7d7dfd233fd5d19bc2641b4c1ca74fc7bc6a","externalIds":{"MAG":"2526379199","ArXiv":"1609.07088","DBLP":"journals/corr/DevinGDAL16","DOI":"10.1109/ICRA.2017.7989250","CorpusId":18015872},"title":"Learning modular neural network policies for multi-task and multi-robot transfer"},{"paperId":"88c307c51594c6d802080a0780d0d654e2e2891f","externalIds":{"MAG":"2964138343","DBLP":"journals/cviu/WuTWSDH17","ArXiv":"1607.05910","DOI":"10.1016/j.cviu.2017.05.001","CorpusId":11746788},"title":"Visual question answering: A survey of methods and datasets"},{"paperId":"e86f71ca2948d17b003a5f068db1ecb2b77827f7","externalIds":{"DBLP":"journals/corr/AmodeiOSCSM16","ArXiv":"1606.06565","MAG":"2462906003","CorpusId":10242377},"title":"Concrete Problems in AI Safety"},{"paperId":"d3aa893e9413903c3fc2f29a9b7b91dc72d826d7","externalIds":{"MAG":"2302290679","DOI":"10.4271/2016-01-0337","CorpusId":112320616},"title":"A Framework for Collaborative Robot (CoBot) Integration in Advanced Manufacturing Systems"},{"paperId":"1fff0ffc21152375413f4f150291ffbfcf5f6995","externalIds":{"MAG":"1766056542","DBLP":"journals/ki/CrockerDT16","DOI":"10.1007/s13218-015-0391-y","CorpusId":18743527},"title":"Information Density and Linguistic Encoding (IDeaL)"},{"paperId":"8e4218bb113cd1727ae75414791c506507e0e78f","externalIds":{"MAG":"2094589399","DOI":"10.1016/J.LINDIF.2015.03.020","CorpusId":145548920},"title":"Are balanced groups better? : Belbin roles in collaborative learning groups"},{"paperId":"65438e0ba226c1f97bd8a36333ebc3297b1a32fd","externalIds":{"DBLP":"journals/ijrr/KoberBP13","MAG":"1977655452","DOI":"10.1177/0278364913495721","CorpusId":1932843},"title":"Reinforcement learning in robotics: A survey"},{"paperId":"00f00870c5de7fd0329c4fa562b960e83914ddfb","externalIds":{"DBLP":"conf/rss/RamanLFLMK13","MAG":"2295357975","DOI":"10.15607/RSS.2013.IX.023","CorpusId":13104095},"title":"Sorry Dave, I'm Afraid I Can't Do That: Explaining Unachievable Robot Tasks Using Natural Language"},{"paperId":"7b220945d96277d86fffadc23e08304a4ea3acf3","externalIds":{"MAG":"2086139748","DOI":"10.1080/15475441.2011.584041","CorpusId":122866773},"title":"Language and Other Cognitive Systems. What Is Special About Language?"},{"paperId":"b8fb4c7e8d2c71b29f0332cd46c023bea711f7a6","externalIds":{"DBLP":"conf/icra/SattarD11","MAG":"2155464705","DOI":"10.1109/ICRA.2011.5979633","CorpusId":11970556},"title":"Towards quantitative modeling of task confirmations in human-robot dialog"},{"paperId":"e4996547720f4801eca284a3c3dfa7943cd08ecf","externalIds":{"MAG":"1606056663","DBLP":"conf/aaai/StoneKKR10","DOI":"10.1609/aaai.v24i1.7529","CorpusId":718373},"title":"Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination"},{"paperId":"fbd9c914dba50a67a2afaf415d69c2549c4e4caf","externalIds":{"MAG":"2062683227","DOI":"10.1007/s10676-007-9138-2","CorpusId":37272949},"title":"AI Armageddon and the Three Laws of Robotics"},{"paperId":"f40973f6b4f8d170b0be62f504779ee3a8329917","externalIds":{"MAG":"1963728726","DOI":"10.1145/1216262.1216282","CorpusId":60876720},"title":"Software engineering team diversity and performance"},{"paperId":"d843b52cfc7acf44c95827ced18639dc4a4f8492","externalIds":{"MAG":"2051671280","DOI":"10.1108/13527590510635134","CorpusId":144266641},"title":"Influence of team composition and task complexity on team performance"},{"paperId":"d6c8902054ff71aed336cbe8acb2e4f0d14cd9f3","externalIds":{"MAG":"2069116603","DOI":"10.1016/S1364-6613(00)01783-6","CorpusId":29580601,"PubMed":"11707373"},"title":"Language shapes thought"},{"paperId":"c112f2c33fe55d9e9b6411c86844c4f8ab7d17eb","externalIds":{"MAG":"1988523219","DOI":"10.1111/1468-0017.00175","CorpusId":16599651},"title":"Thinking Through Language"},{"paperId":"8a99ddac28e5695589789609b1258958c2a6c70a","externalIds":{"MAG":"2022884376","DOI":"10.2307/416234","CorpusId":143780834},"title":"The language instinct : how the mind creates language"},{"paperId":"3de5d40b60742e3dfa86b19e7f660962298492af","externalIds":{"MAG":"2121227244","ACL":"J92-4003","DBLP":"journals/coling/BrownPdLM92","CorpusId":10986188},"title":"Class-Based n-gram Models of Natural Language"},{"paperId":"5d68d1462966920e1c67702f47314e6403f7ab62","externalIds":{"MAG":"2923810312","DBLP":"journals/ai/Reeke91","DOI":"10.1016/0004-3702(91)90034-H","CorpusId":124268831},"title":"Marvin Minsky, The Society of Mind"},{"paperId":"74f05cd2e847a0472a28c475c78d1654422903a5","externalIds":{"MAG":"3022778360","DBLP":"journals/ai/Brooks91","DOI":"10.1016/0004-3702(91)90053-M","CorpusId":207507849},"title":"Intelligence without Representation"},{"paperId":"da2880c1b525ae49125b9b2c627126d6891aab5a","externalIds":{"DBLP":"journals/corr/abs-2402-01586","DOI":"10.48550/arXiv.2402.01586","CorpusId":267406347},"title":"TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution"},{"paperId":"391ba9a9491b3a85ef952bff08cf482c171420d4","externalIds":{"ACL":"2024.alvr-1.18","DOI":"10.18653/v1/2024.alvr-1.18","CorpusId":270819969},"title":"Evolutionary Reward Design and Optimization with Multimodal Large Language Models"},{"paperId":"fed3376de52d70ba83050182e79466dddde45746","externalIds":{"DBLP":"journals/corr/abs-2402-10340","DOI":"10.48550/arXiv.2402.10340","CorpusId":270802839},"title":"On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities"},{"paperId":"7adb88771376c2a31688e3b0395b0550a35b824d","externalIds":{"DBLP":"journals/corr/abs-2402-10189","DOI":"10.48550/arXiv.2402.10189","CorpusId":268890296},"title":"Uncertainty Decomposition and Quantification for In-Context Learning of Large Language Models"},{"paperId":"7781abb2c62d17379a932898874bc90bf0d604e4","externalIds":{"DBLP":"journals/corr/abs-2402-06529","DOI":"10.48550/arXiv.2402.06529","CorpusId":267616999},"title":"Introspective Planning: Guiding Language-Enabled Agents to Refine Their Own Uncertainty"},{"paperId":"1a4c6856292b8c64d19a812a77f0aa6fd47cb96c","externalIds":{"DBLP":"journals/corr/abs-2308-08155","CorpusId":260925901},"title":"AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"},{"paperId":"99bf7219b8d3e6ac1ad8dc9bfd8589cbcf843f23","externalIds":{"DBLP":"conf/nips/WangCCLML23","CorpusId":268042457},"title":"Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents"},{"paperId":"3607b92705cd1fba04eaf295f57be4b085791063","externalIds":{"CorpusId":263613825},"title":"Dialogue Distillery: Crafting Interpolable, Interpretable, and Introspectable Dialogue from LLMs"},{"paperId":"d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43","externalIds":{"ArXiv":"2303.17580","DBLP":"journals/corr/abs-2303-17580","DOI":"10.48550/arXiv.2303.17580","CorpusId":257833781},"title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"},{"paperId":"ac771182d1780c863954243809d1e144433919f9","externalIds":{"DBLP":"journals/corr/abs-2307-12966","DOI":"10.48550/arXiv.2307.12966","CorpusId":260356605},"title":"Aligning Large Language Models with Human: A Survey"},{"paperId":"259d07f47c046389d0b4f256139de64736dd9a94","externalIds":{"DBLP":"journals/corr/abs-2307-08715","DOI":"10.48550/arXiv.2307.08715","CorpusId":270441137},"title":"Jailbreaker: Automated Jailbreak Across Multiple Large Language Model Chatbots"},{"paperId":"10db2cd7e2cd139e63a3bad5d3419dae28615711","externalIds":{"CorpusId":259088739},"title":"Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach"},{"paperId":"7ca954844bc1dd405bc43445b1c990e42d865095","externalIds":{"DBLP":"journals/corr/abs-2303-17760","DOI":"10.48550/arXiv.2303.17760","CorpusId":257900712},"title":"CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society"},{"paperId":"4747e72c5bc706c50e76953188f0144df18992d0","externalIds":{"DBLP":"journals/corr/abs-2307-07924","DOI":"10.48550/arXiv.2307.07924","CorpusId":259936967},"title":"Communicative Agents for Software Development"},{"paperId":"775f42ed458b8c5b0f2094ea4ff5b64c557b1a34","externalIds":{"CorpusId":251881108},"title":"A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27"},{"paperId":"29086dcf01226c5b4e57531c3642a87d44d8d41b","externalIds":{"DBLP":"conf/itqm/LefrancLOP22","DOI":"10.1016/j.procs.2022.11.150","CorpusId":254490034},"title":"Impact of Cobots on automation"},{"paperId":"2739d1e71c72f153d73fe5f62775c87b0afe0a59","externalIds":{"CorpusId":254172909},"title":"Transformer Adapters for Robot Learning"},{"paperId":"211c1b36c9873743b2d5c955a0823143cbd4e8fe","externalIds":{"DBLP":"journals/corr/abs-2106-01288","CorpusId":235294049},"title":"Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic Intelligence as the Convergence of Natural and Artificial Intelligence"},{"paperId":"588a98dc32ac30b4bb036b66b1b2bfa87a0593b2","externalIds":{"MAG":"3129397634","DOI":"10.1016/J.PROCIR.2020.05.213","CorpusId":234130755},"title":"Programming cobots by voice: A human-centered, web-based approach"},{"paperId":"557c1361bdd9841c23aa37020f5ec426ae3c8e1e","externalIds":{"MAG":"3089935969","DBLP":"conf/kes/SetchiDK20","DOI":"10.1016/j.procs.2020.09.198","CorpusId":226256243},"title":"Explainable Robotics in Human-Robot Interactions"},{"paperId":"45b08d91f2e3369d0641875078c5684b4adcc848","externalIds":{"MAG":"2743723307","DOI":"10.1007/978-3-319-64816-3_8","CorpusId":27632740},"title":"The role of trust in human-robot interaction"},{"paperId":"97c796580d4d099dabe85cf4f7d2cb96b4b85153","externalIds":{"MAG":"2781010339","CorpusId":115283847},"title":"The Three Laws of Robotics"},{"paperId":"5a9cac54de14e58697d0315fe3c01f3dbe69c186","externalIds":{"MAG":"1741471588","DBLP":"books/others/91/ClarkB91","DOI":"10.1037/10096-006","CorpusId":153811205},"title":"Grounding in communication"},{"paperId":"299b20cbb968c6ce5175899dc38d2ee8e4e7251a","externalIds":{"MAG":"1995939150","DBLP":"journals/cogsci/GoldsteinP77","DOI":"10.1207/s15516709cog0101_5","CorpusId":62742099},"title":"Artificial Intelligence, Language, and the Study of Knowledge"},{"paperId":"2a882d7103bf1e10177cee692b3be724756b5e79","externalIds":{"CorpusId":269010293},"title":"Large Language Models and User Trust: Focus on Healthcare"},{"paperId":"d371ebf8534234609cd95697d0675ba279a5a26d","externalIds":{"CorpusId":273545913},"title":"ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning"}]}