{"references":[{"paperId":"0eec9f6195545a703cf0131fd89ca6befdb30f45","externalIds":{"DBLP":"journals/corr/abs-2411-14500","ArXiv":"2411.14500","DOI":"10.48550/arXiv.2411.14500","CorpusId":274192757},"title":"Exploring Accuracy-Fairness Trade-off in Large Language Models"},{"paperId":"6f87f020fee2ce2ffd8b9353d227c032ad89ce0d","externalIds":{"DBLP":"journals/corr/abs-2409-16430","ArXiv":"2409.16430","DOI":"10.48550/arXiv.2409.16430","CorpusId":272881257},"title":"A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions"},{"paperId":"8d4f33887d5629255cb71f2a580d8aba6ef15bde","externalIds":{"DBLP":"journals/corr/abs-2409-04340","ArXiv":"2409.04340","DOI":"10.1109/ICASSP49660.2025.10890657","CorpusId":272464141},"title":"AGR: Age Group fairness Reward for Bias Mitigation in LLMs"},{"paperId":"e57c7b94e997517aad07fff04885849da42c7067","externalIds":{"ACL":"2024.emnlp-industry.110","DBLP":"journals/corr/abs-2408-06273","ArXiv":"2408.06273","DOI":"10.48550/arXiv.2408.06273","CorpusId":271855277},"title":"FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data"},{"paperId":"6ba1c2863c1a3c7a87b4de1b5dd65983481c60ee","externalIds":{"DBLP":"journals/air/LinGZZLZ24","DOI":"10.1007/s10462-024-10896-y","CorpusId":271851237},"title":"Towards trustworthy LLMs: a review on debiasing and dehallucinating in large language models"},{"paperId":"40e8af970329135ec95057d73e239dab805ad128","externalIds":{"ArXiv":"2407.21783","CorpusId":271571434},"title":"The Llama 3 Herd of Models"},{"paperId":"c7f9706898bdfa3241601e075b1305649b174ff1","externalIds":{"DBLP":"journals/corr/abs-2406-12793","ArXiv":"2406.12793","DOI":"10.48550/arXiv.2406.12793","CorpusId":270562306},"title":"ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools"},{"paperId":"a050c9b0c321839e4427ab9defa3463be7825ac4","externalIds":{"DBLP":"journals/corr/abs-2401-13601","ArXiv":"2401.13601","DOI":"10.48550/arXiv.2401.13601","CorpusId":267199815},"title":"MM-LLMs: Recent Advances in MultiModal Large Language Models"},{"paperId":"13a6babc740a980056be57bff3eb2a2524b8d335","externalIds":{"ArXiv":"2311.09627","DBLP":"conf/acl/YangKCLJ24","DOI":"10.18653/v1/2024.acl-long.490","CorpusId":265221028},"title":"Mitigating Biases for Instruction-following Language Models via Bias Neurons Elimination"},{"paperId":"578887182fcf49cfd4d99fa3b1de200e8ebb2c45","externalIds":{"DBLP":"journals/corr/abs-2311-01270","ArXiv":"2311.01270","DOI":"10.48550/arXiv.2311.01270","CorpusId":264935274},"title":"People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection"},{"paperId":"ce157cea880c9ab64de64f11a531202f5348fa05","externalIds":{"DBLP":"journals/corr/abs-2310-09219","ArXiv":"2310.09219","DOI":"10.48550/arXiv.2310.09219","CorpusId":264128125},"title":"\"Kelly is a Warm Person, Joseph is a Role Model\": Gender Biases in LLM-Generated Reference Letters"},{"paperId":"d55ed10e6a77e8f0a2359eb92221915f56481843","externalIds":{"DBLP":"conf/acl/KooLRPKK24","ArXiv":"2309.17012","DOI":"10.48550/arXiv.2309.17012","CorpusId":263310448},"title":"Benchmarking Cognitive Biases in Large Language Models as Evaluators"},{"paperId":"749d59f887c8ac83fd4f5178465e8b03e463358c","externalIds":{"DBLP":"journals/corr/abs-2309-15025","ArXiv":"2309.15025","DOI":"10.48550/arXiv.2309.15025","CorpusId":262824801},"title":"Large Language Model Alignment: A Survey"},{"paperId":"c96297261467b5daa2d01227496a70d444602434","externalIds":{"DBLP":"journals/corr/abs-2309-10305","ArXiv":"2309.10305","DOI":"10.48550/arXiv.2309.10305","CorpusId":261951743},"title":"Baichuan 2: Open Large-scale Language Models"},{"paperId":"1ebcf1884390c28f24b3adaf5a7aba5b9453b48b","externalIds":{"ACL":"2024.lrec-main.377","DBLP":"journals/corr/abs-2309-09400","ArXiv":"2309.09400","DOI":"10.48550/arXiv.2309.09400","CorpusId":262044134},"title":"CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large Language Models in 167 Languages"},{"paperId":"02838f3cd9c7bbb679968ba593699f920ef2f4fc","externalIds":{"ArXiv":"2309.05951","DBLP":"conf/adc/JiangQZZ23","DOI":"10.48550/arXiv.2309.05951","CorpusId":261696719},"title":"Balanced and Explainable Social Media Analysis for Public Health with Large Language Models"},{"paperId":"104b0bb1da562d53cbda87aec79ef6a2827d191a","externalIds":{"ArXiv":"2307.09288","DBLP":"journals/corr/abs-2307-09288","CorpusId":259950998},"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models"},{"paperId":"ca31b8584b6c022ef15ddfe994fe361e002b7729","externalIds":{"DBLP":"journals/tist/NaveedKQSAUABM25","ArXiv":"2307.06435","DOI":"10.1145/3744746","CorpusId":259847443},"title":"A Comprehensive Overview of Large Language Models"},{"paperId":"88549b4f48b9709acdfb8b9e41656b6d133c5390","externalIds":{"DBLP":"journals/corr/abs-2307-00101","ArXiv":"2307.00101","DOI":"10.48550/arXiv.2307.00101","CorpusId":259316226},"title":"Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models"},{"paperId":"8c835daaf7720a168e5d3d669f419765c510bbaf","externalIds":{"ArXiv":"2306.13041","DBLP":"journals/jmlr/LeiterLF00E24","DOI":"10.48550/arXiv.2306.13041","CorpusId":259224689},"title":"Towards Explainable Evaluation Metrics for Machine Translation"},{"paperId":"7a1e71cb1310c4a873e7a4e54d1a6dab0553adce","externalIds":{"ArXiv":"2306.01116","DBLP":"journals/corr/abs-2306-01116","DOI":"10.48550/arXiv.2306.01116","CorpusId":259063761},"title":"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"},{"paperId":"f4f5c747dbb09a0846b600987379148ca5e1b167","externalIds":{"DBLP":"journals/corr/abs-2305-16768","ACL":"2023.acl-long.323","ArXiv":"2305.16768","DOI":"10.48550/arXiv.2305.16768","CorpusId":258947231},"title":"Towards a Common Understanding of Contributing Factors for Cross-Lingual Transfer in Multilingual Language Models: A Review"},{"paperId":"6ab06565288cd2bd20e701a2daab192f71c0f7e7","externalIds":{"ACL":"2024.starsem-1.30","ArXiv":"2305.13862","DBLP":"journals/corr/abs-2305-13862","DOI":"10.18653/v1/2024.starsem-1.30","CorpusId":258840972},"title":"A Trip Towards Fairness: Bias and De-Biasing in Large Language Models"},{"paperId":"430a95e3cbebddf8d727c874e007d32ab844f148","externalIds":{"DBLP":"journals/corr/abs-2305-14456","ArXiv":"2305.14456","DOI":"10.48550/arXiv.2305.14456","CorpusId":258865272},"title":"Having Beer after Prayer? Measuring Cultural Bias in Large Language Models"},{"paperId":"e6d1139f185acf6a08260190d4dba138f918e1df","externalIds":{"DBLP":"journals/corr/abs-2305-13286","ArXiv":"2305.13286","DOI":"10.48550/arXiv.2305.13286","CorpusId":258832559},"title":"How do languages influence each other? Studying cross-lingual data sharing during LLM fine-tuning"},{"paperId":"32779af3e76e61272f453d215d86d7f2963fc901","externalIds":{"DBLP":"journals/corr/abs-2305-11673","ArXiv":"2305.11673","DOI":"10.48550/arXiv.2305.11673","CorpusId":258822832},"title":"Bias Beyond English: Counterfactual Tests for Bias in Sentiment Analysis in Four Languages"},{"paperId":"b1e67b0cc5705d6aade931e6414ce23dc0ff44b3","externalIds":{"DBLP":"conf/emnlp/LevyJLVMFBCR23","ArXiv":"2305.11242","DOI":"10.48550/arXiv.2305.11242","CorpusId":258823009},"title":"Comparing Biases and the Impact of Multilingual Training across Multiple Languages"},{"paperId":"e1fb0eb6fe6de9cbc23242baef475fb9b0b70f62","externalIds":{"ArXiv":"2305.10971","DBLP":"journals/corr/abs-2305-10971","ACL":"2023.acl-short.85","DOI":"10.48550/arXiv.2305.10971","CorpusId":258762157},"title":"NollySenti: Leveraging Transfer Learning and Machine Translation for Nigerian Movie Sentiment Classification"},{"paperId":"b6d6c33298b852cf63edac233deca70530d69a2a","externalIds":{"ArXiv":"2305.10403","DBLP":"journals/corr/abs-2305-10403","CorpusId":258740735},"title":"PaLM 2 Technical Report"},{"paperId":"e4aa101556fc5b238a88d99c07c1055fe3bc4764","externalIds":{"ArXiv":"2305.08487","DBLP":"journals/corr/abs-2305-08487","DOI":"10.48550/arXiv.2305.08487","CorpusId":258686435},"title":"Taxi1500: A Multilingual Dataset for Text Classification in 1500 Languages"},{"paperId":"dfd8944d39b378489b878d6e105d040fa0e524db","externalIds":{"DBLP":"conf/naacl/ZhuLDXHKCL24","ArXiv":"2304.04675","DOI":"10.48550/arXiv.2304.04675","CorpusId":258048937},"title":"Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis"},{"paperId":"16d83e930a4dab2d49f5d276838ddce79df3f787","externalIds":{"DBLP":"journals/firstmonday/Ferrara23a","ArXiv":"2304.03738","DOI":"10.5210/fm.v28i11.13346","CorpusId":258041203},"title":"Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models"},{"paperId":"fdaacabb69ca054d1d9acf2f1409c083672adc4a","externalIds":{"DBLP":"journals/ijcv/WangYWHCYXXZ24","ArXiv":"2304.01457","DOI":"10.1007/s11263-023-01868-w","CorpusId":257921626},"title":"Exploring Vision-Language Models for Imbalanced Learning"},{"paperId":"be55e8ec4213868db08f2c3168ae666001bea4b8","externalIds":{"DBLP":"conf/icml/BidermanSABOHKP23","ArXiv":"2304.01373","DOI":"10.48550/arXiv.2304.01373","CorpusId":257921893},"title":"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"362cbfd0d05e139cd6cf049754098a6e1520b910","externalIds":{"ArXiv":"2303.10845","DBLP":"journals/corr/abs-2303-10845","CorpusId":257666647},"title":"PanGu-Î£: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"17133d143f15b5ee549952c0b880d0f76024c4d8","externalIds":{"DBLP":"conf/iccv/WangR23","ArXiv":"2303.06167","DOI":"10.1109/ICCV51070.2023.00366","CorpusId":257496198},"title":"Overwriting Pretrained Bias with Finetuning Data"},{"paperId":"16c64f74ce0e6a59b0709c0d8e66596a5bc08ed6","externalIds":{"DBLP":"journals/corr/abs-2303-03915","ArXiv":"2303.03915","DOI":"10.48550/arXiv.2303.03915","CorpusId":257378329},"title":"The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset"},{"paperId":"38fe8f324d2162e63a967a9ac6648974fc4c66f3","externalIds":{"ArXiv":"2303.03378","DBLP":"journals/corr/abs-2303-03378","DOI":"10.48550/arXiv.2303.03378","CorpusId":257364842},"title":"PaLM-E: An Embodied Multimodal Language Model"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"e8e035f9768a4d4e7fe9a2e167cd93d170407b1b","externalIds":{"DBLP":"journals/corr/abs-2302-08215","ArXiv":"2302.08215","DOI":"10.48550/arXiv.2302.08215","CorpusId":256900692},"title":"Aligning Language Models with Preferences through f-divergence Minimization"},{"paperId":"964bd39b546f0f6625ff3b9ef1083f797807ef2e","externalIds":{"DBLP":"journals/corr/abs-2211-05100","ArXiv":"2211.05100","DOI":"10.48550/arXiv.2211.05100","CorpusId":253420279},"title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"},{"paperId":"fe13d9a9c481efcf5591fd0a57c058d0c0088c43","externalIds":{"ACL":"2022.acl-long.561","DBLP":"conf/acl/ZhengWWXHZ0L22","ArXiv":"2210.16848","DOI":"10.18653/v1/2022.acl-long.561","CorpusId":248779922},"title":"Using Context-to-Vector with Graph Retrofitting to Improve Word Embeddings"},{"paperId":"7259ca612de44763678a30114b02d37c00280c86","externalIds":{"ACL":"2022.emnlp-main.298","ArXiv":"2210.12391","DBLP":"journals/corr/abs-2210-12391","DOI":"10.48550/arXiv.2210.12391","CorpusId":253098583},"title":"MasakhaNER 2.0: Africa-centric Transfer Learning for Named Entity Recognition"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"969f45a3adf5e0bcf741447b1c67a0f3a386801a","externalIds":{"ACL":"2022.emnlp-main.245","DBLP":"conf/emnlp/SunHQH22","ArXiv":"2210.07626","DOI":"10.48550/arXiv.2210.07626","CorpusId":252907549},"title":"BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation"},{"paperId":"1bcfc0beb857f65589be37137e7ed71ae9d1950b","externalIds":{"ArXiv":"2210.05457","DBLP":"conf/coling/PiquerasS22","ACL":"2022.coling-1.318","DOI":"10.48550/arXiv.2210.05457","CorpusId":252547725},"title":"Are Pretrained Multilingual Models Equally Fair across Languages?"},{"paperId":"0d2390cb571477ced2743003c515a47cc9661f57","externalIds":{"ACL":"2022.emnlp-main.404","DBLP":"conf/emnlp/MarchisioVDK22","ArXiv":"2210.05098","DOI":"10.48550/arXiv.2210.05098","CorpusId":252815609},"title":"IsoVec: Controlling the Relative Isomorphism of Word Embedding Spaces"},{"paperId":"62f0db3a5ad5c795ec18fc7a6e7b01836809df57","externalIds":{"DBLP":"conf/iclr/ShiSF0SVCTRZ0W23","ArXiv":"2210.03057","DOI":"10.48550/arXiv.2210.03057","CorpusId":252735112},"title":"Language Models are Multilingual Chain-of-Thought Reasoners"},{"paperId":"1d26c947406173145a4665dd7ab255e03494ea28","externalIds":{"DBLP":"journals/corr/abs-2210-02414","ArXiv":"2210.02414","DOI":"10.48550/arXiv.2210.02414","CorpusId":252715691},"title":"GLM-130B: An Open Bilingual Pre-trained Model"},{"paperId":"74eae12620bd1c1393e268bddcb6f129a5025166","externalIds":{"DBLP":"journals/corr/abs-2209-14375","ArXiv":"2209.14375","DOI":"10.48550/arXiv.2209.14375","CorpusId":252596089},"title":"Improving alignment of dialogue agents via targeted human judgements"},{"paperId":"e5b05125b91caa39f5e8e1c511d586d9f4a9628e","externalIds":{"DBLP":"conf/coling/MalmasiFFKR22","ACL":"2022.coling-1.334","ArXiv":"2208.14536","DOI":"10.48550/arXiv.2208.14536","CorpusId":251953674},"title":"MultiCoNER: A Large-scale Multilingual Dataset for Complex Named Entity Recognition"},{"paperId":"3597d42ed900c7c49a2267bcfe7a8acc0c1f4e0c","externalIds":{"ACL":"2022.naacl-main.347","DBLP":"conf/naacl/SenS0A22","ArXiv":"2205.04238","DOI":"10.48550/arXiv.2205.04238","CorpusId":248572126},"title":"Counterfactually Augmented Data and Unintended Bias: The Case of Sexism and Hate Speech Detection"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"2ac19d63e1adba20473a6d1122c598f81efc3c58","externalIds":{"ArXiv":"2204.06487","DBLP":"conf/coling/AlabiAMK22","ACL":"2022.coling-1.382","CorpusId":252088953},"title":"Adapting Pre-trained Language Models to African Languages via Multilingual Adaptive Fine-Tuning"},{"paperId":"0286b2736a114198b25fb5553c671c33aed5d477","externalIds":{"ArXiv":"2204.05862","DBLP":"journals/corr/abs-2204-05862","DOI":"10.48550/arXiv.2204.05862","CorpusId":248118878},"title":"Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"d9424371662717c8981eef3d501d7ce59c66ce77","externalIds":{"DBLP":"journals/corr/abs-2203-13928","ACL":"2022.acl-short.62","ArXiv":"2203.13928","DOI":"10.48550/arXiv.2203.13928","CorpusId":247762845},"title":"On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations"},{"paperId":"a763a850b2cd1ee7bc1d51638be0d710406eef34","externalIds":{"ACL":"2022.findings-acl.182","DBLP":"conf/acl/HammerlL022","ArXiv":"2203.09326","DOI":"10.48550/arXiv.2203.09326","CorpusId":246000055},"title":"Combining Static and Contextualised Multilingual Embeddings"},{"paperId":"e6b9c2fcff6dcfef2a9cb5019ae6040949616c62","externalIds":{"ACL":"2022.acl-long.367","DBLP":"journals/corr/abs-2203-08459","ArXiv":"2203.08459","DOI":"10.18653/v1/2022.acl-long.367","CorpusId":247475840},"title":"KinyaBERT: a Morphology-aware Kinyarwanda Language Model"},{"paperId":"14147c2dd2de2a03870731bad996fa906061722c","externalIds":{"ArXiv":"2203.08307","ACL":"2022.acl-long.299","DBLP":"conf/acl/Li0CKV22","DOI":"10.18653/v1/2022.acl-long.299","CorpusId":247476049},"title":"Improving Word Translation via Two-Stage Contrastive Learning"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"082de6c8c8f1e33d0b1a545dfe7c2313b5739126","externalIds":{"DBLP":"conf/lrec/YadavS22","ACL":"2022.lrec-1.542","ArXiv":"2202.12576","CorpusId":247155169},"title":"A Survey of Multilingual Models for Automatic Speech Recognition"},{"paperId":"b3848d32f7294ec708627897833c4097eb4d8778","externalIds":{"DBLP":"journals/corr/abs-2201-08239","ArXiv":"2201.08239","CorpusId":246063428},"title":"LaMDA: Language Models for Dialog Applications"},{"paperId":"ecd9168526d1a82ac2348c8de52bff6323322da9","externalIds":{"ArXiv":"2201.08277","DBLP":"conf/lrec/MuhammadAAA22","ACL":"2022.lrec-1.63","CorpusId":246063436},"title":"NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis"},{"paperId":"dab09b61ca05ff57b1bc6937fa7eee96720098e8","externalIds":{"ArXiv":"2201.05609","DBLP":"conf/lrec/Palen-MichelKL22","ACL":"2022.lrec-1.224","CorpusId":249538120},"title":"Multilingual Open Text Release 1: Public Domain News in 44 Languages"},{"paperId":"4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904","externalIds":{"ArXiv":"2112.10668","DBLP":"conf/emnlp/LinMAWCSOGBDPSK22","ACL":"2022.emnlp-main.616","DOI":"10.18653/v1/2022.emnlp-main.616","CorpusId":245334784},"title":"Few-shot Learning with Multilingual Generative Language Models"},{"paperId":"68f141724814839d556a989646194be88641b143","externalIds":{"ArXiv":"2112.11446","DBLP":"journals/corr/abs-2112-11446","CorpusId":245353475},"title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"},{"paperId":"3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e","externalIds":{"ArXiv":"2112.00861","DBLP":"journals/corr/abs-2112-00861","CorpusId":244799619},"title":"A General Language Assistant as a Laboratory for Alignment"},{"paperId":"de6807676d8171472ed6cf421c4e4ed3cbb47699","externalIds":{"ArXiv":"2110.08527","ACL":"2022.acl-long.132","DBLP":"journals/corr/abs-2110-08527","DOI":"10.18653/v1/2022.acl-long.132","CorpusId":239015827},"title":"An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models"},{"paperId":"eea16dfc29f0521dd547e67a84af4ff95a9c5529","externalIds":{"DBLP":"conf/emnlp/0001BPRCE21","ArXiv":"2109.13238","ACL":"2021.emnlp-main.818","DOI":"10.18653/v1/2021.emnlp-main.818","CorpusId":238198104},"title":"Visually Grounded Reasoning across Languages and Cultures"},{"paperId":"dec42306af017bc778bbf1496776f3cd4d5bd42e","externalIds":{"DBLP":"journals/jbd/WongsoLS22","DOI":"10.1186/s40537-022-00590-7","CorpusId":239233347},"title":"Pre-trained transformer-based language models for Sundanese"},{"paperId":"03dff7e980d1ef154ec60badea03fe8c248d881e","externalIds":{"DBLP":"conf/pkdd/TianZL21","ArXiv":"2109.12773","DOI":"10.1007/978-3-030-86486-6_37","CorpusId":236318788},"title":"Rumour Detection via Zero-Shot Cross-Lingual Transfer Learning"},{"paperId":"88ee971d2b00ba0b374aab81daac42e7cc7b8d4d","externalIds":{"ACL":"2021.emnlp-main.28","DBLP":"journals/corr/abs-2109-07022","ArXiv":"2109.07022","DOI":"10.18653/v1/2021.emnlp-main.28","CorpusId":237513667},"title":"How Does Counterfactually Augmented Data Impact Models for Social Computing Constructs?"},{"paperId":"1aa1d6b29ad6fcef78d1eefacb2a7fd75e68c2c0","externalIds":{"DBLP":"conf/emnlp/AhnO21","ArXiv":"2109.05704","ACL":"2021.emnlp-main.42","DOI":"10.18653/v1/2021.emnlp-main.42","CorpusId":237491723},"title":"Mitigating Language-Dependent Ethnic Bias in BERT"},{"paperId":"7a11c1dce5aac45f46e9b75f83c84cea167b02a9","externalIds":{"DBLP":"conf/emnlp/YangYCD21","ACL":"2021.emnlp-main.470","ArXiv":"2109.04727","DOI":"10.18653/v1/2021.emnlp-main.470","CorpusId":237485496},"title":"A Simple and Effective Method To Eliminate the Self Language Bias in Multilingual Representations"},{"paperId":"3146cfab22f88ffed4befa06e8b268d60f479017","externalIds":{"DOI":"10.1016/j.psychres.2021.114135","CorpusId":236217063,"PubMed":"34343877"},"title":"Detecting formal thought disorder by deep contextualized word representations"},{"paperId":"9fd9d9712dd8d5377369ae656c15cf2d84038194","externalIds":{"DBLP":"conf/ht/BansalGS021","ArXiv":"2107.10181","DOI":"10.1145/3465336.3475118","CorpusId":236155077},"title":"Debiasing Multilingual Word Embeddings: A Case Study of Three Indian Languages"},{"paperId":"d725c41b8e0516d0cf84d8fbd25eb7fc01a47342","externalIds":{"ArXiv":"2107.00676","DBLP":"journals/corr/abs-2107-00676","DOI":"10.1145/3727339","CorpusId":235727612},"title":"A Primer on Pretrained Multilingual Language Models"},{"paperId":"6692187d1835e767c5015ab24df8caf9f1d774da","externalIds":{"DBLP":"conf/acl/JoshiH22","ACL":"2022.acl-long.256","ArXiv":"2107.00753","DOI":"10.18653/v1/2022.acl-long.256","CorpusId":235727513},"title":"An Investigation of the (In)effectiveness of Counterfactually Augmented Data"},{"paperId":"048af7345faefb6fb0bee2924275e222f21742e2","externalIds":{"DBLP":"journals/corr/abs-2106-15231","ACL":"2021.acl-long.26","ArXiv":"2106.15231","DOI":"10.18653/v1/2021.acl-long.26","CorpusId":235669817},"title":"Exploring the Efficacy of Automatically Generated Counterfactuals for Sentiment Analysis"},{"paperId":"a6a7724763d8adba466519489b0b9d209e7f2d15","externalIds":{"DBLP":"conf/nips/YuanNL21","ArXiv":"2106.11520","CorpusId":235593404},"title":"BARTScore: Evaluating Generated Text as Text Generation"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"0ff3585e15f8799f191c53daf1cb9ccd330b169a","externalIds":{"DBLP":"conf/acl/WangLW22a","ACL":"2022.findings-acl.211","ArXiv":"2106.06683","DOI":"10.18653/v1/2022.findings-acl.211","CorpusId":235422358},"title":"Assessing Multilingual Fairness in Pre-trained Multimodal Representations"},{"paperId":"9d24d4304078f0be973220c63abcceb3ea1848c2","externalIds":{"DBLP":"journals/corr/abs-2106-03084","ACL":"2021.findings-acl.260","ArXiv":"2106.03084","DOI":"10.18653/v1/2021.findings-acl.260","CorpusId":235358993},"title":"Combining Static Word Embeddings and Contextual Representations for Bilingual Lexicon Induction"},{"paperId":"4eda2b9eaef3ae892382acc21593eed6f56f2ea1","externalIds":{"MAG":"3170344956","DBLP":"journals/natmi/AbidFZ21","DOI":"10.1038/s42256-021-00359-2","CorpusId":236384212},"title":"Large language models associate Muslims with violence"},{"paperId":"dbbed7ddee1fad238d1e560eb1888087fa4b5ddf","externalIds":{"DBLP":"conf/rep4nlp/GoyalDOAC21","ArXiv":"2105.00572","ACL":"2021.repl4nlp-1.4","DOI":"10.18653/v1/2021.repl4nlp-1.4","CorpusId":233481097},"title":"Larger-Scale Transformers for Multilingual Masked Language Modeling"},{"paperId":"78bd4518950e3f0bcd6aa9f7f8e09cbbf13eb11f","externalIds":{"DBLP":"journals/corr/abs-2104-12369","MAG":"3158631574","ArXiv":"2104.12369","CorpusId":233394012},"title":"PanGu-Î±: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation"},{"paperId":"6803adc7d8b891be652d18815f830f7a42a0f5b5","externalIds":{"DBLP":"journals/corr/abs-2103-12028","ArXiv":"2103.12028","ACL":"2022.tacl-1.4","DOI":"10.1162/tacl_a_00447","CorpusId":232307434},"title":"Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets"},{"paperId":"50796b0f3edf9cb5ff1e447c298b33755378aa4f","externalIds":{"DBLP":"conf/acl/DuQLDQY022","ACL":"2022.acl-long.26","ArXiv":"2103.10360","DOI":"10.18653/v1/2022.acl-long.26","CorpusId":247519241},"title":"GLM: General Language Model Pretraining with Autoregressive Blank Infilling"},{"paperId":"ca2f1088d3e581b2c6c75cf0ebc96506d620f64d","externalIds":{"DBLP":"conf/fat/BenderGMS21","DOI":"10.1145/3442188.3445922","CorpusId":262580630},"title":"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ"},{"paperId":"b0dd67bdb6090f575800126f997b5b1dbcee02f3","externalIds":{"MAG":"3046484722","DBLP":"journals/eswa/PikuliakSB21","DOI":"10.1016/j.eswa.2020.113765","CorpusId":224879602},"title":"Cross-lingual learning for text processing: A survey"},{"paperId":"ce9ca56036307217ea565644d3d3bd74b879e045","externalIds":{"DBLP":"journals/tacl/SchickUS21","ArXiv":"2103.00453","DOI":"10.1162/tacl_a_00434","CorpusId":232075876},"title":"Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"},{"paperId":"fcfc9648561a221750b8085790ad9ba1bebb1800","externalIds":{"ArXiv":"2102.00894","ACL":"2021.eacl-main.284","DBLP":"conf/eacl/KassnerDS21","DOI":"10.18653/v1/2021.eacl-main.284","CorpusId":231740666},"title":"Multilingual LAMA: Investigating Knowledge in Multilingual Pretrained Language Models"},{"paperId":"1c301a8a2dc281d43fa34cc7a7eee64a8acd711f","externalIds":{"DBLP":"conf/wacv/KarkkainenJ21","DOI":"10.1109/WACV48630.2021.00159","CorpusId":199577425},"title":"FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age for Bias Measurement and Mitigation"},{"paperId":"0d4b5c9a071557f4eb12f63f785dbc89071d4272","externalIds":{"DBLP":"journals/corr/abs-2012-15613","ACL":"2021.acl-long.243","ArXiv":"2012.15613","DOI":"10.18653/v1/2021.acl-long.243","CorpusId":229924220},"title":"How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models"},{"paperId":"eef65f8affe3dceba40f87b57789a02a40366d30","externalIds":{"ArXiv":"2011.01612","ACL":"2020.coling-main.575","DBLP":"journals/corr/abs-2011-01612","MAG":"3093456628","DOI":"10.18653/V1/2020.COLING-MAIN.575","CorpusId":226237153},"title":"XED: A Multilingual Dataset for Sentiment Analysis and Emotion Detection"},{"paperId":"c3a662b864673d8cc7469051419ab8819926d4b0","externalIds":{"MAG":"3095349973","ACL":"2020.emnlp-main.358","DBLP":"conf/emnlp/DufterS20","DOI":"10.18653/v1/2020.emnlp-main.358","CorpusId":226262235},"title":"Identifying Elements Essential for BERTâ€™s Multilinguality"},{"paperId":"934a7e59533fb0d9f99a3de305ad2b7ae4fe1bf6","externalIds":{"DBLP":"conf/emnlp/SunD20","ACL":"2020.emnlp-main.340","MAG":"3101279614","DOI":"10.18653/v1/2020.emnlp-main.340","CorpusId":226262282},"title":"CLIRMatrix: A Massively Large Collection of Bilingual and Multilingual Datasets for Cross-Lingual Information Retrieval"},{"paperId":"455cdafd55a5b5ddefa029bf97801327e142646d","externalIds":{"DBLP":"conf/naacl/HedderichLASK21","MAG":"3094140582","ACL":"2021.naacl-main.201","ArXiv":"2010.12309","DOI":"10.18653/V1/2021.NAACL-MAIN.201","CorpusId":225062337},"title":"A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios"},{"paperId":"74276a37bfa50f90dfae37f767b2b67784bd402a","externalIds":{"ArXiv":"2010.11934","DBLP":"conf/naacl/XueCRKASBR21","MAG":"3169483174","ACL":"2021.naacl-main.41","DOI":"10.18653/V1/2021.NAACL-MAIN.41","CorpusId":225040574},"title":"mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"},{"paperId":"f886218ddd2b8de54950e5fd46c7d39f85eea0e9","externalIds":{"DBLP":"journals/corr/abs-2010-08432","MAG":"3092817907","ACL":"2021.naacl-main.39","ArXiv":"2010.08432","DOI":"10.18653/V1/2021.NAACL-MAIN.39","CorpusId":223953691},"title":"Multi-Adversarial Learning for Cross-Lingual Word Embeddings"},{"paperId":"9be1d1bf82f6ca6a7bf6a7d92f8f37b647e493d0","externalIds":{"DBLP":"journals/corr/abs-2010-05731","ACL":"2020.emnlp-main.586","MAG":"3099178230","ArXiv":"2010.05731","DOI":"10.18653/v1/2020.emnlp-main.586","CorpusId":222290596},"title":"Probing Pretrained Language Models for Lexical Semantics"},{"paperId":"3d864a8bc5a55ccab9993aa66203d8e70b88148c","externalIds":{"ArXiv":"2010.06032","MAG":"3093211917","DBLP":"journals/corr/abs-2010-06032","CorpusId":222310622},"title":"Measuring and Reducing Gendered Correlations in Pre-trained Models"},{"paperId":"df057d8d4346e938ea6e377065a47ee03e9e67be","externalIds":{"ArXiv":"2010.02573","ACL":"2020.emnlp-main.369","DBLP":"conf/emnlp/KeungLSS20","MAG":"3100880133","DOI":"10.18653/v1/2020.emnlp-main.369","CorpusId":222141483},"title":"The Multilingual Amazon Reviews Corpus"},{"paperId":"645bd6eadc247989abc5e0b0aa0be79ec8b11ea6","externalIds":{"MAG":"3089430725","DBLP":"journals/corr/abs-2010-00133","ArXiv":"2010.00133","ACL":"2020.emnlp-main.154","DOI":"10.18653/v1/2020.emnlp-main.154","CorpusId":222090785},"title":"CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models"},{"paperId":"053b1d7b97eb2c91fc3921d589c160b0923c70b1","externalIds":{"MAG":"3082115681","DBLP":"journals/corr/abs-2009-01325","ArXiv":"2009.01325","CorpusId":221665105},"title":"Learning to summarize from human feedback"},{"paperId":"0d965ed237a3b4592ecefdb618c29f63adedff76","externalIds":{"ArXiv":"2007.08100","ACL":"2020.acl-main.488","DBLP":"conf/acl/LiangLZLSM20","MAG":"3042791954","DOI":"10.18653/v1/2020.acl-main.488","CorpusId":207996257},"title":"Towards Debiasing Sentence Representations"},{"paperId":"ae2b5b75729815c00bedeb931d70098f1a297c45","externalIds":{"MAG":"3034402523","ACL":"2020.acl-main.675","DBLP":"conf/acl/GlavasV20","DOI":"10.18653/v1/2020.acl-main.675","CorpusId":218625432},"title":"Non-Linear Instance-Based Cross-Lingual Mapping for Non-Isomorphic Embedding Spaces"},{"paperId":"c7ee8572a1bdce2978b6ca3f6e28c96ead103de8","externalIds":{"ACL":"2020.acl-main.318","MAG":"3034913382","DBLP":"conf/acl/RenLZM20","DOI":"10.18653/v1/2020.acl-main.318","CorpusId":220048677},"title":"A Graph-based Coarse-to-fine Method for Unsupervised Bilingual Lexicon Induction"},{"paperId":"7ea0e91c5d5dc73f2133bc46d7ebb6cb83034dae","externalIds":{"DBLP":"conf/aies/GuoC21","MAG":"3034115845","ArXiv":"2006.03955","DOI":"10.1145/3461702.3462536","CorpusId":219530686},"title":"Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"14489ec7893e373a0dcc9555c52b99b2b3a429f6","externalIds":{"MAG":"3027825632","DBLP":"journals/corr/abs-2005-09093","ACL":"2020.repl4nlp-1.16","ArXiv":"2005.09093","DOI":"10.18653/v1/2020.repl4nlp-1.16","CorpusId":218684346},"title":"Are All Languages Created Equal in Multilingual BERT?"},{"paperId":"e3e9d2bdcc3fefab7c294196c8b2e149727376ed","externalIds":{"ACL":"2020.acl-main.260","MAG":"3035379020","DBLP":"journals/corr/abs-2005-00699","ArXiv":"2005.00699","DOI":"10.18653/v1/2020.acl-main.260","CorpusId":218487087},"title":"Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer"},{"paperId":"3cc2f69951cd24fe61be4cf32d62afbac297bc2b","externalIds":{"MAG":"3020971214","ArXiv":"2005.00813","DBLP":"conf/acl/HutchinsonPDWZD20","ACL":"2020.acl-main.487","DOI":"10.18653/v1/2020.acl-main.487","CorpusId":218487466},"title":"Social Biases in NLP Models as Barriers for Persons with Disabilities"},{"paperId":"babeda48b10a4d638252118f2238d05a06f4ec55","externalIds":{"ACL":"2021.acl-long.416","DBLP":"journals/corr/abs-2004-09456","MAG":"3019416653","ArXiv":"2004.09456","DOI":"10.18653/v1/2021.acl-long.416","CorpusId":215828184},"title":"StereoSet: Measuring stereotypical bias in pretrained language models"},{"paperId":"69884ea2d2f80a64e94a933069079a1549a43169","externalIds":{"DBLP":"journals/corr/abs-2004-09205","ArXiv":"2004.09205","MAG":"3016562905","CorpusId":215828521},"title":"A Study of Cross-Lingual Ability and Language-specific Information in Multilingual BERT"},{"paperId":"e969aa3422a49152c22f3faf734e4561a2a3cf42","externalIds":{"DBLP":"conf/acl/RavfogelEGTG20","ArXiv":"2004.07667","ACL":"2020.acl-main.647","MAG":"3035241006","DOI":"10.18653/v1/2020.acl-main.647","CorpusId":215786522},"title":"Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection"},{"paperId":"4ae52766028e69186052ea8f33a137fbbbdb986a","externalIds":{"MAG":"3035252911","ArXiv":"2004.04696","DBLP":"conf/acl/SellamDP20","ACL":"2020.acl-main.704","DOI":"10.18653/v1/2020.acl-main.704","CorpusId":215548699},"title":"BLEURT: Learning Robust Metrics for Text Generation"},{"paperId":"043f7d7dd61abba7499ffb4adeb6b696990d4be2","externalIds":{"MAG":"3104180227","ArXiv":"2004.13889","DBLP":"journals/corr/abs-2004-13889","ACL":"2020.emnlp-main.215","DOI":"10.18653/v1/2020.emnlp-main.215","CorpusId":216641774},"title":"LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction through Non-Linear Mapping in Latent Space"},{"paperId":"dbfbfcc2633ef46c53e2343525ee87c700f2cfc3","externalIds":{"DBLP":"conf/emnlp/WangK0R20","MAG":"3098466758","ACL":"2020.findings-emnlp.240","ArXiv":"2004.13640","DOI":"10.18653/v1/2020.findings-emnlp.240","CorpusId":216562574},"title":"Extending Multilingual BERT to Low-Resource Languages"},{"paperId":"ba4a34680e09e77984624c95f5245d91b54373f6","externalIds":{"MAG":"3035579820","DBLP":"conf/icml/HuRSNFJ20","ArXiv":"2003.11080","CorpusId":214641214},"title":"XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalization"},{"paperId":"3bcb17559ce96eb20fa79af8194f4af0380d194a","externalIds":{"DBLP":"journals/corr/abs-2003-08271","MAG":"3088409176","ArXiv":"2003.08271","DOI":"10.1007/s11431-020-1647-3","CorpusId":212747830},"title":"Pre-trained models for natural language processing: A survey"},{"paperId":"d592007d1c106fe1217604eb35664c7a5f07cb32","externalIds":{"MAG":"2995118574","DBLP":"journals/corr/abs-2002-03518","ArXiv":"2002.03518","CorpusId":211069110},"title":"Multilingual Alignment of Contextual Word Representations"},{"paperId":"1359d2ef45f1550941e22bf046026c89f6edf315","externalIds":{"MAG":"3088592174","ACL":"2020.osact-1.2","ArXiv":"2003.00104","DBLP":"journals/corr/abs-2003-00104","CorpusId":211678011},"title":"AraBERT: Transformer-based Model for Arabic Language Understanding"},{"paperId":"495da6f19baa09c6db3697d839e10432cdc25934","externalIds":{"MAG":"3001434439","ArXiv":"2001.08210","DBLP":"journals/corr/abs-2001-08210","DOI":"10.1162/tacl_a_00343","CorpusId":210861178},"title":"Multilingual Denoising Pre-training for Neural Machine Translation"},{"paperId":"a4d5e425cac0bf84c86c0c9f720b6339d6288ffa","externalIds":{"ArXiv":"1912.09582","MAG":"2996580882","DBLP":"journals/corr/abs-1912-09582","CorpusId":209439401},"title":"BERTje: A Dutch BERT Model"},{"paperId":"3b2538f84812f434c740115c185be3e5e216c526","externalIds":{"MAG":"2995015695","DBLP":"conf/iclr/KWMR20","ArXiv":"1912.07840","CorpusId":209183618},"title":"Cross-Lingual Ability of Multilingual BERT: An Empirical Study"},{"paperId":"069e0d896da7c79faeee4cf057548d5da7ce885e","externalIds":{"MAG":"3032532958","DBLP":"conf/lrec/LeVFSCLACBS20","ACL":"2020.lrec-1.302","ArXiv":"1912.05372","CorpusId":209202658},"title":"FlauBERT: Unsupervised Language Model Pre-training for French"},{"paperId":"6fec3e579c7cd4f13bdabbee2b6ac2e8ff5941c6","externalIds":{"MAG":"2983040767","ArXiv":"1911.02116","ACL":"2020.acl-main.747","DBLP":"conf/acl/ConneauKGCWGGOZ20","DOI":"10.18653/v1/2020.acl-main.747","CorpusId":207880568},"title":"Unsupervised Cross-lingual Representation Learning at Scale"},{"paperId":"ecb250b0d411375d7f53e4b5bdfa3ef55426bab5","externalIds":{"MAG":"2970617296","ACL":"D19-1134","DBLP":"conf/emnlp/TaitelbaumCG19","DOI":"10.18653/v1/D19-1134","CorpusId":202784068},"title":"Multilingual word translation using auxiliary languages"},{"paperId":"9eb4cd1a4b4717c97c47e3dc4563a75779ae9390","externalIds":{"ACL":"D19-6106","DBLP":"conf/acl-deeplo/SinghMSX19","MAG":"2985620815","DOI":"10.18653/v1/D19-6106","CorpusId":207924237},"title":"BERT is Not an Interlingua and the Bias of Tokenization"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"fd6bc84144c2d77068bf3f077cb509d539f5f8e2","externalIds":{"ACL":"2020.acl-main.421","MAG":"2982180741","ArXiv":"1910.11856","DBLP":"journals/corr/abs-1910-11856","DOI":"10.18653/v1/2020.acl-main.421","CorpusId":204901567},"title":"On the Cross-lingual Transferability of Monolingual Representations"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"81fbf08beb80b01abaa6ad6a07b48c3034ead8a6","externalIds":{"DBLP":"journals/corr/abs-1910-03806","ArXiv":"1910.03806","MAG":"2979736636","ACL":"W19-6204","CorpusId":203693409},"title":"Is Multilingual BERT Fluent in Language Generation?"},{"paperId":"809cc93921e4698bde891475254ad6dfba33d03b","externalIds":{"DBLP":"journals/corr/abs-1906-01502","ACL":"P19-1493","MAG":"2952638691","ArXiv":"1906.01502","DOI":"10.18653/v1/P19-1493","CorpusId":174798142},"title":"How Multilingual is Multilingual BERT?"},{"paperId":"1670a07b70f90cc4ddba71343e6a7ee4b5198595","externalIds":{"ACL":"P19-1164","MAG":"2947599143","DBLP":"conf/acl/StanovskySZ19","ArXiv":"1906.00591","DOI":"10.18653/v1/P19-1164","CorpusId":173991101},"title":"Evaluating Gender Bias in Machine Translation"},{"paperId":"295065d942abca0711300b2b4c39829551060578","externalIds":{"MAG":"2936695845","ArXiv":"1904.09675","DBLP":"journals/corr/abs-1904-09675","CorpusId":127986044},"title":"BERTScore: Evaluating Text Generation with BERT"},{"paperId":"4ab6b50851ef5d106def6c429b516cd688cb9983","externalIds":{"MAG":"2933610451","ACL":"N19-1386","ArXiv":"1904.04116","DBLP":"journals/corr/abs-1904-04116","DOI":"10.18653/v1/N19-1386","CorpusId":102350797},"title":"Revisiting Adversarial Autoencoder for Unsupervised Word Translation with Cycle Consistency and Improved Training"},{"paperId":"25e9ffae12afac2835eabfe9555561adf1536e56","externalIds":{"ACL":"S19-1010","MAG":"2954519354","DBLP":"conf/starsem/LauscherG19","ArXiv":"1904.11783","DOI":"10.18653/v1/S19-1010","CorpusId":135465247},"title":"Are We Consistently Biased? Multidimensional Analysis of Biases in Distributional Word Vectors"},{"paperId":"e235ad7dcf6e97cd372f09724dc947c5b1efac79","externalIds":{"MAG":"2926555354","ArXiv":"1904.03310","DBLP":"conf/naacl/ZhaoWYCOC19","ACL":"N19-1064","DOI":"10.18653/v1/N19-1064","CorpusId":102352962},"title":"Gender Bias in Contextualized Word Embeddings"},{"paperId":"5e9c85235210b59a16bdd84b444a904ae271f7e7","externalIds":{"MAG":"2963078909","ACL":"N19-1063","DBLP":"conf/naacl/MayWBBR19","ArXiv":"1903.10561","DOI":"10.18653/v1/N19-1063","CorpusId":85518027},"title":"On Measuring Social Biases in Sentence Encoders"},{"paperId":"f1d791b9dd32577609ddd48e6001e46f1780062c","externalIds":{"MAG":"2949188476","DBLP":"journals/corr/abs-1902-09492","ACL":"N19-1162","ArXiv":"1902.09492","DOI":"10.18653/v1/N19-1162","CorpusId":67856005},"title":"Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing"},{"paperId":"c4afa2b3eda95a1194313394901e0e96e24cefaa","externalIds":{"DBLP":"conf/fat/De-ArteagaRWCBC19","MAG":"3105536512","ArXiv":"1901.09451","DOI":"10.1145/3287560.3287572","CorpusId":58006082},"title":"Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting"},{"paperId":"ec4eba83f6b3266d9ae7cabb2b2cb1518f727edc","externalIds":{"DBLP":"journals/corr/abs-1901-07291","ArXiv":"1901.07291","MAG":"2970049541","CorpusId":58981712},"title":"Cross-lingual Language Model Pretraining"},{"paperId":"1c3112ef8a346b9817382ed34a8c146c53d5bcf5","externalIds":{"ArXiv":"1809.05053","ACL":"D18-1269","MAG":"2891555348","DBLP":"conf/emnlp/ConneauRLWBSS18","DOI":"10.18653/v1/D18-1269","CorpusId":52271711},"title":"XNLI: Evaluating Cross-lingual Sentence Representations"},{"paperId":"16b221c831855766dff661e88d0a7a9e835a6cb0","externalIds":{"ACL":"D18-1214","MAG":"2963472233","ArXiv":"1809.00013","DBLP":"conf/emnlp/Alvarez-MelisJ18","DOI":"10.18653/v1/D18-1214","CorpusId":52156206},"title":"Gromov-Wasserstein Alignment of Word Embedding Spaces"},{"paperId":"dda2cee72ffa3e5c70db302a87595ba9e5e72910","externalIds":{"MAG":"2798908575","ArXiv":"1805.06297","ACL":"P18-1073","DBLP":"journals/corr/abs-1805-06297","DOI":"10.18653/v1/P18-1073","CorpusId":21728524},"title":"A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings"},{"paperId":"5d4af8c9321168f9ba7a501f33fb019fa2deaa22","externalIds":{"MAG":"2949534740","DBLP":"journals/corr/abs-1805-04508","ACL":"S18-2005","ArXiv":"1805.04508","DOI":"10.18653/v1/S18-2005","CorpusId":21670658},"title":"Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems"},{"paperId":"de44046f931e0eb47a0a705540d2e00175126eb8","externalIds":{"MAG":"2963047628","DBLP":"conf/acl/SogaardVR18","ArXiv":"1805.03620","ACL":"P18-1072","DOI":"10.18653/v1/P18-1072","CorpusId":13675482},"title":"On the Limitations of Unsupervised Bilingual Dictionary Induction"},{"paperId":"9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7","externalIds":{"MAG":"2963457723","DBLP":"conf/naacl/RudingerNLD18","ArXiv":"1804.09301","ACL":"N18-2002","DOI":"10.18653/v1/N18-2002","CorpusId":13756572},"title":"Gender Bias in Coreference Resolution"},{"paperId":"451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c","externalIds":{"MAG":"2963310665","DBLP":"conf/emnlp/WangSMHLB18","ACL":"W18-5446","ArXiv":"1804.07461","DOI":"10.18653/v1/W18-5446","CorpusId":5034059},"title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"},{"paperId":"0be19fd9896e5d40222c690cc3ff553adc7c0e27","externalIds":{"MAG":"2963526187","DBLP":"conf/naacl/ZhaoWYOC18","ACL":"N18-2003","ArXiv":"1804.06876","DOI":"10.18653/v1/N18-2003","CorpusId":4952494},"title":"Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods"},{"paperId":"562c09c112df56c5696c010d90a815d6018a86c8","externalIds":{"MAG":"2963118869","DBLP":"journals/corr/abs-1710-04087","ArXiv":"1710.04087","CorpusId":3470398},"title":"Word Translation Without Parallel Data"},{"paperId":"5924d089041e48f074c1b0b3ff3c3082a592910a","externalIds":{"MAG":"2963633299","ACL":"I17-2050","DBLP":"conf/ijcnlp/NguyenC17","ArXiv":"1708.09803","CorpusId":3526501},"title":"Transfer Learning across Low-Resource, Related Languages for Neural Machine Translation"},{"paperId":"dce6f9d4017b1785979e7520fd0834ef8cf02f4b","externalIds":{"MAG":"2736601468","DBLP":"journals/corr/SchulmanWDRK17","ArXiv":"1707.06347","CorpusId":28695052},"title":"Proximal Policy Optimization Algorithms"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"5966d7c7f60898d610812e24c64d4d57855ad86a","externalIds":{"MAG":"3105700579","ArXiv":"1608.07187","DBLP":"journals/corr/IslamBN16","DOI":"10.1126/science.aal4230","CorpusId":23163324,"PubMed":"28408601"},"title":"Semantics derived automatically from language corpora contain human-like biases"},{"paperId":"e2dba792360873aef125572812f3673b1a85d850","externalIds":{"ArXiv":"1607.04606","ACL":"Q17-1010","MAG":"2493916176","DBLP":"journals/tacl/BojanowskiGJM17","DOI":"10.1162/tacl_a_00051","CorpusId":207556454},"title":"Enriching Word Vectors with Subword Information"},{"paperId":"e11edb4201007530c3692814a155b22f78a0d659","externalIds":{"ACL":"L16-1147","MAG":"2419539795","DBLP":"conf/lrec/LisonT16","CorpusId":29180066},"title":"OpenSubtitles2016: Extracting Large Parallel Corpora from Movie and TV Subtitles"},{"paperId":"69e76e16740ed69f4dc55361a3d319ac2f1293dd","externalIds":{"MAG":"2964043796","DBLP":"journals/corr/MnihBMGLHSK16","ArXiv":"1602.01783","CorpusId":6875312},"title":"Asynchronous Methods for Deep Reinforcement Learning"},{"paperId":"f37e1b62a767a307c046404ca96bc140b3e68cb5","externalIds":{"DBLP":"conf/emnlp/PenningtonSM14","ACL":"D14-1162","MAG":"2250539671","DOI":"10.3115/v1/D14-1162","CorpusId":1957433},"title":"GloVe: Global Vectors for Word Representation"},{"paperId":"4b2e4bec36d3e7cb4b7086402a3b24cbeb789358","externalIds":{"MAG":"2612560781","DOI":"10.3115/v1/e14-1","CorpusId":67349512},"title":"Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics"},{"paperId":"87f40e6f3022adbc1f1905e3e506abad05a9964f","externalIds":{"ArXiv":"1310.4546","MAG":"2950133940","DBLP":"conf/nips/MikolovSCCD13","CorpusId":16447573},"title":"Distributed Representations of Words and Phrases and their Compositionality"},{"paperId":"ed6262b569c0a62c51d941228c54f34e563af022","externalIds":{"DBLP":"conf/icassp/SchusterN12","MAG":"2121879602","DOI":"10.1109/ICASSP.2012.6289079","CorpusId":22320655},"title":"Japanese and Korean voice search"},{"paperId":"0b274c13464879ca6d03299ed8f1be4fc9830f4c","externalIds":{"PubMedCentral":"7139439","DOI":"10.1007/978-3-540-89702-6_9","CorpusId":219574650},"title":"Singapore"},{"paperId":"2722b9e5ab8da95f03e578bb65879c452c105385","externalIds":{"MAG":"2060277733","DOI":"10.1016/S1364-6613(99)01294-2","CorpusId":2691726,"PubMed":"10322466"},"title":"Catastrophic forgetting in connectionist networks"},{"paperId":"1aa9c0045f1fe8c79cce03c7c14ef4b4643a21f8","externalIds":{"MAG":"46679369","CorpusId":59804030},"title":"A new algorithm for data compression"},{"paperId":"5c3391bde2bb1b3d737913ee8caa01492a782732","externalIds":{"PubMedCentral":"2599584","MAG":"961805690","DOI":"10.1515/cclm.1994.32.8.631","CorpusId":28467205},"title":"WHO Technical Report"},{"paperId":"60999ddb99aea5a93bd2ba16fb7671dc76bf3ba5","externalIds":{"ACL":"2023.acl-long.232","DBLP":"conf/acl/ZhouMYYZ23","DOI":"10.18653/v1/2023.acl-long.232","CorpusId":259370743},"title":"Causal-Debias: Unifying Debiasing in Pretrained Language Models and Fine-tuning via Causal Invariant Learning"},{"paperId":"f375613f17d7fb69b7975c279d4f1147598bb4a2","externalIds":{"ACL":"2023.bsnlp-1.1","DOI":"10.18653/v1/2023.bsnlp-1.1","CorpusId":258486903},"title":"Named Entity Recognition for Low-Resource Languages - Profiting from Language Families"},{"paperId":"bba7358adc89091934ab32abce9ed5e251ee35e4","externalIds":{"ACL":"2023.findings-eacl.93","DBLP":"conf/eacl/OgunremiJM23","DOI":"10.18653/v1/2023.findings-eacl.93","CorpusId":258378192},"title":"Mini But Mighty: Efficient Multilingual Pretraining with Linguistically-Informed Data Selection"},{"paperId":"05aa63683f7d027c18f560d4472ac87c1ea754fe","externalIds":{"DBLP":"conf/nips/PenedoMHCACPAL23","CorpusId":268096300},"title":"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data Only"},{"paperId":"b79bb5e86b0836cb1d305bf7d0481383e39b37b4","externalIds":{"ACL":"2022.acl-long.72","DBLP":"conf/acl/GuoYA22","DOI":"10.18653/v1/2022.acl-long.72","CorpusId":248780440},"title":"Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts"},{"paperId":"42827df167cc7d87774626a7c913d1cdaaa47d10","externalIds":{"ACL":"2022.gebnlp-1.21","DOI":"10.18653/v1/2022.gebnlp-1.21","CorpusId":250391092},"title":"Occupational Biases in Norwegian and Multilingual Language Models"},{"paperId":"cf387294994faf86b3c8332ba72fc17b1442651c","externalIds":{"ACL":"2022.emnlp-main.597","DBLP":"conf/emnlp/OgundepoZSDL22","DOI":"10.18653/v1/2022.emnlp-main.597","CorpusId":256461318},"title":"AfriCLIRMatrix: Enabling Cross-Lingual Information Retrieval for African Languages"},{"paperId":"058dee85d522f6565fe1502cafcf9a5e3f6a6f0e","externalIds":{"ACL":"2022.naacl-main.122","DBLP":"conf/naacl/DelobelleTCB22","DOI":"10.18653/v1/2022.naacl-main.122","CorpusId":250390561},"title":"Measuring Fairness with Biased Rulers: A Comparative Study on Bias Metrics for Pre-trained Language Models"},{"paperId":"72128b2da0ffb784861889462070570b21017b9f","externalIds":{"ACL":"2022.acl-long.583","DBLP":"conf/acl/NeveolDBF22","DOI":"10.18653/v1/2022.acl-long.583","CorpusId":248780290},"title":"French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English"},{"paperId":"21abb6f22851e5447cd810dd9e70a4b8691cee51","externalIds":{"ACL":"2022.bigscience-1.3","DOI":"10.18653/v1/2022.bigscience-1.3","CorpusId":247626152},"title":"You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings"},{"paperId":"2a83a92b08e0f3873d07162c73c67e533321112e","externalIds":{"DBLP":"conf/naacl/LiuZFV22","DOI":"10.18653/v1/2022.findings-naacl.18","CorpusId":250562745},"title":"Aligning Generative Language Models with Human Values"},{"paperId":"ed5ebed7ff668fd7362d531a40b49b3aea33b3a9","externalIds":{"DBLP":"journals/corr/abs-2212-10678","DOI":"10.48550/arXiv.2212.10678","CorpusId":273994217},"title":"Understanding Stereotypes in Language Models: Towards Robust Measurement and Zero-Shot Debiasing"},{"paperId":"b2474a00d7de3373bab934c09acef1994fa82207","externalIds":{"ACL":"2021.mrl-1.11","DOI":"10.18653/v1/2021.mrl-1.11","CorpusId":240225648},"title":"Small Data? No Problem! Exploring the Viability of Pretrained Multilingual Language Models for Low-resourced Languages"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"5f6878bc8aeaec45108933dbde11384efbc13db1","externalIds":{"ACL":"D18-1047","DBLP":"conf/emnlp/Nakashole18","MAG":"2889574253","DOI":"10.18653/v1/D18-1047","CorpusId":52971170},"title":"NORMA: Neighborhood Sensitive Maps for Multilingual Word Embeddings"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":"616253f6b1e83ede361457de2f51b0bf70555b13","externalIds":{"DBLP":"conf/acl/PanZMNKJ17","MAG":"2742113707","ACL":"P17-1178","DOI":"10.18653/v1/P17-1178","CorpusId":29939583},"title":"Cross-lingual Name Tagging and Linking for 282 Languages"},{"paperId":"34f25a8704614163c4095b3ee2fc969b60de4698","externalIds":{"DBLP":"journals/jmlr/SrivastavaHKSS14","MAG":"2095705004","DOI":"10.5555/2627435.2670313","CorpusId":6844431},"title":"Dropout: a simple way to prevent neural networks from overfitting"},{"paperId":"de8ba9b01c9ab7cbabf5c33b80b7bbc618857627","externalIds":{"CorpusId":268232499},"title":"The Claude 3 Model Family: Opus, Sonnet, Haiku"}]}