{"abstract":"Deep learning-based intelligent object recognition algorithm has been widely applied in object detection, auto driving, ect. However, deep neural network is very vulnerable because of its high-dimensional linearization. The object recognition results can be easily mis-leaded through a tiny disturbance in the original image. This kind of sample that adds tiny disturbance to the original image is called adversarial example. The adversarial example attack is a factor that must be considered in the design of robust object recognition algorithm, that is, the need for adversarial defence. An in-depth understanding of adversarial attack can help the model defend successfully. In this survey, an introduction of adversarial attack and defense aiming to object recognition algorithm at the present stage is summarized, and the challenges to be faced and the development trend in the future are pointed out."}