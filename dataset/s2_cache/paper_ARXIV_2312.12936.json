{"paperId":"24aa8c52b062afbfcab0faccf144397503a1873e","externalIds":{"DBLP":"journals/corr/abs-2312-12936","ArXiv":"2312.12936","DOI":"10.1145/3774643","CorpusId":266374560},"title":"Concept-based Explainable Artificial Intelligence: A Survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2312.12936, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2275351206","name":"Eleonora Poeta"},{"authorId":"2275350057","name":"Gabriele Ciravegna"},{"authorId":"51209710","name":"Eliana Pastor"},{"authorId":"1684646","name":"T. Cerquitelli"},{"authorId":"2256210032","name":"Elena Baralis"}],"abstract":"The field of explainable artificial intelligence emerged in response to the growing need for more transparent and reliable models. However, using raw features to provide explanations has been discussed in several works lately, advocating for more user-understandable explanations. To address this issue, a wide range of papers proposing Concept-based eXplainable Artificial Intelligence (C-XAI) methods have been published in recent years. Nevertheless, a unified categorization and precise field definition are still missing. This paper fills the gap by offering a thorough review of C-XAI approaches. We identify and define different concepts and explanation types. We propose a taxonomy comprising nine categories and guidelines for selecting a suitable category based on the application context. Additionally, we discuss common evaluation strategies including metrics, human evaluations, and datasets employed, aiming to assist the development of future methods. Overall, we believe this survey will assist researchers, practitioners, and domain experts in enhancing their understanding and contributing to the progress of this innovative field."}