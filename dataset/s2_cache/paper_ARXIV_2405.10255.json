{"paperId":"bc3965a843b80e720aa03116d3f2cf3896e40592","externalIds":{"ArXiv":"2405.10255","DBLP":"journals/corr/abs-2405-10255","DOI":"10.48550/arXiv.2405.10255","CorpusId":269791266},"title":"When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2405.10255, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2301544160","name":"Xianzheng Ma"},{"authorId":"3469024","name":"Yash Bhalgat"},{"authorId":"2301457194","name":"Brandon Smart"},{"authorId":"2296722898","name":"Shuai Chen"},{"authorId":"2155447960","name":"Xinghui Li"},{"authorId":"2301573180","name":"Jian Ding"},{"authorId":"2345676204","name":"Jindong Gu"},{"authorId":"73286206","name":"Dave Zhenyu Chen"},{"authorId":"2267222520","name":"Songyou Peng"},{"authorId":"3459992","name":"Jiawang Bian"},{"authorId":"2257347697","name":"Philip H. S. Torr"},{"authorId":"2300182737","name":"Marc Pollefeys"},{"authorId":"2264249647","name":"Matthias Nie√üner"},{"authorId":"2291030304","name":"Ian D Reid"},{"authorId":"2301499896","name":"Angel X. Chang"},{"authorId":"3422200","name":"Iro Laina"},{"authorId":"2243268729","name":"V. Prisacariu"}],"abstract":"As large language models (LLMs) evolve, their integration with 3D spatial data (3D-LLMs) has seen rapid progress, offering unprecedented capabilities for understanding and interacting with physical spaces. This survey provides a comprehensive overview of the methodologies enabling LLMs to process, understand, and generate 3D data. Highlighting the unique advantages of LLMs, such as in-context learning, step-by-step reasoning, open-vocabulary capabilities, and extensive world knowledge, we underscore their potential to significantly advance spatial comprehension and interaction within embodied Artificial Intelligence (AI) systems. Our investigation spans various 3D data representations, from point clouds to Neural Radiance Fields (NeRFs). It examines their integration with LLMs for tasks such as 3D scene understanding, captioning, question-answering, and dialogue, as well as LLM-based agents for spatial reasoning, planning, and navigation. The paper also includes a brief review of other methods that integrate 3D and language. The meta-analysis presented in this paper reveals significant progress yet underscores the necessity for novel approaches to harness the full potential of 3D-LLMs. Hence, with this paper, we aim to chart a course for future research that explores and expands the capabilities of 3D-LLMs in understanding and interacting with the complex 3D world. To support this survey, we have established a project page where papers related to our topic are organized and listed: https://github.com/ActiveVisionLab/Awesome-LLM-3D."}