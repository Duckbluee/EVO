{"references":[{"paperId":"850a5c74833054824ce2280cb0d7226cbaac8b46","externalIds":{"DBLP":"journals/csur/CaoLLYDYS25","DOI":"10.1145/3704262","CorpusId":274929812},"title":"A Survey of AI-Generated Content (AIGC)"},{"paperId":"777a9c0dca43f73b4a022cff951475fa033fdb9d","externalIds":{"DOI":"10.1109/ICSSAS64001.2024.10760326","CorpusId":274373730},"title":"Manipulation and Measurement of Knowledge Representations of Language Models"},{"paperId":"b06e1a2c84fb3bff03b10283bc863f007f5483b6","externalIds":{"DOI":"10.1101/2023.01.11.523679","CorpusId":255943445},"title":"The Nucleotide Transformer: Building and Evaluating Robust Foundation Models for Human Genomics"},{"paperId":"631066c55a852fac7b9c9129e166550a6310fa3c","externalIds":{"DBLP":"journals/corr/abs-2403-07920","ArXiv":"2403.07920","DOI":"10.48550/arXiv.2403.07920","CorpusId":268379189},"title":"ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training"},{"paperId":"0e8297549b4ec852ce8fd55dee9ae21501805af2","externalIds":{"PubMedCentral":"10894685","DOI":"10.1098/rsta.2023.0254","CorpusId":257572753,"PubMed":"38403056"},"title":"GPT-4 passes the bar exam"},{"paperId":"fe21b0db9233e921d2e4073fd80baeca124b265a","externalIds":{"ArXiv":"2402.11035","DBLP":"conf/emnlp/ReichmanH24","DOI":"10.18653/v1/2024.findings-emnlp.791","CorpusId":267750652},"title":"Dense Passage Retrieval: Is it Retrieving?"},{"paperId":"7bd792c6541d794c7b1a9150a2ef910206143afd","externalIds":{"ArXiv":"2401.04854","DBLP":"journals/corr/abs-2401-04854","DOI":"10.1162/tacl_a_00690","CorpusId":266903015},"title":"Are Language Models More Like Libraries or Like Librarians? Bibliotechnism, the Novel Reference Problem, and the Attitudes of LLMs"},{"paperId":"3b47f85df53eb5cdc98a95de615b8a076fbf3adf","externalIds":{"DBLP":"journals/corr/abs-2401-03217","ArXiv":"2401.03217","DOI":"10.1145/3610977.3634966","CorpusId":266844892},"title":"Understanding Large-Language Model (LLM)-powered Human-Robot Interaction"},{"paperId":"7b6a8c6d44e0f77bf930484e438d77b7465a69fb","externalIds":{"DOI":"10.2139/ssrn.4337484","CorpusId":256347543},"title":"Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning"},{"paperId":"ddbd8fe782ac98e9c64dd98710687a962195dd9b","externalIds":{"DBLP":"conf/iclr/AsaiWWSH24","ArXiv":"2310.11511","CorpusId":264288947},"title":"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"},{"paperId":"8f72127459ade06831ec2990f7da4914cc1a6e22","externalIds":{"ArXiv":"2310.05002","DBLP":"conf/emnlp/WangLSL23","DOI":"10.48550/arXiv.2310.05002","CorpusId":263828724},"title":"Self-Knowledge Guided Retrieval Augmentation for Large Language Models"},{"paperId":"c3363ae93e48199601c4e28c6e86dc3eb5dbb17f","externalIds":{"DBLP":"conf/iclr/ZhouWPMCHR24","ArXiv":"2309.17249","DOI":"10.48550/arXiv.2309.17249","CorpusId":263310485},"title":"Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering"},{"paperId":"fdc53c2c10742464087c0525f77e32604827a21d","externalIds":{"DBLP":"conf/iclr/XiaoTCHL24","ArXiv":"2309.17453","DOI":"10.48550/arXiv.2309.17453","CorpusId":263310483},"title":"Efficient Streaming Language Models with Attention Sinks"},{"paperId":"2461675ae633a5ef5a3d557299d57f707b3e07cd","externalIds":{"DBLP":"journals/jms/WangGWJXZFWHL23","DOI":"10.1007/s10916-023-01961-0","CorpusId":260888866,"PubMed":"37581690"},"title":"ChatGPT Performs on the Chinese National Medical Licensing Examination"},{"paperId":"c1df8a2089531b7558edd87a74a9570749ae45a2","externalIds":{"DOI":"10.1021/acs.oprd.3c00186","CorpusId":260389713},"title":"Designing Chemical Reaction Arrays Using Phactor and ChatGPT"},{"paperId":"c07a769da491dd5b6d7244c0d8f6614525ccb437","externalIds":{"ArXiv":"2309.00649","DBLP":"journals/corr/abs-2309-00649","DOI":"10.1016/j.frl.2023.104333","CorpusId":261042901},"title":"GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice"},{"paperId":"959e86a5678b5c2f4911cd75af8359acd325d4ad","externalIds":{"DBLP":"conf/aaai/ZongK23","DOI":"10.1609/aaai.v37i13.26896","CorpusId":259738553},"title":"Solving Math Word Problems concerning Systems of Equations with GPT-3"},{"paperId":"aff0fe00ed7892d1185e8c5b66d318d3892abe6e","externalIds":{"DBLP":"journals/bib/TianJYLZCYCKCIKGL24","PubMedCentral":"10614979","ArXiv":"2306.10070","DOI":"10.1093/bib/bbad493","CorpusId":259203988,"PubMed":"38168838"},"title":"Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health"},{"paperId":"9e545ea405b5c5ae42c4df7a10701ee9c4221c87","externalIds":{"DBLP":"journals/jbi/CuiLXWMYYKLZQHFMHWY25","ArXiv":"2306.04802","DOI":"10.1016/j.jbi.2025.104861","CorpusId":259108375,"PubMed":"40712809"},"title":"A review on knowledge graphs for healthcare: Resources, applications, and promises"},{"paperId":"8f831f341e959955a495730d81996e62c57cc0bd","externalIds":{"ArXiv":"2305.03111","DBLP":"conf/nips/LiHQYLLWQGHZ0LC23","DOI":"10.48550/arXiv.2305.03111","CorpusId":258547040},"title":"Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs"},{"paperId":"aad167be3c902388ea625da4117fcae4325b8b7d","externalIds":{"ArXiv":"2305.02301","DBLP":"journals/corr/abs-2305-02301","DOI":"10.48550/arXiv.2305.02301","CorpusId":258461606},"title":"Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"},{"paperId":"4248c6cbdbdbb2ed2727e5203d427d2dc2c935d5","externalIds":{"DOI":"10.2139/ssrn.4337182","CorpusId":256436290},"title":"Sentiment Spin: Attacking Financial Sentiment with GPT-3"},{"paperId":"d553d008f643622e87e3ac061226865cad3b2928","externalIds":{"DBLP":"conf/educon/Qadir23","DOI":"10.1109/EDUCON54358.2023.10125121","CorpusId":258857903},"title":"Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education"},{"paperId":"131c6f328c11706de2c43cd16e0b7c5d5e610b6a","externalIds":{"DBLP":"journals/corr/abs-2304-13712","ArXiv":"2304.13712","DOI":"10.1145/3649506","CorpusId":258331833},"title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"},{"paperId":"f406aceba4f29cc7cfbe7edb2f52f01374486589","externalIds":{"ArXiv":"2304.13734","DBLP":"journals/corr/abs-2304-13734","DOI":"10.18653/v1/2023.findings-emnlp.68","CorpusId":258352729},"title":"The Internal State of an LLM Knows When its Lying"},{"paperId":"cc0f0cb09a73f82ed44d900f5ca710bec784acc1","externalIds":{"DBLP":"conf/nips/PourrezaR23","ArXiv":"2304.11015","DOI":"10.48550/arXiv.2304.11015","CorpusId":258291425},"title":"DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction"},{"paperId":"7f3c4ae39c406867ed1473b1440896242fb91ede","externalIds":{"DBLP":"journals/corr/abs-2304-10597","ArXiv":"2304.10597","DOI":"10.1145/3687123.3698287","CorpusId":258291950},"title":"Text2Seg: Zero-shot Remote Sensing Image Semantic Segmentation via Text-Guided Visual Foundation Models"},{"paperId":"05e003a34148d4663734d3f39deefa0979d2a0e6","externalIds":{"PubMedCentral":"10153281","DBLP":"journals/corr/abs-2304-09667","ArXiv":"2304.09667","DOI":"10.1093/bioinformatics/btae075","CorpusId":258298113,"PubMed":"38341654"},"title":"GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information"},{"paperId":"758d050f2cfc3f504d3cb2ae524fad4a699d209e","externalIds":{"DBLP":"conf/chi/MuraliSYSB23","DOI":"10.1145/3544549.3585602","CorpusId":258216932},"title":"Improving Multiparty Interactions with a Robot Using Large Language Models"},{"paperId":"428057300776bc5a6ed215b351b8d517d484ef1e","externalIds":{"PubMedCentral":"10375390","DOI":"10.2196/48305","CorpusId":259842568,"PubMed":"37440293"},"title":"Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations. Comment on “How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment”"},{"paperId":"ba2f935d2578fbf77ec1aa79e26e3db396771e38","externalIds":{"DBLP":"journals/tosem/DongJJL24","ArXiv":"2304.07590","DOI":"10.1145/3672459","CorpusId":258179537},"title":"Self-Collaboration Code Generation via ChatGPT"},{"paperId":"d26c55bee1ac6856a20862b0f7b4ff38fa39af50","externalIds":{"DBLP":"journals/corr/abs-2304-07619","ArXiv":"2304.07619","DOI":"10.2139/ssrn.4412788","CorpusId":258071542},"title":"Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models"},{"paperId":"ee012d0ec843ccdbddc1b802300090828b8d8293","externalIds":{"DOI":"10.1007/s10439-023-03204-2","CorpusId":258171103,"PubMed":"37061595"},"title":"ChatGPT and the Future of Health Policy Analysis: Potential and Pitfalls of Using ChatGPT in Policymaking"},{"paperId":"a43a3fadc9190e61b34f59a913f1716e443519e4","externalIds":{"ArXiv":"2304.06798","DBLP":"journals/corr/abs-2304-06798","DOI":"10.48550/arXiv.2304.06798","CorpusId":258170346},"title":"On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence"},{"paperId":"a88018cbbaa547d14c19ec7c5abdea70c1e61211","externalIds":{"PubMedCentral":"10863609","DBLP":"journals/corr/abs-2304-05973","ArXiv":"2304.05973","DOI":"10.1145/3539618.3591997","CorpusId":258078967,"PubMed":"38352127"},"title":"HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting"},{"paperId":"5278a8eb2ba2429d4029745caf4e661080073c81","externalIds":{"DBLP":"conf/uist/ParkOCMLB23","ArXiv":"2304.03442","DOI":"10.1145/3586183.3606763","CorpusId":258040990},"title":"Generative Agents: Interactive Simulacra of Human Behavior"},{"paperId":"34d12432af63915caf14eab9a362f7e7d24e4c13","externalIds":{"DBLP":"journals/corr/abs-2304-03816","ArXiv":"2304.03816","DOI":"10.48550/arXiv.2304.03816","CorpusId":258049098},"title":"Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions"},{"paperId":"9e8cb8c91a0acb6e661b58ad724aa758490f2bea","externalIds":{"ArXiv":"2304.03277","DBLP":"journals/corr/abs-2304-03277","CorpusId":257985497},"title":"Instruction Tuning with GPT-4"},{"paperId":"68850153b0210615c86f9a72624f34e2913bcddf","externalIds":{"DBLP":"journals/corr/abs-2304-02210","ArXiv":"2304.02210","DOI":"10.18653/v1/2023.emnlp-main.1036","CorpusId":257952312},"title":"Document-Level Machine Translation with Large Language Models"},{"paperId":"bdb68c5e2369633b20e733774ac66eb4600c34d1","externalIds":{"DBLP":"journals/corr/abs-2304-01933","ArXiv":"2304.01933","DOI":"10.48550/arXiv.2304.01933","CorpusId":257921386},"title":"LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models"},{"paperId":"8b7b0791bed2853fdaef2184b79e53dd55c26708","externalIds":{"ArXiv":"2304.00228","DBLP":"conf/websci/YangM25","DOI":"10.1145/3717867.3717903","CorpusId":257913006},"title":"Accuracy and Political Bias of News Source Credibility Ratings by Large Language Models"},{"paperId":"a98862ffe4c18634a67a3df8a965a35e5e0d7ec8","externalIds":{"DOI":"10.1016/j.lindif.2023.102274","CorpusId":257445349},"title":"ChatGPT for good? On opportunities and challenges of large language models for education"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"7bf72a3b5fbac8bc0f461780810fbc781c28ef53","externalIds":{"DBLP":"conf/nips/LiHIKG23","ArXiv":"2303.17760","CorpusId":268042527},"title":"CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society"},{"paperId":"83edcfbb206ddad38a971d605da09390604248ea","externalIds":{"DBLP":"journals/corr/abs-2303-17564","ArXiv":"2303.17564","CorpusId":257833842},"title":"BloombergGPT: A Large Language Model for Finance"},{"paperId":"72b74bcff8fd76eff6789111a7ce5d0d6c5ac4db","externalIds":{"DOI":"10.1056/NEJMsr2214184","CorpusId":257803472,"PubMed":"36988602"},"title":"Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine."},{"paperId":"ac7771c332da42b29a913b116bd6ef622cbf89cf","externalIds":{"DBLP":"journals/corr/abs-2303-16434","ArXiv":"2303.16434","DOI":"10.48550/arXiv.2303.16434","CorpusId":257804802},"title":"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs"},{"paperId":"a757999ed260d7bc45484dc6b4456bf33fe6f679","externalIds":{"ArXiv":"2303.16199","DBLP":"journals/corr/abs-2303-16199","DOI":"10.48550/arXiv.2303.16199","CorpusId":257771811},"title":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"},{"paperId":"6a3d0b11a0b22bafcce7739cc5eb12dad8bd7565","externalIds":{"ArXiv":"2304.10548","DBLP":"journals/corr/abs-2304-10548","DOI":"10.1145/3581754.3584136","CorpusId":257758261},"title":"Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding"},{"paperId":"1b492746ee3a304a13950cad1a59861b9ee44645","externalIds":{"ArXiv":"2303.11717","DBLP":"journals/corr/abs-2303-11717","DOI":"10.48550/arXiv.2303.11717","CorpusId":257636561},"title":"A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?"},{"paperId":"5555da51fdadbeeaaefa2cfd95db1a5ba3c4ecdf","externalIds":{"PubMedCentral":"10666266","DOI":"10.1021/acs.est.3c01818","CorpusId":257638761,"PubMed":"36943179"},"title":"ChatGPT and Environmental Research"},{"paperId":"12454696085d66beaeb6cd43857de982a8445824","externalIds":{"ArXiv":"2303.11607","DBLP":"journals/corr/abs-2303-11607","DOI":"10.48550/arXiv.2303.11607","CorpusId":257636830},"title":"Transformers in Speech Processing: A Survey"},{"paperId":"6d3f29545fa059f7d24e27aaa9351750636d12ce","externalIds":{"DBLP":"journals/corr/abs-2303-11146","ArXiv":"2303.11146","DOI":"10.1145/3587102.3588827","CorpusId":257631490},"title":"On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?"},{"paperId":"7c1707db9aafd209aa93db3251e7ebd593d55876","externalIds":{"DBLP":"conf/emnlp/ManakulLG23","ArXiv":"2303.08896","DOI":"10.48550/arXiv.2303.08896","CorpusId":257557820},"title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"},{"paperId":"9fe9af7cf3d54b707a7be3c53ce94b77dcc3bae5","externalIds":{"ArXiv":"2303.09136","DBLP":"journals/corr/abs-2303-09136","DOI":"10.48550/arXiv.2303.09136","CorpusId":257557504},"title":"A Short Survey of Viewing Large Language Models in Legal Aspect"},{"paperId":"6e754273d54a91371efbc928cd6b156364d517da","externalIds":{"DBLP":"conf/iccv/SurisMV23","ArXiv":"2303.08128","DOI":"10.1109/ICCV51070.2023.01092","CorpusId":257505358},"title":"ViperGPT: Visual Inference via Python Execution for Reasoning"},{"paperId":"f94c58af515c4c9621762f2276adbe14ac1031d5","externalIds":{"DOI":"10.1080/14703297.2023.2190148","CorpusId":257528988},"title":"Chatting and cheating: Ensuring academic integrity in the era of ChatGPT"},{"paperId":"1aa3fa40f93c084dcb07fd786bf6347a3324b897","externalIds":{"DOI":"10.56741/jpes.v2i01.302","CorpusId":258229546},"title":"ChatGPT and Medical Education: A Double-Edged Sword"},{"paperId":"b92b8a32f89f45cd771359e3351f6ddcad61450c","externalIds":{"DBLP":"journals/corr/abs-2303-09461","ArXiv":"2303.09461","DOI":"10.48550/arXiv.2303.09461","CorpusId":257557508},"title":"ChatGPT Participates in a Computer Science Exam"},{"paperId":"bdf7bf9e81a6c12e22323d0402885b2ba62f623e","externalIds":{"DBLP":"journals/corr/abs-2303-04360","ArXiv":"2303.04360","DOI":"10.48550/arXiv.2303.04360","CorpusId":257405132},"title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?"},{"paperId":"a7b3a868a80dbe97689135c99b1a6b6e10dcdfe5","externalIds":{"ArXiv":"2303.04226","DBLP":"journals/corr/abs-2303-04226","DOI":"10.48550/arXiv.2303.04226","CorpusId":257405349},"title":"A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT"},{"paperId":"6f75404b0d01f9a09afe428f9efd5cbcd7825469","externalIds":{"DBLP":"journals/corr/abs-2303-02909","ArXiv":"2303.02909","DOI":"10.48550/arXiv.2303.02909","CorpusId":257365432},"title":"Dynamic Prompting: A Unified Framework for Prompt Tuning"},{"paperId":"be7b764fe1c9c32cbe349bde1fbb19321fd1d71c","externalIds":{"DBLP":"journals/corr/abs-2303-02151","ArXiv":"2303.02151","DOI":"10.1109/CVPR52729.2023.01460","CorpusId":257353537},"title":"Prompt, Generate, Then Cache: Cascade of Foundation Models Makes Strong Few-Shot Learners"},{"paperId":"74d4fb20b4ab1b27198a8ab4a7f6b4c62f4fb32f","externalIds":{"DOI":"10.1007/s10439-023-03171-8","CorpusId":257257492,"PubMed":"36856927"},"title":"Potential Use of Chat GPT in Global Warming"},{"paperId":"645960e8bcb2a55bc7e8816c49e60e8f98303acb","externalIds":{"ArXiv":"2303.14542","DBLP":"journals/corr/abs-2303-14542","DOI":"10.1109/SANER56733.2023.00071","CorpusId":257767014},"title":"Combining Contexts from Multiple Sources for Documentation-Specific Code Example Generation"},{"paperId":"3bdd17e589af6de6618b32432d0261978df58f66","externalIds":{"DOI":"10.1101/2023.02.25.23286451","CorpusId":257254315},"title":"Does ChatGPT Provide Appropriate and Equitable Medical Advice?: A Vignette-Based, Clinical Evaluation Across Care Contexts"},{"paperId":"fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c","externalIds":{"ArXiv":"2302.14045","DBLP":"conf/nips/Huang0WHSML0MPL23","DOI":"10.48550/arXiv.2302.14045","CorpusId":257219775},"title":"Language Is Not All You Need: Aligning Perception with Language Models"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"bab39663b1f31eb1ac79e6e0b1ed560b086803da","externalIds":{"DOI":"10.1101/2023.02.21.23285886","CorpusId":257204947,"PubMed":"36865204"},"title":"Assessing the Utility of ChatGPT Throughout the Entire Clinical Workflow"},{"paperId":"e5c72b92c48d68594b290c84a8904da7c8335554","externalIds":{"ArXiv":"2302.12813","DBLP":"journals/corr/abs-2302-12813","DOI":"10.48550/arXiv.2302.12813","CorpusId":257205781},"title":"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"},{"paperId":"754ed0deccc8c05e7dd05d5df376f205e569a841","externalIds":{"ArXiv":"2302.13814","DBLP":"journals/corr/abs-2302-13814","DOI":"10.48550/arXiv.2302.13814","CorpusId":257219363},"title":"An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)"},{"paperId":"5a91a012dc51db03d6eb3698d2e1c5b00115835f","externalIds":{"DBLP":"journals/corr/abs-2302-13793","ArXiv":"2302.13793","DOI":"10.48550/arXiv.2302.13793","CorpusId":257219583},"title":"Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts health answer correctness"},{"paperId":"3bbb397ea3b09a10de198f167fba045da680b4e8","externalIds":{"DOI":"10.1101/2023.02.19.23286155","CorpusId":257050179},"title":"The Utility of ChatGPT as an Example of Large Language Models in Healthcare Education, Research and Practice: Systematic Review on the Future Perspectives and Potential Limitations"},{"paperId":"89184ab496b2a1ae31e068e628479b4cd8f4b9d2","externalIds":{"DBLP":"journals/corr/abs-2302-08091","ArXiv":"2302.08091","DOI":"10.48550/arXiv.2302.08091","CorpusId":256900662},"title":"Do We Still Need Clinical Language Models?"},{"paperId":"2029349c55c1dba3493c5b3bd25152f18ba21ae2","externalIds":{"ArXiv":"2302.07842","DBLP":"journals/tmlr/MialonDLNPRRSDC23","CorpusId":256868474},"title":"Augmented Language Models: a Survey"},{"paperId":"629bc57782bb4326a3eb5f89314e350729c5f417","externalIds":{"DBLP":"conf/eacl/ChronopoulouPFD23","ArXiv":"2302.07027","ACL":"2023.findings-eacl.153","DOI":"10.48550/arXiv.2302.07027","CorpusId":256846453},"title":"AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models"},{"paperId":"a3ff4df653b6970898c04e6b768e58b99786d073","externalIds":{"DBLP":"journals/corr/abs-2302-06871","ArXiv":"2302.06871","DOI":"10.48550/arXiv.2302.06871","CorpusId":256846455},"title":"Learning gain differences between ChatGPT and human tutor generated algebra hints"},{"paperId":"5ef821267fa68d3231ed8135ff8ec09f25bb1398","externalIds":{"DBLP":"journals/corr/abs-2302-07257","ArXiv":"2302.07257","DOI":"10.48550/arXiv.2302.07257","CorpusId":256846858},"title":"ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models"},{"paperId":"f27dd152582b9da3c3a879025eceaebbf2a50752","externalIds":{"DOI":"10.2139/ssrn.4333415","CorpusId":256439068},"title":"Chatting about ChatGPT: How May AI and GPT Impact Academia and Libraries?"},{"paperId":"5f5253fb15ac382e96ade0335baf1cfaa240fb1d","externalIds":{"DBLP":"conf/icail/Blair-StanekHD23","ArXiv":"2302.06100","DOI":"10.1145/3594536.3595163","CorpusId":256826996},"title":"Can GPT-3 Perform Statutory Reasoning?"},{"paperId":"9a147712d46d1b01a761987c874b628c34c52cda","externalIds":{"ArXiv":"2303.13521","DBLP":"journals/corr/abs-2303-13521","DOI":"10.48550/arXiv.2303.13521","CorpusId":257757409},"title":"Scamming the Scammers: Using ChatGPT to Reply Mails for Wasting Time and Resources"},{"paperId":"53d128ea815bcc0526856eb5a9c42cc977cb36a7","externalIds":{"DBLP":"journals/corr/abs-2302-04761","ArXiv":"2302.04761","DOI":"10.48550/arXiv.2302.04761","CorpusId":256697342},"title":"Toolformer: Language Models Can Teach Themselves to Use Tools"},{"paperId":"8aeede855e975d98f711ec2c1fad1378b9b7c8b9","externalIds":{"DOI":"10.1093/eurjcn/zvad022","CorpusId":256663929,"PubMed":"36752788"},"title":"ChatGPT: Can artificial intelligence language models be of value for cardiovascular nurses and allied health professionals."},{"paperId":"bf8491bef353df126e2306ad2fe4b898697b906a","externalIds":{"ArXiv":"2302.04023","DBLP":"conf/ijcnlp/BangCLDSWLJYCDXF23","ACL":"2023.ijcnlp-main.45","DOI":"10.18653/v1/2023.ijcnlp-main.45","CorpusId":256662612},"title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity"},{"paperId":"4cd3ae84e24cfff89ef022e36991df314aac83e2","externalIds":{"DBLP":"journals/corr/abs-2302-04335","ArXiv":"2302.04335","DOI":"10.48550/arXiv.2302.04335","CorpusId":256697594},"title":"Will ChatGPT get you caught? Rethinking of Plagiarism Detection"},{"paperId":"10c5079d2baa5a287054d9ddd7806a4c16fd7531","externalIds":{"ArXiv":"2302.03194","DBLP":"journals/corr/abs-2302-03194","ACL":"2023.eacl-main.165","DOI":"10.48550/arXiv.2302.03194","CorpusId":256627195},"title":"UDAPTER - Efficient Domain Adaptation Using Adapters"},{"paperId":"d05ba0c40f3408aab7bb594628f24d9f04bf2831","externalIds":{"DOI":"10.1101/2023.02.02.23285399","CorpusId":256626649,"PubMed":"36798292"},"title":"Evaluating ChatGPT as an Adjunct for Radiologic Decision-Making"},{"paperId":"c1014f86c8d801c93b37eed58311da5f9c9da2e4","externalIds":{"DBLP":"conf/icst/JalilRLML23","ArXiv":"2302.03287","DOI":"10.1109/ICSTW58534.2023.00078","CorpusId":256627809},"title":"ChatGPT and Software Testing Education: Promises & Perils"},{"paperId":"29a32648fe0cb09980697c28176113439a81a64d","externalIds":{"PubMedCentral":"10025693","DOI":"10.12669/pjms.39.2.7653","CorpusId":256682790,"PubMed":"36950398"},"title":"ChatGPT - Reshaping medical education and clinical management"},{"paperId":"6f9d3c3a628e8d842de83f4ba2e41dd1b4b404ac","externalIds":{"ArXiv":"2302.03269","DBLP":"conf/eacl/ChenPTKRLYH23","ACL":"2023.findings-eacl.63","DOI":"10.48550/arXiv.2302.03269","CorpusId":256627323},"title":"PLACES: Prompting Language Models for Social Conversation Synthesis"},{"paperId":"ccb1ccc4deacc4fb18000f0e1ce24329548963ae","externalIds":{"ArXiv":"2302.01560","DBLP":"journals/corr/abs-2302-01560","DOI":"10.48550/arXiv.2302.01560","CorpusId":256598146},"title":"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents"},{"paperId":"1d75f8de31bf47ec46fa5586056420ec8bc97e86","externalIds":{"ArXiv":"2302.00871","DBLP":"journals/corr/abs-2302-00871","DOI":"10.48550/arXiv.2302.00871","CorpusId":256503647},"title":"Using In-Context Learning to Improve Dialogue Safety"},{"paperId":"102e4c860e39a2bfd7bf3f03b9ad69aac7bf3b5f","externalIds":{"ArXiv":"2302.00763","DBLP":"journals/corr/abs-2302-00763","DOI":"10.48550/arXiv.2302.00763","CorpusId":253180684},"title":"Collaborating with language models for embodied reasoning"},{"paperId":"ea09853b45c3c9dcec9918a1d51428ef8a8a7149","externalIds":{"PubMedCentral":"9931398","DOI":"10.7759/cureus.35029","CorpusId":256897987,"PubMed":"36819954"},"title":"ChatGPT Output Regarding Compulsory Vaccination and COVID-19 Vaccine Conspiracy: A Descriptive Study at the Outset of a Paradigm Shift in Online Search for Information"},{"paperId":"0b1c6e2f2a04496dac42bd562f518a0f7415b31f","externalIds":{"PubMedCentral":"9931307","DOI":"10.1371/journal.pdig.0000205","CorpusId":256747912,"PubMed":"36812618"},"title":"ChatGPT passing USMLE shines a spotlight on the flaws of medical education"},{"paperId":"6fbfceb15b4b9e70de475f8aa1a9a1ec12a9d851","externalIds":{"DOI":"10.1016/j.resuscitation.2023.109732","CorpusId":256814535,"PubMed":"36775020"},"title":"Can ChatGPT Pass the Life Support Exams without Entering the American Heart Association Course?"},{"paperId":"465471bb5bf1a945549d6291c2d23367966b4957","externalIds":{"ArXiv":"2302.00083","DBLP":"journals/corr/abs-2302-00083","DOI":"10.1162/tacl_a_00605","CorpusId":256459451},"title":"In-Context Retrieval-Augmented Language Models"},{"paperId":"3f2cb353c7528efafb847309ab1e1e95245740a4","externalIds":{"DBLP":"journals/corr/abs-2301-13867","ArXiv":"2301.13867","CorpusId":256415984},"title":"Mathematical Capabilities of ChatGPT"},{"paperId":"86478f285356b5c8d27423e6b939634d9e010fba","externalIds":{"DBLP":"journals/corr/abs-2301-12314","ArXiv":"2301.12314","DOI":"10.48550/arXiv.2301.12314","CorpusId":256390383},"title":"Progressive Prompts: Continual Learning for Language Models"},{"paperId":"1bfe1e6626067e9075570c575153e2b366f9d6cf","externalIds":{"ArXiv":"2301.12127","DOI":"10.1103/PhysRevPhysEducRes.19.010132","CorpusId":256389361},"title":"Could an artificial-intelligence agent pass an introductory physics course?"},{"paperId":"835c305e52769a8433f8383e91d33ba6c66ad55b","externalIds":{"DOI":"10.1038/s41587-022-01618-2","CorpusId":256304602,"PubMed":"36702895"},"title":"Large language models generate functional protein sequences across diverse families"},{"paperId":"621b8c4b37d1e22d440262dda2206ac13da6d779","externalIds":{"DOI":"10.1148/radiol.230163","CorpusId":256272939,"PubMed":"36700838"},"title":"ChatGPT and Other Large Language Models Are Double-edged Swords."},{"paperId":"9460f9fbc532416c8ec39591577032a5fa4a79b3","externalIds":{"DOI":"10.37074/jalt.2023.6.1.9","CorpusId":261067729},"title":"ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?"},{"paperId":"a525cbb8600ab6d2a1351f6883937c1774642d76","externalIds":{"DBLP":"conf/edm/PhungCGKMSS23","ArXiv":"2302.04662","DOI":"10.48550/arXiv.2302.04662","CorpusId":256697110},"title":"Generating High-Precision Feedback for Programming Syntax Errors using Large Language Models"},{"paperId":"35cdc00a4e2bc1f6c253a34a5e3a6f697050d1e9","externalIds":{"PubMedCentral":"10272508","DOI":"10.1101/2023.01.22.23284882","CorpusId":256194018,"PubMed":"37334036"},"title":"Evaluating the Performance of ChatGPT in Ophthalmology"},{"paperId":"3c76d5b253a3f8f2bb2294e94037b6fe16bf1ab1","externalIds":{"PubMedCentral":"9905868","DOI":"10.3352/jeehp.2023.20.01","CorpusId":255594082,"PubMed":"36627845"},"title":"Are ChatGPT’s knowledge and interpretation ability comparable to those of medical students in Korea for taking a parasitology examination?: a descriptive study"},{"paperId":"651dac86d8bf847ec6780a878cb1e04d3d41f356","externalIds":{"ArXiv":"2301.04408","DBLP":"journals/corr/abs-2301-04408","DOI":"10.2139/ssrn.4322372","CorpusId":255595524},"title":"GPT as Knowledge Worker: A Zero-Shot Evaluation of (AI)CPA Capabilities"},{"paperId":"7ec58d26c4dddb4bc3b6829fa0654a22cc26fdfe","externalIds":{"ArXiv":"2301.04589","DBLP":"journals/corr/abs-2301-04589","DOI":"10.48550/arXiv.2301.04589","CorpusId":255595513},"title":"Memory Augmented Large Language Models are Computationally Universal"},{"paperId":"9dafa6c5c609348b46734fc8997b93b3587fec6e","externalIds":{"DOI":"10.1177/10776958221149577","CorpusId":255726867},"title":"Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education"},{"paperId":"288078127a3078332230442170f6745ed333c700","externalIds":{"DOI":"10.1007/s12195-022-00754-8","CorpusId":255660738,"PubMed":"36660590"},"title":"A Conversation on Artificial Intelligence, Chatbots, and Plagiarism in Higher Education"},{"paperId":"490d8006851b1562cfd9ec1f057471f2868289d1","externalIds":{"DBLP":"journals/corr/abs-2301-00303","ArXiv":"2301.00303","DOI":"10.48550/arXiv.2301.00303","CorpusId":255372320},"title":"Rethinking with Retrieval: Faithful Large Language Model Inference"},{"paperId":"23cae400cfd1a7c455c721256b838e98a307d5e6","externalIds":{"DBLP":"journals/corr/abs-2212-14882","ArXiv":"2212.14882","PubMedCentral":"11126432","DOI":"10.1007/s00330-023-10213-1","CorpusId":255340809,"PubMed":"37794249"},"title":"ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports"},{"paperId":"2b79d1a8ce840578fcdfea7f18779a9cc8b907d1","externalIds":{"ArXiv":"2301.00665","DBLP":"journals/corr/abs-2301-00665","DOI":"10.48550/arXiv.2301.00665","CorpusId":255372245},"title":"Targeted Phishing Campaigns using Large Scale Language Models"},{"paperId":"458147b5f7242c998ec4f33798a59b7c48867329","externalIds":{"DBLP":"journals/corr/abs-2212-14402","ArXiv":"2212.14402","DOI":"10.48550/arXiv.2212.14402","CorpusId":255340451},"title":"GPT Takes the Bar Exam"},{"paperId":"6052486bc9144dc1730c12bf35323af3792a1fd0","externalIds":{"ArXiv":"2212.13138","DBLP":"journals/corr/abs-2212-13138","PubMedCentral":"10396962","DOI":"10.1038/s41586-023-06291-2","CorpusId":255124952,"PubMed":"37438534"},"title":"Large language models encode clinical knowledge"},{"paperId":"e65b346d442e9962a4276dc1c1af2956d9d5f1eb","externalIds":{"DBLP":"journals/corr/abs-2212-10560","ArXiv":"2212.10560","ACL":"2023.acl-long.754","DOI":"10.48550/arXiv.2212.10560","CorpusId":254877310},"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions"},{"paperId":"cf1f26e7cbed3958b3c2870656568c299fece6e3","externalIds":{"PubMedCentral":"9931230","DOI":"10.1371/journal.pdig.0000198","CorpusId":254876189,"PubMed":"36812645"},"title":"Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models"},{"paperId":"5aa7bdcae38076b80229c0a024f5b656ac6607af","externalIds":{"DBLP":"journals/corr/abs-2212-10650","ArXiv":"2212.10650","DOI":"10.48550/arXiv.2212.10650","CorpusId":254926823},"title":"KronA: Parameter Efficient Tuning with Kronecker Adapter"},{"paperId":"8822357efe500caded16e603d21239be3a39547c","externalIds":{"DBLP":"journals/corr/abs-2212-09292","ArXiv":"2212.09292","DOI":"10.3390/educsci14060656","CorpusId":254853785},"title":"ChatGPT: The End of Online Exam Integrity?"},{"paperId":"3b8ccc7ec80b8775de603e248ac1ca2b919d6b70","externalIds":{"DBLP":"journals/corr/abs-2212-11126","ArXiv":"2212.11126","DOI":"10.48550/arXiv.2212.11126","CorpusId":254926835},"title":"Chatbots in a Botnet World"},{"paperId":"c90151f00b1ac4abf1cc353849b453aa21cc2df3","externalIds":{"ArXiv":"2212.04092","DBLP":"conf/emnlp/DuaG0G22","ACL":"2022.emnlp-main.81","DOI":"10.48550/arXiv.2212.04092","CorpusId":254408974},"title":"Successive Prompting for Decomposing Complex Questions"},{"paperId":"86c79317afa13ea4a74f656e3c48f012ee1fc326","externalIds":{"DBLP":"journals/corr/abs-2212-03613","ArXiv":"2212.03613","ACL":"2022.emnlp-main.441","DOI":"10.48550/arXiv.2212.03613","CorpusId":254366524},"title":"G-MAP: General Memory-Augmented Pre-trained Language Model for Domain Tasks"},{"paperId":"4ce44071832c6eeb819ee0a1c5279624d9fbf362","externalIds":{"DBLP":"journals/corr/abs-2212-03241","ArXiv":"2212.03241","DOI":"10.1109/ICCV51070.2023.01707","CorpusId":254275229},"title":"PØDA: Prompt-driven Zero-shot Domain Adaptation"},{"paperId":"ec27f85979899a4193a8ec3b932ddb677c59be62","externalIds":{"DBLP":"journals/corr/abs-2212-02199","ArXiv":"2212.02199","DOI":"10.48550/arXiv.2212.02199","CorpusId":254246291},"title":"Legal Prompt Engineering for Multilingual Legal Judgement Prediction"},{"paperId":"ca7363451d032c0ffc229b4e5efc390d52ddeebb","externalIds":{"DBLP":"journals/corr/abs-2212-01117","ArXiv":"2212.01117","DOI":"10.48550/arXiv.2212.01117","CorpusId":254220830},"title":"Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning"},{"paperId":"cc43306e22dbfd5bc35251ab8c8ba37e4fc2a1b3","externalIds":{"DBLP":"journals/corr/abs-2212-01326","ArXiv":"2212.01326","DOI":"10.48550/arXiv.2212.01326","CorpusId":254221002},"title":"Legal Prompting: Teaching a Language Model to Think Like a Lawyer"},{"paperId":"8fd462f6248d5e3f1b6602697c09489086b5655f","externalIds":{"DBLP":"conf/acl/ShridharSS23","ArXiv":"2212.00193","DOI":"10.18653/v1/2023.findings-acl.441","CorpusId":258762841},"title":"Distilling Reasoning Capabilities into Smaller Language Models"},{"paperId":"b8b9ddf6cd23dec702f90c5f01c1733616f823df","externalIds":{"DOI":"10.1016/j.nepr.2022.103537","CorpusId":254813158,"PubMed":"36549229"},"title":"Open artificial intelligence platforms in nursing education: Tools for academic progress or abuse?"},{"paperId":"840028b328612a7eb7c3d5e60f5cb779065d7b4c","externalIds":{"ArXiv":"2211.16740","DBLP":"journals/corr/abs-2211-16740","DOI":"10.48550/arXiv.2211.16740","CorpusId":254096061},"title":"Explicit Knowledge Transfer for Weakly-Supervised Code Generation"},{"paperId":"2677645b0f96c8c055b83c904d531cfe22b2e623","externalIds":{"ArXiv":"2211.14228","DBLP":"journals/corr/abs-2211-14228","DOI":"10.1007/s40593-023-00340-7","CorpusId":254018349},"title":"GPT-3-Driven Pedagogical Agents to Train Children’s Curious Question-Asking Skills"},{"paperId":"6c943670dca38bfc7c8b477ae7c2d1fba1ad3691","externalIds":{"DBLP":"journals/tmlr/ChenM0C23","ArXiv":"2211.12588","CorpusId":253801709},"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"},{"paperId":"6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7","externalIds":{"ArXiv":"2211.10435","DBLP":"journals/corr/abs-2211-10435","DOI":"10.48550/arXiv.2211.10435","CorpusId":253708270},"title":"PAL: Program-aided Language Models"},{"paperId":"ee8de585183763ff64cb3c81ecda2fc75fa81507","externalIds":{"ArXiv":"2211.05110","DBLP":"journals/corr/abs-2211-05110","DOI":"10.48550/arXiv.2211.05110","CorpusId":253420654},"title":"Large Language Models with Controllable Working Memory"},{"paperId":"ce7d122dc55fa0329f7817964ae5b7c2b10cf69b","externalIds":{"ArXiv":"2211.03831","DBLP":"conf/nips/Page-CacciaPSPR23","CorpusId":259262344},"title":"Multi-Head Adapter Routing for Cross-Task Generalization"},{"paperId":"bf5c307aa7c4bdb912408ffd831553f0ae86ffe7","externalIds":{"ArXiv":"2211.03154","DBLP":"journals/corr/abs-2211-03154","DOI":"10.48550/arXiv.2211.03154","CorpusId":253384134},"title":"On the Domain Adaptation and Generalization of Pretrained Language Models: A Survey"},{"paperId":"a6e2bc7016a076e133b022dbefa5c19904e32869","externalIds":{"DBLP":"conf/nips/Zhang0LZZJ22","ArXiv":"2211.01642","DOI":"10.48550/arXiv.2211.01642","CorpusId":253265166},"title":"Fine-Tuning Pre-Trained Language Models Effectively by Optimizing Subnetworks Adaptively"},{"paperId":"de1c66454220eeb93f92b66bacad9d4f7dc8b2ab","externalIds":{"DBLP":"conf/prdc/HewettL22","DOI":"10.1109/PRDC55274.2022.00034","CorpusId":256563926},"title":"Developing a GPT-3-Based Automated Victim for Advance Fee Fraud Disruption"},{"paperId":"2c0b112d66d70487971bc96ef8c927464af8c8a8","externalIds":{"DBLP":"conf/gis/MaiCCHLE22","DOI":"10.1145/3557915.3561043","CorpusId":253763615},"title":"Towards a foundation model for geospatial artificial intelligence (vision paper)"},{"paperId":"ed38c6b157c11476939c426ec6871c926f2f3524","externalIds":{"ArXiv":"2210.12353","DBLP":"journals/corr/abs-2210-12353","DOI":"10.48550/arXiv.2210.12353","CorpusId":253098700},"title":"Leveraging Large Language Models for Multiple Choice Question Answering"},{"paperId":"7de36d6b14aadc8cdb6ad1340b9ca64b15375bca","externalIds":{"DBLP":"journals/corr/abs-2210-12283","ArXiv":"2210.12283","DOI":"10.48550/arXiv.2210.12283","CorpusId":253098549},"title":"Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs"},{"paperId":"aca584d4e5f4e80ef471cceefa8600b4daeddb2b","externalIds":{"DBLP":"journals/corr/abs-2210-12050","ArXiv":"2210.12050","DOI":"10.48550/arXiv.2210.12050","CorpusId":253080826},"title":"Clip-Tuning: Towards Derivative-free Prompt Learning with a Mixture of Rewards"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"3fa70115248377c3d1517c9f978791a296fbc1dd","externalIds":{"DBLP":"conf/emnlp/0001GHW00023","ArXiv":"2210.11610","DOI":"10.48550/arXiv.2210.11610","CorpusId":253080328},"title":"Large Language Models Can Self-Improve"},{"paperId":"a981a57848e19adb80c4a29471fbb798ac050a8f","externalIds":{"DBLP":"journals/corr/abs-2210-11292","ArXiv":"2210.11292","DOI":"10.48550/arXiv.2210.11292","CorpusId":253018816},"title":"Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts"},{"paperId":"5c919b3669aaa382daba912be0b6f7f492e6d2ef","externalIds":{"DBLP":"conf/emnlp/ZhaoTM22","ACL":"2022.emnlp-main.444","ArXiv":"2211.01979","DOI":"10.48550/arXiv.2211.01979","CorpusId":253265357},"title":"Tiny-Attention Adapter: Contexts Are More Important Than the Number of Parameters"},{"paperId":"801d660d7b02ece15c3416364e62369dbbc98f7e","externalIds":{"DBLP":"conf/nips/0004LSLLYA22","ArXiv":"2210.08654","DOI":"10.48550/arXiv.2210.08654","CorpusId":252918814},"title":"Learning to Sample and Aggregate: Few-shot Reasoning over Temporal Knowledge Graphs"},{"paperId":"85e959eef45114974c8f8643e88af23936fff3d1","externalIds":{"DBLP":"journals/corr/abs-2210-07558","ACL":"2023.eacl-main.239","ArXiv":"2210.07558","DOI":"10.48550/arXiv.2210.07558","CorpusId":252907428},"title":"DyLoRA: Parameter-Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation"},{"paperId":"2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413","externalIds":{"DBLP":"conf/iclr/MengSABB23","ArXiv":"2210.07229","DOI":"10.48550/arXiv.2210.07229","CorpusId":252873467},"title":"Mass-Editing Memory in a Transformer"},{"paperId":"39e40821b7207125e54e6ed7112e55cd38c6f0c3","externalIds":{"DBLP":"conf/emnlp/MadaanZ0YN22","ACL":"2022.emnlp-main.90","ArXiv":"2210.07128","DOI":"10.48550/arXiv.2210.07128","CorpusId":252873120},"title":"Language Models of Code are Few-Shot Commonsense Learners"},{"paperId":"2cb97b2bb6ab2eb17add9ffe69d5cbeaca2b29c8","externalIds":{"DBLP":"journals/corr/abs-2210-05359","ArXiv":"2210.05359","DOI":"10.48550/arXiv.2210.05359","CorpusId":252815535},"title":"Mind's Eye: Grounded Language Model Reasoning through Simulation"},{"paperId":"473e55ded26b201b834ae73966474299528ec48d","externalIds":{"ArXiv":"2210.04492","DBLP":"journals/corr/abs-2210-04492","DOI":"10.48550/arXiv.2210.04492","CorpusId":252780503},"title":"Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization"},{"paperId":"7bd551537b67a31a733ac12a8de69968bc190f66","externalIds":{"ArXiv":"2210.04284","DBLP":"conf/emnlp/He0DZT22","DOI":"10.48550/arXiv.2210.04284","CorpusId":252780333},"title":"SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency of Adapters"},{"paperId":"90350aa626bed47b02d0c162462e5b0ca82be6b2","externalIds":{"DBLP":"journals/corr/abs-2210-03493","ArXiv":"2210.03493","CorpusId":252762275},"title":"Automatic Chain of Thought Prompting in Large Language Models"},{"paperId":"f58ca7ba4a08b7082e86b7a5989b4b0fda2107ab","externalIds":{"DBLP":"journals/corr/abs-2210-02875","ArXiv":"2210.02875","CorpusId":252734772},"title":"Binding Language Models in Symbolic Languages"},{"paperId":"a046c4ca678ab402ac380ed171caa0e48fc51378","externalIds":{"DBLP":"journals/corr/abs-2210-02952","ArXiv":"2210.02952","DOI":"10.48550/arXiv.2210.02952","CorpusId":252735158},"title":"Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation"},{"paperId":"07955e96cbd778d0ae2a68f09d073b866dd84c2a","externalIds":{"ArXiv":"2210.02406","DBLP":"conf/iclr/KhotTFF0CS23","DOI":"10.48550/arXiv.2210.02406","CorpusId":252715485},"title":"Decomposed Prompting: A Modular Approach for Solving Complex Tasks"},{"paperId":"fb49e88c6bd676516898e911e42b4f8479e6f1bf","externalIds":{"ArXiv":"2210.02441","DBLP":"journals/corr/abs-2210-02441","DOI":"10.48550/arXiv.2210.02441","CorpusId":252716013},"title":"Ask Me Anything: A simple strategy for prompting language models"},{"paperId":"40047a74b707743157051d38f76061ba5ff9aab4","externalIds":{"DBLP":"journals/corr/abs-2209-15003","ArXiv":"2209.15003","CorpusId":252596001},"title":"Compositional Semantic Parsing with Large Language Models"},{"paperId":"9ea7c47298c7e396571f89adb67a3841de0d632d","externalIds":{"DOI":"10.1109/ICAICTA56449.2022.9932928","CorpusId":253252935},"title":"A response generation method of chat-bot system using input formatting and reference resolution"},{"paperId":"44279244407a64431810f982be6d0c7da4429dd7","externalIds":{"ArXiv":"2210.10341","DBLP":"journals/bib/LuoSXQZPL22","DOI":"10.1093/bib/bbac409","CorpusId":252542956,"PubMed":"36156661"},"title":"BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining"},{"paperId":"e86009d9f9b1cdf083a48d087552bc4153784451","externalIds":{"DBLP":"journals/corr/abs-2209-11755","ArXiv":"2209.11755","DOI":"10.48550/arXiv.2209.11755","CorpusId":252519173},"title":"Promptagator: Few-shot Dense Retrieval From 8 Examples"},{"paperId":"c03fa01fbb9c77fe3d10609ba5f1dee33a723867","externalIds":{"DBLP":"journals/corr/abs-2209-11302","ArXiv":"2209.11302","DOI":"10.1109/ICRA48891.2023.10161317","CorpusId":252519594},"title":"ProgPrompt: Generating Situated Robot Task Plans using Large Language Models"},{"paperId":"863171ed35ca0035074f73bb202b153cc346f2f3","externalIds":{"DBLP":"journals/tkde/XueS24","ArXiv":"2210.08964","DOI":"10.1109/TKDE.2023.3342137","CorpusId":253254774},"title":"PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting"},{"paperId":"91deaf9d324c8feafc189da0da03e60a60287bca","externalIds":{"ArXiv":"2209.07753","DBLP":"conf/icra/LiangHXXHIFZ23","DOI":"10.1109/ICRA48891.2023.10160591","CorpusId":252355542},"title":"Code as Policies: Language Model Programs for Embodied Control"},{"paperId":"007fe51fddfae031570f2d69e67dc67e1fe33621","externalIds":{"DBLP":"journals/corr/abs-2209-03320","ArXiv":"2209.03320","DOI":"10.1109/ICCV51070.2023.01438","CorpusId":252111028},"title":"What does a platypus look like? Generating customized prompts for zero-shot image classification"},{"paperId":"8c870bef01a4fbb20f60722ffc2f6bee3870b18b","externalIds":{"DBLP":"journals/corr/abs-2209-03143","ArXiv":"2209.03143","DOI":"10.1109/TASLP.2023.3288409","CorpusId":252111134},"title":"AudioLM: A Language Modeling Approach to Audio Generation"},{"paperId":"0f3873c4b60074bcdd8880d34ccda61d778df2c7","externalIds":{"DBLP":"journals/corr/abs-2208-08225","ACL":"2023.tacl-1.3","ArXiv":"2208.08225","DOI":"10.1162/tacl_a_00532","CorpusId":251622330},"title":"On the Role of Negative Precedent in Legal Outcome Prediction"},{"paperId":"e61c6213bd7e4d3ca3156723c2146294ea1b4414","externalIds":{"DBLP":"conf/icse/LiWLWCWG23","ArXiv":"2208.08289","DOI":"10.1109/ICSE48619.2023.00110","CorpusId":251623193},"title":"CCTEST: Testing and Repairing Code Completion Systems"},{"paperId":"916be31cbf847faa65cad0549e153f0c25b9f424","externalIds":{"ArXiv":"2208.03299","DBLP":"journals/jmlr/IzacardLLHPSDJRG23","CorpusId":251371732},"title":"Few-shot Learning with Retrieval Augmented Language Models"},{"paperId":"a01acd2acfdee967f3ed3753ec260a132cc8008d","externalIds":{"DBLP":"journals/corr/abs-2208-02070","ArXiv":"2208.02070","DOI":"10.48550/arXiv.2208.02070","CorpusId":251280259},"title":"Efficient Fine-Tuning of Compressed Language Models with Learners"},{"paperId":"dcb31b98ec58f3fff9f94f148e2952595f017fd9","externalIds":{"PubMedCentral":"9329459","DOI":"10.1038/s41467-022-32007-7","CorpusId":247439606,"PubMed":"35896542"},"title":"ProtGPT2 is a deep unsupervised language model for protein design"},{"paperId":"e9fc39f56abbc6b8aed1e05496d985e70345a95a","externalIds":{"DBLP":"conf/issta/ZengTZLZZ22","DOI":"10.1145/3533767.3534390","CorpusId":250109930},"title":"An extensive study on pre-trained models for program understanding and generation"},{"paperId":"d697b440dd0e65a05fe027e4c0ea85f62dcba033","externalIds":{"DBLP":"journals/patterns/LievinHMW24","ArXiv":"2207.08143","PubMedCentral":"10935498","DOI":"10.1016/j.patter.2024.100943","CorpusId":250627547,"PubMed":"38487804"},"title":"Can large language models reason about medical questions?"},{"paperId":"12d6df963b91829fddef3d2242f93c0156c379f8","externalIds":{"ArXiv":"2207.05875","DBLP":"journals/corr/abs-2207-05875","DOI":"10.48550/arXiv.2207.05875","CorpusId":250491945},"title":"A Novel DeBERTa-based Model for Financial Question Answering Task"},{"paperId":"b17cc18e4130505b939f7d527082eb6be2a7fd5b","externalIds":{"DBLP":"journals/corr/abs-2207-00747","ArXiv":"2207.00747","DOI":"10.48550/arXiv.2207.00747","CorpusId":250264890},"title":"Rationale-Augmented Ensembles in Language Models"},{"paperId":"f0631f7928b99ee51f8164acd04889219b2bcdbb","externalIds":{"DBLP":"conf/sigsoft/Zhang0S022","ArXiv":"2206.14390","DOI":"10.1145/3540250.3549094","CorpusId":250113729},"title":"Diet code is healthy: simplifying programs for pre-trained models of code"},{"paperId":"dac3a172b504f4e33c029655e9befb3386e5f63a","externalIds":{"DBLP":"journals/corr/abs-2206-07682","ArXiv":"2206.07682","DOI":"10.48550/arXiv.2206.07682","CorpusId":249674500},"title":"Emergent Abilities of Large Language Models"},{"paperId":"1d650f1afd45c59ff907396fe8b678595dcb85ea","externalIds":{"DBLP":"conf/icml/MitchellLBMF22","ArXiv":"2206.06520","CorpusId":249642147},"title":"Memory-Based Model Editing at Scale"},{"paperId":"960d40497717ad22a7ebb84db238fa2415fc89cc","externalIds":{"DBLP":"journals/corr/abs-2206-06522","ArXiv":"2206.06522","DOI":"10.48550/arXiv.2206.06522","CorpusId":249642544},"title":"LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning"},{"paperId":"0d08ffccc982781e310bb184397bbe64b9aef157","externalIds":{"DBLP":"journals/corr/abs-2206-11861","ArXiv":"2206.11861","DOI":"10.1145/3501385.3543957","CorpusId":249954011},"title":"Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models"},{"paperId":"07759a84f27e43cfa5bc8d579f8227c96e6ae1dc","externalIds":{"ArXiv":"2205.12548","DBLP":"journals/corr/abs-2205-12548","ACL":"2022.emnlp-main.222","DOI":"10.48550/arXiv.2205.12548","CorpusId":249062787},"title":"RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning"},{"paperId":"686d9ee744fa013cc21cdd86acd864c936e9e456","externalIds":{"DBLP":"conf/emnlp/AgrawalHLKS22","ArXiv":"2205.12689","ACL":"2022.emnlp-main.130","DOI":"10.18653/v1/2022.emnlp-main.130","CorpusId":249062918},"title":"Large language models are few-shot clinical information extractors"},{"paperId":"d304d0bdfa81fd10b187aa0e4f41d410eb19d6e3","externalIds":{"ACL":"2022.emnlp-main.410","ArXiv":"2205.12393","DBLP":"conf/emnlp/ScialomCM22","DOI":"10.18653/v1/2022.emnlp-main.410","CorpusId":252815378},"title":"Fine-tuned Language Models are Continual Learners"},{"paperId":"55a250868627de2d202d06e7cb3f6cbcd3a66f88","externalIds":{"DBLP":"conf/emnlp/AsaiSPH22","ACL":"2022.emnlp-main.446","ArXiv":"2205.11961","DOI":"10.18653/v1/2022.emnlp-main.446","CorpusId":254125751},"title":"ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"5bdb78fb79e54679a8bb45b05f77a8bf5989cfdf","externalIds":{"DBLP":"conf/emnlp/BhardwajSHP22","ACL":"2022.emnlp-main.455","ArXiv":"2205.11024","DOI":"10.48550/arXiv.2205.11024","CorpusId":248986718},"title":"Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding"},{"paperId":"5437e8adab596d7294124c0e798708e050e25321","externalIds":{"ArXiv":"2205.10625","DBLP":"conf/iclr/ZhouSHWS0SCBLC23","DOI":"10.48550/arXiv.2205.10625","CorpusId":248986239},"title":"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"},{"paperId":"29c4e190bfc8fc328b1fb93322716600acfc68a6","externalIds":{"DBLP":"journals/corr/abs-2205-07540","ArXiv":"2205.07540","DOI":"10.48550/arXiv.2205.07540","CorpusId":248811624},"title":"The AI Teacher Test: Measuring the Pedagogical Ability of Blender and GPT-3 in Educational Dialogues"},{"paperId":"716f9d0f6e96f437e127de90c87f7b2f7a6c8f12","externalIds":{"DBLP":"journals/corr/abs-2205-07381","ArXiv":"2205.07381","DOI":"10.48550/arXiv.2205.07381","CorpusId":248811193},"title":"SeqZero: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models"},{"paperId":"7cdaa08890895e1ad92afb5fad429690ad7b1dac","externalIds":{"DBLP":"conf/nips/LiuTMMHBR22","ArXiv":"2205.05638","DOI":"10.48550/arXiv.2205.05638","CorpusId":248693283},"title":"Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning"},{"paperId":"09797949fc70fbad8f3fed4f6cf4a91a9c709652","externalIds":{"DOI":"10.1136/bjophthalmol-2022-321141","CorpusId":248553336,"PubMed":"35523534"},"title":"New meaning for NLP: the trials and tribulations of natural language processing with GPT-3 in ophthalmology"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","externalIds":{"DBLP":"journals/corr/abs-2204-14198","ArXiv":"2204.14198","CorpusId":248476411},"title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"3b8b2d43e38eb4d48d97b14a8f981e96a6c60df0","externalIds":{"ArXiv":"2204.10019","DBLP":"journals/corr/abs-2204-10019","DOI":"10.48550/arXiv.2204.10019","CorpusId":248299683},"title":"Standing on the Shoulders of Giant Frozen Language Models"},{"paperId":"bb7e46f316d319f9819c3554c99995ef8361ae9c","externalIds":{"ArXiv":"2204.08941","DBLP":"journals/corr/abs-2204-08941","DOI":"10.48550/arXiv.2204.08941","CorpusId":248240093},"title":"CodexDB: Generating Code for Processing SQL Queries using GPT-3 Codex"},{"paperId":"a7b92f9c62cdf35c37d9ccdb20e43807eb86900a","externalIds":{"ACL":"2022.naacl-main.403","DBLP":"journals/corr/abs-2204-04497","ArXiv":"2204.04497","DOI":"10.48550/arXiv.2204.04497","CorpusId":248084930},"title":"IDPG: An Instance-Dependent Prompt Generation Method"},{"paperId":"456a70485aafc12dfed4fb7354668d72aae9b658","externalIds":{"ArXiv":"2204.02685","DBLP":"conf/securecomm/AghaeiNSA22","DOI":"10.1007/978-3-031-25538-0_3","CorpusId":253080552},"title":"SecureBERT: A Domain-Specific Language Model for Cybersecurity"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"8666f9f379389a5dff31e72fb0f992a37763ba41","externalIds":{"ArXiv":"2203.11147","DBLP":"journals/corr/abs-2203-11147","DOI":"10.48550/arXiv.2203.11147","CorpusId":247594830},"title":"Teaching language models to support answers with verified quotes"},{"paperId":"cf934ddd3c852ba9c67cdfd21bf41e7723fc6d9e","externalIds":{"ArXiv":"2203.07281","ACL":"2023.eacl-main.277","DBLP":"conf/eacl/PrasadHZB23","DOI":"10.48550/arXiv.2203.07281","CorpusId":247447170},"title":"GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models"},{"paperId":"8c62277dada489904a63de4dd87336c27c68fb5e","externalIds":{"DBLP":"journals/corr/abs-2203-06904","ArXiv":"2203.06904","DOI":"10.48550/arXiv.2203.06904","CorpusId":247446969},"title":"Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"0d56e3d69c9b3112d77187f96fabcfbdf5303971","externalIds":{"DBLP":"journals/corr/abs-2202-13914","ArXiv":"2202.13914","CorpusId":247158312},"title":"Combining Modular Skills in Multitask Learning"},{"paperId":"f4df78183261538e718066331898ee5cad7cad05","externalIds":{"DBLP":"journals/corr/abs-2202-12837","ArXiv":"2202.12837","ACL":"2022.emnlp-main.759","DOI":"10.18653/v1/2022.emnlp-main.759","CorpusId":247155069},"title":"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"},{"paperId":"759b5f58e58a76f79a7d845acd3169dc899d0ac2","externalIds":{"DBLP":"journals/corr/abs-2202-06687","ArXiv":"2202.06687","DOI":"10.1109/TNNLS.2023.3327962","CorpusId":246823759,"PubMed":"37943650"},"title":"Domain Adaptation via Prompt Learning"},{"paperId":"996445d847f06e99b0bd259345408a0cf1bce87e","externalIds":{"DBLP":"conf/nips/MengBAB22","ArXiv":"2202.05262","CorpusId":255825985},"title":"Locating and Editing Factual Associations in GPT"},{"paperId":"3def68bd0f856886d34272840a7f81588f2bc082","externalIds":{"DBLP":"journals/corr/abs-2202-03629","ArXiv":"2202.03629","DOI":"10.1145/3571730","CorpusId":246652372},"title":"Survey of Hallucination in Natural Language Generation"},{"paperId":"5cbe278b65a81602a864184bbca37de91448a5f5","externalIds":{"ArXiv":"2203.07814","DBLP":"journals/corr/abs-2203-07814","DOI":"10.1126/science.abq1158","CorpusId":246527904,"PubMed":"36480631"},"title":"Competition-level code generation with AlphaCode"},{"paperId":"332dc8b2ca9d49fad607c7282f3360bb2a9aacf3","externalIds":{"PubMedCentral":"9792464","DBLP":"journals/npjdm/0015CPSSPC0CFZM22","ArXiv":"2203.03540","DOI":"10.1038/s41746-022-00742-2","CorpusId":255175535,"PubMed":"36572766"},"title":"A large language model for electronic health records"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"6071b89c257d36490fd6f0877174adabad265d92","externalIds":{"DBLP":"conf/www/YeZDCCXCC22","ArXiv":"2201.11332","DOI":"10.1145/3485447.3511921","CorpusId":246294860},"title":"Ontology-enhanced Prompt-tuning for Few-shot Learning"},{"paperId":"4d1e6c441a0b6aa2b9ec500a5064dc307d797b0c","externalIds":{"DBLP":"journals/tacl/LiuYB22","ArXiv":"2201.09680","ACL":"2022.tacl-1.32","DOI":"10.1162/tacl_a_00476","CorpusId":246240585},"title":"Relational Memory-Augmented Language Models"},{"paperId":"62b4845be5a4b8ccc7ac3896d03c023193208e95","externalIds":{"ArXiv":"2201.07126","DBLP":"journals/corr/abs-2201-07126","DOI":"10.1145/3604613","CorpusId":246036341},"title":"Instance-Aware Prompt Learning for Language Understanding and Generation"},{"paperId":"002c58077a1f1b296468b117230a1199e91f35c2","externalIds":{"ArXiv":"2201.03514","DBLP":"conf/icml/SunSQHQ22","CorpusId":245836882},"title":"Black-Box Tuning for Language-Model-as-a-Service"},{"paperId":"2f3efe44083af91cef562c1a3451eee2f8601d22","externalIds":{"DBLP":"journals/corr/abs-2112-09332","ArXiv":"2112.09332","CorpusId":245329531},"title":"WebGPT: Browser-assisted question-answering with human feedback"},{"paperId":"6e8f8e2d2c73c91d1c9198eb802f1c64b860ea4a","externalIds":{"ArXiv":"2112.08696","ACL":"2022.naacl-main.396","DBLP":"journals/corr/abs-2112-08696","DOI":"10.18653/v1/2022.naacl-main.396","CorpusId":245218525},"title":"Few-Shot Semantic Parsing with Language Models Trained on Code"},{"paperId":"f04291ce23cd5af351a7d77722923c43c9027ffd","externalIds":{"DBLP":"conf/asru/Lopez-ZorrillaT21","DOI":"10.1109/ASRU51503.2021.9688296","CorpusId":246532066},"title":"Audio Embeddings Help to Learn Better Dialogue Policies"},{"paperId":"002c256d30d6be4b23d365a8de8ae0e67e4c9641","externalIds":{"DBLP":"journals/corr/abs-2112-04426","ArXiv":"2112.04426","CorpusId":244954723},"title":"Improving language models by retrieving from trillions of tokens"},{"paperId":"d095f9ffcb5905bf0858ad1769d3d90e2e8737e2","externalIds":{"DBLP":"conf/icse/JainVINPR022","ArXiv":"2112.02969","DOI":"10.1145/3510003.3510203","CorpusId":244908632},"title":"Jigsaw: Large Language Models meet Program Synthesis"},{"paperId":"a5731122200fbb8b37f048010a1e1ca4474aa606","externalIds":{"DBLP":"conf/sp/PearceTAKD23","ArXiv":"2112.02125","DOI":"10.1109/SP46215.2023.10179324","CorpusId":251563966},"title":"Examining Zero-Shot Vulnerability Repair with Large Language Models"},{"paperId":"46d846aa7df7b5c0cd4b129591b5754272701eae","externalIds":{"ArXiv":"2111.06719","ACL":"2022.naacl-main.290","DBLP":"conf/naacl/SuWQCLWWLLL0SZ22","DOI":"10.18653/v1/2022.naacl-main.290","CorpusId":248405974},"title":"On Transferability of Prompt Tuning for Natural Language Processing"},{"paperId":"c23d9d44e8bc68408cea9f305d1f24d915bc0d0d","externalIds":{"ArXiv":"2111.01243","DBLP":"journals/corr/abs-2111-01243","DOI":"10.1145/3605943","CorpusId":240420063},"title":"Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"},{"paperId":"007088458d6d508e8a1ffc4dce24750461453d61","externalIds":{"ArXiv":"2111.00667","DBLP":"journals/corr/abs-2111-00667","CorpusId":240354626},"title":"Unsupervised Domain Adaptation with Adapter"},{"paperId":"9286ac6e9b1aacd7d93496eb4615ae7678876d2a","externalIds":{"DBLP":"journals/corr/abs-2110-11309","ArXiv":"2110.11309","CorpusId":239050360},"title":"Fast Model Editing at Scale"},{"paperId":"c28b7dfe341f1e13a5a98efbce7946ef795cf9b8","externalIds":{"DBLP":"journals/corr/abs-2110-07904","ArXiv":"2110.07904","ACL":"2022.acl-long.346","DOI":"10.18653/v1/2022.acl-long.346","CorpusId":239009558},"title":"SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer"},{"paperId":"17dd3555fd1ccf1141cf984347fa1b3fd6b009ca","externalIds":{"ArXiv":"2110.08207","DBLP":"journals/corr/abs-2110-08207","CorpusId":239009562},"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization"},{"paperId":"fa133b4200729a57db96ae50aff8c4a5ff819f43","externalIds":{"DBLP":"journals/corr/abs-2110-07298","ArXiv":"2110.07298","CorpusId":238856821},"title":"LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5"},{"paperId":"ad471be93216ddbf8544721d50ee5aed14f07cae","externalIds":{"DBLP":"conf/acl/MaoMHAM0YK22","ACL":"2022.acl-long.433","ArXiv":"2110.07577","DOI":"10.18653/v1/2022.acl-long.433","CorpusId":238857301},"title":"UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning"},{"paperId":"f3a332ff1b73acda482e5d83696b2c701f487819","externalIds":{"DBLP":"journals/corr/abs-2110-07602","ArXiv":"2110.07602","CorpusId":238857040},"title":"P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"},{"paperId":"43a87867fe6bf4eb920f97fc753be4b727308923","externalIds":{"DBLP":"journals/corr/abs-2110-04366","ArXiv":"2110.04366","CorpusId":238583580},"title":"Towards a Unified View of Parameter-Efficient Transfer Learning"},{"paperId":"f45261b7b53043c316f45f613cb735907b93fb5a","externalIds":{"ArXiv":"2109.05687","ACL":"2021.emnlp-main.749","DBLP":"journals/corr/abs-2109-05687","DOI":"10.18653/v1/2021.emnlp-main.749","CorpusId":237491053},"title":"Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning"},{"paperId":"e553407be283d018e275f472d4d2fd709a6c9248","externalIds":{"DBLP":"conf/acl/GuHLH22","ArXiv":"2109.04332","ACL":"2022.acl-long.576","DOI":"10.18653/v1/2022.acl-long.576","CorpusId":237452236},"title":"PPT: Pre-trained Prompt Tuning for Few-shot Learning"},{"paperId":"ff0b2681d7b05e16c46dfb71d980cc2f605907cd","externalIds":{"DBLP":"journals/corr/abs-2109-01652","ArXiv":"2109.01652","CorpusId":237416585},"title":"Finetuned Language Models Are Zero-Shot Learners"},{"paperId":"c07506e0dec92b2cc7552b810c82d90de3c92aa9","externalIds":{"ArXiv":"2108.10168","DBLP":"journals/corr/abs-2108-10168","CorpusId":237267183},"title":"CGEMs: A Metric Model for Automatic Code Generation using GPT-3"},{"paperId":"6f0aba8102d63938ce0b48ec23ff5ddd8110f2e8","externalIds":{"ACL":"2022.acl-long.158","DBLP":"conf/acl/HuDWLWLWS22","ArXiv":"2108.02035","DOI":"10.18653/v1/2022.acl-long.158","CorpusId":236912915},"title":"Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification"},{"paperId":"28692beece311a90f5fa1ca2ec9d0c2ce293d069","externalIds":{"DBLP":"journals/csur/LiuYFJHN23","ArXiv":"2107.13586","DOI":"10.1145/3560815","CorpusId":236493269},"title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"},{"paperId":"de549c1592a62c129b8d49c8c0137aa6859b103f","externalIds":{"DBLP":"journals/corr/abs-2107-07566","ACL":"2022.acl-long.579","ArXiv":"2107.07566","DOI":"10.18653/v1/2022.acl-long.579","CorpusId":236034557},"title":"Internet-Augmented Dialogue Generation"},{"paperId":"acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269","externalIds":{"DBLP":"journals/corr/abs-2107-03374","ArXiv":"2107.03374","CorpusId":235755472},"title":"Evaluating Large Language Models Trained on Code"},{"paperId":"339b2b711fb5b228d097b03ebc3e62a521779235","externalIds":{"DBLP":"conf/acl/ZakenGR22","ACL":"2022.acl-short.1","ArXiv":"2106.10199","DOI":"10.18653/v1/2022.acl-short.1","CorpusId":231672601},"title":"BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models"},{"paperId":"df59d0098c1b2c1ee8995da802dd6b12d158c2b8","externalIds":{"DBLP":"journals/natmi/RossBCPMD22","ArXiv":"2106.09553","DOI":"10.1038/s42256-022-00580-7","CorpusId":254636625},"title":"Large-scale chemical language representations capture molecular structure and properties"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"6d4a9f1c41b078846901362ba0dce8295dd6a2a8","externalIds":{"ArXiv":"2106.05346","DBLP":"journals/corr/abs-2106-05346","CorpusId":235390519},"title":"End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering"},{"paperId":"656ed155c2d345c19d9bff4b50f2ae00db8407cc","externalIds":{"ArXiv":"2106.04647","DBLP":"conf/nips/MahabadiHR21","CorpusId":235356070},"title":"Compacter: Efficient Low-Rank Hypercomplex Adapter Layers"},{"paperId":"5c52e6a85cb3f68804bf0c875e88fa2f44160220","externalIds":{"DBLP":"conf/cvpr/YuCYKK21","DOI":"10.1109/CVPR46437.2021.01247","CorpusId":235703153},"title":"Transitional Adaptation of Pretrained Models for Visual Storytelling"},{"paperId":"2c871df72c52b58f05447fcb3afc838168d94505","externalIds":{"ArXiv":"2104.08696","DBLP":"journals/corr/abs-2104-08696","ACL":"2022.acl-long.581","DOI":"10.18653/v1/2022.acl-long.581","CorpusId":233296761},"title":"Knowledge Neurons in Pretrained Transformers"},{"paperId":"0adec918885dff698acf359988ed79a543157f80","externalIds":{"DBLP":"journals/corr/abs-2104-08786","ArXiv":"2104.08786","ACL":"2022.acl-long.556","DOI":"10.18653/v1/2022.acl-long.556","CorpusId":233296494},"title":"Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"},{"paperId":"ffdbd7f0b03b85747b001b4734d5ee31b5229aa4","externalIds":{"DBLP":"journals/corr/abs-2104-08691","ArXiv":"2104.08691","ACL":"2021.emnlp-main.243","DOI":"10.18653/v1/2021.emnlp-main.243","CorpusId":233296808},"title":"The Power of Scale for Parameter-Efficient Prompt Tuning"},{"paperId":"240b0caabb415578bdea4da7d0a32bdff2e8163f","externalIds":{"DBLP":"journals/corr/abs-2104-08164","ArXiv":"2104.08164","ACL":"2021.emnlp-main.522","DOI":"10.18653/v1/2021.emnlp-main.522","CorpusId":233289412},"title":"Editing Factual Knowledge in Language Models"},{"paperId":"1a2e90dff605dad7dbefeed121e6d295c7a77d62","externalIds":{"DBLP":"journals/corr/abs-2104-07650","ArXiv":"2104.07650","DOI":"10.1145/3485447.3511998","CorpusId":237295186},"title":"KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction"},{"paperId":"0c97903e7d85c05bcd2a7e26fc2a4a47998f5dde","externalIds":{"MAG":"3125358881","DOI":"10.3354/ESEP00195","CorpusId":233676730},"title":"Plagiarism in the age of massive Generative Pre-trained Transformers (GPT-3)"},{"paperId":"7e5008713c404445dd8786753526f1a45b93de12","externalIds":{"MAG":"3212496002","DOI":"10.5281/ZENODO.5297715","CorpusId":245758737},"title":"GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"},{"paperId":"e403faa971e2c750999a3d10bef8b01dd3e85f7b","externalIds":{"ArXiv":"2102.12206","DBLP":"journals/tacl/Ben-DavidOR22","ACL":"2022.tacl-1.24","DOI":"10.1162/tacl_a_00468","CorpusId":246062387},"title":"PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains"},{"paperId":"616e0ed02ca024a8c1d4b86167f7486ea92a13d9","externalIds":{"DBLP":"conf/cvpr/ChenGY0E22","ArXiv":"2102.10407","DOI":"10.1109/CVPR52688.2022.01750","CorpusId":235351128},"title":"VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning"},{"paperId":"1d5f5df837139d4ae8af23e3634295594c5b85db","externalIds":{"DBLP":"journals/corr/abs-2102-08597","ArXiv":"2102.08597","CorpusId":231942691},"title":"Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with 1/n Parameters"},{"paperId":"5a2e45ce35fb26ab70a61b424a49f8e5b4532a8e","externalIds":{"DBLP":"conf/acl/HambardzumyanKM20","ACL":"2021.acl-long.381","ArXiv":"2101.00121","DOI":"10.18653/v1/2021.acl-long.381","CorpusId":230437613},"title":"WARP: Word-level Adversarial ReProgramming"},{"paperId":"e54ffc76d805c48660bb0fd20019ca82ac94ba0d","externalIds":{"ArXiv":"2012.13255","DBLP":"conf/acl/AghajanyanGZ20","ACL":"2021.acl-long.568","DOI":"10.18653/v1/2021.acl-long.568","CorpusId":229371560},"title":"Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning"},{"paperId":"9db7ebe9e3a27118300a105531aa7e9309f993d9","externalIds":{"ArXiv":"2102.05757","DBLP":"journals/corr/abs-2102-05757","DOI":"10.1109/BigData50022.2020.9378201","CorpusId":231879790},"title":"Customizing Contextualized Language Models for Legal Document Reviews"},{"paperId":"f6245b3e6270e4dc2e279c4b728030523dffcff4","externalIds":{"ACL":"2020.findings-emnlp.261","DBLP":"journals/corr/abs-2010-02559","MAG":"3099950029","ArXiv":"2010.02559","DOI":"10.18653/v1/2020.findings-emnlp.261","CorpusId":222141043},"title":"LEGAL-BERT: “Preparing the Muppets for Court’”"},{"paperId":"184d1bd08401de386c5b49c2ee66ff00681ea1be","externalIds":{"MAG":"2996455562","DOI":"10.1201/9781315213125","CorpusId":214275746},"title":"Distributed Denial of Service Attacks"},{"paperId":"063f8b1ecf2394ca776ac61869734de9c1953808","externalIds":{"DBLP":"journals/corr/abs-2007-07779","MAG":"3042667808","ArXiv":"2007.07779","ACL":"2020.emnlp-demos.7","DOI":"10.18653/v1/2020.emnlp-demos.7","CorpusId":220525782},"title":"AdapterHub: A Framework for Adapting Transformers"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"5d4de0fa45aeddc31142e6a24666d06ed7923f1e","externalIds":{"PubMedCentral":"8137882","DBLP":"journals/corr/abs-2005-12833","MAG":"3030156796","ArXiv":"2005.12833","DOI":"10.1038/s41746-021-00455-y","CorpusId":218889776,"PubMed":"34017034"},"title":"Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction"},{"paperId":"659bf9ce7175e1ec266ff54359e2bd76e0b7ff31","externalIds":{"DBLP":"conf/nips/LewisPPPKGKLYR020","MAG":"3027879771","ArXiv":"2005.11401","CorpusId":218869575},"title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"},{"paperId":"98ef0db84e62aef969629264c9de1f4d0013f3b9","externalIds":{"ArXiv":"2005.00247","ACL":"2021.eacl-main.39","DBLP":"journals/corr/abs-2005-00247","MAG":"3023528699","DOI":"10.18653/v1/2021.eacl-main.39","CorpusId":218470208},"title":"AdapterFusion: Non-Destructive Task Composition for Transfer Learning"},{"paperId":"26299d5fdc5137291dc6a091573b3d18aba1d1c2","externalIds":{"ACL":"2020.emnlp-main.617","MAG":"3023911605","ArXiv":"2005.00052","DBLP":"conf/emnlp/PfeifferVGR20","DOI":"10.18653/v1/2020.emnlp-main.617","CorpusId":218470133},"title":"MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer"},{"paperId":"f2f3c83db919a2429c4fcad2d0a0ed4e5294354a","externalIds":{"MAG":"3104215796","ArXiv":"2004.12651","ACL":"2020.emnlp-main.634","DBLP":"conf/emnlp/ChenHCCLY20","DOI":"10.18653/v1/2020.emnlp-main.634","CorpusId":216553067},"title":"Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting"},{"paperId":"3bcb17559ce96eb20fa79af8194f4af0380d194a","externalIds":{"DBLP":"journals/corr/abs-2003-08271","MAG":"3088409176","ArXiv":"2003.08271","DOI":"10.1007/s11431-020-1647-3","CorpusId":212747830},"title":"Pre-trained models for natural language processing: A survey"},{"paperId":"e2bda1a9c0c5263b0812a9227460db6b710c9fac","externalIds":{"MAG":"3027496982","PubMedCentral":"7265654","DOI":"10.2196/19273","CorpusId":219259575,"PubMed":"32427106"},"title":"Tracking Social Media Discourse About the COVID-19 Pandemic: Development of a Public Coronavirus Twitter Data Set"},{"paperId":"3a0d4a245095ffee14fcef8f3c0e78bf02c66609","externalIds":{"ArXiv":"2003.01680","MAG":"3009655069","DBLP":"journals/corr/abs-2003-01680","CorpusId":211817915},"title":"Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation"},{"paperId":"80376bdec5f534be78ba82821f540590ebce5559","externalIds":{"DBLP":"journals/corr/abs-2002-08910","MAG":"3102659883","ACL":"2020.emnlp-main.437","ArXiv":"2002.08910","DOI":"10.18653/v1/2020.emnlp-main.437","CorpusId":211205183},"title":"How Much Knowledge Can You Pack into the Parameters of a Language Model?"},{"paperId":"4f03e69963b9649950ba29ae864a0de8c14f1f86","externalIds":{"DBLP":"conf/acl/WangTDWHJCJZ21","ArXiv":"2002.01808","MAG":"3005441132","ACL":"2021.findings-acl.121","DOI":"10.18653/v1/2021.findings-acl.121","CorpusId":211031933},"title":"K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters"},{"paperId":"e6c561d02500b2596a230b341a8eb8b921ca5bf2","externalIds":{"MAG":"3001279689","ArXiv":"2001.08361","DBLP":"journals/corr/abs-2001-08361","CorpusId":210861095},"title":"Scaling Laws for Neural Language Models"},{"paperId":"8ae9a17c87a4518b513e860683a0ef7824be994d","externalIds":{"MAG":"3002104146","ArXiv":"2001.07676","ACL":"2021.eacl-main.20","DBLP":"journals/corr/abs-2001-07676","DOI":"10.18653/v1/2021.eacl-main.20","CorpusId":210838924},"title":"Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference"},{"paperId":"ab70853cd5912c470f6ff95e95481980f0a2a41b","externalIds":{"MAG":"3035204084","DBLP":"conf/acl/JiangHCLGZ20","ArXiv":"1911.03437","ACL":"2020.acl-main.197","DOI":"10.18653/v1/2020.acl-main.197","CorpusId":207847598},"title":"SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization"},{"paperId":"7be8c119dbe065c52125ee7716601751f3116844","externalIds":{"MAG":"2988841832","ArXiv":"1911.00172","DBLP":"journals/corr/abs-1911-00172","CorpusId":207870430},"title":"Generalization through Memorization: Nearest Neighbor Language Models"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"48530f3d6425f2f150f07ccdd61ba951951a0a7d","externalIds":{"ACL":"D19-1165","MAG":"2970925270","DBLP":"journals/corr/abs-1909-08478","ArXiv":"1909.08478","DOI":"10.18653/v1/D19-1165","CorpusId":202660912},"title":"Simple, Scalable Adaptation for Neural Machine Translation"},{"paperId":"7a15950dc71079285a4eaf195de5aadd87c41b40","externalIds":{"MAG":"2973379954","DBLP":"journals/corr/abs-1909-08593","ArXiv":"1909.08593","CorpusId":202660943},"title":"Fine-Tuning Language Models from Human Preferences"},{"paperId":"7102bb3fe73bd057ff161d9db5214a267c1ef312","externalIds":{"MAG":"2970636124","ArXiv":"1908.10063","DBLP":"journals/corr/abs-1908-10063","CorpusId":201646244},"title":"FinBERT: Financial Sentiment Analysis with Pre-trained Language Models"},{"paperId":"52c90c5c0677d6f7e91a3b6edb8ebab8e1c0ec45","externalIds":{"MAG":"2952337279","DBLP":"conf/scc2/QuahC19","DOI":"10.1007/978-3-030-23554-3_8","CorpusId":195064929},"title":"Chatbot Assisted Marketing in Financial Service Industry"},{"paperId":"18a93dc1558bf9d7534d0b416633cebaf75c1145","externalIds":{"DBLP":"journals/pnas/RivesMSGLLGOZMF21","PubMedCentral":"8053943","MAG":"2943495267","DOI":"10.1101/622803","CorpusId":155162335,"PubMed":"33876751"},"title":"Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences"},{"paperId":"29ddc1f43f28af7c846515e32cc167bc66886d0c","externalIds":{"DBLP":"journals/corr/abs-1902-00751","ArXiv":"1902.00751","MAG":"2964303773","CorpusId":59599816},"title":"Parameter-Efficient Transfer Learning for NLP"},{"paperId":"dd8785b26e9efe8bf23a96850e53b4f913b8ffa5","externalIds":{"DBLP":"journals/jocss/SoumaVA19","MAG":"2912723748","DOI":"10.1007/s42001-019-00035-x","CorpusId":86577387},"title":"Enhanced news sentiment analysis using deep learning methods"},{"paperId":"42ec3db12a2e4628885451b13035c2e975220a25","externalIds":{"ArXiv":"1811.03962","MAG":"2964098911","DBLP":"journals/corr/abs-1811-03962","CorpusId":53250107},"title":"A Convergence Theory for Deep Learning via Over-Parameterization"},{"paperId":"1e077413b25c4d34945cc2707e17e46ed4fe784a","externalIds":{"ACL":"P18-1031","MAG":"2952772027","DBLP":"conf/acl/RuderH18","DOI":"10.18653/v1/P18-1031","CorpusId":40100965},"title":"Universal Language Model Fine-tuning for Text Classification"},{"paperId":"f4dd755a7f6238bf7f1b8671e57e098f248402e4","externalIds":{"MAG":"2766718178","DBLP":"journals/air/XingCW18","DOI":"10.1007/s10462-017-9588-9","CorpusId":207079655},"title":"Natural language based financial forecasting: a survey"},{"paperId":"bb48e44c8ed7160b8ffaa84fcad13cbc6a22e556","externalIds":{"MAG":"2798334860","DOI":"10.1109/ICACCAF.2017.8344724","CorpusId":5040480},"title":"Man-in-the-middle attack in wireless and computer networking — A review"},{"paperId":"c6c171d2a9be192d60af7b434e4ba2fcbbad7f48","externalIds":{"DBLP":"conf/emnlp/FengZZWA17","MAG":"2952023692","ArXiv":"1708.02005","ACL":"D17-1146","DOI":"10.18653/v1/D17-1146","CorpusId":22002351},"title":"Memory-augmented Neural Machine Translation"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd","externalIds":{"MAG":"2626804490","ArXiv":"1706.03741","DBLP":"conf/nips/ChristianoLBMLA17","CorpusId":4787508},"title":"Deep Reinforcement Learning from Human Preferences"},{"paperId":"d89ee98810039d2061ed42ee8026da49c503d16b","externalIds":{"ArXiv":"1705.08045","DBLP":"conf/nips/RebuffiBV17","MAG":"2616957565","CorpusId":215826266},"title":"Learning multiple visual domains with residual adapters"},{"paperId":"59a922212153d3407e658109f36c11a34ee7d283","externalIds":{"MAG":"2963559848","DBLP":"conf/nips/ShinLKK17","ArXiv":"1705.08690","CorpusId":1888776},"title":"Continual Learning with Deep Generative Replay"},{"paperId":"2d7782c225e0fc123d6e227f2cb253e58279ac73","externalIds":{"DBLP":"conf/iclr/GraveJU17","MAG":"2571859396","ArXiv":"1612.04426","CorpusId":8693672},"title":"Improving Neural Language Models with a Continuous Cache"},{"paperId":"efbd381493bb9636f489b965a2034d529cd56bcd","externalIds":{"ArXiv":"1609.07843","MAG":"2525332836","DBLP":"journals/corr/MerityXBS16","CorpusId":16299141},"title":"Pointer Sentinel Mixture Models"},{"paperId":"8da4e6fcf185fbba07fa8f6d5f83568c7cee722e","externalIds":{"MAG":"2292869588","DBLP":"journals/isafm/FisherGH16","DOI":"10.1002/isaf.1386","CorpusId":205966938},"title":"Natural Language Processing in Accounting, Auditing and Finance: A Synthesis of the Literature with a Roadmap for Future Research"},{"paperId":"de5e7320729f5d3cbb6709eb6329ec41ace8c95d","externalIds":{"ArXiv":"1606.08415","MAG":"2899663614","CorpusId":125617073},"title":"Gaussian Error Linear Units (GELUs)"},{"paperId":"4361e64f2d12d63476fdc88faf72a0f70d9a2ffb","externalIds":{"DBLP":"journals/corr/HendrycksG16","MAG":"2462831000","CorpusId":2359786},"title":"Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units"},{"paperId":"0ebb041524a751276219a396c634da15742a6e6a","externalIds":{"MAG":"2065890363","DBLP":"conf/ccs/BilgeD12","DOI":"10.1145/2382196.2382284","CorpusId":3417875},"title":"Before we knew it: an empirical study of zero-day attacks in the real world"},{"paperId":"9c69ec5f4258ca956e6dbb4dce98d8b3a995ce1b","externalIds":{"ACL":"2024.conll-1.3","DOI":"10.18653/v1/2024.conll-1.3","CorpusId":273901350},"title":"Multi-Cultural Norm Base: Frame-based Norm Discovery in Multi-Cultural Settings"},{"paperId":"dfeaaf97e347b3317eba326ec8161fc6650fedc0","externalIds":{"DBLP":"journals/corr/abs-2402-11035","DOI":"10.48550/arXiv.2402.11035","CorpusId":273799974},"title":"Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?"},{"paperId":"0774a8f9baeb78666f6888251a8939b7db8149f5","externalIds":{"DOI":"10.2139/ssrn.4386113","CorpusId":257504301},"title":"Chatgpt for Designing Course Outlines: A Boon or Bane to Modern Technology"},{"paperId":"a5880a05011362ce5719c05ef3d0d8789321f1a5","externalIds":{"DBLP":"conf/cogsci/MarjiehSRJ023","DOI":"10.48550/arXiv.2302.01308","CorpusId":256503519},"title":"What Language Reveals about Perception: Distilling Psychophysical Knowledge from Large Language Models"},{"paperId":"d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43","externalIds":{"ArXiv":"2303.17580","DBLP":"journals/corr/abs-2303-17580","DOI":"10.48550/arXiv.2303.17580","CorpusId":257833781},"title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"},{"paperId":"7ca954844bc1dd405bc43445b1c990e42d865095","externalIds":{"DBLP":"journals/corr/abs-2303-17760","DOI":"10.48550/arXiv.2303.17760","CorpusId":257900712},"title":"CAMEL: Communicative Agents for \"Mind\" Exploration of Large Scale Language Model Society"},{"paperId":"7d5b03befa4b276e581e74d300cf0f18a7253890","externalIds":{"DBLP":"journals/corr/abs-2304-00740","DOI":"10.48550/arXiv.2304.00740","CorpusId":257913329},"title":"Measuring and Manipulating Knowledge Representations in Language Models"},{"paperId":"a99df4187e94a842504759eaa61ce864a31f30a3","externalIds":{"DOI":"10.2139/ssrn.4338981","CorpusId":256347474},"title":"A Computer Wrote this Paper: What ChatGPT Means for Education, Research, and Writing"},{"paperId":"372fe9428dff788274081b00634d484db0c2fda4","externalIds":{"DOI":"10.2139/ssrn.4335905","CorpusId":256409866},"title":"ChatGPT Goes to Law School"},{"paperId":"6ea22dc509377c076abca0d668ff6404661f4bce","externalIds":{"DOI":"10.2139/ssrn.4342686","CorpusId":256479722},"title":"ChatGPT & Generative AI Systems as Quasi-Expert Legal Advice Lawyers - Case Study Considering Potential Appeal Against Conviction of Tom Hayes"},{"paperId":"51a7f466057e94b81f8d1b3e15c86586f77f4f2b","externalIds":{"DOI":"10.2139/ssrn.4324310","CorpusId":256493437},"title":"Is ChatGPT a Good Tool for T&CM Students in Studying Pharmacology?"},{"paperId":"f491eccf9353148dcc37f238fe94a4d2139cabe9","externalIds":{"DOI":"10.2139/ssrn.4366749","CorpusId":257737763},"title":"How ChatGPT and Generative AI Systems will Revolutionize Legal Services and the Legal Profession"},{"paperId":"0995fc83865e03a592c21bd5f21ef15f9b3012d1","externalIds":{"DOI":"10.2139/ssrn.4339839","CorpusId":256571867},"title":"ChatGPT by OpenAI: The End of Litigation Lawyers?"},{"paperId":"09d00a772c16ff4f381c72b39e1dcbab42702e58","externalIds":{"DOI":"10.2139/ssrn.4384861","CorpusId":257488812},"title":"Gpt as a Financial Advisor"},{"paperId":"ca8cafc961fafe7d0720941f71c860b62c4c2dca","externalIds":{"DBLP":"conf/emnlp/LingZZLCOOMCZ23","DOI":"10.18653/v1/2023.findings-emnlp.540","CorpusId":266177143},"title":"Open-ended Commonsense Reasoning with Unrestricted Answer Candidates"},{"paperId":"6c5a1079d9705c0ee022cef77207daa20ce2cde5","externalIds":{"DBLP":"journals/corr/abs-2304-01852","DOI":"10.48550/arXiv.2304.01852","CorpusId":263893278},"title":"Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models"},{"paperId":"f96addec50f6dfe192e298a3ecd5e5932d4ea1bc","externalIds":{"DBLP":"journals/corr/abs-2306-04802","DOI":"10.48550/arXiv.2306.04802","CorpusId":271244158},"title":"A Survey on Knowledge Graphs for Healthcare: Resources, Applications, and Promises"},{"paperId":"2cc134293669b20dce3d55a67d08fea665745e7b","externalIds":{"DBLP":"conf/eacl/PontiSBR23","ACL":"2023.eacl-main.49","DOI":"10.18653/v1/2023.eacl-main.49","CorpusId":258378176},"title":"Combining Parameter-efficient Modules for Task-level Generalisation"},{"paperId":"9201e46b2fe90c636d57b076020051953456473c","externalIds":{"DBLP":"journals/corr/abs-2211-03831","DOI":"10.48550/arXiv.2211.03831","CorpusId":253397727},"title":"Multi-Head Adapter Routing for Data-Efficient Fine-Tuning"},{"paperId":"72123a86eae2cb5c4eae8650f43524039d48875d","externalIds":{"DBLP":"journals/corr/abs-2212-00193","DOI":"10.48550/arXiv.2212.00193","CorpusId":254125395},"title":"Distilling Multi-Step Reasoning Capabilities of Large Language Models into Smaller Models via Semantic Decompositions"},{"paperId":"7e2530784eeae241e997627795819cf42ba8562f","externalIds":{"DBLP":"journals/corr/abs-2205-12410","DOI":"10.48550/arXiv.2205.12410","CorpusId":249063002},"title":"AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large Language Models"},{"paperId":"731fd88b97990f1aab4589ed75e9071fb27451d3","externalIds":{"DBLP":"conf/circle/PrasadBD22","CorpusId":251258139},"title":"Effect of Hierarchical Domain-specific Language Models and Attention in the Classification of Decisions for Legal Cases"},{"paperId":"ad87749fe414c307e1516db287a442c1ea75dc91","externalIds":{"ACL":"2022.coling-1.169","DBLP":"conf/coling/LiMFWWZL22","CorpusId":252819354},"title":"KiPT: Knowledge-injected Prompt Tuning for Event Detection"},{"paperId":"d361b7aafcb9ff71304aba8eb415a13085d38d0b","externalIds":{"DBLP":"conf/emnlp/JiaZ22","ACL":"2022.emnlp-main.690","DOI":"10.18653/v1/2022.emnlp-main.690","CorpusId":256461303},"title":"Prompt-based Distribution Alignment for Domain Generalization in Text Classification"},{"paperId":"f85cd06395716f4debbfabf1eb503decebd3ff02","externalIds":{"DOI":"10.2139/ssrn.4312358","CorpusId":255624599},"title":"Exploring the Role of Artificial Intelligence in Enhancing Academic Performance: A Case Study of ChatGPT"},{"paperId":"6fd85727e91ded0f66c9862b1677b62f2b2a4375","externalIds":{"DOI":"10.2139/ssrn.4312418","CorpusId":255713254},"title":"ChatGPT User Experience: Implications for Education"},{"paperId":"728af2eadeb65eba906c6fc7240438fc5e5d7828","externalIds":{"DOI":"10.3934/dsfe.2022011","CorpusId":251268144},"title":"Text-Based Chatbot in Financial Sector: A Systematic Literature Review"},{"paperId":"2083581337c9280ae59ea53beecb24d59cf6c206","externalIds":{"CorpusId":247448035},"title":"GatorTron : A Large Language Model for Clinical Natural Language Processing"},{"paperId":"e6a6b66eeb506dc326e3c3f7f49a1f260469c281","externalIds":{"DBLP":"journals/corr/abs-2201-12723","CorpusId":246431252},"title":"VC-GPT: Visual Conditioned GPT for End-to-End Generative Vision-and-Language Pre-training"},{"paperId":"9cd1ded98b669fb35c57d0d3285ff08355e34ecd","externalIds":{"DBLP":"conf/dbsec/AkbarHHSKT22","DOI":"10.1007/978-3-031-10684-2_7","CorpusId":250534075},"title":"Knowledge Mining in Cybersecurity: From Attack to Defense"},{"paperId":"f1a4c9e98f3a59b1fc8a6f910825b93a29692dc4","externalIds":{"DBLP":"conf/ectel/MooreNBDS22","DOI":"10.1007/978-3-031-16290-9_18","CorpusId":252112137},"title":"Assessing the Quality of Student-Generated Short Answer Questions Using GPT-3"},{"paperId":"fe0825f9ddb1cccb545f4249da55b6b55e577bbd","externalIds":{"DBLP":"conf/iclr/SanhWRBSACSRDBX22","CorpusId":276421109},"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization"},{"paperId":"55adc6c9ad132d814e8c6e81b4e229fc9e6bcb82","externalIds":{"DBLP":"journals/corr/abs-2211-00635","DOI":"10.48550/arXiv.2211.00635","CorpusId":263883564},"title":"Preserving In-Context Learning ability in Large Language Model Fine-tuning"},{"paperId":"ec936b808e0fab9281c050ad4010cddec92c8cbe","externalIds":{"ACL":"2022.acl-short.8","DBLP":"conf/acl/LiuJFTDY022","DOI":"10.18653/v1/2022.acl-short.8","CorpusId":248780177},"title":"P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"},{"paperId":"53d8b356551a2361020a948f64454a6d599af69f","externalIds":{"DBLP":"conf/acl/LiL20","ACL":"2021.acl-long.353","ArXiv":"2101.00190","DOI":"10.18653/v1/2021.acl-long.353","CorpusId":230433941},"title":"Prefix-Tuning: Optimizing Continuous Prompts for Generation"},{"paperId":"32ead456a7316d26893861169f57ddaeb512dabb","externalIds":{"CorpusId":243844336},"title":"CTR-BERT: Cost-effective knowledge distillation for billion-parameter teacher models"},{"paperId":"5ff9032d0f7f246d01ae7b2c231ab03469a7344a","externalIds":{"DBLP":"journals/corr/abs-2112-02125","CorpusId":244909393},"title":"Can OpenAI Codex and Other Large Language Models Help Us Fix Security Bugs?"},{"paperId":"37be9a34e6a75844c228b049a6dc54a5acd3c1c9","externalIds":{"MAG":"3028643109","DBLP":"journals/access/ZhaoZYLSZ20","DOI":"10.1109/ACCESS.2020.2997969","CorpusId":219547145},"title":"The Study on the Text Classification for Financial News Based on Partial Information"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":"44ee91d83d3b804780d8ec43ee5af0e41d3b0787","externalIds":{"MAG":"2787423662","DBLP":"conf/acl-alta/AlvaradoVB15","ACL":"U15-1010","CorpusId":3003995},"title":"Domain Adaption of Named Entity Recognition to Support Credit Risk Assessment"},{"paperId":"57abadf88a1470daebe9e54a02b845bfb54866c3","externalIds":{"MAG":"2911209336","CorpusId":17231714},"title":"News Analytics and Sentiment Analysis to Predict Stock Price Trends"},{"paperId":"8002e92349c8ff84f39b99dd38dc96ff993e9e2c","externalIds":{"MAG":"2766986850","CorpusId":149390243},"title":"N. D. I."},{"paperId":"43b6ae6aacc219bd9d6218d3f30698b740dd6096","externalIds":{"CorpusId":269242766},"title":"Opportunities and Challenges of ChatGPT in Academia: A Conceptual Analysis"}]}