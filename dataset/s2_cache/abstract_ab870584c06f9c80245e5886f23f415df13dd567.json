{"abstract":"Due to the covariate shift, deep neural networks performance always degrades when applied to novel domains. In order to mitigate this problem, domain adaptation techniques require samples from target data during the feature extraction training, which is not always applicable in real-world scenarios. Batch Normalization is a known component of computer vision models, aiming at reducing the training-time covariate shift. However, facing distribution shift results in an internal state mismatch inside the Batch-Norm layers during the inference time. In favor of alleviating the induced mismatch, this paper proposes a sourcefree, lightweight and straightforward approach by introducing the “Visual Domain Bridge” concept reducing the BatchNorm’s internal mismatch in the cross-domain settings. Compared to the other BatchNorm-based source-free domain adaptation techniques such as AdaBN and Prediction-BN, our method formed a new state-of-the-art cross-domain few-shot fine-tuning method neglecting extra augmentations; while improving the performance in near-domain settings too. The proposed method can integrate with other domain adaptation methods and enhance their performance requiring just a few lines of modification in the BatchNorm’s implementation. Implementations are available in https://github.com/MosyMosy/VDB"}