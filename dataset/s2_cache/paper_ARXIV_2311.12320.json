{"paperId":"451539c0d0f5f5785ff58d09ca5e67a5f129f9de","externalIds":{"ArXiv":"2311.12320","DBLP":"journals/corr/abs-2311-12320","DOI":"10.1109/WACVW60836.2024.00106","CorpusId":265308931},"title":"A Survey on Multimodal Large Language Models for Autonomous Driving","openAccessPdf":{"url":"https://arxiv.org/pdf/2311.12320","status":"GREEN","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2311.12320, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2242949023","name":"Can Cui"},{"authorId":"2109267955","name":"Yunsheng Ma"},{"authorId":"2258143637","name":"Xu Cao"},{"authorId":"122298411","name":"Wenqian Ye"},{"authorId":"2145500237","name":"Yang Zhou"},{"authorId":"2243335661","name":"Kaizhao Liang"},{"authorId":"2267536793","name":"Jintai Chen"},{"authorId":"2053819036","name":"Juanwu Lu"},{"authorId":"2267506629","name":"Zichong Yang"},{"authorId":"2243338841","name":"Kuei-Da Liao"},{"authorId":"2243338432","name":"Tianren Gao"},{"authorId":"2053811911","name":"Erlong Li"},{"authorId":"2267492045","name":"Kun Tang"},{"authorId":"2267998934","name":"Zhipeng Cao"},{"authorId":"1934822874","name":"Tongxi Zhou"},{"authorId":"2238913896","name":"Ao Liu"},{"authorId":"2267624378","name":"Xinrui Yan"},{"authorId":"47330207","name":"Shuqi Mei"},{"authorId":"2267758440","name":"Jianguo Cao"},{"authorId":"2243360882","name":"Ziran Wang"},{"authorId":"2197781066","name":"Chao Zheng"}],"abstract":"With the emergence of Large Language Models (LLMs) and Vision Foundation Models (VFMs), multimodal AI systems benefiting from large models have the potential to equally perceive the real world, make decisions, and control tools as humans. In recent months, LLMs have shown widespread attention in autonomous driving and map systems. Despite its immense potential, there is still a lack of a comprehensive understanding of key challenges, opportunities, and future endeavors to apply in LLM driving systems. In this paper, we present a systematic investigation in this field. We first introduce the background of Multimodal Large Language Models (MLLMs), the multimodal models development using LLMs, and the history of autonomous driving. Then, we overview existing MLLM tools for driving, transportation, and map systems together with existing datasets and benchmarks. Moreover, we summarized the works in The 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD), which is the first workshop of its kind regarding LLMs in autonomous driving. To further promote the development of this field, we also discuss several important problems regarding using MLLMs in autonomous driving systems that need to be solved by both academia and industry."}