{"paperId":"f2665e9d29836166beef6afccd9378030b352a2c","externalIds":{"ArXiv":"2310.14414","DOI":"10.1109/tiv.2024.3402136","CorpusId":269865211},"title":"Vision Language Models in Autonomous Driving: A Survey and Outlook","openAccessPdf":{"url":"","status":"CLOSED","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2310.14414, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2261365902","name":"Xingcheng Zhou"},{"authorId":"2258947403","name":"Mingyu Liu"},{"authorId":"2424538","name":"Ekim Yurtsever"},{"authorId":"146317932","name":"B. L. Å½agar"},{"authorId":"2264662960","name":"Walter Zimmer"},{"authorId":"2264417836","name":"Hu Cao"},{"authorId":"2248367568","name":"Alois C. Knoll"}],"abstract":"The applications of Vision-Language Models (VLMs) in the field of Autonomous Driving (AD) have attracted widespread attention due to their outstanding performance and the ability to leverage Large Language Models (LLMs). By incorporating language data, driving systems can gain a better understanding of real-world environments, thereby enhancing driving safety and efficiency. In this work, we present a comprehensive and systematic survey of the advances in vision language models in this domain, encompassing perception and understanding, navigation and planning, decision-making and control, end-to-end autonomous driving, and data generation. We introduce the mainstream VLM tasks in AD and the commonly utilized metrics. Additionally, we review current studies and applications in various areas and summarize the existing language-enhanced autonomous driving datasets thoroughly. Lastly, we discuss the benefits and challenges of VLMs in AD and provide researchers with the current research gaps and future trends."}