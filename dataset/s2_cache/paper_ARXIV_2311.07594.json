{"paperId":"2d7f1324398bf2266fd52d1364bbecb8183313ed","externalIds":{"ArXiv":"2311.07594","CorpusId":280710126},"title":"How to Bridge the Gap between Modalities: Survey on Multimodal Large Language Model","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2311.07594, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2152569963","name":"Shezheng Song"},{"authorId":"2266495625","name":"Xiaopeng Li"},{"authorId":"1484986130","name":"Shasha Li"},{"authorId":"2275542733","name":"Shan Zhao"},{"authorId":"2116457427","name":"Jie Yu"},{"authorId":"2152610427","name":"Jun Ma"},{"authorId":"2275248076","name":"Xiaoguang Mao"},{"authorId":"2282091207","name":"Weimin Zhang"}],"abstract":"We explore Multimodal Large Language Models (MLLMs), which integrate LLMs like GPT-4 to handle multimodal data, including text, images, audio, and more. MLLMs demonstrate capabilities such as generating image captions and answering image-based questions, bridging the gap towards real-world human-computer interactions and hinting at a potential pathway to artificial general intelligence. However, MLLMs still face challenges in addressing the semantic gap in multimodal data, which may lead to erroneous outputs, posing potential risks to society. Selecting the appropriate modality alignment method is crucial, as improper methods might require more parameters without significant performance improvements. This paper aims to explore modality alignment methods for LLMs and their current capabilities. Implementing effective modality alignment can help LLMs address environmental issues and enhance accessibility. The study surveys existing modality alignment methods for MLLMs, categorizing them into four groups: (1) Multimodal Converter, which transforms data into a format that LLMs can understand; (2) Multimodal Perceiver, which improves how LLMs percieve different types of data; (3) Tool Learning, which leverages external tools to convert data into a common format, usually text; and (4) Data-Driven Method, which teaches LLMs to understand specific data types within datasets."}