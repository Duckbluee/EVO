{"paperId":"45a476cb04cccee74b9ddabce4d58d928be99f7d","externalIds":{"ArXiv":"2310.19736","DBLP":"journals/corr/abs-2310-19736","DOI":"10.48550/arXiv.2310.19736","CorpusId":264825354},"title":"Evaluating Large Language Models: A Comprehensive Survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2310.19736, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2246789578","name":"Zishan Guo"},{"authorId":"2184143149","name":"Renren Jin"},{"authorId":"2116348128","name":"Chuang Liu"},{"authorId":"2263648395","name":"Yufei Huang"},{"authorId":"2263734437","name":"Dan Shi"},{"authorId":"2264274578","name":"Supryadi"},{"authorId":"2217579802","name":"Linhao Yu"},{"authorId":"2246949835","name":"Yan Liu"},{"authorId":"2264285923","name":"Jiaxuan Li"},{"authorId":"2263520727","name":"Bojian Xiong"},{"authorId":"2263617513","name":"Deyi Xiong"}],"abstract":"Large language models (LLMs) have demonstrated remarkable capabilities across a broad spectrum of tasks. They have attracted significant attention and been deployed in numerous downstream applications. Nevertheless, akin to a double-edged sword, LLMs also present potential risks. They could suffer from private data leaks or yield inappropriate, harmful, or misleading content. Additionally, the rapid progress of LLMs raises concerns about the potential emergence of superintelligent systems without adequate safeguards. To effectively capitalize on LLM capacities as well as ensure their safe and beneficial development, it is critical to conduct a rigorous and comprehensive evaluation of LLMs. This survey endeavors to offer a panoramic perspective on the evaluation of LLMs. We categorize the evaluation of LLMs into three major groups: knowledge and capability evaluation, alignment evaluation and safety evaluation. In addition to the comprehensive review on the evaluation methodologies and benchmarks on these three aspects, we collate a compendium of evaluations pertaining to LLMs' performance in specialized domains, and discuss the construction of comprehensive evaluation platforms that cover LLM evaluations on capabilities, alignment, safety, and applicability. We hope that this comprehensive overview will stimulate further research interests in the evaluation of LLMs, with the ultimate goal of making evaluation serve as a cornerstone in guiding the responsible development of LLMs. We envision that this will channel their evolution into a direction that maximizes societal benefit while minimizing potential risks. A curated list of related papers has been publicly available at https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers."}