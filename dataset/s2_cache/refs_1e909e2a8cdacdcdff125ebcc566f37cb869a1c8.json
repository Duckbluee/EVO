{"references":[{"paperId":"cbbe1ae3983f8e1215f34db5c5b24b2a70555411","externalIds":{"ArXiv":"2406.19820","DBLP":"conf/acl/ChuCCWZDYLQ24","DOI":"10.48550/arXiv.2406.19820","CorpusId":270845599},"title":"BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering"},{"paperId":"0e8297549b4ec852ce8fd55dee9ae21501805af2","externalIds":{"PubMedCentral":"10894685","DOI":"10.1098/rsta.2023.0254","CorpusId":257572753,"PubMed":"38403056"},"title":"GPT-4 passes the bar exam"},{"paperId":"a314b4c385e9732794a48d1d34f637b13245c71d","externalIds":{"DBLP":"conf/acl/ZhangFC24","ArXiv":"2402.16457","DOI":"10.48550/arXiv.2402.16457","CorpusId":268033124},"title":"RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering"},{"paperId":"6af460d34bfc8e955e43fbe15cedcf329b48bc19","externalIds":{"DBLP":"conf/emnlp/ZhangLDMS23","ArXiv":"2311.01740","DOI":"10.48550/arXiv.2311.01740","CorpusId":265019095},"title":"SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency"},{"paperId":"a56128e550d4b396ac46dbd3973f3e3210025c65","externalIds":{"DBLP":"conf/emnlp/FengFLLYWHL024","ArXiv":"2310.19347","DOI":"10.18653/v1/2024.findings-emnlp.648","CorpusId":264803615},"title":"Improving Factual Consistency of News Summarization by Contrastive Preference Optimization"},{"paperId":"c1284ee1ddf29955a1a02bdc45abdaac63745017","externalIds":{"ArXiv":"2310.17918","DBLP":"journals/corr/abs-2310-17918","ACL":"2024.naacl-long.390","DOI":"10.48550/arXiv.2310.17918","CorpusId":264555682},"title":"Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method"},{"paperId":"d566d6859e22cfdcd59d735f6865fb5f0b50f3c9","externalIds":{"DBLP":"journals/corr/abs-2310-18344","ArXiv":"2310.18344","DOI":"10.48550/arXiv.2310.18344","CorpusId":264590664},"title":"Chainpoll: A high efficacy method for LLM hallucination detection"},{"paperId":"161b3e82567b9a9c6911171fa55f05695bf93217","externalIds":{"DBLP":"journals/corr/abs-2310-12397","ArXiv":"2310.12397","DOI":"10.48550/arXiv.2310.12397","CorpusId":264305982},"title":"GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems"},{"paperId":"c65867e127e39f03eda29ca5d82c298fad29d0b3","externalIds":{"DBLP":"conf/emnlp/LattimerC0Y23","ArXiv":"2310.13189","DOI":"10.18653/v1/2023.emnlp-main.105","CorpusId":264405939},"title":"Fast and Accurate Factual Inconsistency Detection Over Long Documents"},{"paperId":"ea61232aa8932f79d6151a025496dc806e4603d6","externalIds":{"DBLP":"journals/corr/abs-2310-12150","ArXiv":"2310.12150","DOI":"10.48550/arXiv.2310.12150","CorpusId":264288955},"title":"Understanding Retrieval Augmentation for Long-Form Question Answering"},{"paperId":"6abd2c18bc5c9441465ae094eb1e93c25b3732c3","externalIds":{"DBLP":"conf/emnlp/PinterE23","ArXiv":"2310.11958","DOI":"10.48550/arXiv.2310.11958","CorpusId":264288692},"title":"Emptying the Ocean with a Spoon: Should We Edit Models?"},{"paperId":"ee96922369a8ee1eb7bda1501520bb7916cde733","externalIds":{"DBLP":"conf/acl/RavautSCJ24","ArXiv":"2310.10570","DOI":"10.18653/v1/2024.acl-long.153","CorpusId":264146949},"title":"On Context Utilization in Summarization with Large Language Models"},{"paperId":"e6f74f2746a9e8bc90701f2afcf3c47e5e98b2dd","externalIds":{"ArXiv":"2310.09044","DBLP":"journals/corr/abs-2310-09044","DOI":"10.48550/arXiv.2310.09044","CorpusId":264128245},"title":"KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection"},{"paperId":"e879f54b2b5760bbb6d010977ddcedfb62452b38","externalIds":{"ArXiv":"2310.08118","DBLP":"journals/corr/abs-2310-08118","DOI":"10.48550/arXiv.2310.08118","CorpusId":263909251},"title":"Can Large Language Models Really Improve by Self-critiquing Their Own Plans?"},{"paperId":"03fab98a9be74a253688840dba9144737a8ca92d","externalIds":{"DBLP":"journals/corr/abs-2310-07521","ArXiv":"2310.07521","DOI":"10.48550/arXiv.2310.07521","CorpusId":263835211},"title":"Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity"},{"paperId":"cd2e04598909158494e556823d9de8baa692cee2","externalIds":{"DBLP":"journals/corr/abs-2310-06271","ArXiv":"2310.06271","DOI":"10.48550/arXiv.2310.06271","CorpusId":263828949},"title":"Towards Mitigating Hallucination in Large Language Models via Self-Reflection"},{"paperId":"495c36dba73fa97e2f742827c03c3d61a83b3a01","externalIds":{"DBLP":"conf/emnlp/YangS023","ArXiv":"2310.06498","DOI":"10.48550/arXiv.2310.06498","CorpusId":263830009},"title":"A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection"},{"paperId":"c36d7bc6adeee7d16df1194c44cb66c48c9ae681","externalIds":{"ArXiv":"2310.05338","DBLP":"journals/corr/abs-2310-05338","ACL":"2024.alvr-1.4","DOI":"10.48550/arXiv.2310.05338","CorpusId":263829510},"title":"Negative Object Presence Evaluation (NOPE) to Measure Object Hallucination in Vision-Language Models"},{"paperId":"2392b6d3a5cad9e5cf349169eaeee848266adf6a","externalIds":{"ArXiv":"2310.05736","DBLP":"journals/corr/abs-2310-05736","DOI":"10.48550/arXiv.2310.05736","CorpusId":263830701},"title":"LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models"},{"paperId":"23af54b82c951317f1fc1841164d8a441a2d8120","externalIds":{"DBLP":"conf/iclr/XuSC24","ArXiv":"2310.04408","DOI":"10.48550/arXiv.2310.04408","CorpusId":263830734},"title":"RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation"},{"paperId":"79429814fd4d967b9277af2805c53f370e52ebb5","externalIds":{"ArXiv":"2310.03951","DBLP":"journals/corr/abs-2310-03951","DOI":"10.48550/arXiv.2310.03951","CorpusId":263831527},"title":"Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations"},{"paperId":"be177300487b6d0f25e6cade9a31900454b13281","externalIds":{"DBLP":"journals/corr/abs-2310-03214","ArXiv":"2310.03214","DOI":"10.48550/arXiv.2310.03214","CorpusId":263672149},"title":"FreshLLMs: Refreshing Large Language Models with Search Engine Augmentation"},{"paperId":"6d4bacb69923e1e94fb4de468b939ce6db32fb51","externalIds":{"DBLP":"conf/iclr/0009CMZYSZ24","ArXiv":"2310.01798","DOI":"10.48550/arXiv.2310.01798","CorpusId":263609132},"title":"Large Language Models Cannot Self-Correct Reasoning Yet"},{"paperId":"dd4d82299b4209db539d639f836fcee663cf72b3","externalIds":{"ArXiv":"2310.01469","DBLP":"journals/corr/abs-2310-01469","DOI":"10.48550/arXiv.2310.01469","CorpusId":263608740},"title":"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples"},{"paperId":"d6ae4c0679bdceb029f652efd2a854ac5ade772f","externalIds":{"ACL":"2023.bigpicture-1.9","ArXiv":"2310.01387","DBLP":"journals/corr/abs-2310-01387","DOI":"10.48550/arXiv.2310.01387","CorpusId":263605610},"title":"It‚Äôs MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk"},{"paperId":"f148b3a0106cbaba356b9f099f1a10c072c0b3c5","externalIds":{"DBLP":"journals/corr/abs-2309-15840","ArXiv":"2309.15840","DOI":"10.48550/arXiv.2309.15840","CorpusId":263152829},"title":"How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions"},{"paperId":"8eafec7014d08043517834b5a2ed26384f188873","externalIds":{"ArXiv":"2309.12288","DBLP":"journals/corr/abs-2309-12288","CorpusId":262083829},"title":"The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\""},{"paperId":"cff6eb25c029d079089f42b45f5c3e02970e7461","externalIds":{"ArXiv":"2309.07852","ACL":"2024.naacl-long.167","DBLP":"conf/naacl/MalaviyaLCSYR24","DOI":"10.48550/arXiv.2309.07852","CorpusId":261823130},"title":"ExpertQA: Expert-Curated Questions and Attributed Answers"},{"paperId":"71bc0c97c20fffce796a355b16bd202987260029","externalIds":{"ArXiv":"2309.05922","DBLP":"journals/corr/abs-2309-05922","DOI":"10.48550/arXiv.2309.05922","CorpusId":261696947},"title":"A Survey of Hallucination in Large Foundation Models"},{"paperId":"e26888285436bc7998e5c95102a9beb60144be5e","externalIds":{"DBLP":"journals/corr/abs-2309-05463","ArXiv":"2309.05463","DOI":"10.48550/arXiv.2309.05463","CorpusId":261696657},"title":"Textbooks Are All You Need II: phi-1.5 technical report"},{"paperId":"92221598758165d1679c8c9792435bb5a9a547a0","externalIds":{"DBLP":"journals/corr/abs-2308-12674","ArXiv":"2308.12674","DOI":"10.48550/arXiv.2308.12674","CorpusId":261101210},"title":"Improving Translation Faithfulness of Large Language Models via Augmenting Instructions"},{"paperId":"f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f","externalIds":{"ArXiv":"2308.10792","DBLP":"journals/corr/abs-2308-10792","DOI":"10.1145/3777411","CorpusId":261049152},"title":"Instruction Tuning for Large Language Models: A Survey"},{"paperId":"ac4ab9b23a002e81c9419c520747a603fbcbb40d","externalIds":{"ArXiv":"2308.10173","DBLP":"journals/corr/abs-2308-10173","DOI":"10.48550/arXiv.2308.10173","CorpusId":261048937},"title":"FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training and Knowledge Graph Prompt"},{"paperId":"440ca16479ece9ed61461032b9b2fcde36c8ae7a","externalIds":{"DBLP":"journals/ipm/WuWPLLSS26","ArXiv":"2308.09954","DOI":"10.1016/j.ipm.2025.104299","CorpusId":261049822},"title":"DocTER: Evaluating document-based knowledge editing"},{"paperId":"7142e920b6b9355d9cbacc9450818f912eca138e","externalIds":{"ArXiv":"2308.05374","DBLP":"journals/corr/abs-2308-05374","DOI":"10.48550/arXiv.2308.05374","CorpusId":260775522},"title":"Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment"},{"paperId":"ee19d5c943f1ebcd1a9e52a7bf494a88255b8e04","externalIds":{"ArXiv":"2308.03188","DBLP":"journals/corr/abs-2308-03188","DOI":"10.48550/arXiv.2308.03188","CorpusId":260682695},"title":"Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies"},{"paperId":"76513f54fcecf7a380f77ad785f05c3bc869db4a","externalIds":{"DBLP":"journals/tacl/AdlakhaBLMR24a","ACL":"2024.tacl-1.38","ArXiv":"2307.16877","DOI":"10.1162/tacl_a_00667","CorpusId":260334056},"title":"Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering"},{"paperId":"7a5b44ea10a51708e18786595c8d70b18950da11","externalIds":{"DBLP":"journals/corr/abs-2307-13528","ArXiv":"2307.13528","DOI":"10.48550/arXiv.2307.13528","CorpusId":260154834},"title":"FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios"},{"paperId":"84b77180228051040286423cec82b62c323a8fda","externalIds":{"ArXiv":"2307.11019","DBLP":"journals/corr/abs-2307-11019","DOI":"10.48550/arXiv.2307.11019","CorpusId":259991467},"title":"Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation"},{"paperId":"a72975eb88eb31f193e9587e7415cb04e7bcdbee","externalIds":{"ACL":"2024.eacl-long.4","DBLP":"conf/eacl/MuhlgayRMLRBALSS24","ArXiv":"2307.06908","DOI":"10.48550/arXiv.2307.06908","CorpusId":259847758},"title":"Generating Benchmarks for Factuality Evaluation of Language Models"},{"paperId":"1827dd28ef866eaeb929ddf4bcfa492880aba4c7","externalIds":{"DBLP":"journals/corr/abs-2307-03987","ArXiv":"2307.03987","DOI":"10.48550/arXiv.2307.03987","CorpusId":263699899},"title":"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation"},{"paperId":"1733eb7792f7a43dd21f51f4d1017a1bffd217b5","externalIds":{"DBLP":"journals/tacl/LiuLHPBPL24","ArXiv":"2307.03172","ACL":"2024.tacl-1.9","DOI":"10.1162/tacl_a_00638","CorpusId":259360665},"title":"Lost in the Middle: How Language Models Use Long Contexts"},{"paperId":"c7091540c1fa77f1c6b27482f349330f8e559d6f","externalIds":{"DBLP":"journals/corr/abs-2307-00175","ArXiv":"2307.00175","DOI":"10.1007/s11098-023-02094-3","CorpusId":259316868},"title":"Still no lie detector for language models: probing empirical and conceptual roadblocks"},{"paperId":"c7a7104df3db13737a865ede2be8146990fa4026","externalIds":{"ArXiv":"2306.14565","DBLP":"conf/iclr/LiuLLWYW24","CorpusId":259251834},"title":"Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning"},{"paperId":"d5bf1808eebf0560b9a18fbdd11c2fac9e7af9f7","externalIds":{"ArXiv":"2306.13781","DBLP":"journals/corr/abs-2306-13781","DOI":"10.48550/arXiv.2306.13781","CorpusId":259251952},"title":"Retrieving Supporting Evidence for LLMs Generated Answers"},{"paperId":"8f7297454d7f44365b9bcda5ebb9439a43daf5e6","externalIds":{"DBLP":"journals/corr/abs-2306-13063","ArXiv":"2306.13063","DOI":"10.48550/arXiv.2306.13063","CorpusId":259224389},"title":"Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"},{"paperId":"678cfca72b7de72b005f71207bc8a522ea9ac62c","externalIds":{"ACL":"2023.matching-1.7","ArXiv":"2306.04136","DOI":"10.18653/v1/2023.matching-1.7","CorpusId":260063238},"title":"Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering"},{"paperId":"024169b83522f1de4e6c505ca11d534f58965087","externalIds":{"ArXiv":"2306.03601","DBLP":"journals/corr/abs-2306-03601","DOI":"10.48550/arXiv.2306.03601","CorpusId":259089064},"title":"The Creative Frontier of Generative AI: Managing the Novelty-Usefulness Tradeoff"},{"paperId":"405f8f5f1c6df1b3343c812832479aad5180b65f","externalIds":{"ArXiv":"2306.03341","DBLP":"journals/corr/abs-2306-03341","CorpusId":259088877},"title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language Model"},{"paperId":"4d74a5048b884e8bb3842240abf98915c619c8f8","externalIds":{"ArXiv":"2306.01200","DBLP":"conf/acl/JainKSF0NZ23","DOI":"10.18653/v1/2023.findings-acl.537","CorpusId":259064002},"title":"Multi-Dimensional Evaluation of Text Summarization with In-Context Learning"},{"paperId":"d40dbe668d5b68419e934dfa4c5851ffa1c24aa2","externalIds":{"DBLP":"journals/corr/abs-2306-00946","ArXiv":"2306.00946","DOI":"10.48550/arXiv.2306.00946","CorpusId":258999835},"title":"Exposing Attention Glitches with Flip-Flop Language Modeling"},{"paperId":"7a1e71cb1310c4a873e7a4e54d1a6dab0553adce","externalIds":{"ArXiv":"2306.01116","DBLP":"journals/corr/abs-2306-01116","DOI":"10.48550/arXiv.2306.01116","CorpusId":259063761},"title":"The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only"},{"paperId":"c18e13ba65c7247774301314d181c87ee5ebc847","externalIds":{"DBLP":"journals/corr/abs-2305-18248","ArXiv":"2305.18248","ACL":"2024.findings-eacl.62","DOI":"10.48550/arXiv.2305.18248","CorpusId":258960346},"title":"Do Language Models Know When They‚Äôre Hallucinating References?"},{"paperId":"984d4a1d41bfc8184fb77b8aa0eb8e96d536d048","externalIds":{"DBLP":"conf/naacl/ShiHLTZY24","ArXiv":"2305.14739","ACL":"2024.naacl-short.69","DOI":"10.48550/arXiv.2305.14739","CorpusId":258866080},"title":"Trusting Your Evidence: Hallucinate Less with Context-aware Decoding"},{"paperId":"a1675f47125aa409525c5f759b5e6bcc1c8831aa","externalIds":{"ArXiv":"2305.15294","DBLP":"journals/corr/abs-2305-15294","DOI":"10.48550/arXiv.2305.15294","CorpusId":258866037},"title":"Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy"},{"paperId":"26f5a7259bad9ff05f481aeb57d7431d499fb100","externalIds":{"DBLP":"conf/emnlp/WangF0XLSB23","ArXiv":"2305.14869","DOI":"10.48550/arXiv.2305.14869","CorpusId":258866021},"title":"CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering"},{"paperId":"56e952fd463accff09cf2e35432aaabd7c7c57f3","externalIds":{"DBLP":"conf/emnlp/ZhongWMPC23","ArXiv":"2305.14795","DOI":"10.48550/arXiv.2305.14795","CorpusId":258865984},"title":"MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions"},{"paperId":"7db7653c581d7823cb9c328f2d742ec70d7a0ce4","externalIds":{"DBLP":"journals/corr/abs-2305-14908","ArXiv":"2305.14908","DOI":"10.48550/arXiv.2305.14908","CorpusId":258865339},"title":"PURR: Efficiently Editing Language Model Hallucinations by Denoising Language Model Corruptions"},{"paperId":"4780d0a027c5c5a8e01d7cf697f6296880ffc945","externalIds":{"ArXiv":"2305.14325","DBLP":"journals/corr/abs-2305-14325","DOI":"10.48550/arXiv.2305.14325","CorpusId":258841118},"title":"Improving Factuality and Reasoning in Language Models through Multiagent Debate"},{"paperId":"bd5deadc58ee45b5e004378ba1d54a96bc947b4a","externalIds":{"ArXiv":"2305.14251","DBLP":"conf/emnlp/MinKLLYKIZH23","DOI":"10.48550/arXiv.2305.14251","CorpusId":258841470},"title":"FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"},{"paperId":"4115a24474ef5f184f5cbae3f43aca4d3bb07bea","externalIds":{"ArXiv":"2305.14002","DBLP":"journals/corr/abs-2305-14002","DOI":"10.48550/arXiv.2305.14002","CorpusId":258841029},"title":"Improving Language Models via Plug-and-Play Retrieval Feedback"},{"paperId":"6327740b98005b5c9d090e5f1d474ff656d4174b","externalIds":{"DBLP":"journals/corr/abs-2305-14540","ArXiv":"2305.14540","DOI":"10.48550/arXiv.2305.14540","CorpusId":258865817},"title":"LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond"},{"paperId":"62b322b0bead56d6a252a2e24de499ea8385ad7f","externalIds":{"DBLP":"journals/corr/abs-2305-13669","DOI":"10.48550/arXiv.2305.13669","CorpusId":258840979},"title":"Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment"},{"paperId":"2c67ee597ed38f43ec0f123a3f1cce38cbd3b5b4","externalIds":{"DBLP":"journals/corr/abs-2305-14552","ArXiv":"2305.14552","DOI":"10.48550/arXiv.2305.14552","CorpusId":258865517},"title":"Sources of Hallucination by Large Language Models on Inference Tasks"},{"paperId":"6825ba09383bc758f9a2feaebabe35a6cd4adc4c","externalIds":{"DBLP":"conf/icml/ZhangPMLS24","ArXiv":"2305.13534","DOI":"10.48550/arXiv.2305.13534","CorpusId":258841857},"title":"How Language Model Hallucinations Can Snowball"},{"paperId":"ed0ed87161a2beab9e1bed3e783d7487a5f1062a","externalIds":{"ArXiv":"2305.13281","DBLP":"conf/emnlp/CohenHGG23","DOI":"10.48550/arXiv.2305.13281","CorpusId":258833288},"title":"LM vs LM: Detecting Factual Errors via Cross Examination"},{"paperId":"f5c73d9e6641b018b633690102121f5605d34fb0","externalIds":{"DBLP":"conf/emnlp/YaoWT0LDC023","ArXiv":"2305.13172","DOI":"10.48550/arXiv.2305.13172","CorpusId":258833129},"title":"Editing Large Language Models: Problems, Methods, and Opportunities"},{"paperId":"672491163a327f80e08ce3ef4751e94c78631822","externalIds":{"DBLP":"conf/acl/ChangYG0M23","ArXiv":"2305.12289","DOI":"10.48550/arXiv.2305.12289","CorpusId":258833010},"title":"Revisiting the Architectures like Pointer Networks to Efficiently Improve the Next Word Distribution, Summarization Factuality, and Beyond"},{"paperId":"4fb0e1283194c0d20ac0396bc375fdf91c14da1e","externalIds":{"ACL":"2024.naacl-long.196","ArXiv":"2305.11859","DBLP":"journals/corr/abs-2305-11859","DOI":"10.48550/arXiv.2305.11859","CorpusId":258822852},"title":"Complex Claim Verification with Evidence Retrieved in the Wild"},{"paperId":"bcdaf6c98ddbd6809cf6241aa77200d7394db163","externalIds":{"DBLP":"conf/iclr/GouSGSYDC24","ArXiv":"2305.11738","DOI":"10.48550/arXiv.2305.11738","CorpusId":258823123},"title":"CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing"},{"paperId":"546d0624adfc6e18fb87d8cc77e7705bb9ea7445","externalIds":{"ArXiv":"2305.11206","DBLP":"conf/nips/ZhouLX0SMMEYYZG23","CorpusId":258822910},"title":"LIMA: Less Is More for Alignment"},{"paperId":"4e7cf247aa3f346fa5385381e5817c1d5c330d26","externalIds":{"DBLP":"conf/acl/Wang0L23","ArXiv":"2305.09154","DOI":"10.48550/arXiv.2305.09154","CorpusId":258714995},"title":"Progressive Translation: Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences"},{"paperId":"416248cae7fd843e73f37141fad9fe25dfb9a08b","externalIds":{"DOI":"10.3390/math11102320","CorpusId":258768397},"title":"A Mathematical Investigation of Hallucination and Creativity in GPT Models"},{"paperId":"236c7dafea3df7ecffb5f18ec780d12f2f27d4b0","externalIds":{"DBLP":"conf/nips/HuangBZZZSLLZLF23","ArXiv":"2305.08322","DOI":"10.48550/arXiv.2305.08322","CorpusId":258685666},"title":"C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models"},{"paperId":"c3ed333a37a6d9a0fcf1dad3106a114f66a45b99","externalIds":{"DBLP":"journals/corr/abs-2305-06849","ArXiv":"2305.06849","ACL":"2023.acl-long.499","DOI":"10.48550/arXiv.2305.06849","CorpusId":258615343},"title":"WebCPM: Interactive Web Search for Chinese Long-form Question Answering"},{"paperId":"629c441076da3f8185b1cf85e8036064b714e249","externalIds":{"DBLP":"conf/acl/ZhaoLJQB23","ACL":"2023.acl-long.320","ArXiv":"2305.03268","DOI":"10.48550/arXiv.2305.03268","CorpusId":258547173},"title":"Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework"},{"paperId":"03055978e278960de9fbb5c648b1779ef9f26cd1","externalIds":{"ArXiv":"2305.01937","DBLP":"conf/acl/ChiangL23","ACL":"2023.acl-long.870","DOI":"10.48550/arXiv.2305.01937","CorpusId":258461287},"title":"Can Large Language Models Be an Alternative to Human Evaluations?"},{"paperId":"56fa65d8dc41708082f9b2ef7752c49cee9ebe01","externalIds":{"DBLP":"conf/acl/WangWLGYR23","ACL":"2023.acl-long.304","ArXiv":"2305.01879","DOI":"10.48550/arXiv.2305.01879","CorpusId":258461058},"title":"SCOTT: Self-Consistent Chain-of-Thought Distillation"},{"paperId":"f406aceba4f29cc7cfbe7edb2f52f01374486589","externalIds":{"ArXiv":"2304.13734","DBLP":"journals/corr/abs-2304-13734","DOI":"10.18653/v1/2023.findings-emnlp.68","CorpusId":258352729},"title":"The Internal State of an LLM Knows When its Lying"},{"paperId":"e03dc5bd72bea7d1db03de380d4c43b7e610fbee","externalIds":{"DBLP":"conf/emnlp/LiuZL23","ArXiv":"2304.09848","DOI":"10.48550/arXiv.2304.09848","CorpusId":258212854},"title":"Evaluating Verifiability in Generative Search Engines"},{"paperId":"82e440220e29d6c2c5866f9cb40e522ca0c8a22d","externalIds":{"DBLP":"journals/corr/abs-2304-02554","ArXiv":"2304.02554","DOI":"10.48550/arXiv.2304.02554","CorpusId":257952492},"title":"Human-like Summarization Evaluation with ChatGPT"},{"paperId":"a206a0c96d6076c6ab081288b0c2c95d3c7efd64","externalIds":{"ArXiv":"2304.00740","CorpusId":258833476},"title":"Inspecting and Editing Knowledge Representations in Language Models"},{"paperId":"3aaf6a2cbad5850ad81ab5c163599cb3d523436f","externalIds":{"DBLP":"journals/corr/abs-2303-17651","ArXiv":"2303.17651","DOI":"10.48550/arXiv.2303.17651","CorpusId":257900871},"title":"Self-Refine: Iterative Refinement with Self-Feedback"},{"paperId":"039f82bdfac8aef61f64c3dfa4dc54ac75e418b2","externalIds":{"ArXiv":"2303.15621","CorpusId":258108400},"title":"ChatGPT as a Factual Inconsistency Evaluator for Text Summarization"},{"paperId":"8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c","externalIds":{"ArXiv":"2303.12712","DBLP":"journals/corr/abs-2303-12712","CorpusId":257663729},"title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4"},{"paperId":"638b08154fbb71fd34db2aae6cb40045577fe0de","externalIds":{"DBLP":"journals/corr/abs-2303-09540","ArXiv":"2303.09540","DOI":"10.48550/arXiv.2303.09540","CorpusId":257557221},"title":"SemDeDup: Data-efficient learning at web-scale through semantic deduplication"},{"paperId":"8221f1597000543432b7021ca79dbc51a7a63f9c","externalIds":{"DBLP":"journals/corr/abs-2303-04048","ArXiv":"2303.04048","ACL":"2023.newsum-1.1","DOI":"10.48550/arXiv.2303.04048","CorpusId":257378627},"title":"Is ChatGPT a Good NLG Evaluator? A Preliminary Study"},{"paperId":"3d20d1d3ec1199c35d13e60351b358ac1e317401","externalIds":{"ArXiv":"2302.09736","DBLP":"journals/corr/abs-2302-09736","DOI":"10.48550/arXiv.2302.09736","CorpusId":257038499},"title":"STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training"},{"paperId":"a3a241e9397fe29b37f96cb5e8f4b8bebed3d3da","externalIds":{"DBLP":"journals/corr/abs-2302-06729","ArXiv":"2302.06729","DOI":"10.48550/arXiv.2302.06729","CorpusId":256846551},"title":"STREET: A Multi-Task Structured Reasoning and Explanation Benchmark"},{"paperId":"bf8491bef353df126e2306ad2fe4b898697b906a","externalIds":{"ArXiv":"2302.04023","DBLP":"conf/ijcnlp/BangCLDSWLJYCDXF23","ACL":"2023.ijcnlp-main.45","DOI":"10.18653/v1/2023.ijcnlp-main.45","CorpusId":256662612},"title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity"},{"paperId":"a4a41319d5805a29316f24ed9519f09db77d4c29","externalIds":{"ArXiv":"2301.13848","DBLP":"journals/tacl/ZhangLDLMH24a","ACL":"2024.tacl-1.3","DOI":"10.1162/tacl_a_00632","CorpusId":256416014},"title":"Benchmarking Large Language Models for News Summarization"},{"paperId":"3d68522abfadfc8ee6b7ec9edaaf91f1b2f38e5e","externalIds":{"DBLP":"journals/corr/abs-2302-00093","ArXiv":"2302.00093","DOI":"10.48550/arXiv.2302.00093","CorpusId":256459776},"title":"Large Language Models Can Be Easily Distracted by Irrelevant Context"},{"paperId":"465471bb5bf1a945549d6291c2d23367966b4957","externalIds":{"ArXiv":"2302.00083","DBLP":"journals/corr/abs-2302-00083","DOI":"10.1162/tacl_a_00605","CorpusId":256459451},"title":"In-Context Retrieval-Augmented Language Models"},{"paperId":"b115c1e1e9e51f8ad7d47b745bc04e29a654b84d","externalIds":{"DBLP":"journals/corr/abs-2301-13379","ACL":"2023.ijcnlp-main.20","ArXiv":"2301.13379","DOI":"10.48550/arXiv.2301.13379","CorpusId":256416127},"title":"Faithful Chain-of-Thought Reasoning"},{"paperId":"a9be51698e7c2247853b7b6f1f70fc4d6d7ef605","externalIds":{"DBLP":"journals/corr/abs-2301-09785","ArXiv":"2301.09785","DOI":"10.48550/arXiv.2301.09785","CorpusId":256194369},"title":"Transformer-Patcher: One Mistake worth One Neuron"},{"paperId":"0ae3b108ff9ed67a3c28b355d28b439242e1fbd7","externalIds":{"DBLP":"journals/pami/YuWLXG23","DOI":"10.1109/TPAMI.2023.3238699","CorpusId":256225424,"PubMed":"37022056"},"title":"Knowledge-Aware Global Reasoning for Situation Recognition"},{"paperId":"490d8006851b1562cfd9ec1f057471f2868289d1","externalIds":{"DBLP":"journals/corr/abs-2301-00303","ArXiv":"2301.00303","DOI":"10.48550/arXiv.2301.00303","CorpusId":255372320},"title":"Rethinking with Retrieval: Faithful Large Language Model Inference"},{"paperId":"e965e93e76a9e6c4e4863d145b5c007b540d575d","externalIds":{"ArXiv":"2212.12017","DBLP":"journals/corr/abs-2212-12017","CorpusId":255096269},"title":"OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"},{"paperId":"f208ea909fa7f54fea82def9a92fd81dfc758c39","externalIds":{"ArXiv":"2212.10509","DBLP":"journals/corr/abs-2212-10509","ACL":"2023.acl-long.557","DOI":"10.48550/arXiv.2212.10509","CorpusId":254877499},"title":"Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions"},{"paperId":"c6ee979c2da4b55a8486abae4cd720422ab09b26","externalIds":{"ArXiv":"2212.10511","ACL":"2023.acl-long.546","DBLP":"conf/acl/MallenAZDKH23","DOI":"10.18653/v1/2023.acl-long.546","CorpusId":254877603},"title":"When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories"},{"paperId":"6845bea94b2fb17d4377b3bb2bd10f73a959f9cc","externalIds":{"DBLP":"journals/corr/abs-2212-09597","ArXiv":"2212.09597","ACL":"2023.acl-long.294","DOI":"10.48550/arXiv.2212.09597","CorpusId":254854219},"title":"Reasoning with Language Model Prompting: A Survey"},{"paperId":"3eb37f8318abcc56912931205a4f4c85920ff87a","externalIds":{"DBLP":"journals/corr/abs-2212-08307","ACL":"2023.acl-long.704","ArXiv":"2212.08307","DOI":"10.48550/arXiv.2212.08307","CorpusId":254823470},"title":"Controllable Text Generation via Probability Density Estimation in the Latent Space"},{"paperId":"391246ce9c59d61c94cca3f8bef56c95542a4708","externalIds":{"ArXiv":"2212.07919","DBLP":"journals/corr/abs-2212-07919","DOI":"10.48550/arXiv.2212.07919","CorpusId":254685985},"title":"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning"},{"paperId":"89c3bd70ad33c4f8832f00ab98872b77861ee0ec","externalIds":{"DBLP":"journals/corr/abs-2212-03827","ArXiv":"2212.03827","DOI":"10.48550/arXiv.2212.03827","CorpusId":254366253},"title":"Discovering Latent Knowledge in Language Models Without Supervision"},{"paperId":"3a07a87090a061ca41dd30ac8398a9a5d9d39826","externalIds":{"DBLP":"journals/tois/ZhaoLRW24","ArXiv":"2211.14876","DOI":"10.1145/3637870","CorpusId":254044526},"title":"Dense Text Retrieval Based on Pretrained Language Models: A Survey"},{"paperId":"560b1bc012588731b26748e33236570df777baa0","externalIds":{"ArXiv":"2211.11031","DBLP":"conf/nips/HartvigsenSPKG23","DOI":"10.48550/arXiv.2211.11031","CorpusId":253735429},"title":"Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors"},{"paperId":"7d645a3fd276918374fd9483fd675c28e46506d1","externalIds":{"DBLP":"journals/corr/abs-2211-09085","ArXiv":"2211.09085","CorpusId":253553203},"title":"Galactica: A Large Language Model for Science"},{"paperId":"75f7e9e2b59fb640ef9d1dff94097175daf46c4d","externalIds":{"ArXiv":"2211.08411","DBLP":"journals/corr/abs-2211-08411","CorpusId":253522998},"title":"Large Language Models Struggle to Learn Long-Tail Knowledge"},{"paperId":"ee8de585183763ff64cb3c81ecda2fc75fa81507","externalIds":{"ArXiv":"2211.05110","DBLP":"journals/corr/abs-2211-05110","DOI":"10.48550/arXiv.2211.05110","CorpusId":253420654},"title":"Large Language Models with Controllable Working Memory"},{"paperId":"88b62496cbc52072bfa8f4b29d172b0477b701bc","externalIds":{"DBLP":"conf/acl/LiHFLEHZL23","ArXiv":"2210.15097","ACL":"2023.acl-long.687","DOI":"10.48550/arXiv.2210.15097","CorpusId":253157949},"title":"Contrastive Decoding: Open-ended Text Generation as Optimization"},{"paperId":"d785f543f7a344fcec7ccbe55089a7f782e32bd7","externalIds":{"ACL":"2022.emnlp-main.399","DBLP":"journals/corr/abs-2210-13210","ArXiv":"2210.13210","DOI":"10.48550/arXiv.2210.13210","CorpusId":253097869},"title":"Mutual Information Alleviates Hallucinations in Abstractive Summarization"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"66242baf48b0f6b828e7547ac39ffaa5e1b2cb3e","externalIds":{"ArXiv":"2210.08726","DBLP":"conf/acl/GaoDPCCFZLLJG23","ACL":"2023.acl-long.910","DOI":"10.18653/v1/2023.acl-long.910","CorpusId":254247260},"title":"RARR: Researching and Revising What Language Models Say, Using Language Models"},{"paperId":"2fe1ac0b09cc0f50eb83eef6c7c6b45ac8b12413","externalIds":{"DBLP":"conf/iclr/MengSABB23","ArXiv":"2210.07229","DOI":"10.48550/arXiv.2210.07229","CorpusId":252873467},"title":"Mass-Editing Memory in a Transformer"},{"paperId":"e070ff286709db28312e08b52b05539debe88146","externalIds":{"DBLP":"conf/emnlp/PressZMSSL23","ArXiv":"2210.03350","DOI":"10.48550/arXiv.2210.03350","CorpusId":252762102},"title":"Measuring and Narrowing the Compositionality Gap in Language Models"},{"paperId":"7471cb40a33e9d971a922b5dff5ca9b4a73ca609","externalIds":{"DBLP":"journals/corr/abs-2210-03329","ArXiv":"2210.03329","DOI":"10.48550/arXiv.2210.03329","CorpusId":252762125},"title":"Calibrating Factual Knowledge in Pretrained Language Models"},{"paperId":"99832586d55f540f603637e458a292406a0ed75d","externalIds":{"DBLP":"conf/iclr/YaoZYDSN023","ArXiv":"2210.03629","CorpusId":252762395},"title":"ReAct: Synergizing Reasoning and Acting in Language Models"},{"paperId":"2383140a30cbd5e66db3f73e488ebfdc7a7fbb56","externalIds":{"ACL":"2022.emnlp-main.67","DBLP":"conf/emnlp/GuFMZG022","ArXiv":"2210.02889","DOI":"10.48550/arXiv.2210.02889","CorpusId":252735212},"title":"A Distributional Lens for Multi-Aspect Controllable Text Generation"},{"paperId":"07955e96cbd778d0ae2a68f09d073b866dd84c2a","externalIds":{"ArXiv":"2210.02406","DBLP":"conf/iclr/KhotTFF0CS23","DOI":"10.48550/arXiv.2210.02406","CorpusId":252715485},"title":"Decomposed Prompting: A Modular Approach for Solving Complex Tasks"},{"paperId":"51b21f6c9f6a7d6887b9a027bc159747d7a57199","externalIds":{"DBLP":"conf/nips/ChenL0022","ArXiv":"2210.01877","DOI":"10.48550/arXiv.2210.01877","CorpusId":252715398},"title":"Towards Improving Faithfulness in Abstractive Summarization"},{"paperId":"f56d363635bc378a196bae6d886ddd2d2899a220","externalIds":{"DBLP":"conf/iclr/MoschellaMFNLR23","ArXiv":"2209.15430","CorpusId":252668844},"title":"Relative representations enable zero-shot latent space communication"},{"paperId":"b2542a738b75ee9b7ce1a13d8b78f9095d212412","externalIds":{"ArXiv":"2209.10063","DBLP":"conf/iclr/0002IWXJ000023","CorpusId":252408513},"title":"Generate rather than Retrieve: Large Language Models are Strong Context Generators"},{"paperId":"916be31cbf847faa65cad0549e153f0c25b9f424","externalIds":{"ArXiv":"2208.03299","DBLP":"journals/jmlr/IzacardLLHPSDJRG23","CorpusId":251371732},"title":"Few-shot Learning with Retrieval Augmented Language Models"},{"paperId":"422d8c989adeb904563d0c96d5038f6c8596fa99","externalIds":{"ArXiv":"2208.00399","DBLP":"conf/nlpcc/DaiJDLS23","DOI":"10.48550/arXiv.2208.00399","CorpusId":251223709},"title":"Neural Knowledge Bank for Pretrained Transformers"},{"paperId":"dc5518e1db565a8c52084f27353461df474403d8","externalIds":{"DBLP":"conf/nips/KasaiST0A0RS0I23","ArXiv":"2207.13332","DOI":"10.48550/arXiv.2207.13332","CorpusId":251105205},"title":"RealTime QA: What's the Answer Right Now?"},{"paperId":"142ebbf4760145f591166bde2564ac70c001e927","externalIds":{"ArXiv":"2207.05221","DBLP":"journals/corr/abs-2207-05221","DOI":"10.48550/arXiv.2207.05221","CorpusId":250451161},"title":"Language Models (Mostly) Know What They Know"},{"paperId":"1d650f1afd45c59ff907396fe8b678595dcb85ea","externalIds":{"DBLP":"conf/icml/MitchellLBMF22","ArXiv":"2206.06520","CorpusId":249642147},"title":"Memory-Based Model Editing at Scale"},{"paperId":"29acc890e521f7a6415666ab9eb3432c49b4587a","externalIds":{"DBLP":"journals/corr/abs-2206-05802","ArXiv":"2206.05802","DOI":"10.48550/arXiv.2206.05802","CorpusId":249626555},"title":"Self-critiquing models for assisting human evaluators"},{"paperId":"f12a6168ed8de1aee69fee51b469b1aecd5f903e","externalIds":{"ArXiv":"2206.04624","DBLP":"conf/nips/LeePXPFSC22","DOI":"10.48550/arXiv.2206.04624","CorpusId":249538460},"title":"Factuality Enhanced Language Models for Open-Ended Text Generation"},{"paperId":"e582e09c3a74f2a7f3e2a7dbdbcdc003e74f6a84","externalIds":{"DBLP":"journals/corr/abs-2205-12854","ArXiv":"2205.12854","ACL":"2023.acl-long.650","DOI":"10.48550/arXiv.2205.12854","CorpusId":249062579},"title":"Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"aa4d9972af3264d032dbee58501ed4ac49477103","externalIds":{"ArXiv":"2205.10487","DBLP":"journals/corr/abs-2205-10487","DOI":"10.48550/arXiv.2205.10487","CorpusId":248986979},"title":"Scaling Laws and Interpretability of Learning from Repeated Data"},{"paperId":"00642bcfa319e0da3e2f56b59e9e0614fffd02de","externalIds":{"ArXiv":"2205.02832","DBLP":"journals/corr/abs-2205-02832","DOI":"10.48550/arXiv.2205.02832","CorpusId":248525074},"title":"Entity Cloze By Date: What LMs Know About Unseen Entities"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"fcd7bdf37cec0845f6960aa1ab87685b73fcfd2f","externalIds":{"ACL":"2022.emnlp-main.566","DBLP":"conf/emnlp/StelmakhLDC22","ArXiv":"2204.06092","DOI":"10.48550/arXiv.2204.06092","CorpusId":248157463},"title":"ASQA: Factoid Questions Meet Long-Form Answers"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"0e3d6a7c9c04cf3ba9c902724548846a5ade04b4","externalIds":{"ArXiv":"2204.01171","DBLP":"journals/corr/abs-2204-01171","ACL":"2022.findings-acl.58","DOI":"10.48550/arXiv.2204.01171","CorpusId":247939224},"title":"Why Exposure Bias Matters: An Imitation Learning Perspective of Error Accumulation in Language Generation"},{"paperId":"f2b0869b17bace854d73c19b449e3f88b9fed82e","externalIds":{"DBLP":"conf/acl/LiLSDSLJJL22","ACL":"2022.findings-acl.136","ArXiv":"2203.16747","DOI":"10.48550/arXiv.2203.16747","CorpusId":247839380},"title":"How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"d3dd80269f2542cc173afb3a1df24b582a1e4af2","externalIds":{"ArXiv":"2202.12172","DBLP":"conf/acl/0001C22","ACL":"2022.acl-long.527","DOI":"10.18653/v1/2022.acl-long.527","CorpusId":247084324},"title":"Overcoming a Theoretical Limitation of Self-Attention"},{"paperId":"996445d847f06e99b0bd259345408a0cf1bce87e","externalIds":{"DBLP":"conf/nips/MengBAB22","ArXiv":"2202.05262","CorpusId":255825985},"title":"Locating and Editing Factual Associations in GPT"},{"paperId":"3def68bd0f856886d34272840a7f81588f2bc082","externalIds":{"DBLP":"journals/corr/abs-2202-03629","ArXiv":"2202.03629","DOI":"10.1145/3571730","CorpusId":246652372},"title":"Survey of Hallucination in Natural Language Generation"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"07283e1578a50e15ac66efcc35b4ae0cbf2159ef","externalIds":{"DBLP":"journals/corr/abs-2112-12870","ArXiv":"2112.12870","DOI":"10.1162/coli_a_00486","CorpusId":245502761},"title":"Measuring Attribution in Natural Language Generation Models"},{"paperId":"9a970e7ec3158655738d4f8494d27ab9e00337cc","externalIds":{"ArXiv":"2112.08542","DBLP":"conf/naacl/FabbriWLX22","ACL":"2022.naacl-main.187","DOI":"10.18653/v1/2022.naacl-main.187","CorpusId":245218667},"title":"QAFactEval: Improved QA-Based Factual Consistency Evaluation for Summarization"},{"paperId":"fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf","externalIds":{"ArXiv":"2112.04359","DBLP":"journals/corr/abs-2112-04359","CorpusId":244954639},"title":"Ethical and social risks of harm from Language Models"},{"paperId":"ee1ef7b70dc34adcc90c42cc28168165ea56501f","externalIds":{"ArXiv":"2111.09525","DBLP":"journals/tacl/LabanSBH22","ACL":"2022.tacl-1.10","DOI":"10.1162/tacl_a_00453","CorpusId":244345901},"title":"SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization"},{"paperId":"db70933b9a95162664328823c2045982abc6b626","externalIds":{"DBLP":"journals/patterns/VincentH21","PubMedCentral":"8600242","DOI":"10.1016/j.patter.2021.100388","CorpusId":244085394,"PubMed":"34820655"},"title":"Preview of ‚ÄúData and its (dis)contents: A survey of dataset development and use in machine learning research‚Äù"},{"paperId":"b4e2e29bf0ea891610618b0615b540d4ed5a6004","externalIds":{"ArXiv":"2110.05456","DBLP":"journals/corr/abs-2110-05456","CorpusId":238583083},"title":"Rome was built in 1776: A Case Study on Factual Correctness in Knowledge-Grounded Response Generation"},{"paperId":"77d956cdab4508d569ae5741549b78e715fd0749","externalIds":{"DBLP":"journals/corr/abs-2109-07958","ACL":"2022.acl-long.229","ArXiv":"2109.07958","DOI":"10.18653/v1/2022.acl-long.229","CorpusId":237532606},"title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods"},{"paperId":"02e46711fc86877bdd279c736abe5415a2415e48","externalIds":{"ArXiv":"2108.11896","DBLP":"journals/tacl/GuoSV22","ACL":"2022.tacl-1.11","DOI":"10.1162/tacl_a_00454","CorpusId":237304047},"title":"A Survey on Automated Fact-Checking"},{"paperId":"4c600b466942417e2e0d12c4cd35c8aa1a556262","externalIds":{"DBLP":"journals/corr/abs-2108-02365","ArXiv":"2108.02365","DOI":"10.1145/3474085.3475638","CorpusId":236924520},"title":"Hybrid Reasoning Network for Video-based Commonsense Captioning"},{"paperId":"4566c0d22ebf3c31180066ab23b6c445aeec78d5","externalIds":{"ACL":"2022.acl-long.577","DBLP":"journals/corr/abs-2107-06499","ArXiv":"2107.06499","DOI":"10.18653/v1/2022.acl-long.577","CorpusId":235829052},"title":"Deduplicating Training Data Makes Language Models Better"},{"paperId":"9541fd32d09728ce10b105cbcd662a081cefab68","externalIds":{"ACL":"2021.naacl-main.104","MAG":"3168251909","DBLP":"conf/naacl/MishraPVLKT21","DOI":"10.18653/V1/2021.NAACL-MAIN.104","CorpusId":235097442},"title":"Looking Beyond Sentence-Level Natural Language Inference for Question Answering and Text Summarization"},{"paperId":"82b57e0ed286fd8bc591c77b5301c1414055244c","externalIds":{"DBLP":"conf/acl/MiaoMLZ020","ACL":"2021.acl-long.268","ArXiv":"2105.11098","DOI":"10.18653/v1/2021.acl-long.268","CorpusId":235166394},"title":"Prevent the Language Model from being Overconfident in Neural Machine Translation"},{"paperId":"0921322cf6ea34d1852f13cb67eeac9d1f863518","externalIds":{"DBLP":"conf/iclr/MalininG21","MAG":"3123791752","DOI":"10.17863/CAM.63497","CorpusId":231895728},"title":"Uncertainty Estimation in Autoregressive Structured Prediction"},{"paperId":"c2d140865e25bbb5a76e167baf48083cb38066dd","externalIds":{"DBLP":"journals/corr/abs-2104-14839","ArXiv":"2104.14839","CorpusId":233476302},"title":"The Factual Inconsistency Problem in Abstractive Text Summarization: A Survey"},{"paperId":"667bdd2a8dc997d40c106ff6761babebe4050762","externalIds":{"ArXiv":"2104.13346","MAG":"3170432046","ACL":"2021.naacl-main.383","DBLP":"journals/corr/abs-2104-13346","DOI":"10.18653/V1/2021.NAACL-MAIN.383","CorpusId":233407441},"title":"Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics"},{"paperId":"889feabe31ba0d24c093ac94d54a06eecb87e3f4","externalIds":{"DBLP":"conf/emnlp/DziriMZB21","ACL":"2021.emnlp-main.168","ArXiv":"2104.08455","DOI":"10.18653/v1/2021.emnlp-main.168","CorpusId":233296059},"title":"Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding"},{"paperId":"240b0caabb415578bdea4da7d0a32bdff2e8163f","externalIds":{"DBLP":"journals/corr/abs-2104-08164","ArXiv":"2104.08164","ACL":"2021.emnlp-main.522","DOI":"10.18653/v1/2021.emnlp-main.522","CorpusId":233289412},"title":"Editing Factual Knowledge in Language Models"},{"paperId":"36f141fc5bc6813073736cf886e264606d9403bf","externalIds":{"DBLP":"conf/emnlp/HonovichCANSA21","ArXiv":"2104.08202","ACL":"2021.emnlp-main.619","DOI":"10.18653/v1/2021.emnlp-main.619","CorpusId":233289483},"title":"Q^{2}: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering"},{"paperId":"a2a7033a5a859e3a6e6f0a83018326400b4c5faa","externalIds":{"DBLP":"conf/emnlp/0001PCKW21","ArXiv":"2104.07567","DOI":"10.18653/v1/2021.findings-emnlp.320","CorpusId":233240939},"title":"Retrieval Augmentation Reduces Hallucination in Conversation"},{"paperId":"f2885c6a25756cf81aa23b41bc62696a5be5c94d","externalIds":{"DBLP":"journals/corr/abs-2104-05240","MAG":"3166986030","ACL":"2021.naacl-main.398","ArXiv":"2104.05240","DOI":"10.18653/V1/2021.NAACL-MAIN.398","CorpusId":233210199},"title":"Factual Probing Is [MASK]: Learning vs. Learning to Recall"},{"paperId":"f434ca09c7e4acd8dbe2ba54c1a99a930bbfeeba","externalIds":{"DBLP":"journals/corr/abs-2104-04302","ArXiv":"2104.04302","ACL":"2021.naacl-main.114","MAG":"3169283369","DOI":"10.18653/V1/2021.NAACL-MAIN.114","CorpusId":233204406},"title":"Annotating and Modeling Fine-grained Factuality in Summarization"},{"paperId":"2476832edb11cb3de46587f55e270d6df328b32d","externalIds":{"ACL":"2021.eacl-main.236","DBLP":"conf/eacl/XiaoW21","ArXiv":"2103.15025","DOI":"10.18653/v1/2021.eacl-main.236","CorpusId":232404053},"title":"On Hallucination and Predictive Uncertainty in Conditional Language Generation"},{"paperId":"6ca07b95e6b68798e89888d3c2f5f43938feb419","externalIds":{"DBLP":"conf/emnlp/ScialomDLPSWG21","ArXiv":"2103.12693","ACL":"2021.emnlp-main.529","DOI":"10.18653/v1/2021.emnlp-main.529","CorpusId":233219059},"title":"QuestEval: Summarization Asks for Fact-based Evaluation"},{"paperId":"ca2f1088d3e581b2c6c75cf0ebc96506d620f64d","externalIds":{"DBLP":"conf/fat/BenderGMS21","DOI":"10.1145/3442188.3445922","CorpusId":262580630},"title":"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú"},{"paperId":"06f6869f8eb90a35148f1dde9a4baff03460d699","externalIds":{"DBLP":"journals/corr/abs-2102-09130","MAG":"3130250071","ArXiv":"2102.09130","ACL":"2021.eacl-main.235","DOI":"10.18653/v1/2021.eacl-main.235","CorpusId":231951460},"title":"Entity-level Factual Consistency of Abstractive Text Summarization"},{"paperId":"db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e","externalIds":{"DBLP":"journals/corr/abs-2101-00027","ArXiv":"2101.00027","CorpusId":230435736},"title":"The Pile: An 800GB Dataset of Diverse Text for Language Modeling"},{"paperId":"4a54d58a4b20e4f3af25cea3c188a12082a95e02","externalIds":{"DBLP":"conf/emnlp/GevaSBL21","ACL":"2021.emnlp-main.446","ArXiv":"2012.14913","DOI":"10.18653/v1/2021.emnlp-main.446","CorpusId":229923720},"title":"Transformer Feed-Forward Layers Are Key-Value Memories"},{"paperId":"df7d26339adf4eb0c07160947b9d2973c24911ba","externalIds":{"DBLP":"journals/corr/abs-2012-07805","MAG":"3112689365","ArXiv":"2012.07805","CorpusId":229156229},"title":"Extracting Training Data from Large Language Models"},{"paperId":"cddcad3b819277cc58f420050013aba90944682a","externalIds":{"MAG":"3106302287","ACL":"2020.emnlp-main.508","DBLP":"journals/corr/abs-2010-07882","ArXiv":"2010.07882","DOI":"10.18653/v1/2020.emnlp-main.508","CorpusId":222378161},"title":"Understanding Neural Abstractive Summarization Models via Uncertainty"},{"paperId":"708dcd8456426cd609c89a86344e0007c04c80bf","externalIds":{"DBLP":"conf/emnlp/JiangAADN20","MAG":"3092939616","ACL":"2020.emnlp-main.479","ArXiv":"2010.06189","DOI":"10.18653/v1/2020.emnlp-main.479","CorpusId":222310559},"title":"X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models"},{"paperId":"da43a455e65f8d1fec2ac72932ac2dd6c6ddc20d","externalIds":{"DBLP":"journals/corr/abs-2010-05478","ACL":"2020.findings-emnlp.322","MAG":"3092958231","ArXiv":"2010.05478","DOI":"10.18653/v1/2020.findings-emnlp.322","CorpusId":222291532},"title":"Evaluating Factuality in Generation with Dependency-level Entailment"},{"paperId":"7c72039c8597efab591aef878f6e3d0a96fdbd50","externalIds":{"ArXiv":"2010.05873","DBLP":"journals/corr/abs-2010-05873","MAG":"3093852412","ACL":"2020.findings-emnlp.76","DOI":"10.18653/v1/2020.findings-emnlp.76","CorpusId":222290728},"title":"Controlled Hallucinations: Learning to Generate Faithfully from Noisy Data"},{"paperId":"05cfd96eed27ceb2aa35285991a745a5cd119abc","externalIds":{"MAG":"3102657423","DBLP":"conf/emnlp/MeisterCV20","ArXiv":"2010.02650","ACL":"2020.emnlp-main.170","DOI":"10.18653/v1/2020.emnlp-main.170","CorpusId":222141794},"title":"If Beam Search Is the Answer, What Was the Question?"},{"paperId":"814a4f680b9ba6baba23b93499f4b48af1a27678","externalIds":{"ArXiv":"2009.03300","DBLP":"journals/corr/abs-2009-03300","MAG":"3083410900","CorpusId":221516475},"title":"Measuring Massive Multitask Language Understanding"},{"paperId":"053b1d7b97eb2c91fc3921d589c160b0923c70b1","externalIds":{"MAG":"3082115681","DBLP":"journals/corr/abs-2009-01325","ArXiv":"2009.01325","CorpusId":221665105},"title":"Learning to summarize from human feedback"},{"paperId":"781b9a445d1878ee4744546f2b8c7466e3cbbd1a","externalIds":{"DBLP":"journals/corr/abs-2007-12626","MAG":"3045321166","ArXiv":"2007.12626","DOI":"10.1162/tacl_a_00373","CorpusId":220768873},"title":"SummEval: Re-evaluating Summarization Evaluation"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"b873d3aed0b09d41d9347f10a7e2aa267e1684a3","externalIds":{"MAG":"3026758008","ArXiv":"2005.11739","DBLP":"journals/corr/abs-2005-11739","CorpusId":218870458},"title":"Adversarial NLI for Factual Correctness in Text Summarisation Models"},{"paperId":"659bf9ce7175e1ec266ff54359e2bd76e0b7ff31","externalIds":{"DBLP":"conf/nips/LewisPPPKGKLYR020","MAG":"3027879771","ArXiv":"2005.11401","CorpusId":218869575},"title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"},{"paperId":"273e7a33ec437dab8c1c4640f54891dcfe8d5fab","externalIds":{"ACL":"2020.lrec-1.113","DBLP":"conf/lrec/GyawaliAK20","MAG":"3032503335","CorpusId":218974370},"title":"Deduplication of Scholarly Documents using Locality Sensitive Hashing and Word Embeddings"},{"paperId":"11b6d1fee0f47a8f9f892ab0d86f370c449097aa","externalIds":{"MAG":"3099766584","DBLP":"journals/corr/abs-2005-03754","ACL":"2020.acl-main.454","ArXiv":"2005.03754","DOI":"10.18653/V1/2020.ACL-MAIN.454","CorpusId":218571335},"title":"FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization"},{"paperId":"0b15c6acfc9f7f92c52aa6a185a829f88975c743","externalIds":{"MAG":"3022463379","ArXiv":"2005.03642","ACL":"2020.acl-main.326","DBLP":"journals/corr/abs-2005-03642","DOI":"10.18653/v1/2020.acl-main.326","CorpusId":218538004},"title":"On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation"},{"paperId":"29e86cbeacf1e2235cc320ad240956012b294646","externalIds":{"MAG":"3021150969","DBLP":"conf/acl/WangWAYC20","ArXiv":"2005.00969","ACL":"2020.acl-main.101","DOI":"10.18653/v1/2020.acl-main.101","CorpusId":218487237},"title":"Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints"},{"paperId":"47fd2e73a9be04ed2186c03d8f88d5c87f64e4e4","externalIds":{"MAG":"3022814719","DBLP":"journals/corr/abs-2004-14373","ArXiv":"2004.14373","ACL":"2020.emnlp-main.89","DOI":"10.18653/v1/2020.emnlp-main.89","CorpusId":216641852},"title":"ToTTo: A Controlled Table-To-Text Generation Dataset"},{"paperId":"3ed06aca3b25a9af89f08b949753372d29647a10","externalIds":{"MAG":"3154046074","ACL":"2021.humeval-1.3","DBLP":"journals/corr/abs-2004-10450","ArXiv":"2004.10450","CorpusId":216056240},"title":"Trading Off Diversity and Quality in Natural Language Generation"},{"paperId":"5e0daaeceb75ffbbe23be13d34ffae830cb4e8c4","externalIds":{"DBLP":"conf/acl/AtanasovaSLA20","MAG":"3035317050","ACL":"2020.acl-main.656","ArXiv":"2004.05773","DOI":"10.18653/v1/2020.acl-main.656","CorpusId":215744944},"title":"Generating Fact Checking Explanations"},{"paperId":"b26f2037f769d5ffc5f7bdcec2de8da28ec14bee","externalIds":{"MAG":"3015883388","ArXiv":"2004.04906","DBLP":"conf/emnlp/KarpukhinOMLWEC20","ACL":"2020.emnlp-main.550","DOI":"10.18653/v1/2020.emnlp-main.550","CorpusId":215737187},"title":"Dense Passage Retrieval for Open-Domain Question Answering"},{"paperId":"925ad2897d1b5decbea320d07e99afa9110e09b2","externalIds":{"DBLP":"journals/corr/abs-2004-05150","MAG":"3015468748","ArXiv":"2004.05150","CorpusId":215737171},"title":"Longformer: The Long-Document Transformer"},{"paperId":"d36e39aedd802aea4be1ea303c70dc56e97dbc3c","externalIds":{"ArXiv":"2004.04228","ACL":"2020.acl-main.450","DBLP":"journals/corr/abs-2004-04228","MAG":"3034188538","DOI":"10.18653/v1/2020.acl-main.450","CorpusId":215548661},"title":"Asking and Answering Questions to Evaluate the Factual Consistency of Summaries"},{"paperId":"e165b379f983152874299e0f5a6e0c9596c9a3e8","externalIds":{"DBLP":"conf/iclr/SinitsinPPPB20","ArXiv":"2004.00345","MAG":"3014924543","CorpusId":213938729},"title":"Editable Neural Networks"},{"paperId":"aa58b78207bd248dbd66b912863850ca67d5fd5c","externalIds":{"MAG":"3006320872","ArXiv":"2002.06353","DBLP":"journals/corr/abs-2002-06353","CorpusId":211132410},"title":"UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation"},{"paperId":"832fff14d2ed50eb7969c4c4b976c35776548f56","externalIds":{"ArXiv":"2002.08909","MAG":"3034671305","DBLP":"conf/icml/GuuLTPC20","CorpusId":211204736},"title":"REALM: Retrieval-Augmented Language Model Pre-Training"},{"paperId":"80376bdec5f534be78ba82821f540590ebce5559","externalIds":{"DBLP":"journals/corr/abs-2002-08910","MAG":"3102659883","ACL":"2020.emnlp-main.437","ArXiv":"2002.08910","DOI":"10.18653/v1/2020.emnlp-main.437","CorpusId":211205183},"title":"How Much Knowledge Can You Pack into the Parameters of a Language Model?"},{"paperId":"e6c561d02500b2596a230b341a8eb8b921ca5bf2","externalIds":{"MAG":"3001279689","ArXiv":"2001.08361","DBLP":"journals/corr/abs-2001-08361","CorpusId":210861095},"title":"Scaling Laws for Neural Language Models"},{"paperId":"f4061bd225b3be5b3f5b18eb1a229ce991efefeb","externalIds":{"MAG":"2996264288","ArXiv":"1912.08777","DBLP":"conf/icml/ZhangZSL20","CorpusId":209405420},"title":"PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"0c5598424cc96d8fb500eb553cb7969f86a0ede0","externalIds":{"MAG":"2981456979","ArXiv":"1910.12840","DBLP":"journals/corr/abs-1910-12840","ACL":"2020.emnlp-main.750","DOI":"10.18653/v1/2020.emnlp-main.750","CorpusId":204976362},"title":"Evaluating the Factual Consistency of Abstractive Text Summarization"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"e04a80263d252a3d8a382ba37a249b9345620570","externalIds":{"DBLP":"conf/iclr/DathathriMLHFMY20","ArXiv":"1912.02164","MAG":"2993398598","CorpusId":208617790},"title":"Plug and Play Language Models: A Simple Approach to Controlled Text Generation"},{"paperId":"80c65cac35a43f7e88917cb6d517554c7b175259","externalIds":{"MAG":"2981259322","ArXiv":"1910.08684","DBLP":"journals/corr/abs-1910-08684","CorpusId":204800468},"title":"Sticking to the Facts: Confident Decoding for Faithful Data-to-Text Generation"},{"paperId":"d8cb11d4be955f9869387a18967dee366eb851d9","externalIds":{"DBLP":"journals/corr/abs-1909-03242","ACL":"D19-1475","MAG":"2971911738","ArXiv":"1909.03242","DOI":"10.18653/v1/D19-1475","CorpusId":202541363},"title":"MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims"},{"paperId":"d0086b86103a620a86bc918746df0aa642e2a8a3","externalIds":{"DBLP":"journals/corr/abs-1909-01066","MAG":"2996758945","ArXiv":"1909.01066","ACL":"D19-1250","DOI":"10.18653/v1/D19-1250","CorpusId":202539551},"title":"Language Models as Knowledge Bases?"},{"paperId":"6897deee6838921dabcc4ef2c958b995e1404893","externalIds":{"DBLP":"conf/conll/HanselowskiSSLG19","ACL":"K19-1046","MAG":"2988245244","ArXiv":"1911.01214","DOI":"10.18653/v1/K19-1046","CorpusId":207779874},"title":"A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking"},{"paperId":"d3231772937a2182b2377d028417245c49868dd1","externalIds":{"ACL":"D19-1331","DBLP":"journals/corr/abs-1908-10090","MAG":"2971351767","ArXiv":"1908.10090","DOI":"10.18653/v1/D19-1331","CorpusId":201646223},"title":"On NMT Search Errors and Model Errors: Cat Got Your Tongue?"},{"paperId":"e47e6c814d2742527fdd352db13a5fd95b7ce24b","externalIds":{"DBLP":"journals/corr/abs-1908-04942","ArXiv":"1908.04942","MAG":"2994900646","CorpusId":199577786},"title":"Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation"},{"paperId":"53a77e8f73f2ca422d6e38fa9ecc490231ac044c","externalIds":{"MAG":"2968297680","DBLP":"conf/iclr/WelleckKRDCW20","ArXiv":"1908.04319","CorpusId":199551982},"title":"Neural Text Generation with Unlikelihood Training"},{"paperId":"17dbd7b72029181327732e4d11b52a08ed4630d0","externalIds":{"ACL":"Q19-1026","MAG":"2912924812","DBLP":"journals/tacl/KwiatkowskiPRCP19","DOI":"10.1162/tacl_a_00276","CorpusId":86611921},"title":"Natural Questions: A Benchmark for Question Answering Research"},{"paperId":"ebf59587f8f170ff4241c42263bbfb9da5bd2135","externalIds":{"MAG":"2964040452","DBLP":"conf/acl/FanJPGWA19","ACL":"P19-1346","ArXiv":"1907.09190","DOI":"10.18653/v1/P19-1346","CorpusId":196170479},"title":"ELI5: Long Form Question Answering"},{"paperId":"b3564be8b79f25585acb035f3deaf4ae93c26d8f","externalIds":{"MAG":"2952744660","DBLP":"journals/tacl/Hahn20","ACL":"2020.tacl-1.11","ArXiv":"1906.06755","DOI":"10.1162/tacl_a_00306","CorpusId":189928186},"title":"Theoretical Limitations of Self-Attention in Neural Sequence Models"},{"paperId":"8d89f85b5f8a1d65b4e93a7ebb793618641c3ece","externalIds":{"MAG":"2963040760","DBLP":"conf/kdd/GoodrichRLS19","ArXiv":"1905.13322","DOI":"10.1145/3292500.3330955","CorpusId":173188138},"title":"Assessing The Factual Accuracy of Generated Text"},{"paperId":"470c7c26f16bc52ea68a159c84f07b78d58fd02a","externalIds":{"MAG":"2951211142","DBLP":"conf/acl/FalkeRUDG19","ACL":"P19-1213","DOI":"10.18653/v1/P19-1213","CorpusId":196187162},"title":"Ranking Generated Summaries by Correctness: An Interesting but Challenging Application for Natural Language Inference"},{"paperId":"07a64686ce8e43ac475a8d820a8a9f1d87989583","externalIds":{"MAG":"2951528897","DBLP":"journals/corr/abs-1905-09418","ACL":"P19-1580","ArXiv":"1905.09418","DOI":"10.18653/v1/P19-1580","CorpusId":162183964},"title":"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"},{"paperId":"cf4aa38ae31b43fd07abe13b4ffdb265babb7be1","externalIds":{"DBLP":"journals/corr/abs-1904-09751","MAG":"2938704169","ArXiv":"1904.09751","CorpusId":127986954},"title":"The Curious Case of Neural Text Degeneration"},{"paperId":"1cbf4e4804ea636d78293964bffe7b2493444f9a","externalIds":{"DBLP":"journals/taslp/ZhangZLZ19","MAG":"2903268415","DOI":"10.1109/TASLP.2018.2883740","CorpusId":56597185},"title":"Attention With Sparsity Regularization for Neural Machine Translation and Summarization"},{"paperId":"6dfc2ff03534a4325d06c6f88c3144831996629b","externalIds":{"MAG":"2958882215","ArXiv":"1811.10830","DBLP":"conf/cvpr/ZellersBFC19","DOI":"10.1109/CVPR.2019.00688","CorpusId":53734356},"title":"From Recognition to Cognition: Visual Commonsense Reasoning"},{"paperId":"22655979df781d222eaf812b0d325fa9adf11594","externalIds":{"ACL":"D18-1259","DBLP":"journals/corr/abs-1809-09600","MAG":"2952862139","ArXiv":"1809.09600","DOI":"10.18653/v1/D18-1259","CorpusId":52822214},"title":"HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"},{"paperId":"305b2cf37e5dece81e95c92883d5a6e28ac93b22","externalIds":{"DBLP":"conf/emnlp/NarayanCL18","MAG":"2888482885","ArXiv":"1808.08745","ACL":"D18-1206","DOI":"10.18653/v1/D18-1206","CorpusId":215768182},"title":"Don‚Äôt Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"},{"paperId":"29de7c0fb3c09eaf55b20619bceaeafe72fd87a6","externalIds":{"MAG":"2963096510","DBLP":"conf/acl/LewisDF18","ArXiv":"1805.04833","ACL":"P18-1082","DOI":"10.18653/v1/P18-1082","CorpusId":44134226},"title":"Hierarchical Neural Story Generation"},{"paperId":"ef9ddbc35676ce8ffc2a8067044473727839dbac","externalIds":{"ArXiv":"1711.03953","MAG":"2767321762","DBLP":"journals/corr/abs-1711-03953","CorpusId":26238954},"title":"Breaking the Softmax Bottleneck: A High-Rank RNN Language Model"},{"paperId":"dce6f9d4017b1785979e7520fd0834ef8cf02f4b","externalIds":{"MAG":"2736601468","DBLP":"journals/corr/SchulmanWDRK17","ArXiv":"1707.06347","CorpusId":28695052},"title":"Proximal Policy Optimization Algorithms"},{"paperId":"5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd","externalIds":{"MAG":"2626804490","ArXiv":"1706.03741","DBLP":"conf/nips/ChristianoLBMLA17","CorpusId":4787508},"title":"Deep Reinforcement Learning from Human Preferences"},{"paperId":"802168a81571dde28f5ddb94d84677bc007afa7b","externalIds":{"DBLP":"conf/nips/Lakshminarayanan17","ArXiv":"1612.01474","MAG":"2963238274","CorpusId":6294674},"title":"Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles"},{"paperId":"b7aee9dfb027d6061c6a653684c0fa9a9bba750d","externalIds":{"ArXiv":"1511.06732","MAG":"2950469587","DBLP":"journals/corr/RanzatoCAZ15","CorpusId":7147309},"title":"Sequence Level Training with Recurrent Neural Networks"},{"paperId":"62adfea3cc1cd9eb6b53e0e8a40be5dfda2adf8d","externalIds":{"MAG":"2164411961","DBLP":"conf/icml/BlundellCKW15","CorpusId":39895556},"title":"Weight Uncertainty in Neural Network"},{"paperId":"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99","externalIds":{"MAG":"648786980","DBLP":"conf/nips/BengioVJS15","ArXiv":"1506.03099","CorpusId":1820089},"title":"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks"},{"paperId":"f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6","externalIds":{"MAG":"2964059111","DBLP":"conf/icml/GalG16","ArXiv":"1506.02142","CorpusId":160705},"title":"Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"},{"paperId":"60b05f32c32519a809f21642ef1eb3eaf3848008","externalIds":{"MAG":"2154652894","ACL":"W04-1013","CorpusId":964287},"title":"ROUGE: A Package for Automatic Evaluation of Summaries"},{"paperId":"8addb1718c2bc6bbb0d82cd1a57b41198bf65965","externalIds":{"MAG":"2968856527","DBLP":"conf/sequences/Broder97","DOI":"10.1109/SEQUEN.1997.666900","CorpusId":11748509},"title":"On the resemblance and containment of documents"},{"paperId":"1337a72073e2c80da6e53b776ccb469d5abb0579","externalIds":{"MAG":"1969173824","DBLP":"conf/soda/ManberM90","DOI":"10.1137/0222058","CorpusId":5074629},"title":"Suffix arrays: a new method for on-line string searches"},{"paperId":"7d47ee5f84103529f84297c98c21dadb4742e3ff","externalIds":{"MAG":"2013784666","DOI":"10.1093/BIOMET/39.3-4.324","CorpusId":121987403},"title":"RANK ANALYSIS OF INCOMPLETE BLOCK DESIGNS THE METHOD OF PAIRED COMPARISONS"},{"paperId":"04dd492b506e48b7dd91ecb1e1fdb80c1ce30e34","externalIds":{"DBLP":"journals/corr/abs-2308-11914","DOI":"10.48550/arXiv.2308.11914","CorpusId":261076364},"title":"Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs"},{"paperId":"95dc92fe93ebb187e00f0137920241e8b5d34b1e","externalIds":{"DBLP":"journals/corr/abs-2304-10513","DOI":"10.48550/arXiv.2304.10513","CorpusId":258236218},"title":"Why Does ChatGPT Fall Short in Answering Questions Faithfully?"},{"paperId":"f48287e9ed131ff8ffa79b66717887c5af74f203","externalIds":{"ACL":"2023.eacl-main.234","DBLP":"conf/eacl/LadhakDSZJMH23","DOI":"10.18653/v1/2023.eacl-main.234","CorpusId":258378241},"title":"When Do Pre-Training Biases Propagate to Downstream Tasks? A Case Study in Text Summarization"},{"paperId":"c9dff8253b2e776abf363d0a4836abcaf64ee327","externalIds":{"DBLP":"journals/corr/abs-2303-14070","DOI":"10.48550/arXiv.2303.14070","CorpusId":257756992},"title":"ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge"},{"paperId":"65d5728ea17f016382870aa27aac1e78d590b50c","externalIds":{"DBLP":"journals/corr/abs-2310-14566","DOI":"10.48550/arXiv.2310.14566","CorpusId":264426657},"title":"HallusionBench: You See What You Think? Or You Think What You See? An Image-Context Reasoning Benchmark Challenging for GPT-4V(ision), LLaVA-1.5, and Other Multi-modality Models"},{"paperId":"5b2aa9b3912025db43315475c8eca164b876de4a","externalIds":{"DBLP":"journals/corr/abs-2309-15402","DOI":"10.48550/arXiv.2309.15402","CorpusId":281603643},"title":"A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"},{"paperId":"06080f8c586643a5a2e759f036b728bece876ef2","externalIds":{"DBLP":"conf/acl/GuFMWG022","ACL":"2022.findings-acl.272","DOI":"10.18653/v1/2022.findings-acl.272","CorpusId":248780081},"title":"Improving Controllable Text Generation with Position-Aware Weighted Decoding"},{"paperId":"7450a612ef291216b0cd48e09b8879be4675c6eb","externalIds":{"ACL":"2022.acl-long.554","DBLP":"conf/acl/ChangM22","DOI":"10.18653/v1/2022.acl-long.554","CorpusId":248780434},"title":"Softmax Bottleneck Makes Language Models Unable to Represent Multi-mode Word Distributions"},{"paperId":"5b91b9b3a28cd774fcacad2f21130fe731bddb41","externalIds":{"ACL":"2021.emnlp-main.113","DBLP":"conf/emnlp/BrancoBRS21","DOI":"10.18653/v1/2021.emnlp-main.113","CorpusId":243865348},"title":"Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning"},{"paperId":"787d8ae2d303619b7009cf84e13950d1f330c185","externalIds":{"DBLP":"journals/corr/abs-2105-00071","CorpusId":263881474},"title":"Evaluating Groundedness in Dialogue Systems: The BEGIN Benchmark"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"5c55e60ffc892ee231952ae514e3dcea86ffb375","externalIds":{"MAG":"2970184163","DBLP":"conf/nips/YangLSL19","CorpusId":202788213},"title":"Mixtape: Breaking the Softmax Bottleneck Efficiently"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"}]}