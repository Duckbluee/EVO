{"paperId":"c950833b4306f78eddcb651dd17d9b9670b77a2f","externalIds":{"ArXiv":"2408.14520","DBLP":"journals/corr/abs-2408-14520","DOI":"10.48550/arXiv.2408.14520","CorpusId":271962801},"title":"Towards Graph Prompt Learning: A Survey and Beyond","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2408.14520, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2282338959","name":"Qingqing Long"},{"authorId":"2284862834","name":"Yuchen Yan"},{"authorId":"2317132394","name":"Peiyan Zhang"},{"authorId":"2253465330","name":"Chen Fang"},{"authorId":"2324804426","name":"Wentao Cui"},{"authorId":"2053976443","name":"Zhiyuan Ning"},{"authorId":"2311703192","name":"Meng Xiao"},{"authorId":"2317012275","name":"Ning Cao"},{"authorId":"2288690172","name":"Xiao Luo"},{"authorId":"2317027895","name":"Lingjun Xu"},{"authorId":"2317029013","name":"Shiyue Jiang"},{"authorId":"2282505948","name":"Zheng Fang"},{"authorId":"2257378991","name":"Chong Chen"},{"authorId":"2238119871","name":"Xian-Sheng Hua"},{"authorId":"2259918839","name":"Yuanchun Zhou"}],"abstract":"Large-scale\"pre-train and prompt learning\"paradigms have demonstrated remarkable adaptability, enabling broad applications across diverse domains such as question answering, image recognition, and multimodal retrieval. This approach fully leverages the potential of large-scale pre-trained models, reducing downstream data requirements and computational costs while enhancing model applicability across various tasks. Graphs, as versatile data structures that capture relationships between entities, play pivotal roles in fields such as social network analysis, recommender systems, and biological graphs. Despite the success of pre-train and prompt learning paradigms in Natural Language Processing (NLP) and Computer Vision (CV), their application in graph domains remains nascent. In graph-structured data, not only do the node and edge features often have disparate distributions, but the topological structures also differ significantly. This diversity in graph data can lead to incompatible patterns or gaps between pre-training and fine-tuning on downstream graphs. We aim to bridge this gap by summarizing methods for alleviating these disparities. This includes exploring prompt design methodologies, comparing related techniques, assessing application scenarios and datasets, and identifying unresolved problems and challenges. This survey categorizes over 100 relevant works in this field, summarizing general design principles and the latest applications, including text-attributed graphs, molecules, proteins, and recommendation systems. Through this extensive review, we provide a foundational understanding of graph prompt learning, aiming to impact not only the graph mining community but also the broader Artificial General Intelligence (AGI) community."}