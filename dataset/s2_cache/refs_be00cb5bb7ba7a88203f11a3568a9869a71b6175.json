{"references":[{"paperId":"65372e6a46c37c91fd7ca59598baa0be18600555","externalIds":{"DBLP":"journals/inffus/HuangHZXZ24","DOI":"10.1016/j.inffus.2024.102505","CorpusId":270346457},"title":"STFDiff: Remote sensing image spatiotemporal fusion with diffusion models"},{"paperId":"27a6a9310b77bbcf9d9669542a93a8a4926d28fc","externalIds":{"ArXiv":"2405.19237","DBLP":"journals/corr/abs-2405-19237","DOI":"10.48550/arXiv.2405.19237","CorpusId":270095429},"title":"ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning"},{"paperId":"c5357fe6549d026c2a028c1fbd2b3e8f899f4ecf","externalIds":{"ArXiv":"2405.16341","DBLP":"journals/corr/abs-2405-16341","DOI":"10.48550/arXiv.2405.16341","CorpusId":270063150},"title":"R.A.C.E.: Robust Adversarial Concept Erasure for Secure Text-to-Image Diffusion Model"},{"paperId":"914d075845ae26e1671b00836189fbd2fb20bf0c","externalIds":{"DBLP":"conf/aaai/WuZYWCZHZ025","ArXiv":"2405.15304","DOI":"10.48550/arXiv.2405.15304","CorpusId":270045623},"title":"Unlearning Concepts in Diffusion Model via Concept Domain Correction and Concept Preserving Gradient"},{"paperId":"3fdda2d3fe6156f7f0e48e4af62ff995484fe866","externalIds":{"DBLP":"conf/nips/ZhangCJZFL0DL24","ArXiv":"2405.15234","DOI":"10.48550/arXiv.2405.15234","CorpusId":270045486},"title":"Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models"},{"paperId":"0b481351bf96c1e741b0770458228e4a2f38ac4b","externalIds":{"DBLP":"journals/inffus/YiTZXM24","DOI":"10.1016/j.inffus.2024.102450","CorpusId":269584817},"title":"Diff-IF: Multi-modality image fusion via diffusion model with fusion knowledge prior"},{"paperId":"f526b38c863d4b89ec5b5744f5f1d623275a22b7","externalIds":{"ArXiv":"2404.08031","DBLP":"conf/eccv/LiuKGCTP24","DOI":"10.48550/arXiv.2404.08031","CorpusId":269137365},"title":"Latent Guard: a Safety Framework for Text-to-image Generation"},{"paperId":"18e10a05b80794e14a046833eae526eca718bfa7","externalIds":{"DBLP":"conf/naacl/MaLXCZYZ25","ArXiv":"2404.02928","DOI":"10.48550/arXiv.2404.02928","CorpusId":268889549},"title":"Jailbreaking Prompt Attack: A Controllable Adversarial Attack against Diffusion Models"},{"paperId":"1df9a99f1c2aebcdec1d17c268bf2f128a55d6c4","externalIds":{"ArXiv":"2403.04279","DBLP":"journals/corr/abs-2403-04279","DOI":"10.1109/TPAMI.2025.3646548","CorpusId":268264822,"PubMed":"41418008"},"title":"Controllable Generation with Text-to-Image Diffusion Models: A Survey"},{"paperId":"9d4cd5e3ab44f0d1dfe201c6be70aa7a692ac7f1","externalIds":{"ArXiv":"2403.01446","DBLP":"conf/nips/Yang0YZ024","DOI":"10.48550/arXiv.2403.01446","CorpusId":268249097},"title":"GuardT2I: Defending Text-to-Image Models from Adversarial Prompts"},{"paperId":"91d85905a8e9ae6ba62e562bba32d61c619a8155","externalIds":{"ArXiv":"2402.12100","DBLP":"journals/corr/abs-2402-12100","DOI":"10.48550/arXiv.2402.12100","CorpusId":267750760},"title":"Groot: Adversarial Testing for Generative Text-to-Image Models with Tree-based Semantic Transformation"},{"paperId":"76ef69130c4d3e020ed94b17d2f7557574eb9c24","externalIds":{"DBLP":"journals/corr/abs-2402-10882","ArXiv":"2402.10882","ACL":"2024.naacl-long.351","DOI":"10.48550/arXiv.2402.10882","CorpusId":267740666},"title":"Universal Prompt Optimizer for Safe Text-to-Image Generation"},{"paperId":"f568a7bf423121780a552d6819ca6623112578f7","externalIds":{"DBLP":"conf/fat/QuayePIRKKLBTWC24","ArXiv":"2403.12075","DOI":"10.1145/3630106.3658913","CorpusId":268532170},"title":"Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation"},{"paperId":"5873075c75d90bb3f2275ee689102efad27fdc35","externalIds":{"ArXiv":"2401.11631","DBLP":"journals/corr/abs-2401-11631","DOI":"10.48550/arXiv.2401.11631","CorpusId":267068435},"title":"Text-to-Image Cross-Modal Generation: A Systematic Review"},{"paperId":"33f4b3521fd8c4d3365bb44616415e2602925f63","externalIds":{"ArXiv":"2401.08725","DBLP":"journals/corr/abs-2401-08725","DOI":"10.48550/arXiv.2401.08725","CorpusId":267028287},"title":"Revealing Vulnerabilities in Stable Diffusion via Targeted Attacks"},{"paperId":"49cd807031bb658e13df21fc05a79c77f0c6b6d3","externalIds":{"ArXiv":"2312.14440","DBLP":"conf/acl/ShahgirKSD24","DOI":"10.48550/arXiv.2312.14440","CorpusId":266521564},"title":"Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks"},{"paperId":"3b07dd8eeb08aa90012b8602d43c2f9aa03373df","externalIds":{"DBLP":"conf/aaai/HongLW24","ArXiv":"2312.12807","DOI":"10.48550/arXiv.2312.12807","CorpusId":266374816},"title":"All but One: Surgical Concept Erasing with Model Preservation in Text-to-Image Diffusion Models"},{"paperId":"50e46bffb3d6e6818b98584507a25575d43d7728","externalIds":{"DBLP":"conf/cvpr/Yang0WHX024","ArXiv":"2311.17516","DOI":"10.1109/CVPR52733.2024.00739","CorpusId":265498727},"title":"MMA-Diffusion: MultiModal Attack on Diffusion Models"},{"paperId":"9557fdd24eb15a70eebc7a8093fd44a0ae7f4294","externalIds":{"DBLP":"conf/eccv/HuangCTLYW24","ArXiv":"2311.17717","DOI":"10.48550/arXiv.2311.17717","CorpusId":265498506},"title":"Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via Lightweight Erasers"},{"paperId":"11551d9311339daa37613eef74adc099b31fcd86","externalIds":{"DBLP":"conf/eccv/ZhangJCCZLDL24","ArXiv":"2310.11868","DOI":"10.48550/arXiv.2310.11868","CorpusId":264289091},"title":"To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy To Generate Unsafe Images ... For Now"},{"paperId":"04983bbf48ab9649e3e6dcb7f4fadd7d04c89bbd","externalIds":{"DBLP":"journals/corr/abs-2310-10012","ArXiv":"2310.10012","DOI":"10.48550/arXiv.2310.10012","CorpusId":264146485},"title":"Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion Models?"},{"paperId":"4f63c5a89c7299a864c6c48aa1844fb0fe8c9437","externalIds":{"ArXiv":"2310.10844","DBLP":"journals/corr/abs-2310-10844","DOI":"10.48550/arXiv.2310.10844","CorpusId":264172191},"title":"Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks"},{"paperId":"e1decb86f2a6aba8682d2fc4e427424b0b49e0d0","externalIds":{"ArXiv":"2309.14122","DBLP":"conf/ccs/BaZL0WQ0024","DOI":"10.1145/3658644.3690346","CorpusId":262465788},"title":"SurrogatePrompt: Bypassing the Safety Filter of Text-to-Image Models via Substitution"},{"paperId":"e78722bd95ace8c29458ac22967784edf54658b2","externalIds":{"DBLP":"journals/corr/abs-2309-11575","ACL":"2023.artofsafety-1.3","ArXiv":"2309.11575","DOI":"10.48550/arXiv.2309.11575","CorpusId":262083985},"title":"Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge"},{"paperId":"f4b88a1a6a877cbeb9faaf99eccc5e1ed9f2ea6b","externalIds":{"DBLP":"conf/icml/ChinJHCC24","ArXiv":"2309.06135","DOI":"10.48550/arXiv.2309.06135","CorpusId":261696559},"title":"Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by Finding Problematic Prompts"},{"paperId":"e367992ca8deed39d18717a3ef08aa05a94128c0","externalIds":{"ArXiv":"2308.14761","DBLP":"conf/wacv/GandikotaOBMB24","DOI":"10.1109/WACV57701.2024.00503","CorpusId":261276613},"title":"Unified Concept Editing in Diffusion Models"},{"paperId":"ad97671a924a9b3a060fee857e561f140ec79dd7","externalIds":{"DBLP":"conf/iclr/ChenSZ0YCYLHQQC24","ArXiv":"2308.10848","DOI":"10.48550/arXiv.2308.10848","CorpusId":261048935},"title":"AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents"},{"paperId":"19443d48399d4fe89a4b0a96917c50c6fd9c5af1","externalIds":{"DBLP":"journals/corr/abs-2308-04265","ArXiv":"2308.04265","ACL":"2024.emnlp-main.41","DOI":"10.48550/arXiv.2308.04265","CorpusId":260704223},"title":"FLIRT: Feedback Loop In-context Red Teaming"},{"paperId":"5bc18d44a8c021f15c5fb9ba3350c9da2076db19","externalIds":{"DBLP":"journals/corr/abs-2308-02552","ArXiv":"2308.02552","DOI":"10.1145/3581783.3611867","CorpusId":260682786},"title":"Degeneration-Tuning: Using Scrambled Grid shield Unwanted Concepts from Stable Diffusion"},{"paperId":"703035b483c181953de1b55b5fd59cd4cd4cf211","externalIds":{"DBLP":"journals/corr/abs-2308-00352","ArXiv":"2308.00352","DOI":"10.48550/arXiv.2308.00352","CorpusId":260351380},"title":"MetaGPT: Meta Programming for Multi-Agent Collaborative Framework"},{"paperId":"40719b9f384077bc077ccb8a37b214074672049d","externalIds":{"ArXiv":"2307.05977","DBLP":"journals/corr/abs-2307-05977","DOI":"10.48550/arXiv.2307.05977","CorpusId":259837117},"title":"Towards Safe Self-Distillation of Internet-Scale Text-to-Image Diffusion Models"},{"paperId":"587352c3b95c90de6d37f061c8e117f42be0b575","externalIds":{"DBLP":"journals/corr/abs-2307-02485","ArXiv":"2307.02485","DOI":"10.48550/arXiv.2307.02485","CorpusId":259342833},"title":"Building Cooperative Embodied Agents Modularly with Large Language Models"},{"paperId":"d7890d1906d95c4ae4c430b350455156d6d8aed9","externalIds":{"DBLP":"conf/iclr/PodellELBDMPR24","ArXiv":"2307.01952","CorpusId":259341735},"title":"SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis"},{"paperId":"d115238c6ee8fcdd635247f871d25732b457d1d3","externalIds":{"DBLP":"journals/corr/abs-2306-13754","ArXiv":"2306.13754","DOI":"10.1109/ICCV51070.2023.00207","CorpusId":259252153},"title":"Zero-shot spatial layout conditioning for text-to-image diffusion models"},{"paperId":"7d22ad3573101337bca2091fb0114b377c4f3db6","externalIds":{"DBLP":"journals/corr/abs-2306-11695","ArXiv":"2306.11695","DOI":"10.48550/arXiv.2306.11695","CorpusId":259203115},"title":"A Simple and Effective Pruning Approach for Large Language Models"},{"paperId":"0b4e869d583092a950e7c44f94f0f6646b6685b2","externalIds":{"ArXiv":"2306.13103","DBLP":"journals/corr/abs-2306-13103","DOI":"10.48550/arXiv.2306.13103","CorpusId":259244070},"title":"Evaluating the Robustness of Text-to-image Diffusion Models against Real-world Attacks"},{"paperId":"a903e1e0ffd04dd666f3537f6570d742d7be3486","externalIds":{"ArXiv":"2306.05427","DBLP":"conf/cvpr/PhungGH24","DOI":"10.1109/CVPR52733.2024.00758","CorpusId":259108247},"title":"Grounded Text-to-Image Synthesis with Attention Refocusing"},{"paperId":"1df88172eccd35ea5cb74bfc1d4a31b6e8c4742c","externalIds":{"DBLP":"journals/inffus/BanieckiB24","ArXiv":"2306.06123","DOI":"10.1016/j.inffus.2024.102303","CorpusId":259138334},"title":"Adversarial Attacks and Defenses in Explainable Artificial Intelligence: A Survey"},{"paperId":"9523e62dc3a1195bb6e7bf9678664b48f0c84257","externalIds":{"ArXiv":"2306.02583","DBLP":"conf/nips/Du0Q023","DOI":"10.48550/arXiv.2306.02583","CorpusId":259075287},"title":"Stable Diffusion is Unstable"},{"paperId":"21512c6f104db13b669238299226e83599c96c7d","externalIds":{"ArXiv":"2306.00738","DBLP":"conf/naacl/AradOB24","ACL":"2024.naacl-long.140","DOI":"10.48550/arXiv.2306.00738","CorpusId":258999989},"title":"ReFACT: Updating Text-to-Image Models by Editing the Text Encoder"},{"paperId":"586c5eac39919f81f05c1e3d0737e446b6457f53","externalIds":{"DBLP":"conf/cvpr/LiuWZ0Z23","DOI":"10.1109/CVPR52729.2023.01972","CorpusId":260055051},"title":"RIATIG: Reliable and Imperceptible Adversarial Text-to-Image Generation with Natural Prompts"},{"paperId":"e9ae0c76a71b8f302eb17b1c4462b9cc97d87cd0","externalIds":{"DBLP":"journals/tmlr/LianLYD24","ArXiv":"2305.13655","DOI":"10.48550/arXiv.2305.13655","CorpusId":258841035},"title":"LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models"},{"paperId":"c9e548d72f5ad72215025602be36f72042219baf","externalIds":{"DBLP":"conf/ccs/QuSH0Z023","ArXiv":"2305.13873","DOI":"10.1145/3576915.3616679","CorpusId":258841623},"title":"Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes From Text-To-Image Models"},{"paperId":"f5c73d9e6641b018b633690102121f5605d34fb0","externalIds":{"DBLP":"conf/emnlp/YaoWT0LDC023","ArXiv":"2305.13172","DOI":"10.48550/arXiv.2305.13172","CorpusId":258833129},"title":"Editing Large Language Models: Problems, Methods, and Opportunities"},{"paperId":"9f411fda2ad5b141a3115f707bcf5ee865b3fb94","externalIds":{"DBLP":"conf/nips/TangYZ0B23","ArXiv":"2305.11846","DOI":"10.48550/arXiv.2305.11846","CorpusId":258822817},"title":"Any-to-Any Generation via Composable Diffusion"},{"paperId":"4e75ae56dc134abb076c3c6513d4d80751393df1","externalIds":{"ArXiv":"2305.10120","DBLP":"conf/nips/HengS23","DOI":"10.48550/arXiv.2305.10120","CorpusId":258740988},"title":"Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models"},{"paperId":"83cebf919635504786fc220d569284842b0f0a09","externalIds":{"DBLP":"journals/csur/GoyalDKR23","DOI":"10.1145/3593042","CorpusId":260927597},"title":"A Survey of Adversarial Defenses and Robustness in NLP"},{"paperId":"d9b95937934d7291b7c253b28b6c9aaee033c91d","externalIds":{"DBLP":"journals/corr/abs-2303-17591","ArXiv":"2303.17591","DOI":"10.1109/CVPRW63382.2024.00182","CorpusId":257833863},"title":"Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models"},{"paperId":"8aa63acc55ff58423aadb8ad4a2884d751673109","externalIds":{"DBLP":"journals/corr/abs-2303-16378","ArXiv":"2303.16378","DOI":"10.1109/CVPRW59228.2023.00236","CorpusId":257804994},"title":"A Pilot Study of Query-Free Adversarial Attack against Stable Diffusion"},{"paperId":"62b368417eca18fe68d209e5a077392748450a29","externalIds":{"DBLP":"journals/corr/abs-2303-13516","ArXiv":"2303.13516","DOI":"10.1109/ICCV51070.2023.02074","CorpusId":257687839},"title":"Ablating Concepts in Text-to-Image Diffusion Models"},{"paperId":"db581c816341e2c0e743841fa45697827153a4ef","externalIds":{"DBLP":"journals/corr/abs-2303-08084","ArXiv":"2303.08084","DOI":"10.1109/ICCV51070.2023.00649","CorpusId":257505246},"title":"Editing Implicit Assumptions in Text-to-Image Diffusion Models"},{"paperId":"35ccd924de9e8483bdcf144cbf2edf09be157b7e","externalIds":{"ArXiv":"2303.07909","DBLP":"journals/corr/abs-2303-07909","DOI":"10.48550/arXiv.2303.07909","CorpusId":257505012},"title":"Text-to-image Diffusion Models in Generative AI: A Survey"},{"paperId":"7a106b9e32a40b523e80ef1ef262f39213aeed81","externalIds":{"DBLP":"conf/iccv/GandikotaMFB23","ArXiv":"2303.07345","DOI":"10.1109/ICCV51070.2023.00230","CorpusId":257495777},"title":"Erasing Concepts from Diffusion Models"},{"paperId":"9ced6e814457eae83f5415364e266143defc81d1","externalIds":{"DBLP":"journals/corr/abs-2302-08113","ArXiv":"2302.08113","DOI":"10.48550/arXiv.2302.08113","CorpusId":256900756},"title":"MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation"},{"paperId":"6c489a9dc649298aea729c91822a3c89de503729","externalIds":{"ArXiv":"2302.04237","CorpusId":258960116},"title":"Black Box Adversarial Prompting for Foundation Models"},{"paperId":"c3c7464acb90049c5f520b0732dc7435ba3690bd","externalIds":{"DBLP":"journals/tog/CheferAVWC23","ArXiv":"2301.13826","DOI":"10.1145/3592116","CorpusId":256416326},"title":"Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models"},{"paperId":"6e3a3b7a8a0376d867cad72eedf2f9b746f29a33","externalIds":{"DBLP":"journals/corr/abs-2301-11093","ArXiv":"2301.11093","DOI":"10.48550/arXiv.2301.11093","CorpusId":256274516},"title":"simple diffusion: End-to-end diffusion for high resolution images"},{"paperId":"012fee40a9dfafc5f4d56ac47acdede3d386935e","externalIds":{"DBLP":"journals/tcyb/LiWHTLLL23","DOI":"10.1109/TCYB.2022.3227805","CorpusId":255621195,"PubMed":"37018298"},"title":"Influence Maximization in Multiagent Systems by a Graph Embedding Method: Dealing With Probabilistically Unstable Links"},{"paperId":"736973165f98105fec3729b7db414ae4d80fcbeb","externalIds":{"DBLP":"journals/corr/abs-2212-09748","ArXiv":"2212.09748","DOI":"10.1109/ICCV51070.2023.00387","CorpusId":254854389},"title":"Scalable Diffusion Models with Transformers"},{"paperId":"16de2006e2960ba410772c6b6d460b83c0a5cc4b","externalIds":{"ArXiv":"2212.07143","DBLP":"journals/corr/abs-2212-07143","DOI":"10.1109/CVPR52729.2023.00276","CorpusId":254636568},"title":"Reproducible Scaling Laws for Contrastive Language-Image Learning"},{"paperId":"25de00096c45121a06668bc501f91adec5d0aff9","externalIds":{"ArXiv":"2212.05032","DBLP":"conf/iclr/FengHFJANBWW23","DOI":"10.48550/arXiv.2212.05032","CorpusId":254535649},"title":"Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis"},{"paperId":"35c7586457f8a158a967a3d73207ee8ecd1e8eb6","externalIds":{"DBLP":"journals/corr/abs-2211-14305","ArXiv":"2211.14305","DOI":"10.1109/CVPR52729.2023.01762","CorpusId":254018089},"title":"SpaText: Spatio-Textual Representation for Controllable Image Generation"},{"paperId":"a2d2bbe4c542173662a444b33b76c66992697830","externalIds":{"DBLP":"conf/cvpr/BrooksHE23","ArXiv":"2211.09800","DOI":"10.1109/CVPR52729.2023.01764","CorpusId":253581213},"title":"InstructPix2Pix: Learning to Follow Image Editing Instructions"},{"paperId":"0231f2aed9a96cb516242fb57f2cb63f5651c4d8","externalIds":{"DBLP":"journals/corr/abs-2211-05105","ArXiv":"2211.05105","DOI":"10.1109/CVPR52729.2023.02157","CorpusId":253420366},"title":"Safe Latent Diffusion: Mitigating Inappropriate Degeneration in Diffusion Models"},{"paperId":"e24f4b28167b05fbf7d29000490fc0a4e4c109c7","externalIds":{"ArXiv":"2211.01324","DBLP":"journals/corr/abs-2211-01324","DOI":"10.48550/arXiv.2211.01324","CorpusId":253254800},"title":"eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers"},{"paperId":"8fe6a16df99a87f79fc0cb0fbd1af44f79f7885f","externalIds":{"DBLP":"conf/acl/WangMMYHC23","ArXiv":"2210.14896","ACL":"2023.acl-long.51","DOI":"10.48550/arXiv.2210.14896","CorpusId":253116574},"title":"DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models"},{"paperId":"e5c8960eb2ec034ffbd353ef39fd1cb541d3c7c9","externalIds":{"DBLP":"conf/nips/SchuhmannBVGWCC22","ArXiv":"2210.08402","DOI":"10.48550/arXiv.2210.08402","CorpusId":252917726},"title":"LAION-5B: An open large-scale dataset for training next generation image-text models"},{"paperId":"1300e9287ae63473b05f8808883ca83b02943dbf","externalIds":{"ArXiv":"2210.04610","DBLP":"journals/corr/abs-2210-04610","DOI":"10.48550/arXiv.2210.04610","CorpusId":252780252},"title":"Red-Teaming the Stable Diffusion Safety Filter"},{"paperId":"4494d7639ab0377c33433acee687887c002ecd52","externalIds":{"ArXiv":"2209.08891","DBLP":"journals/jair/StruppekHFBSK23","DOI":"10.1613/jair.1.15388","CorpusId":256827140},"title":"Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis"},{"paperId":"efa1647594b236361610a20d507127f0586a379b","externalIds":{"DBLP":"journals/corr/abs-2209-04747","ArXiv":"2209.04747","DOI":"10.1109/TPAMI.2023.3261988","CorpusId":252199918,"PubMed":"37030794"},"title":"Diffusion Models in Vision: A Survey"},{"paperId":"35a29c47d5292e8967e5a9a8a21b23d8637b7d07","externalIds":{"DBLP":"journals/tkde/CaoTGXCHL24","ArXiv":"2209.02646","DOI":"10.1109/TKDE.2024.3361474","CorpusId":265039918},"title":"A Survey on Generative Diffusion Models"},{"paperId":"e342165a614588878ad0f4bc9bacf3905df34d08","externalIds":{"DBLP":"journals/corr/abs-2209-00796","ArXiv":"2209.00796","DOI":"10.1145/3626235","CorpusId":252070859},"title":"Diffusion Models: A Comprehensive Survey of Methods and Applications"},{"paperId":"5b19bf6c3f4b25cac96362c98b930cf4b37f6744","externalIds":{"ArXiv":"2208.12242","DBLP":"conf/cvpr/RuizLJPRA23","DOI":"10.1109/CVPR52729.2023.02155","CorpusId":251800180},"title":"DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation"},{"paperId":"7ac353d4468753e9a6cab80102b5f3fa4f9d6d60","externalIds":{"ArXiv":"2208.04135","DBLP":"journals/corr/abs-2208-04135","DOI":"10.48550/arXiv.2208.04135","CorpusId":251402769},"title":"Adversarial Attacks on Image Generation With Made-Up Words"},{"paperId":"af9f365ed86614c800f082bd8eb14be76072ad16","externalIds":{"DBLP":"journals/corr/abs-2207-12598","ArXiv":"2207.12598","DOI":"10.48550/arXiv.2207.12598","CorpusId":249145348},"title":"Classifier-Free Diffusion Guidance"},{"paperId":"1243e13254bb4ea1f71b4be8a3e4e54ffd02d2fe","externalIds":{"DBLP":"journals/tmlr/YuXKLBWVKYAHHPLZBW22","ArXiv":"2206.10789","DOI":"10.48550/arXiv.2206.10789","CorpusId":249926846},"title":"Scaling Autoregressive Models for Content-Rich Text-to-Image Generation"},{"paperId":"9695824d7a01fad57ba9c01d7d76a519d78d65e7","externalIds":{"DBLP":"journals/corr/abs-2205-11487","ArXiv":"2205.11487","DOI":"10.48550/arXiv.2205.11487","CorpusId":248986576},"title":"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"},{"paperId":"75bb9eda70751c63fc54dbe63377c673b7dbdb15","externalIds":{"DBLP":"journals/corr/abs-2204-14217","ArXiv":"2204.14217","DOI":"10.48550/arXiv.2204.14217","CorpusId":248476190},"title":"CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers"},{"paperId":"0ed8340d8c7e46047677c84929e72b3f1fc274c2","externalIds":{"ArXiv":"2201.08135","DBLP":"journals/inffus/BarrosoJLHM23","DOI":"10.1016/j.inffus.2022.09.011","CorpusId":246063583},"title":"Survey on Federated Learning Threats: concepts, taxonomy on attacks and defences, experimental study and challenges"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","externalIds":{"ArXiv":"2112.10752","DBLP":"journals/corr/abs-2112-10752","DOI":"10.1109/CVPR52688.2022.01042","CorpusId":245335280},"title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"7002ae048e4b8c9133a55428441e8066070995cb","externalIds":{"ArXiv":"2112.10741","DBLP":"journals/corr/abs-2112-10741","CorpusId":245335086},"title":"GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"},{"paperId":"97bee918b08c244eb2e54d41e8ea6da00a3e5dbf","externalIds":{"DBLP":"conf/eccv/WuLJYFJD22","ArXiv":"2111.12417","DOI":"10.1007/978-3-031-19787-1_41","CorpusId":244527261},"title":"NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion"},{"paperId":"3099a01b0e1c6ccc02da19b3c47a299f07d2c44c","externalIds":{"DOI":"10.1109/ITNEC52019.2021.9587104","CorpusId":243766443},"title":"Adversarial Attacks and defenses on Deep Learning Models in Natural Language Processing"},{"paperId":"1a0829a7bef8ea3ecb33b55871b4498dd328ff68","externalIds":{"DBLP":"journals/access/AkhtarMKS21","ArXiv":"2108.00401","DOI":"10.1109/ACCESS.2021.3127960","CorpusId":237396325},"title":"Advances in adversarial attacks and defenses in computer vision: A survey"},{"paperId":"1197ae4a62f0e0e4e3f3fb70396b5ff06ef371aa","externalIds":{"DBLP":"conf/nips/DingYHZZYLZSYT21","ArXiv":"2105.13290","CorpusId":235212350},"title":"CogView: Mastering Text-to-Image Generation via Transformers"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"2cd605106b88c85d7d8b865b1ef0f8c8293debf1","externalIds":{"ArXiv":"2102.12092","DBLP":"conf/icml/RameshPGGVRCS21","MAG":"3170016573","CorpusId":232035663},"title":"Zero-Shot Text-to-Image Generation"},{"paperId":"5c126ae3421f05768d8edd97ecd44b1364e2c99a","externalIds":{"DBLP":"conf/nips/HoJA20","MAG":"3100572490","ArXiv":"2006.11239","CorpusId":219955663},"title":"Denoising Diffusion Probabilistic Models"},{"paperId":"8e58dc63817a2a26e5a2ddad38d8b1d19d1c3795","externalIds":{"ArXiv":"1912.03817","DBLP":"journals/corr/abs-1912-03817","DOI":"10.1109/SP40001.2021.00019","CorpusId":208909851},"title":"Machine Unlearning"},{"paperId":"c956d133b78e0d9b20885593809f0b636ce34093","externalIds":{"ArXiv":"1911.04933","MAG":"2985940692","DBLP":"conf/cvpr/GolatkarAS20","DOI":"10.1109/cvpr42600.2020.00932","CorpusId":207863297},"title":"Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks"},{"paperId":"86d21de665d9e70882dd21d9923d04fbe6fc0a73","externalIds":{"MAG":"2969999645","ArXiv":"1910.01739","DBLP":"conf/nips/ErikssonPGTP19","CorpusId":202769642},"title":"Scalable Global Optimization via Local Bayesian Optimization"},{"paperId":"652107ea8161f607e3bdabc89199e9ff2fdfd015","externalIds":{"MAG":"2940009958","CorpusId":260428188},"title":"Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey"},{"paperId":"b514949ad8344071c0f342f182390d2d88bcc26d","externalIds":{"MAG":"2962700793","DBLP":"journals/corr/abs-1801-00553","ArXiv":"1801.00553","DOI":"10.1109/ACCESS.2018.2807385","CorpusId":3536399},"title":"Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey"},{"paperId":"231af7dc01a166cac3b5b01ca05778238f796e41","externalIds":{"MAG":"2963981733","DBLP":"conf/nips/HeuselRUNH17","CorpusId":326772},"title":"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"},{"paperId":"7aa38b85fa8cba64d6a4010543f6695dbf5f1386","externalIds":{"DBLP":"conf/iclr/MadryMSTV18","MAG":"2952649158","ArXiv":"1706.06083","CorpusId":3488815},"title":"Towards Deep Learning Models Resistant to Adversarial Attacks"},{"paperId":"e1773b5fb1af0e9d238a436912baacf5d15abe34","externalIds":{"DBLP":"conf/nips/TolstikhinSS16","MAG":"2551879329","CorpusId":10240721},"title":"Minimax Estimation of Maximum Mean Discrepancy with Radial Kernels"},{"paperId":"571b0750085ae3d939525e62af510ee2cee9d5ea","externalIds":{"DBLP":"conf/nips/SalimansGZCRCC16","ArXiv":"1606.03498","MAG":"2949938177","CorpusId":1687220},"title":"Improved Techniques for Training GANs"},{"paperId":"23ffaa0fe06eae05817f527a47ac3291077f9e58","externalIds":{"MAG":"2183341477","DBLP":"conf/cvpr/SzegedyVISW16","ArXiv":"1512.00567","DOI":"10.1109/CVPR.2016.308","CorpusId":206593880},"title":"Rethinking the Inception Architecture for Computer Vision"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","externalIds":{"ArXiv":"1405.0312","DBLP":"conf/eccv/LinMBHPRDZ14","MAG":"2952122856","DOI":"10.1007/978-3-319-10602-1_48","CorpusId":14113767},"title":"Microsoft COCO: Common Objects in Context"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","externalIds":{"DBLP":"conf/cvpr/DengDSLL009","MAG":"2108598243","DOI":"10.1109/CVPR.2009.5206848","CorpusId":57246310},"title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"f3837314c0c90e741ea27111b4418b841821beb7","externalIds":{"DBLP":"journals/ijcga/AltG95","MAG":"2124299914","DOI":"10.1142/S0218195995000064","CorpusId":20039238},"title":"Computing the Fréchet distance between two polygonal curves"},{"paperId":"31ca4e864074747ca459e9aad06ffe1d655faa39","externalIds":{"DOI":"10.1177/002743218206900222","CorpusId":221040406},"title":"Composer"},{"paperId":"2b043bc694be06596ee75c56f3bb38259662f2ad","externalIds":{"ArXiv":"1310.0150","DOI":"10.3150/13-BEJSP14","CorpusId":34482083},"title":"Stability"},{"paperId":"7dbfabfcb125c33cc6153406ea2d50dc67cb4d0b","externalIds":{"DBLP":"journals/corr/abs-2403-11821","DOI":"10.48550/arXiv.2403.11821","CorpusId":283454236},"title":"Evaluating Text-to-Image Synthesis: Survey and Taxonomy of Image Quality Metrics"},{"paperId":"b10b05f1fe9816f602d893b1c849988db182ef4b","externalIds":{"DBLP":"journals/corr/abs-2305-12082","DOI":"10.48550/arXiv.2305.12082","CorpusId":258833299},"title":"SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models' Safety Filters"},{"paperId":"fe568badb02858df92eaf423787ed3388d2b454f","externalIds":{"DBLP":"journals/corr/abs-2312-07130","DOI":"10.48550/arXiv.2312.07130","CorpusId":266174762},"title":"Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass the Censorship of Text-to-Image Generation Model"},{"paperId":"1a4c6856292b8c64d19a812a77f0aa6fd47cb96c","externalIds":{"DBLP":"journals/corr/abs-2308-08155","CorpusId":260925901},"title":"AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework"},{"paperId":"82c09a2f3cc6b9d112f4c2d03ad0cf1f3cf63e04","externalIds":{"DBLP":"journals/corr/abs-2306-04607","DOI":"10.48550/arXiv.2306.04607","CorpusId":271746201},"title":"Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"cfee1826dd4743eab44c6e27a0cc5970effa4d80","externalIds":{"CorpusId":264403242},"title":"Improving Image Generation with Better Captions"}]}