{"abstract":"Under the privacy protection policy, federated learning has received more and more attention. Vertical federated learning (VFL) uses the same samples local in different parties to build prediction model. However, the same samples (overlapping samples) may be limited, while a large number of non-overlapping samples in each party are not utilized. If the non-overlapping samples can be utilized for training, it can benefit the prediction model. In this paper, we propose a novel VFL method, called Multi-View Federated Learning with Data collaboration (FedMC), to solve the problem of insufficient overlapping samples by exploiting suitable non-overlapping samples for data training. The proposed FedMC method first constructs a common feature space based on the overlapping samples, then projects the non-overlapping samples into the common feature space. We measure the similarity for each pair of the non-overlapping samples by calculating their distance in this space. When the distance is less than a threshold, we match them and add this pair to the overlapping samples. The expanded overlapping samples are finally used for training to build the prediction model. We evaluate the proposed method on real-world datasets. The experimental results show that the proposed method can improve the classification result by exploiting the non-overlapping samples for training."}