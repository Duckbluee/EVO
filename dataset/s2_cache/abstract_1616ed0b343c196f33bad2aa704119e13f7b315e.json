{"abstract":"Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through multi-round natural language dialogues. However, most existing CRS models mainly focus on dialogue comprehension and preferences mining from the current dialogue session, overlooking user preferences in historical dialogue sessions. The preferences embedded in historical sessions and the current session exhibit continuity and sequentiality, and we refer to such CRSs as sequential CRSs. In this work, we leverage memory-enhanced LLMs to model the preference continuity, addressing two key issues: (1) redundancy and noise in historical dialogue sessions, and (2) the cold-start users problem. Thus, we propose a Memory-enhanced Conversational Recommender System Framework with Large Language Models (dubbed MemoCRS), consisting of user-specific memory and general memory. User-specific memory is tailored to each user's interests and uses an entity-based memory bank to refine preferences and retrieve relevant memory, thereby reducing the redundancy and noise of historical sessions. The general memory, encapsulating collaborative knowledge and reasoning guidelines, can provide shared knowledge for users, especially cold-start users. With the above memory, LLMs are empowered to deliver more precise and tailored recommendations for each user. Extensive experiments on Chinese and English datasets demonstrate MemoCRS's effectiveness."}