{"abstract":"Sleep staging by highly trained specialists is laborious. Although automatic sleep staging with supervised learning methods has been implemented for almost a decade, it requires lots of manually annotated data. Self-supervised learning methods have recently been gaining attention. They can learn representations with unlabeled data, which alleviates the cost of labeling work. However, the problem is that these self-supervised sleep staging methods either require prior knowledge, as with frequency information, or they produce unsatisfactory results. Thus, we propose a deep sequential sleep network (DSSNet), a self-supervised framework that aims to perform multi-view representations based on contrastive learning. It utilizes a single-channel electroencephalogram but achieves competitive performance. We also explore the impact of different contrastive mechanisms on DSSNet performance. The results of the Sleep-EDF dataset prove that the consistency of negative samples is crucial for improving performance. We evaluate DSSNet on Sleep-EDF and ISRUC-Sleep and achieve accuracies of 80.0% and 71.4%."}