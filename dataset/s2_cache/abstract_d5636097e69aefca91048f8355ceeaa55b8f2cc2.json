{"abstract":"This paper presents a deep semantic communication system based on federated learning with dynamic model aggregation, namely DeepSC-FedDMA, considering time-varying channel conditions. Each local model is associated with an aggregation indicator reflecting how well the model is trained under the current channel condition. After local training, each local model sends its aggregation indicator and model parameters to the central server that allocates a proper aggregation weight to the local model for global model update. In this way, more effective models contribute more to the dynamic model aggregation while less effective ones maintain appropriate level of diversity. Simulation results demonstrate that the proposed DeepSC-FedDMA overwhelms the semantic communication systems with federated averaging and pure local training in terms of mean square error and peak signal-to-noise ratio, under three kinds of channels."}