{"abstract":"Artificial Intelligence (AI) is applied in almost every public sector because of its positive impacts. However, AI’s ethical aspects and trustworthiness constitute a significant uproar and concern among different AI stakeholders due to AI’s adverse effect on users when the AI system lacks cautionary measures. AI is used in the criminal justice system for predicting recidivism risk. However, AI’s negative impact translates into bias and high incarceration towards a group of defendants in a population assessed for recidivism risk. This paper focuses on fairness as a requirement of a trustworthy AI framework previously proposed to ascertain the appropriate application of AI systems in predicting recidivism. This paper aims to raise awareness about the fairness of AI models and stimulate further research and deployment of efficient and effective exploitation of fair and trustworthy AI models in the criminal justice system when predicting recidivism. Fairness has been a significant concern for criminal justice system stakeholders and has received considerable attention with more theoretical and practical studies than other trustworthy AI requirements. Hence, this paper reviews state-of-the-art fairness, outlines valuable findings, and proposes future directions to achieve fair AI systems for predicting recidivism risk. In addition, this paper ensures mapping existing technical works in the literature to the fairness pipeline corresponding to the criminal justice system’s AI development phases."}