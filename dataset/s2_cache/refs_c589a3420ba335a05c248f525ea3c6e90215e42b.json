{"references":[{"paperId":"7bdeb028268852ae6c473d837711fbe6a5a62316","externalIds":{"ArXiv":"2306.09327","DBLP":"conf/cvpr/McKeeSSR23","DOI":"10.1109/CVPR52729.2023.01420","CorpusId":259171763},"title":"Language-Guided Music Recommendation for Video via Prompt Analogies"},{"paperId":"7376d5230f0e9e88e3d7ffcb5cb262030217be24","externalIds":{"DBLP":"journals/corr/abs-2305-18212","ArXiv":"2305.18212","DOI":"10.48550/arXiv.2305.18212","CorpusId":258960170},"title":"Multimodal Recommendation Dialog with Subjective Preference: A New Challenge and Benchmark"},{"paperId":"0d230fe2af4fe4fd2257ba2a10cfeb91126e27a3","externalIds":{"ArXiv":"2305.14302","DBLP":"conf/emnlp/GengT0FZ23","DOI":"10.48550/arXiv.2305.14302","CorpusId":258841635},"title":"VIP5: Towards Multimodal Foundation Models for Recommendation"},{"paperId":"242cf4d15893db7f8fd2615edf0d6b7f59aa707c","externalIds":{"DBLP":"journals/tois/WangZW23","DOI":"10.1145/3594633","CorpusId":258486726},"title":"Quotation Recommendation for Multi-party Online Conversations Based on Semantic and Topic Fusion"},{"paperId":"ca7bd64d372e3bcb3f4633ca4a20291ff57de3c3","externalIds":{"DBLP":"journals/corr/abs-2304-10149","ArXiv":"2304.10149","DOI":"10.48550/arXiv.2304.10149","CorpusId":258236609},"title":"Is ChatGPT a Good Recommender? A Preliminary Study"},{"paperId":"2ee1f98649ff27378fc341cae907eb89aba8fba4","externalIds":{"DBLP":"journals/corr/abs-2304-05263","ArXiv":"2304.05263","DOI":"10.1145/3539618.3591752","CorpusId":258059770},"title":"Prompt Learning for News Recommendation"},{"paperId":"da5509599d7d5ab4336d524b65467f561d18a887","externalIds":{"DBLP":"journals/tkde/GuoWWZY25","ArXiv":"2304.04218","DOI":"10.1109/TKDE.2025.3589721","CorpusId":258049281},"title":"Automated Prompting for Non-Overlapping Cross-Domain Sequential Recommendation"},{"paperId":"26f7785ef8da35820599799549152b9ef695dae2","externalIds":{"DBLP":"journals/corr/abs-2304-03879","ArXiv":"2304.03879","DOI":"10.48550/arXiv.2304.03879","CorpusId":258048480},"title":"GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation"},{"paperId":"0cfdd655100055f234fd23ebecd915504b8e00e3","externalIds":{"DBLP":"journals/corr/abs-2303-14524","ArXiv":"2303.14524","CorpusId":257766541},"title":"Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System"},{"paperId":"615908f5fbdb40f980bf9cd0183c38ac3b903b3f","externalIds":{"DBLP":"journals/tois/0001MMO23","DOI":"10.1145/3568953","CorpusId":254151773},"title":"Graph Neural Pre-training for Recommendation with Side Information"},{"paperId":"15a7eec200461dfe10192c5261b049b84fd45698","externalIds":{"DBLP":"journals/ipm/LiXZZTZH22","DOI":"10.1016/j.ipm.2022.103067","CorpusId":252247321},"title":"Self-Supervised learning for Conversational Recommendation"},{"paperId":"5cb1872a34e1755d41ed9cd481fbeb33d0665b5f","externalIds":{"DBLP":"conf/www/HouHMZ23","ArXiv":"2210.12316","DOI":"10.1145/3543507.3583434","CorpusId":253098091},"title":"Learning Vector-Quantized Item Representation for Transferable Sequential Recommenders"},{"paperId":"38ad4e789ad16eb530333498e2d04d6e70ed86b5","externalIds":{"ArXiv":"2209.11386","DBLP":"journals/tkde/WangJGZW24","DOI":"10.1109/TKDE.2024.3397321","CorpusId":252519442},"title":"Improving Conversational Recommender System Via Contextual and Time-Aware Modeling With Less Domain-Specific Knowledge"},{"paperId":"f5888d776f122f53292973bd3693628ebd265bc6","externalIds":{"ArXiv":"2209.07562","DBLP":"conf/kdd/0002MFPM0E23","DOI":"10.1145/3580305.3599921","CorpusId":252355474},"title":"TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations at Twitter"},{"paperId":"64c4d622b88a88b9f5ab5fdc6cb01f1ce9ccb883","externalIds":{"ArXiv":"2209.12613","DBLP":"journals/corr/abs-2209-12613","DOI":"10.48550/arXiv.2209.12613","CorpusId":252531445},"title":"Factual and Informative Review Generation for Explainable Recommendation"},{"paperId":"6ff7021ad6a66f5a9f4f3e755f5d6d367e656ff7","externalIds":{"DBLP":"journals/corr/abs-2208-10174","ArXiv":"2208.10174","DOI":"10.1145/3511808.3557106","CorpusId":251718944},"title":"KEEP: An Industrial Pre-Training Framework for Online Recommendation via Knowledge Extraction and Plugging"},{"paperId":"58e4eb1967c38840b0ecf24f26e8f3f1a13ab8a7","externalIds":{"ArXiv":"2207.04648","DBLP":"journals/corr/abs-2207-04648","DOI":"10.48550/arXiv.2207.04648","CorpusId":250426537},"title":"Learning Large-scale Universal User Representation with Sparse Mixture of Experts"},{"paperId":"ffbe69194970b6c1486548b9b1b78eeedeade262","externalIds":{"DBLP":"conf/sigir/WuWQZHX22","DOI":"10.1145/3477495.3531896","CorpusId":250340315},"title":"MM-Rec: Visiolinguistic Model Empowered Multimodal News Recommendation"},{"paperId":"04e5bd3e708ae231afc15671cd2bf0e5a50dff7a","externalIds":{"DBLP":"conf/sigir/Zhao22","DOI":"10.1145/3477495.3532054","CorpusId":250340238},"title":"RESETBERT4Rec: A Pre-training Model Integrating Time And User Historical Behavior for Sequential Recommendation"},{"paperId":"d6db74a36301fdbb4859b5f7ff302337666b93ce","externalIds":{"DBLP":"journals/corr/abs-2206-09363","ArXiv":"2206.09363","DOI":"10.1145/3534678.3539382","CorpusId":249889013},"title":"Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning"},{"paperId":"65587d4927fccc30788d3dfc9b639567721ff393","externalIds":{"ArXiv":"2206.07353","DBLP":"conf/sigir/XinPKRCR22","DOI":"10.1145/3477495.3531714","CorpusId":249674368},"title":"Rethinking Reinforcement Learning for Recommendation: A Prompt Perspective"},{"paperId":"e7f3f2b77994c2cabad612ba0881e63763ec2dad","externalIds":{"ArXiv":"2206.05941","DBLP":"journals/corr/abs-2206-05941","DOI":"10.1145/3534678.3539381","CorpusId":249625869},"title":"Towards Universal Sequence Representation Learning for Recommender Systems"},{"paperId":"4d431b88f7dfe1e75b0e23bb21fc9dd378b15cf2","externalIds":{"DBLP":"conf/cvpr/SarkarBVLBLM22","DOI":"10.1109/CVPRW56347.2022.00249","CorpusId":251090657},"title":"OutfitTransformer: Outfit Representations for Fashion Recommendation"},{"paperId":"3f1cad02a01c8e3f3811bbce6b1986d3cd3faf5d","externalIds":{"DBLP":"journals/corr/abs-2205-09489","ArXiv":"2205.09489","DOI":"10.48550/arXiv.2205.09489","CorpusId":248887328},"title":"Spatial Autoregressive Coding for Graph Neural Recommendation"},{"paperId":"75f4423820a6d2de93535fda5f80e17ae051dc47","externalIds":{"DBLP":"conf/www/GengFTGMZ22","DOI":"10.1145/3485447.3511937","CorpusId":248367470},"title":"Path Language Modeling over Knowledge Graphsfor Explainable Recommendation"},{"paperId":"66ee488cf3dad5bb83804124367460edddd3c271","externalIds":{"DBLP":"conf/ijcai/LongCHY22","ArXiv":"2204.07356","DOI":"10.48550/arXiv.2204.07356","CorpusId":248218612},"title":"Vision-and-Language Pretrained Models: A Survey"},{"paperId":"fa52baef4ba2603c4382858669887b89cb9e62a0","externalIds":{"DBLP":"journals/corr/abs-2204-06923","ArXiv":"2204.06923","DOI":"10.1145/3570640","CorpusId":248177909},"title":"A Unified Multi-task Learning Framework for Multi-goal Conversational Recommender Systems"},{"paperId":"77a4bfee40f0016ca5eaeda81f186fc807edfeae","externalIds":{"DBLP":"journals/corr/abs-2204-04179","ArXiv":"2204.04179","ACL":"2022.naacl-main.61","DOI":"10.18653/v1/2022.naacl-main.61","CorpusId":248069204},"title":"GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based Collaborative Filtering"},{"paperId":"2e6654520d8831f1721d4ec2dd1089b5d27f460f","externalIds":{"ArXiv":"2203.15876","DBLP":"journals/tkde/YuYXCLH24","DOI":"10.1109/TKDE.2023.3282907","CorpusId":247794106},"title":"Self-Supervised Learning for Recommender Systems: A Survey"},{"paperId":"df602516e28a9ef0ef665ed0aef551984d8d770d","externalIds":{"ArXiv":"2203.13366","DBLP":"conf/recsys/Geng0FGZ22","DOI":"10.1145/3523227.3546767","CorpusId":247749019},"title":"Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)"},{"paperId":"e72ce8bd009e1c97fbd896321efe5a63b3d95c34","externalIds":{"ArXiv":"2203.10965","DBLP":"journals/corr/abs-2203-10965","DOI":"10.1145/3524610.3527897","CorpusId":247594801},"title":"PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with Pre-trained Models"},{"paperId":"8498daeeb893870524ffaa63086f8528795003d4","externalIds":{"DBLP":"journals/tois/LiZC23","ArXiv":"2202.07371","DOI":"10.1145/3580488","CorpusId":246863587},"title":"Personalized Prompt Learning for Explainable Recommendation"},{"paperId":"a5888f9be28f1bd23cfbae925d8f8e92ab1ee10c","externalIds":{"ArXiv":"2112.08140","DBLP":"journals/corr/abs-2112-08140","DOI":"10.18653/v1/2022.findings-naacl.4","CorpusId":245144291},"title":"Improving Conversational Recommendation Systems' Quality with Context-Aware Item Meta Information"},{"paperId":"445526148e456216025483e96364921061a73543","externalIds":{"DBLP":"books/crc/p/LuccheseMPSVV14","DOI":"10.1007/978-1-4614-6170-8_100614","CorpusId":1381259},"title":"Recommender Systems"},{"paperId":"873bdaeb8110bcd660d0fa21a42b5d105767856c","externalIds":{"DBLP":"conf/ecir/SileoVR22","ArXiv":"2112.04184","DOI":"10.1007/978-3-030-99739-7_26","CorpusId":244954768},"title":"Zero-Shot Recommendation as Language Modeling"},{"paperId":"54cbf83555636ce7cfdf55a02297ddddd4717b46","externalIds":{"DBLP":"conf/emnlp/YuWWY022","ACL":"2022.emnlp-main.368","ArXiv":"2112.00944","DOI":"10.18653/v1/2022.emnlp-main.368","CorpusId":254564256},"title":"Tiny-NewsRec: Effective and Efficient PLM-based News Recommendation"},{"paperId":"7567744a0e23174166575e8d98590967684696b4","externalIds":{"DBLP":"journals/corr/abs-2111-11294","ArXiv":"2111.11294","DOI":"10.1609/aaai.v37i4.25582","CorpusId":244477730},"title":"Scaling Law for Recommendation Models: Towards General-purpose User Representations"},{"paperId":"e52d0d7bf383f0209a07bfe178df185f1d809e9f","externalIds":{"DBLP":"conf/mm/LiuYLWTZSM21","DOI":"10.1145/3474085.3475709","CorpusId":230877924},"title":"Pre-training Graph Transformer with Multimodal Side Information for Recommendation"},{"paperId":"7a83729b2e79ce0d96f6035b7da91237666c63be","externalIds":{"DBLP":"conf/ijcnlp/WangHSXJW22","ArXiv":"2110.07477","ACL":"2022.aacl-main.37","DOI":"10.18653/v1/2022.aacl-main.37","CorpusId":252762690},"title":"RecInDial: A Unified Framework for Conversational Recommendation with Pretrained Language Models"},{"paperId":"dca4d9abbc82e57dfa52f932e893d467a63e0682","externalIds":{"DBLP":"conf/recsys/MoreiraRLAO21","DOI":"10.1145/3460231.3474255","CorpusId":237494589},"title":"Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation"},{"paperId":"6d4f77455bf4b8288a5d7e2c2a9d50d1d2022b50","externalIds":{"DBLP":"conf/recsys/SankarWKS21","DOI":"10.1145/3460231.3474268","CorpusId":237350607},"title":"ProtoCF: Prototypical Collaborative Filtering for Few-shot Recommendation"},{"paperId":"d50f7e9fdcce8bf9f34bac969e091603f4727054","externalIds":{"DBLP":"conf/ijcai/ZhangLJWZWH21","DOI":"10.24963/ijcai.2021/462","CorpusId":237101122},"title":"UNBERT: User-News Matching BERT for News Recommendation"},{"paperId":"28692beece311a90f5fa1ca2ec9d0c2ce293d069","externalIds":{"DBLP":"journals/csur/LiuYFJHN23","ArXiv":"2107.13586","DOI":"10.1145/3560815","CorpusId":236493269},"title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"},{"paperId":"75c979466fac5073831269d2b257d9755af4dd72","externalIds":{"DBLP":"conf/sigir/HadaMS21","DOI":"10.1145/3404835.3462939","CorpusId":235792544},"title":"ReXPlug: Explainable Recommendation using Plug-and-Play Language Model"},{"paperId":"c910abb1d3b52403ebcc91f9faf84e4d537447e9","externalIds":{"DBLP":"journals/tkde/ChenYYHLY23","ArXiv":"2106.07864","DOI":"10.1109/TKDE.2021.3119619","CorpusId":235436093},"title":"User-Specific Adaptive Fine-Tuning for Cross-Domain Recommendations"},{"paperId":"e766e44c5219d42b562de5b296b8588342da6c96","externalIds":{"DBLP":"journals/corr/abs-2106-06722","ArXiv":"2106.06722","DOI":"10.1145/3528667","CorpusId":235422525},"title":"Curriculum Pre-training Heterogeneous Subgraph Transformer for Top-N Recommendation"},{"paperId":"0c9a2adda11ed49d091948211fcfd517113b5243","externalIds":{"DBLP":"journals/corr/abs-2105-11601","ACL":"2021.acl-long.383","ArXiv":"2105.11601","DOI":"10.18653/v1/2021.acl-long.383","CorpusId":235187032},"title":"Personalized Transformer for Explainable Recommendation"},{"paperId":"8baedb6c558bfea8ad9c17404f58b77368476a0f","externalIds":{"DBLP":"conf/aaai/QiuWG021","DOI":"10.1609/aaai.v35i5.16557","CorpusId":235306483},"title":"U-BERT: Pre-training User Representations for Improved Recommendation"},{"paperId":"f665c28c6d5acb171774b85f85970a0428000eb8","externalIds":{"DBLP":"journals/corr/abs-2104-07413","ArXiv":"2104.07413","DOI":"10.1145/3404835.3463069","CorpusId":233241208},"title":"Empowering News Recommendation with Pre-trained Language Models"},{"paperId":"209f9bde2dee7cf1677801586562ffe56d435d38","externalIds":{"DBLP":"conf/naacl/QinE21","ACL":"2021.naacl-main.410","ArXiv":"2104.06599","MAG":"3166846774","DOI":"10.18653/v1/2021.naacl-main.410","CorpusId":233231453},"title":"Learning How to Ask: Querying LMs with Mixtures of Soft Prompts"},{"paperId":"e259ee075998eedc0b0c91c17769bf9dffeba46f","externalIds":{"DBLP":"journals/corr/abs-2103-00111","ArXiv":"2103.00111","DOI":"10.1109/TKDE.2022.3172903","CorpusId":232076112},"title":"Graph Self-Supervised Learning: A Survey"},{"paperId":"d377637332773fb89d45ee90244bb7d321b64384","externalIds":{"DBLP":"journals/corr/abs-2102-10989","ArXiv":"2102.10989","CorpusId":231985487},"title":"UPRec: User-Aware Pre-training for Recommender Systems"},{"paperId":"62842f5a587485e59068e216425b10362b1113e1","externalIds":{"DBLP":"conf/kdd/XiaoLSDMWX22","ArXiv":"2102.09268","DOI":"10.1145/3534678.3539120","CorpusId":232139754},"title":"Training Large-Scale News Recommenders with Pretrained Language Models in the Loop"},{"paperId":"efbbb401050d3ce443a0e04b2a907f8fa263cd32","externalIds":{"MAG":"3099577420","DBLP":"journals/corr/abs-2009-13292","ACL":"2020.findings-emnlp.154","ArXiv":"2009.13292","DOI":"10.18653/v1/2020.findings-emnlp.154","CorpusId":221970965},"title":"Optimizing BERT for Unlabeled Text-Based Items Similarity"},{"paperId":"0cd4811f7387486dc4a967f964f7e662ab79e212","externalIds":{"DBLP":"journals/corr/abs-2009-09226","ArXiv":"2009.09226","MAG":"3136606064","PubMedCentral":"8013982","DOI":"10.3389/fdata.2021.602071","CorpusId":221819497,"PubMed":"33817631"},"title":"Knowledge Transfer via Pre-training for Recommendation: A Review and Prospect"},{"paperId":"39dbb388062b63e82e984d46e2c20b5ca9885b42","externalIds":{"DBLP":"conf/cikm/ZhouWZZWZWW20","MAG":"3100260481","ArXiv":"2008.07873","DOI":"10.1145/3340531.3411954","CorpusId":221150341},"title":"S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization"},{"paperId":"cc4db47a416aba22d1073e59a6867b6997928b7c","externalIds":{"DBLP":"journals/corr/abs-2007-15356","MAG":"3046039946","ArXiv":"2007.15356","DOI":"10.1145/3383313.3412249","CorpusId":220870937},"title":"What does BERT know about books, movies and music? Probing BERT for Conversational Recommendation"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"3bcb17559ce96eb20fa79af8194f4af0380d194a","externalIds":{"DBLP":"journals/corr/abs-2003-08271","MAG":"3088409176","ArXiv":"2003.08271","DOI":"10.1007/s11431-020-1647-3","CorpusId":212747830},"title":"Pre-trained models for natural language processing: A survey"},{"paperId":"f64e1d6bc13aae99aab5449fc9ae742a9ba7761e","externalIds":{"ArXiv":"2002.12804","DBLP":"journals/corr/abs-2002-12804","MAG":"3035606497","CorpusId":211572655},"title":"UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"},{"paperId":"2ca1abd015c72e7c04d63fa653b0a27d9592fc02","externalIds":{"DBLP":"conf/sigir/Yuan0KZ20","MAG":"3034896171","DOI":"10.1145/3397271.3401156","CorpusId":210164320},"title":"Parameter-Efficient Transfer from Sequential Behaviors for User Modeling and Recommendation"},{"paperId":"7a064df1aeada7e69e5173f7d4c8606f4470365b","externalIds":{"MAG":"2996428491","DBLP":"journals/corr/abs-1909-11942","ArXiv":"1909.11942","CorpusId":202888986},"title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"e0c6abdbdecf04ffac65c440da77fb9d66bb474c","externalIds":{"MAG":"2950813464","DBLP":"journals/corr/abs-1906-08237","ArXiv":"1906.08237","CorpusId":195069387},"title":"XLNet: Generalized Autoregressive Pretraining for Language Understanding"},{"paperId":"b1ded85bbcacc3dca108ac87f4d714a0fc888b6d","externalIds":{"MAG":"3012907770","DBLP":"conf/www/Yuan0JGXXX20","ArXiv":"1906.04473","DOI":"10.1145/3366423.3380116","CorpusId":210921264},"title":"Future Data Helps Training: Modeling Future Contexts for Session-based Recommendation"},{"paperId":"c3229debfda1b015c88404cf98f1074237d80809","externalIds":{"MAG":"2965570621","DBLP":"conf/ijcai/ShangMXS19","ArXiv":"1906.00346","DOI":"10.24963/ijcai.2019/825","CorpusId":173990821},"title":"Pre-training of Graph Augmented Transformers for Medication Recommendation"},{"paperId":"690edf44e8739fd80bdfb76f40c9a4a222f3bba8","externalIds":{"MAG":"2984100107","DBLP":"conf/cikm/SunLWPLOJ19","ArXiv":"1904.06690","DOI":"10.1145/3357384.3357895","CorpusId":119181611},"title":"BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer"},{"paperId":"0d2336389dff3031910bd21dd1c44d1b4cd51725","externalIds":{"MAG":"2964947096","DBLP":"journals/jmlr/ErhanCBV10","DOI":"10.5555/1756006.1756025","CorpusId":15796526},"title":"Why Does Unsupervised Pre-training Help Deep Learning?"},{"paperId":"c652fa4691f50bd96fcb41e459c3c633d973f177","externalIds":{"MAG":"1497750527","DOI":"10.3115/1620853","CorpusId":60738116},"title":"Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics"},{"paperId":"bc6dff14a130c57a91d5a21339c23471faf1d46f","externalIds":{"DOI":"10.1136/ebmh.11.4.102","CorpusId":11759366,"PubMed":"22365577"},"title":"Et al"},{"paperId":"e8925b0bbf5e9e53300fbad3e79469742a703833","externalIds":{"DBLP":"journals/corr/abs-2205-09666","DOI":"10.48550/arXiv.2205.09666","CorpusId":248887296},"title":"Personalized Prompts for Sequential Recommendation"},{"paperId":"37e2b60379654f6584a4cb5fea65346954ec91aa","externalIds":{"ACL":"2022.coling-1.249","DBLP":"conf/coling/LiuZD022","CorpusId":252819494},"title":"Boosting Deep CTR Prediction with a Plug-and-Play Pre-trainer for News Recommendation"},{"paperId":"fd4e3ccf44919ff2f03740e19bb5cd9a1e057ca5","externalIds":{"DBLP":"conf/emnlp/WangZW22","DOI":"10.18653/v1/2022.findings-emnlp.225","CorpusId":256631062},"title":"Learning When and What to Quote: A Quotation Recommender System with Mutual Promotion of Recommendation and Generation"},{"paperId":"28d25de2e57c0ea5a99355ec7e0646385e8727d6","externalIds":{"DBLP":"conf/acl/GengFGLMZ22","ACL":"2022.acl-long.20","DOI":"10.18653/v1/2022.acl-long.20","CorpusId":248780017},"title":"Improving Personalized Explanation Generation through Visualization"},{"paperId":"96d384244fa7c28dddd484d15b1e7c9c68ee890c","externalIds":{"CorpusId":244797941},"title":"Language Models as Recommender Systems: Evaluations and Limitations"},{"paperId":"e940eb6464e452ecfdefa8a9521099e2ff022626","externalIds":{"ACL":"2021.emnlp-main.275","DBLP":"conf/emnlp/KangW00Y21","DOI":"10.18653/v1/2021.emnlp-main.275","CorpusId":243865365},"title":"APIRecX: Cross-Library API Recommendation via Pre-Trained Language Model"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"ebedc59db15570e9f3a11c90be72da3685f2162f","externalIds":{"MAG":"25807249","DOI":"10.5840/raven2002/20039/1090","CorpusId":108136814},"title":"AT MINNEAPOLIS, MINNESOTA"}]}