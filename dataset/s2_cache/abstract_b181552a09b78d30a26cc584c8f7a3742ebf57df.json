{"abstract":"We analyze the expected behavior of an advanced artiﬁcial agent with a learned goal planning in an unknown environment. Given a few assumptions, we argue that it will encounter a fundamental ambiguity in the data about its goal. For example, if we provide a large reward to indicate that something about the world is satisfactory to us, it may hypothesize that what satisﬁed us was the sending of the reward itself; no observation can refute that. Then we argue this ambiguity will lead it to intervene in whatever protocol we set up to provide data for the agent about its goal. We discuss an analogous failure mode of approximate solutions to assistance games. Finally, we brieﬂy review some recent approaches that may avoid this problem."}