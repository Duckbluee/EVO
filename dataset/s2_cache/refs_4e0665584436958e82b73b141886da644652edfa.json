{"references":[{"paperId":"62749fbe7bfb0cd3abe0a8897efd3989ef867941","externalIds":{"DBLP":"journals/tdsc/LiuWLPW23","DOI":"10.1109/TDSC.2022.3180828","CorpusId":249595286},"title":"Membership Inference Attacks Against Machine Learning Models via Prediction Sensitivity"},{"paperId":"ecaad743c0f9dc8d174786867475928dcfb2064e","externalIds":{"DBLP":"conf/ccs/0002HCM22","ArXiv":"2211.05249","DOI":"10.1145/3548606.3560581","CorpusId":253371218},"title":"QuerySnout: Automating the Discovery of Attribute Inference Attacks against Query-Based Systems"},{"paperId":"166804591abf73b79d9f8e8153299a1a2fa2a1f8","externalIds":{"DBLP":"journals/corr/abs-2210-00968","ArXiv":"2210.00968","DOI":"10.48550/arXiv.2210.00968","CorpusId":252683365},"title":"Membership Inference Attacks Against Text-to-image Generation Models"},{"paperId":"31405ee9b9665252be53cb7a74d300fb348356a7","externalIds":{"DBLP":"journals/corr/abs-2206-14724","ArXiv":"2206.14724","DOI":"10.56553/popets-2023-0041","CorpusId":250113699},"title":"Private Graph Extraction via Feature Explanations"},{"paperId":"f1ed4161ce4d015bf88a6ca70ca64cdc800af1bb","externalIds":{"MAG":"3200394043","DBLP":"journals/iotj/MaLJCGM22","DOI":"10.1109/jiot.2021.3112737","CorpusId":240562643},"title":"NOSnoop: An Effective Collaborative Meta-Learning Scheme Against Property Inference Attack"},{"paperId":"58eb2d747e102932989f2ad1fedda30854e24102","externalIds":{"ArXiv":"2203.11894","DBLP":"journals/corr/abs-2203-11894","DOI":"10.1109/CVPR52688.2022.00978","CorpusId":247597146},"title":"GradViT: Gradient Inversion of Vision Transformers"},{"paperId":"6d95a678903347b8764e04d287c672242dae29dc","externalIds":{"ArXiv":"2203.09566","DBLP":"journals/corr/abs-2203-09566","DOI":"10.1109/CVPR52688.2022.01015","CorpusId":247595200},"title":"Leveraging Adversarial Examples to Quantify Membership Information Leakage"},{"paperId":"0504ae983a51293e92431a08273c9e81bfcfb6f6","externalIds":{"ArXiv":"2203.06555","DBLP":"journals/corr/abs-2203-06555","DOI":"10.48550/arXiv.2203.06555","CorpusId":247447597},"title":"Label-only Model Inversion Attack: The Attack that Requires the Least Information"},{"paperId":"f65e0f8d2d9929e3ee1d68229029a34f62c659ad","externalIds":{"DBLP":"journals/corr/abs-2203-06570","ArXiv":"2203.06570","DOI":"10.48550/arXiv.2203.06570","CorpusId":247446879},"title":"Model Inversion Attack against Transfer Learning: Inverting a Model without Accessing It"},{"paperId":"0229f134fd9f67028ed62331b3fd5d26f7f95603","externalIds":{"DBLP":"journals/corr/abs-2203-02077","ArXiv":"2203.02077","DOI":"10.48550/arXiv.2203.02077","CorpusId":247244765},"title":"User-Level Membership Inference Attack against Metric Embedding Learning"},{"paperId":"b3e386618e3832fb704fb6bffe0ca7150d2a23aa","externalIds":{"DBLP":"journals/corr/abs-2203-01925","ArXiv":"2203.01925","DOI":"10.1109/CVPR52688.2022.01462","CorpusId":247222707},"title":"Label-Only Model Inversion Attacks via Boundary Repulsion"},{"paperId":"f0645e5613acdb6d4e60d2e60479870e5ff6f178","externalIds":{"DBLP":"journals/tissec/UsyninRK23","ArXiv":"2203.00481","DOI":"10.1145/3592800","CorpusId":247187971},"title":"Beyond Gradients: Exploiting Adversarial Priors in Model Inversion Attacks"},{"paperId":"633b3435b4ddd48bf8430a0d9e4872572f6a18f2","externalIds":{"DBLP":"conf/uss/Yuan022","ArXiv":"2202.03335","CorpusId":246634340},"title":"Membership Inference Attacks and Defenses in Neural Network Pruning"},{"paperId":"7b37573d452df48383d2be0a0c21987b6ee47f90","externalIds":{"ArXiv":"2202.02242","DBLP":"journals/corr/abs-2202-02242","CorpusId":246607982},"title":"Dikaios: Privacy Auditing of Algorithmic Fairness via Attribute Inference Attacks"},{"paperId":"ea06b5d1d383481fd7b203fe66cb6f4e2bc55e8f","externalIds":{"ArXiv":"2201.10787","DBLP":"journals/corr/abs-2201-10787","CorpusId":246285612},"title":"Variational Model Inversion Attacks"},{"paperId":"1c5508302ae71d7b591acceec645ed64ef22efe6","externalIds":{"DBLP":"conf/uss/MehnazDKLB22","ArXiv":"2201.09370","CorpusId":246241051},"title":"Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models"},{"paperId":"5cb3d28958c5c0cb9e17ae28b4904fbbd8529588","externalIds":{"DBLP":"journals/corr/abs-2112-13416","ArXiv":"2112.13416","CorpusId":245502347},"title":"Attribute Inference Attack of Speech Emotion Recognition in Federated Learning Settings"},{"paperId":"6296aa7cab06eaf058f7291040b320b5a83c0091","externalIds":{"DBLP":"journals/corr/abs-2203-00667","ArXiv":"2203.00667","DOI":"10.1109/ICCCNT56998.2023.10306417","CorpusId":1033682},"title":"Generative Adversarial Networks"},{"paperId":"54d7ae7cfee56b0e19fd42c45d365f760a41794d","externalIds":{"ArXiv":"2112.03570","DBLP":"conf/sp/CarliniCN0TT22","DOI":"10.1109/sp46214.2022.9833649","CorpusId":244920593},"title":"Membership Inference Attacks From First Principles"},{"paperId":"42159cac4247ccc8c8eb13e0dca730508fa88c4e","externalIds":{"DBLP":"conf/dac/Hernandez-CanoC21","DOI":"10.1109/dac18074.2021.9586217","CorpusId":243928303},"title":"PRID: Model Inversion Privacy Attacks in Hyperdimensional Learning Systems"},{"paperId":"f6e5ab183e69f19adab45bad96421bf7352c3182","externalIds":{"DBLP":"conf/globecom/WuCFWYY21","DOI":"10.1109/GLOBECOM46510.2021.9685603","CorpusId":246477970},"title":"Data Privacy Protection based on Feature Dilution in Cloud Services"},{"paperId":"af3916cd55f82229d61e8312be3f678a4dd89361","externalIds":{"ArXiv":"2111.07608","DBLP":"journals/corr/abs-2111-07608","DOI":"10.14722/ndss.2022.23019","CorpusId":244117091},"title":"Property Inference Attacks Against GANs"},{"paperId":"85d26f399e6a92d0096f56beb7986c8aff791241","externalIds":{"DBLP":"conf/ccs/ZhangRWRCHZ21","ArXiv":"2109.08045","DOI":"10.1145/3460120.3484770","CorpusId":237532289},"title":"Membership Inference Attacks Against Recommender Systems"},{"paperId":"f269623b323f155c21a06bce3fd3d92a22295617","externalIds":{"ArXiv":"2109.05659","DBLP":"journals/corr/abs-2109-05659","DOI":"10.1109/ICDM51629.2021.00129","CorpusId":237491049},"title":"Source Inference Attacks in Federated Learning"},{"paperId":"c91b8cb2129654ab91f9374e10c90756f64ee880","externalIds":{"DBLP":"conf/interspeech/ShahSMMD21","DOI":"10.21437/interspeech.2021-1188","CorpusId":236880971},"title":"Evaluating the Vulnerability of End-to-End Automatic Speech Recognition Models to Membership Inference Attacks"},{"paperId":"163d9fe4c45d38e31a53464b5af7638d70839a9b","externalIds":{"DBLP":"journals/corr/abs-2108-06504","ArXiv":"2108.06504","DOI":"10.1109/sp46214.2022.9833806","CorpusId":237091834},"title":"LINKTELLER: Recovering Private Edges from Graph Neural Networks via Influence Analysis"},{"paperId":"b4549a32594279a9abc86f3bc0a6c1aedcd25f39","externalIds":{"DBLP":"journals/iotj/HeZL21","MAG":"3084432478","DOI":"10.1109/JIOT.2020.3022358","CorpusId":226478768},"title":"Attacking and Protecting Data Privacy in Edge–Cloud Collaborative Inference Systems"},{"paperId":"50f0472497791f4a3186c07ee3d447763c2e4a20","externalIds":{"MAG":"3172555720","DBLP":"journals/tii/JiaZLZHL22","DOI":"10.1109/TII.2021.3085960","CorpusId":236289951},"title":"Blockchain-Enabled Federated Learning Data Protection Aggregation Scheme With Differential Privacy and Homomorphic Encryption in IIoT"},{"paperId":"4886dcba109d330626a268510e4eaf4acccfb045","externalIds":{"ArXiv":"2106.02820","DBLP":"journals/corr/abs-2106-02820","DOI":"10.24963/ijcai.2021/516","CorpusId":235358225},"title":"GraphMI: Extracting Private Graph Data from Graph Neural Networks"},{"paperId":"e68ff35082803a7f86c51ae3f2372f98df345eac","externalIds":{"DBLP":"journals/ijon/LiLQP21","MAG":"3165924587","DOI":"10.1016/J.NEUCOM.2021.05.098","CorpusId":236220879},"title":"Improving GAN with inverse cumulative distribution function for tabular data synthesis"},{"paperId":"d5781dfbcf133e31535de32e325d68638d61e413","externalIds":{"DBLP":"conf/midl/GuptaSLTAS21","ArXiv":"2105.02866","CorpusId":233864706},"title":"Membership Inference Attacks on Deep Regression Models for Neuroimaging"},{"paperId":"839589b258ce4ea3af93d2ac0368e78e3eeaa45c","externalIds":{"DBLP":"conf/cscwd/ZhangWCGLB21","DOI":"10.1109/CSCWD49262.2021.9437808","CorpusId":235235859},"title":"TEA-RNN: Topic-Enhanced Attentive RNN for Attribute Inference Attacks via User Behaviors"},{"paperId":"ebb0ca72775413d0f7c9cbd3c088a87a9fe586e2","externalIds":{"DBLP":"journals/corr/abs-2010-04092","MAG":"3092633571","CorpusId":222276664},"title":"Improved Techniques for Model Inversion Attacks"},{"paperId":"8a29ca5c3e488ef4b28c3725b593f344373cc1b8","externalIds":{"DBLP":"journals/tii/KongYLLWC021","MAG":"3158003593","DOI":"10.1109/TII.2021.3075683","CorpusId":235509562},"title":"Privacy-Preserving Aggregation for Federated Learning-Based Navigation in Vehicular Fog"},{"paperId":"c5430faa6a52125e65f821b51efa319346a09fb0","externalIds":{"DBLP":"journals/corr/abs-2104-13061","ArXiv":"2104.13061","DOI":"10.5220/0010555607150721","CorpusId":233407626},"title":"Property Inference Attacks on Convolutional Neural Networks: Influence and Implications of Target Model's Complexity"},{"paperId":"284b0e87ad6bb4d95918f375431bc27285bcee88","externalIds":{"DBLP":"journals/corr/abs-2104-12669","ArXiv":"2104.12669","DOI":"10.1109/ICCV48922.2021.00072","CorpusId":233394557},"title":"Exploiting Explanations for Model Inversion Attacks"},{"paperId":"6eb1eb3e008d3af3edc5b97482dfb840c352ad2e","externalIds":{"DBLP":"journals/corr/abs-2104-08273","ArXiv":"2104.08273","CorpusId":233289867},"title":"Membership Inference Attacks on Knowledge Graphs"},{"paperId":"0fd50e1483f761ba2bae44de54c5e8db6e35de5a","externalIds":{"DBLP":"conf/cvpr/YinMVAKM21","ArXiv":"2104.07586","DOI":"10.1109/CVPR46437.2021.01607","CorpusId":233241017},"title":"See through Gradients: Image Batch Recovery via GradInversion"},{"paperId":"62bf733526786fefcbb318fb5525a71c52394d7e","externalIds":{"MAG":"3144804712","DBLP":"journals/isci/WangS21","DOI":"10.1016/J.INS.2021.03.042","CorpusId":233669449},"title":"The improved AdaBoost algorithms for imbalanced data classification"},{"paperId":"ac40415570e7d51efb237c5e4b4dbe4e93919409","externalIds":{"DBLP":"journals/corr/abs-2103-07853","ArXiv":"2103.07853","DOI":"10.1145/3523273","CorpusId":232233426},"title":"Membership Inference Attacks on Machine Learning: A Survey"},{"paperId":"c60b03c2e2cbae505811c46af69f44763ac8e488","externalIds":{"ArXiv":"2103.07101","DBLP":"conf/eurosp/ZhaoACABKWD21","DOI":"10.1109/EuroSP51992.2021.00025","CorpusId":232222684},"title":"On the (In)Feasibility of Attribute Inference Attacks on Machine Learning Models"},{"paperId":"8c25151fc1afca7df346bc2aa251e6bd7eb7dbc4","externalIds":{"ArXiv":"2103.03228","DBLP":"conf/icml/BlumHPS21","CorpusId":232110665},"title":"One for One, or All for All: Equilibria and Optimality of Collaboration in Federated Learning"},{"paperId":"2f65c6ac06bfcd992d4dd75f0099a072f5c3cc8c","externalIds":{"DBLP":"journals/cacm/ZhangBHRV21","DOI":"10.1145/3446776","CorpusId":231991101},"title":"Understanding deep learning (still) requires rethinking generalization"},{"paperId":"fadc8d6d6db499c0effe009331e4c3428c0948cb","externalIds":{"MAG":"3091068973","DBLP":"journals/iotj/ShenWZZXLD21","DOI":"10.1109/JIOT.2020.3028110","CorpusId":226437277},"title":"Exploiting Unintended Property Leakage in Blockchain-Assisted Federated Learning for Intelligent Edge Computing"},{"paperId":"23099e2bf6e6675caf021fd1337e0988f8ed7d40","externalIds":{"ArXiv":"2102.06387","DBLP":"conf/icml/KairouzL021","CorpusId":231918556},"title":"The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation"},{"paperId":"a29b5bd9d0ff416a232b8ba9b3fe0052d389d6d5","externalIds":{"ArXiv":"2101.07078","DBLP":"conf/sp/ViandJH21","DOI":"10.1109/SP40001.2021.00068","CorpusId":231632269},"title":"SoK: Fully Homomorphic Encryption Compilers"},{"paperId":"32842a656099e34bd68c41b2a90a2d635a4dbaf0","externalIds":{"ArXiv":"2101.06570","DBLP":"journals/corr/abs-2101-06570","DOI":"10.1109/TPSISA52974.2021.00002","CorpusId":231632628},"title":"Membership Inference Attack on Graph Neural Networks"},{"paperId":"f0f44898d09750eb037bdb51c6938bd140fc24ab","externalIds":{"MAG":"3138758728","DBLP":"conf/ndss/HuiYYBGC21","ArXiv":"2101.01341","DOI":"10.14722/ndss.2021.24293","CorpusId":230523638},"title":"Practical Blind Membership Inference Attack via Differential Comparisons"},{"paperId":"df7d26339adf4eb0c07160947b9d2973c24911ba","externalIds":{"DBLP":"journals/corr/abs-2012-07805","MAG":"3112689365","ArXiv":"2012.07805","CorpusId":229156229},"title":"Extracting Training Data from Large Language Models"},{"paperId":"2fa0924006e5dcc48df1cd30f328c1fc20a14bc1","externalIds":{"DBLP":"conf/bigdataconf/KasichainulaMS20","DOI":"10.1109/BigData50022.2020.9378377","CorpusId":232373458},"title":"Privacy Preserving Proxy for Machine Learning as a Service"},{"paperId":"266524a79cb5bbfdf08263cca3d6ec84b3cf4697","externalIds":{"MAG":"3111351313","ArXiv":"2012.02670","DBLP":"conf/ccs/PasquiniAB21","DOI":"10.1145/3460120.3485259","CorpusId":227306193},"title":"Unleashing the Tiger: Inference Attacks on Split Learning"},{"paperId":"096a6f1c18f7b670d78d7c94a5c917649141e0bb","externalIds":{"DBLP":"journals/corr/abs-2011-14661","ArXiv":"2011.14661","MAG":"3109565608","DOI":"10.1109/IJCNN52387.2021.9534207","CorpusId":227227868},"title":"TransMIA: Membership Inference Attacks Using Transfer Shadow Training"},{"paperId":"4b8122f3ef568f8a628ae34eea10705266658a04","externalIds":{"DBLP":"conf/iiwas/PhilippMSV20","DOI":"10.1145/3428757.3429152","CorpusId":231713686},"title":"Machine Learning as a Service: Challenges in Research and Applications"},{"paperId":"e46cca4e67a53f1594782a7572df5caa1f31a3c0","externalIds":{"MAG":"3096959809","ArXiv":"2011.00177","DBLP":"journals/corr/abs-2011-00177","CorpusId":226226769},"title":"Evaluation of Inference Attack Models for Deep Learning on Medical Data"},{"paperId":"f8b72650d37d3362f6c55a28e543d5ddf672edc7","externalIds":{"MAG":"3110283378","DBLP":"conf/ml4cs/MoHX20","DOI":"10.1002/int.22315","CorpusId":226301140},"title":"Querying little is enough: Model inversion attack via latent information"},{"paperId":"359f56a7fee457c2729f0a2d2ce27757c33da6c7","externalIds":{"DBLP":"conf/icde/LuoWXO21","MAG":"3094542121","ArXiv":"2010.10152","DOI":"10.1109/ICDE51399.2021.00023","CorpusId":224803115},"title":"Feature Inference Attack on Model Predictions in Vertical Federated Learning"},{"paperId":"00b521c07e9065801fabe4d76c5198e74f3d49b4","externalIds":{"DBLP":"journals/corr/abs-2010-08762","ArXiv":"2010.08762","MAG":"3093470984","CorpusId":224705997},"title":"Layer-wise Characterization of Latent Information Leakage in Federated Learning"},{"paperId":"5f3044b037f4ab067ea6e488977c2b8e78b8257f","externalIds":{"MAG":"3091473186","ArXiv":"2010.00906","DBLP":"journals/corr/abs-2010-00906","DOI":"10.1145/3448891.3448939","CorpusId":222125006},"title":"Quantifying Privacy Leakage in Graph Embedding"},{"paperId":"c5de8b8d1ca58bca4f6edf4238bfb5c4332ed598","externalIds":{"DBLP":"journals/corr/abs-2009-03728","ArXiv":"2009.03728","MAG":"3084139925","DOI":"10.1145/3485133","CorpusId":221535235},"title":"Adversarial Machine Learning in Image Classification: A Survey Toward the Defender’s Perspective"},{"paperId":"e2a9f9026501eb4f1afc6ecb758d15b5d568c80f","externalIds":{"DBLP":"conf/eurosp/LongWBB0TGC20","MAG":"3096692244","DOI":"10.1109/EuroSP48549.2020.00040","CorpusId":226266600},"title":"A Pragmatic Approach to Membership Inferences on Machine Learning Models"},{"paperId":"671fdddfa9debef365e19d0e2b61a8b6ca7b451e","externalIds":{"MAG":"3042006926","DBLP":"journals/csur/WoodNK20","DOI":"10.1145/3394658","CorpusId":218517776},"title":"Homomorphic Encryption for Machine Learning in Medicine and Bioinformatics"},{"paperId":"5d4821e83b33998266df11b125f8adf3b2b6fed1","externalIds":{"MAG":"3088273839","DOI":"10.1109/IHMSC49165.2020.00057","CorpusId":221914892},"title":"Subject Property Inference Attack in Collaborative Learning"},{"paperId":"3ccf68128d78cb98d638b5b882d1be0fa3d8cb49","externalIds":{"ArXiv":"2007.15528","DBLP":"conf/ccs/LiZ21","DOI":"10.1145/3460120.3484575","CorpusId":237563320},"title":"Membership Leakage in Label-Only Exposures"},{"paperId":"a8f9e4947ec46a07c25c37f4da9c8f2f612cd460","externalIds":{"DBLP":"journals/corr/abs-2007-15528","MAG":"3046208783","CorpusId":220871217},"title":"Label-Leaks: Membership Inference Attack with Label"},{"paperId":"a14d6a842ac94cc561f39a5cab6ec133862d5f42","externalIds":{"DBLP":"journals/corr/abs-2007-14321","ArXiv":"2007.14321","MAG":"3046102592","CorpusId":220831381},"title":"Label-Only Membership Inference Attacks"},{"paperId":"2a63d18efaee5f61a7083d548dacdb5ada979de4","externalIds":{"DBLP":"journals/corr/abs-2007-09339","ArXiv":"2007.09339","MAG":"3042943646","CorpusId":220647336},"title":"ML Privacy Meter: Aiding Regulatory Compliance by Quantifying the Privacy Risks of Machine Learning"},{"paperId":"2175722c19a6a258fc0b56acc90fc66cb765734f","externalIds":{"MAG":"3150395569","DBLP":"journals/corr/abs-2005-10881","ArXiv":"2005.10881","DOI":"10.2478/popets-2021-0031","CorpusId":218862728},"title":"Revisiting Membership Inference Under Realistic Assumptions"},{"paperId":"d5ffa58133940646d1339c2610cb35f27442e0d3","externalIds":{"DBLP":"conf/cvpr/Kariyappa0Q21","MAG":"3023663521","ArXiv":"2005.03161","DOI":"10.1109/CVPR46437.2021.01360","CorpusId":218538003},"title":"MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient Estimation"},{"paperId":"4ebdc89a4dac0d05d8a2567e3b7849be198cb0ba","externalIds":{"ArXiv":"2005.02205","DBLP":"journals/corr/abs-2005-02205","MAG":"3023153742","DOI":"10.1145/3460120.3484756","CorpusId":218502126},"title":"When Machine Unlearning Jeopardizes Privacy"},{"paperId":"e4b1d7553020258d7e537e2cfa53865359389eac","externalIds":{"DBLP":"conf/uss/HeJ0G021","ArXiv":"2005.02131","MAG":"3022536969","CorpusId":218502486},"title":"Stealing Links from Graph Neural Networks"},{"paperId":"25f7be43a5589013c9553ccb9badf17fe38a7521","externalIds":{"DBLP":"journals/tetc/SunZLYX20","MAG":"2791827614","DOI":"10.1109/TETC.2018.2794611","CorpusId":67278416},"title":"Private Machine Learning Classification Based on Fully Homomorphic Encryption"},{"paperId":"5eb417d3f6f8f91a6620bd6791826a6815b56c3a","externalIds":{"MAG":"3013435976","PubMedCentral":"7146645","DOI":"10.1016/s0140-6736(20)30792-3","CorpusId":214754839,"PubMed":"32246915"},"title":"Racism and discrimination in COVID-19 responses"},{"paperId":"8ed2bf55f385a4c61ecda001dfbf37c1c9e3506d","externalIds":{"DBLP":"journals/tifs/ShamsabadiGHC20","MAG":"3016648217","ArXiv":"2004.05574","DOI":"10.1109/TIFS.2020.2988132","CorpusId":215745386},"title":"PrivEdge: From Local to Distributed Private Training and Prediction"},{"paperId":"0e0eaa200bfe4cdaf15a18e9faccf4dd1d1c0f4c","externalIds":{"DBLP":"journals/corr/abs-2004-00053","ArXiv":"2004.00053","MAG":"3096738375","DOI":"10.1145/3372297.3417270","CorpusId":214743021},"title":"Information Leakage in Embedding Models"},{"paperId":"698ab1cc02a79596a87f92d5a0882ab1a7aee266","externalIds":{"MAG":"3105285631","DBLP":"conf/nips/GeipingBD020","ArXiv":"2003.14053","CorpusId":214728347},"title":"Inverting Gradients - How easy is it to break privacy in federated learning?"},{"paperId":"382289836d91327f6e407a145cca94248e420d07","externalIds":{"DBLP":"conf/sac/PijaniIR20","MAG":"3014471672","DOI":"10.1145/3341105.3373943","CorpusId":214693518},"title":"You are what emojis say about your pictures: language-independent gender inference attack on Facebook"},{"paperId":"fd6e4d74b8df1eed41a0915c5d760fe3cfa58278","externalIds":{"DBLP":"conf/uss/SongM21","ArXiv":"2003.10595","MAG":"3013068160","CorpusId":214623088},"title":"Systematic Evaluation of Privacy Risks of Machine Learning Models"},{"paperId":"f3b684f3d2ddd29134c842f6d31664157703a089","externalIds":{"ArXiv":"2003.02133","MAG":"3010262580","DBLP":"journals/corr/abs-2003-02133","CorpusId":211990905},"title":"Threats to Federated Learning: A Survey"},{"paperId":"abbb0fd559ade70265f4f528df094fbbd8ae2040","externalIds":{"MAG":"3007665694","ArXiv":"2002.12200","DBLP":"journals/corr/abs-2002-12200","CorpusId":211532649},"title":"Entangled Watermarks as a Defense against Model Extraction"},{"paperId":"6fecbba689f686a706d4d09800a581ff7a4cca0b","externalIds":{"DOI":"10.1007/978-3-319-77525-8_100175","CorpusId":5674305},"title":"Inference"},{"paperId":"1a636292de5a610b0f201970518e615cf0fdda36","externalIds":{"PubMedCentral":"9477916","DBLP":"journals/corr/abs-2002-02730","MAG":"3004443750","ArXiv":"2002.02730","DOI":"10.1007/s10994-022-06178-9","CorpusId":211066387,"PubMed":"36124289"},"title":"Machine unlearning: linear filtration for logit-based classifiers"},{"paperId":"2808b8344324e812bf9badb3519d1d05b73d7840","externalIds":{"DBLP":"journals/tifs/TsengW20","MAG":"3003011734","DOI":"10.1109/TIFS.2020.2968188","CorpusId":211118747},"title":"Compressive Privacy Generative Adversarial Network"},{"paperId":"0b5f443d9fae1d5cb90994025e0ce21ddc49c21c","externalIds":{"MAG":"3000479830","ArXiv":"2001.02610","DBLP":"journals/corr/abs-2001-02610","CorpusId":210064455},"title":"iDLG: Improved Deep Leakage from Gradients"},{"paperId":"113e4c4ee777ce0cae57f3293a5c19a4c11dae13","externalIds":{"DBLP":"journals/corr/abs-1912-12115","ArXiv":"1912.12115","MAG":"2998600867","CorpusId":209500485},"title":"Split Learning for collaborative deep learning in healthcare"},{"paperId":"2cb1f4688f8ba457b4fa2ed36deae5a98f4249ca","externalIds":{"MAG":"2989885118","DBLP":"conf/acsac/HeZL19","DOI":"10.1145/3359789.3359824","CorpusId":208277767},"title":"Model inversion attacks against collaborative inference"},{"paperId":"babf3916f3734fceeccf7aecb8da2353d92451e8","externalIds":{"MAG":"3035616549","ArXiv":"1911.07135","DBLP":"journals/corr/abs-1911-07135","DOI":"10.1109/cvpr42600.2020.00033","CorpusId":208139345},"title":"The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks"},{"paperId":"2bac6b71d252f93c4841e325ca111f2752109931","externalIds":{"DBLP":"conf/icml/GuoGHM20","MAG":"3035556513","ArXiv":"1911.03030","CorpusId":207847600},"title":"Certified Data Removal from Machine Learning Models"},{"paperId":"9a748e1697853b2942d0468359425a6cb85aeb7d","externalIds":{"MAG":"2985580374","DBLP":"conf/ccs/YangZCL19","DOI":"10.1145/3319535.3354261","CorpusId":207941008},"title":"Neural Network Inversion in Adversarial Setting via Background Knowledge Alignment"},{"paperId":"ac713aebdcc06f15f8ea61e1140bb360341fdf27","externalIds":{"MAG":"2994896922","DBLP":"journals/corr/abs-1910-12366","ArXiv":"1910.12366","CorpusId":204907203},"title":"Thieves on Sesame Street! Model Extraction of BERT-based APIs"},{"paperId":"2b4a6fe027dba9d16581884a760684b06b174c91","externalIds":{"DBLP":"journals/corr/abs-1909-11835","MAG":"2975819162","ArXiv":"1909.11835","CorpusId":202888587},"title":"GAMIN: An Adversarial Approach to Black-Box Model Inversion"},{"paperId":"8bedaca9ebb1d055046643802683d013fd1b2da9","externalIds":{"DBLP":"conf/esorics/ZhengYHFS19","MAG":"2972997402","DOI":"10.1007/978-3-030-29959-0_4","CorpusId":202579639},"title":"BDPL: A Boundary Differentially Private Layer Against Machine Learning Model Extraction Attacks"},{"paperId":"857986936ac87e1fa7c0a9b2923908f6d0656fd2","externalIds":{"DBLP":"journals/corr/abs-1909-10594","MAG":"2976822050","ArXiv":"1909.10594","DOI":"10.1145/3319535.3363201","CorpusId":202734167},"title":"MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples"},{"paperId":"75183df0e5d4fdcd71e73f1df6ba38df151b69b1","externalIds":{"MAG":"3002341117","DOI":"10.7544/ISSN1000-1239.2019.20180353","CorpusId":213421961},"title":"A Generative Model for Synthesizing Structured Datasets Based on GAN"},{"paperId":"580bba032938bdc88754490c8525eff99ded4a8d","externalIds":{"MAG":"3071470454","DBLP":"conf/ccs/ChenYZF20","DOI":"10.1145/3372297.3417238","CorpusId":221203089},"title":"GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models"},{"paperId":"bdb094bd4b7da0af03f306ce8f12302bf52c79ef","externalIds":{"MAG":"2969080507","DBLP":"conf/trustbus/AlipourIR19","DOI":"10.1007/978-3-030-27813-7_10","CorpusId":201059215},"title":"Gender Inference for Facebook Picture Owners"},{"paperId":"e7f3478fd8aac6940a4bf4f5eb60ac38f6b0b85b","externalIds":{"MAG":"2970533824","ArXiv":"1907.00503","DBLP":"conf/nips/XuSCV19","CorpusId":195767064},"title":"Modeling Tabular data using Conditional GAN"},{"paperId":"1e47d5f0fb35a9e19df0a1e4d697e71eaa00f224","externalIds":{"MAG":"3094629855","DBLP":"conf/aies/ShokriSZ21","DOI":"10.1145/3461702.3462533","CorpusId":220514835},"title":"On the Privacy Risks of Model Explanations"},{"paperId":"a7da2f44aa205b9b99d8c04d3dfa51c2840b6605","externalIds":{"MAG":"2956128647","DBLP":"journals/corr/abs-1906-11798","ArXiv":"1906.11798","CorpusId":195699554},"title":"Stolen Memories: Leveraging Model Memorization for Calibrated White-Box Membership Inference"},{"paperId":"da10f79f983fd4fbd589ed7ffa68d33964841443","externalIds":{"ArXiv":"1906.10908","MAG":"3009932828","DBLP":"conf/iclr/OrekondySF20","CorpusId":209314546},"title":"Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks"},{"paperId":"a50b65a5927343aabc8bca035befbe252d92c67a","externalIds":{"MAG":"2965527189","DBLP":"journals/corr/abs-1906-03006","ArXiv":"1906.03006","DOI":"10.2478/popets-2019-0067","CorpusId":199546273},"title":"Monte Carlo and Reconstruction Membership Inference Attacks against Generative Models"},{"paperId":"5507d267bbf0b4cdb9f893c3c0960a45016f7010","externalIds":{"DBLP":"journals/corr/abs-1906-08935","MAG":"2953304078","ArXiv":"1906.08935","DOI":"10.1007/978-3-030-63076-8_2","CorpusId":195316471},"title":"Deep Leakage from Gradients"},{"paperId":"ae8c317961f2b72266ab343c78cbd1100f6173f6","externalIds":{"ArXiv":"1908.11229","MAG":"2970708603","DBLP":"conf/icml/SablayrollesDSO19","CorpusId":174799799},"title":"White-box vs Black-box: Bayes Optimal Strategies for Membership Inference"},{"paperId":"4f39e93e1f53b573f3f1fb67921e3f7fa37b89ad","externalIds":{"MAG":"3104224589","ArXiv":"1905.10291","DBLP":"conf/ccs/SongSM19","DOI":"10.1145/3319535.3354211","CorpusId":165163934},"title":"Privacy Risks of Securing Machine Learning Models against Adversarial Examples"},{"paperId":"555b847ee9c39c12d5764f4e11b888b331a89cfb","externalIds":{"MAG":"2973414778","DBLP":"conf/sp/LeeEMS19","DOI":"10.1109/SPW.2019.00020","CorpusId":202700739},"title":"Defending Against Neural Network Model Stealing Attacks Using Deceptive Perturbations"},{"paperId":"35d02c98d78abbd2b7239a44cdc920634af6926f","externalIds":{"DBLP":"conf/cf/WangHZZM19","MAG":"2944442501","DOI":"10.1145/3310273.3323070","CorpusId":153314358},"title":"NPUFort: a secure architecture of DNN accelerator against model inversion attack"},{"paperId":"1da3aab62fc3d4540b36c851df7993c53441d2a7","externalIds":{"MAG":"2999818223","DBLP":"conf/kbse/GopinathCPT19","DOI":"10.1109/ASE.2019.00079","CorpusId":202577825},"title":"Property Inference for Deep Neural Networks"},{"paperId":"3c5cd5a430e3a37cd0056ed057e7185b5570ad2b","externalIds":{"DBLP":"journals/corr/abs-1904-01067","MAG":"3048684575","ArXiv":"1904.01067","CorpusId":91184074},"title":"Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning"},{"paperId":"8f8542a6aa8c76e8a4441d1ca722e230aa5d6c9e","externalIds":{"MAG":"2947693768","DBLP":"conf/uss/Jayaraman019","CorpusId":173990571},"title":"Evaluating Differentially Private Machine Learning in Practice"},{"paperId":"1d88162907ff9a0b4ca9e39db3b8d593fb83bc64","externalIds":{"MAG":"2912023992","DBLP":"journals/tsc/TruexLGYW21","DOI":"10.1109/TSC.2019.2897554","CorpusId":86836429},"title":"Demystifying Membership Inference Attacks in Machine Learning as a Service"},{"paperId":"988a378f640eb7fb681f977d6cb1e0c830c07b4c","externalIds":{"MAG":"2906186365","DBLP":"conf/icml/GilmerFCC19","ArXiv":"1901.10513","CorpusId":59413762},"title":"Adversarial Examples Are a Natural Consequence of Test Error in Noise"},{"paperId":"f5014e34ed13191082cd20cc279ca4cc9adee84f","externalIds":{"MAG":"2906869444","ArXiv":"1812.11720","DBLP":"journals/corr/abs-1812-11720","CorpusId":57189435},"title":"Stealing Neural Networks via Timing Side Channels"},{"paperId":"089c6224cfbcf5c18b63564eb65001c7c42a7acf","externalIds":{"MAG":"2905209730","ArXiv":"1812.02766","DBLP":"journals/corr/abs-1812-02766","DOI":"10.1109/CVPR.2019.00509","CorpusId":54457412},"title":"Knockoff Nets: Stealing Functionality of Black-Box Models"},{"paperId":"fd9541fe4317904b9a0637b6505fb0bea0979491","externalIds":{"MAG":"3103245149","DBLP":"conf/sp/NasrSH19","DOI":"10.1109/SP.2019.00065","CorpusId":133091488},"title":"Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning"},{"paperId":"d0c63d02bd63ecc0fb9debfe2b93b2e6be983ed8","externalIds":{"MAG":"2902901670","DBLP":"journals/corr/abs-1811-11264","ArXiv":"1811.11264","CorpusId":53816815},"title":"Synthesizing Tabular Data using Generative Adversarial Networks"},{"paperId":"35c863e151e47b6dbf6356e9a1abaa2a0eeab3fc","externalIds":{"ArXiv":"1811.02054","MAG":"3049515540","DBLP":"conf/uss/ChandrasekaranC20","CorpusId":67876983},"title":"Exploring Connections Between Active Learning and Model Extraction"},{"paperId":"490c30b1d6b680be3c5a13552073e4fc10a850dc","externalIds":{"MAG":"2897830718","DBLP":"conf/ccs/GanjuWYGB18","DOI":"10.1145/3243734.3243834","CorpusId":52218951},"title":"Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations"},{"paperId":"8294698a449b6f701aaf6d2d8f8af03ce948392b","externalIds":{"ArXiv":"1810.09957","MAG":"2895976713","DBLP":"journals/corr/abs-1810-09957","CorpusId":53037322},"title":"NSML: Meet the MLaaS platform with a real-world case study"},{"paperId":"a1fdd44a1c90dd2ad6d08c5560116f5cb3e74857","externalIds":{"DBLP":"journals/scn/LiCYHS18","MAG":"2895530113","DOI":"10.1155/2018/3530123","CorpusId":53528270},"title":"Differentially Private Recommendation System Based on Community Detection in Social Network Applications"},{"paperId":"356bb26086b2bbc36ed099ee4bec4555d7f89c4c","externalIds":{"MAG":"2886130191","DBLP":"journals/computer/IsaakH18","DOI":"10.1109/MC.2018.3191268","CorpusId":52047339},"title":"User Data Privacy: Facebook, Cambridge Analytica, and Privacy Protection"},{"paperId":"8a4de50cca1675737990002f32aa5c62621a115a","externalIds":{"DBLP":"conf/fat/MilliSDH19","MAG":"2963560987","ArXiv":"1807.05185","DOI":"10.1145/3287560.3287562","CorpusId":49741763},"title":"Model Reconstruction from Model Explanations"},{"paperId":"81e5423f3a7d31a9abd0966a21eda564339c754d","externalIds":{"DBLP":"journals/tdsc/CaiHGL18","MAG":"2526910689","DOI":"10.1109/TDSC.2016.2613521","CorpusId":43996915},"title":"Collective Data-Sanitization for Preventing Sensitive Information Inference Attacks in Social Networks"},{"paperId":"a68fccc152d238f62848de1be8522ccd71137ac0","externalIds":{"MAG":"2963378725","ArXiv":"1806.01246","DBLP":"journals/corr/abs-1806-01246","DOI":"10.14722/NDSS.2019.23119","CorpusId":46933970},"title":"ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models"},{"paperId":"180a03aa6f09e2b06417b86e8f1828861633bd37","externalIds":{"DBLP":"journals/popets/HesamifardTGW18","MAG":"2801491268","DOI":"10.1515/popets-2018-0024","CorpusId":13689415},"title":"Privacy-preserving Machine Learning as a Service"},{"paperId":"291ac97d951026dfaa080bcbd46bdb9bde94ad4c","externalIds":{"MAG":"2799694080","DBLP":"conf/uss/JiaG18","ArXiv":"1805.04810","CorpusId":44108074},"title":"AttriGuard: A Practical Defense Against Attribute Inference Attacks via Adversarial Machine Learning"},{"paperId":"30e0ffeb519a4df2d4a2067e899c5fb5c5e85e70","externalIds":{"MAG":"2898291644","DBLP":"conf/sp/MelisSCS19","ArXiv":"1805.04049","DOI":"10.1109/SP.2019.00029","CorpusId":53099247},"title":"Exploiting Unintended Feature Leakage in Collaborative Learning"},{"paperId":"4582e2350e4822834dcf266522690722dd4430d4","externalIds":{"MAG":"2969695741","ArXiv":"1805.02628","DBLP":"conf/eurosp/JuutiSMA19","DOI":"10.1109/EuroSP.2019.00044","CorpusId":21670607},"title":"PRADA: Protecting Against DNN Model Stealing Attacks"},{"paperId":"b3f2a11d45757e675be123d55ec0eb192bcca990","externalIds":{"ArXiv":"1803.05961","MAG":"2793398195","DBLP":"journals/corr/abs-1803-05961","CorpusId":3970945},"title":"Chiron: Privacy-preserving Machine Learning as a Service"},{"paperId":"520ec00dc35475e0554dbb72f27bd2eeb6f4191d","externalIds":{"DBLP":"conf/uss/Carlini0EKS19","MAG":"2946930197","ArXiv":"1802.08232","CorpusId":170076423},"title":"The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks"},{"paperId":"869eb7e00da4496ef3392ce009654919d4e60552","externalIds":{"DBLP":"journals/corr/abs-1802-04889","MAG":"2786233556","ArXiv":"1802.04889","CorpusId":3619789},"title":"Understanding Membership Inferences on Well-Generalized Learning Models"},{"paperId":"13d907e1b009eee7f3910c7d813f2dcb5a4bca71","externalIds":{"MAG":"3105676597","ArXiv":"1802.02601","DBLP":"journals/ijmir/NagaiUSS18","DOI":"10.1007/s13735-018-0147-1","CorpusId":3357507},"title":"Digital watermarking for deep neural networks"},{"paperId":"0e5663313b95f3abe96188aa1d53135ad29ddfa1","externalIds":{"MAG":"2949492662","DBLP":"conf/ccs/NasrSH18","ArXiv":"1807.05852","DOI":"10.1145/3243734.3243855","CorpusId":49863840},"title":"Machine Learning with Membership Privacy using Adversarial Regularization"},{"paperId":"be275d4b2caa9466fd3b3474431f3c5f85077db4","externalIds":{"MAG":"2781896769","DBLP":"journals/tissec/GongL18","DOI":"10.1145/3154793","CorpusId":4940117},"title":"Attribute Inference Attacks in Online Social Networks"},{"paperId":"181fe8787937dbf7abf886042855be1bc6149f80","externalIds":{"DBLP":"journals/corr/abs-1711-07221","ArXiv":"1711.07221","MAG":"2949743418","DOI":"10.1145/3274694.3274740","CorpusId":21327267},"title":"Model Extraction Warning in MLaaS Paradigm"},{"paperId":"ed46493d568030b42f0154d9e5bf39bbd07962b3","externalIds":{"MAG":"2784621220","DBLP":"conf/iclr/McMahanRT018","CorpusId":3461939},"title":"Learning Differentially Private Recurrent Language Models"},{"paperId":"18cfd4b9e35fb12fbebedb0fdc3f7811090372bf","externalIds":{"MAG":"2949338291","DBLP":"conf/ccs/SongRS17","ArXiv":"1709.07886","DOI":"10.1145/3133956.3134077","CorpusId":2904063},"title":"Machine Learning Models that Remember Too Much"},{"paperId":"c8f216f663660ff3bc195ecd3a8ad61f0ed1d9d7","externalIds":{"MAG":"2795435272","DBLP":"conf/csfw/YeomGFJ18","DOI":"10.1109/CSF.2018.00027","CorpusId":2656445},"title":"Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting"},{"paperId":"e0a8797a1669eff68617532aec872288f6f408ee","externalIds":{"DBLP":"conf/csfw/AbadiEGMMPTZ17","MAG":"2963909826","ArXiv":"1708.08022","DOI":"10.1109/CSF.2017.10","CorpusId":20182008},"title":"On the Protection of Private Information in Machine Learning Systems: Two Recent Approches"},{"paperId":"2624867f9bd13a623f412468903ebe20eb630785","externalIds":{"MAG":"2895805829","DBLP":"conf/pst/HidanoMKKH17","DOI":"10.1109/PST.2017.00023","CorpusId":52916090},"title":"Model Inversion Attacks for Prediction Systems: Without Knowledge of Non-Sensitive Attributes"},{"paperId":"cc8bd663fcdb6dd8c0ea8db0326047b33ed89ea9","externalIds":{"MAG":"2735439080","DBLP":"conf/papis/LiCHZW16","CorpusId":23492621},"title":"Scaling Machine Learning as a Service"},{"paperId":"7aa38b85fa8cba64d6a4010543f6695dbf5f1386","externalIds":{"DBLP":"conf/iclr/MadryMSTV18","MAG":"2952649158","ArXiv":"1706.06083","CorpusId":3488815},"title":"Towards Deep Learning Models Resistant to Adversarial Attacks"},{"paperId":"6b7d6e6416343b2a122f8416e69059ce919026ef","externalIds":{"DBLP":"conf/nips/HamiltonYL17","MAG":"2952779545","ArXiv":"1706.02216","CorpusId":4755450},"title":"Inductive Representation Learning on Large Graphs"},{"paperId":"68564f11e79c19195d0e82854a0aa156d7764922","externalIds":{"MAG":"2617799811","ArXiv":"1705.08504","DBLP":"journals/corr/BastaniKB17","CorpusId":42219049},"title":"Interpreting Blackbox Models via Model Extraction"},{"paperId":"5daf6e4b51387d2a57ca0b4cefdf459aa57893ac","externalIds":{"DBLP":"journals/popets/HayesMDC19","MAG":"2887995258","DOI":"10.2478/popets-2019-0008","CorpusId":52211986},"title":"LOGAN: Membership Inference Attacks Against Generative Models"},{"paperId":"2ac11a0b84580e88bb8c6e5edb38c92fe1456864","externalIds":{"MAG":"2623427976","DOI":"10.1109/THS.2017.7943475","CorpusId":43625028},"title":"How to steal a machine learning classifier with deep learning"},{"paperId":"5320c90d52541d5581f0a8c4b75d9b2da81299ce","externalIds":{"MAG":"2963671176","ArXiv":"1703.06490","DBLP":"conf/mlhc/ChoiBMDSS17","CorpusId":7739761},"title":"Generating Multi-label Discrete Patient Records using Generative Adversarial Networks"},{"paperId":"a456265138c088a894301c0433dae938705a9bec","externalIds":{"ArXiv":"1703.06114","CorpusId":4870287},"title":"Deep Sets"},{"paperId":"44a97f4eaaefaf5338f8aed2913d5debb2459f7e","externalIds":{"MAG":"2951368041","ArXiv":"1702.07464","DBLP":"journals/corr/HitajAP17","DOI":"10.1145/3133956.3134012","CorpusId":5051282},"title":"Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning"},{"paperId":"b0dc598adda48acab590f95a5985fcc7abf2aca9","externalIds":{"MAG":"2594877703","ArXiv":"1702.01135","DBLP":"conf/cav/KatzBDJK17","DOI":"10.1007/978-3-319-63387-9_5","CorpusId":516928},"title":"Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks"},{"paperId":"f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d","externalIds":{"ArXiv":"1610.05820","DBLP":"journals/corr/ShokriSS16","MAG":"2535690855","DOI":"10.1109/SP.2017.41","CorpusId":10488675},"title":"Membership Inference Attacks Against Machine Learning Models"},{"paperId":"e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9","externalIds":{"DBLP":"journals/corr/PapernotAEGT16","ArXiv":"1610.05755","MAG":"2532781556","CorpusId":8696462},"title":"Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data"},{"paperId":"df40ce107a71b770c9d0354b78fdd8989da80d2f","externalIds":{"DBLP":"conf/sp/Carlini017","MAG":"2951755642","ArXiv":"1608.04644","DOI":"10.1109/SP.2017.49","CorpusId":2893830},"title":"Towards Evaluating the Robustness of Neural Networks"},{"paperId":"8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e","externalIds":{"MAG":"2461943168","ArXiv":"1609.02943","DBLP":"conf/uss/TramerZJRR16","CorpusId":2984526},"title":"Stealing Machine Learning Models via Prediction APIs"},{"paperId":"ae5c45c7fe5a028666de116fe55caf134ccceb1a","externalIds":{"MAG":"2413206043","DOI":"10.1142/9789814704830_0046","CorpusId":62986110},"title":"Improving Attribute Inference Attack Using Link Prediction in Online Social Networks"},{"paperId":"e9a986c8ff6c2f381d026fe014f6aaa865f34da7","externalIds":{"MAG":"3098586851","ArXiv":"1607.00133","DBLP":"conf/ccs/AbadiCGMMT016","DOI":"10.1145/2976749.2978318","CorpusId":207241585},"title":"Deep Learning with Differential Privacy"},{"paperId":"03508376a5b1352e132e78a4dfa86236d6a096a2","externalIds":{"MAG":"2953300909","DBLP":"conf/uss/GongL16","ArXiv":"1606.05893","CorpusId":4948164},"title":"You Are Who You Know and How You Behave: Attribute Inference Attacks via Users' Social Friends and Behaviors"},{"paperId":"d1dbf643447405984eeef098b1b320dee0b3b8a7","externalIds":{"MAG":"2950745363","DBLP":"conf/aistats/McMahanMRHA17","ArXiv":"1602.05629","CorpusId":14955348},"title":"Communication-Efficient Learning of Deep Networks from Decentralized Data"},{"paperId":"2fe465b7beffa6687452b3ef80f555d8bd8ec0c0","externalIds":{"MAG":"2263253503","ArXiv":"1602.03552","DBLP":"journals/corr/HammCB16","CorpusId":28404},"title":"Learning privately from multiparty data"},{"paperId":"e8b8a7778ace2a02f8db6fe321a54520c6b283ca","externalIds":{"DBLP":"conf/icml/LarsenSLW16","MAG":"2202109488","ArXiv":"1512.09300","CorpusId":8785311},"title":"Autoencoding beyond pixels using a learned similarity metric"},{"paperId":"ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30","externalIds":{"MAG":"2294710185","DBLP":"conf/icmla/RibeiroGC15","DOI":"10.1109/ICMLA.2015.152","CorpusId":206823005},"title":"MLaaS: Machine Learning as a Service"},{"paperId":"819167ace2f0caae7745d2f25a803979be5fbfae","externalIds":{"MAG":"2949152835","ArXiv":"1511.07528","DBLP":"conf/eurosp/PapernotMJFCS16","DOI":"10.1109/EUROSP.2016.36","CorpusId":7004303},"title":"The Limitations of Deep Learning in Adversarial Settings"},{"paperId":"8388f1be26329fa45e5807e968a641ce170ea078","externalIds":{"MAG":"2949811265","ArXiv":"1511.06434","DBLP":"journals/corr/RadfordMC15","CorpusId":11758569},"title":"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"},{"paperId":"d1b9a3b11e6c9571a1553556f82b605b2b4baec3","externalIds":{"DBLP":"conf/ccs/FredriksonJR15","MAG":"2051267297","DOI":"10.1145/2810103.2813677","CorpusId":207229839},"title":"Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures"},{"paperId":"9699fbc6a1326b550e789b96587b63378ec31c40","externalIds":{"MAG":"2074388704","DBLP":"conf/ccs/NaveedKW15","DOI":"10.1145/2810103.2813651","CorpusId":493307},"title":"Inference Attacks on Property-Preserving Encrypted Databases"},{"paperId":"d422df8bff4e677a3077635db116679d25142bfc","externalIds":{"MAG":"1901616594","DOI":"10.1126/science.aaa8415","CorpusId":677218,"PubMed":"26185243"},"title":"Machine learning: Trends, perspectives, and prospects"},{"paperId":"2f2ade8c4944a96a44e6f70ef403b80b058d1725","externalIds":{"DBLP":"conf/sp/CaoY15","MAG":"1488996941","DOI":"10.1109/SP.2015.35","CorpusId":5945696},"title":"Towards Making Systems Forget with Machine Unlearning"},{"paperId":"b023ac9848659893c2ed17c5b6ad5e1a9448c590","externalIds":{"DBLP":"conf/eurocrypt/DucasM15","MAG":"913176383","DOI":"10.1007/978-3-662-46800-5_24","CorpusId":6713594},"title":"FHEW: Bootstrapping Homomorphic Encryption in Less Than a Second"},{"paperId":"bee044c8e8903fb67523c1f8c105ab4718600cdb","externalIds":{"MAG":"2952181735","DBLP":"journals/corr/GoodfellowSS14","ArXiv":"1412.6572","CorpusId":6706414},"title":"Explaining and Harnessing Adversarial Examples"},{"paperId":"bef926d63512dbffcf1af59f72295ef497f5acf9","externalIds":{"MAG":"2072273451","DBLP":"journals/access/GalballyMF14","DOI":"10.1109/ACCESS.2014.2381273","CorpusId":416565},"title":"Biometric Antispoofing Methods: A Survey in Face Recognition"},{"paperId":"4c32a35890b894d6e360257e0709a21df9affa85","externalIds":{"MAG":"1473189865","DBLP":"conf/uss/FredriksonLJLPR14","CorpusId":2148083,"PubMed":"27077138"},"title":"Privacy in Pharmacogenetics: An End-to-End Case Study of Personalized Warfarin Dosing"},{"paperId":"0023582fde36430c7e3ae81611a14e558c8f4bae","externalIds":{"DBLP":"journals/fttcs/DworkR14","MAG":"2027595342","DOI":"10.1561/0400000042","CorpusId":207178262},"title":"The Algorithmic Foundations of Differential Privacy"},{"paperId":"6c9a850125cde0ae999f0617a54feb29b4a2b96c","externalIds":{"DBLP":"journals/tbc/LuoXZDXYZ14","MAG":"2077386717","DOI":"10.1109/TBC.2013.2295894","CorpusId":206606227},"title":"You Are What You Watch and When You Watch: Inferring Household Structures From IPTV Viewing Data"},{"paperId":"318a4a5665212d230c2418815acfb11274aee2c4","externalIds":{"MAG":"2118675731","DBLP":"conf/recsys/BhagatWIT14","ArXiv":"1311.6802","DOI":"10.1145/2645710.2645747","CorpusId":3044479},"title":"Recommending with an agenda: active learning of private attributes using matrix factorization"},{"paperId":"f63487b3fda2d96d8b3e97391448c76e00f2353c","externalIds":{"MAG":"2962835266","ArXiv":"1306.4447","DBLP":"journals/corr/AtenieseFMSVV13","DOI":"10.1504/IJSN.2015.071829","CorpusId":14757739},"title":"Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers"},{"paperId":"bfc1c08ba71294ce5de5e131561cfa7594d64a0f","externalIds":{"MAG":"2153803020","DOI":"10.1073/pnas.1218772110","CorpusId":456889,"PubMed":"23479631"},"title":"Private traits and attributes are predictable from digital records of human behavior"},{"paperId":"44f2984cd69d05861c696c5a0ea7ecb3e2c18218","externalIds":{"MAG":"2159196732","DBLP":"conf/recsys/WeinsbergBIT12","DOI":"10.1145/2365952.2365989","CorpusId":9507515},"title":"BlurMe: inferring and obfuscating user gender based on ratings"},{"paperId":"990a02f20529f5ce3b382f1d54648afaab391179","externalIds":{"ArXiv":"1206.6389","DBLP":"conf/icml/BiggioNL12","MAG":"2112507308","CorpusId":9089716},"title":"Poisoning Attacks against Support Vector Machines"},{"paperId":"f7108386f0ba56da9839bd8b1d6206b14904bb0f","externalIds":{"MAG":"35446969","DBLP":"conf/dasfaa/LiuY12","DOI":"10.1007/978-3-642-29038-1_25","CorpusId":30913230},"title":"Protecting Sensitive Relationships against Inference Attacks in Social Networks"},{"paperId":"bfd53f3f786490c28f73f92d74d430f0880a5686","externalIds":{"DBLP":"conf/ndss/AbdelberiAK12","MAG":"2279779665","CorpusId":11490787},"title":"You are what you like! Information leakage through users' Interests"},{"paperId":"a7645855533c6514b04c269ac0e1885b4f274bf3","externalIds":{"MAG":"2129905915","DBLP":"journals/ejisec/RathgebU11","DOI":"10.1186/1687-417X-2011-3","CorpusId":5313655},"title":"A survey on biometric cryptosystems and cancelable biometrics"},{"paperId":"4e108f9eefc36525e121c236234d9658c7aa9bbe","externalIds":{"DBLP":"journals/corr/abs-1102-2166","MAG":"2150256170","ArXiv":"1102.2166","DOI":"10.2139/ssrn.1470768","CorpusId":11554719},"title":"Social Structure of Facebook Networks"},{"paperId":"3a643074ed1f7b90f65ec7b7a3eb07172c9621e3","externalIds":{"MAG":"2110287632","DBLP":"conf/nips/PathakRR10","CorpusId":13487372},"title":"Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers"},{"paperId":"9f253c0ede9b30ad7e54343f08a95df0fdb2ece2","externalIds":{"MAG":"1602027763","DBLP":"conf/pet/ThomasGN10","DOI":"10.1007/978-3-642-14527-8_14","CorpusId":12170312},"title":"unFriendly: Multi-party Privacy Risks in Social Networks"},{"paperId":"c6d3d381b8f23228ac3714b06797aa2d18c12cff","externalIds":{"MAG":"2136486572","DBLP":"conf/wsdm/MisloveVGD10","DOI":"10.1145/1718487.1718519","CorpusId":11196829},"title":"You are who you know: inferring user profiles in online social networks"},{"paperId":"569702d3f854ecd55d3877d2b6cb45292aa7ae29","externalIds":{"DBLP":"conf/www/ZhelevaG09","MAG":"2103133870","DOI":"10.1145/1526709.1526781","CorpusId":7667947},"title":"To join or not to join: the illusion of privacy in social networks with mixed public and private user profiles"},{"paperId":"83b60b919278bbf72a79cff23dce953a9d5b0110","externalIds":{"PubMedCentral":"2516199","MAG":"2040228409","DOI":"10.1371/journal.pgen.1000167","CorpusId":916355,"PubMed":"18769715"},"title":"Resolving Individuals Contributing Trace Amounts of DNA to Highly Complex Mixtures Using High-Density SNP Genotyping Microarrays"},{"paperId":"42db943d7d2a6a9caf2fd9fc8c78df5660a4e209","externalIds":{"MAG":"1563889237","DBLP":"conf/icml/MacKinnonW06","DOI":"10.1007/978-3-540-73133-7_14","CorpusId":917475},"title":"Age and Geographic Inferences of the LiveJournal Social Network"},{"paperId":"732cee3bddcbdf14404f14450dc09a6534b72188","externalIds":{"DBLP":"conf/isi/HeCL06","MAG":"2110156460","DOI":"10.1007/11760146_14","CorpusId":9399884},"title":"Inferring Privacy Information from Social Networks"},{"paperId":"56800ea46f23427ef5b57448d00b15dc9833af4c","externalIds":{"CorpusId":249432162},"title":"Subject Membership Inference Attacks in Federated Learning"},{"paperId":"e3dd857b2302327674dfaa90d3f29c57055e7205","externalIds":{"DBLP":"conf/icml/BeguelinTPK21","CorpusId":235640832},"title":"Grey-box Extraction of Natural Language Models"},{"paperId":"7e6e17337eee53d90988ec23ee11f223de7b592a","externalIds":{"DBLP":"journals/corr/abs-2102-07762","CorpusId":263890541},"title":"Reconstruction-Based Membership Inference Attacks are Easier on Difficult Problems"},{"paperId":"82a50e3b54d665b11b65f04a10a7e0aa294d608e","externalIds":{"DBLP":"journals/corr/abs-2112-08806","CorpusId":245219037},"title":"Dataset correlation inference attacks against machine learning models"},{"paperId":"81e2a82360524014938dbc5721051cce7f3145e7","externalIds":{"DBLP":"journals/itiis/KhosravyNHNB21","DOI":"10.3837/tiis.2021.03.015","CorpusId":242690709},"title":"Model Inversion Attack: Analysis under Gray-box Scenario on Deep Learning based Face Recognition System"},{"paperId":"7351ac6dabf267f708b3a638765825effb9cb1ee","externalIds":{"MAG":"3085052658","DBLP":"journals/access/TanuwidjajaCBK20","DOI":"10.1109/ACCESS.2020.3023084","CorpusId":221725546},"title":"Privacy-Preserving Deep Learning on Machine Learning as a Service—a Comprehensive Survey"},{"paperId":"0d763d3e95c60445e004871ea4d5751199e5755c","externalIds":{"DBLP":"conf/l4dc/Zhang0L20","CorpusId":203591799},"title":"Online Data Poisoning Attacks"},{"paperId":"5a297feea7b23f96efb88f314847d428f6e7bf7c","externalIds":{"DBLP":"journals/iacr/HaleviS20","CorpusId":227298439},"title":"Design and implementation of HElib: a homomorphic encryption library"},{"paperId":"172ea9dd7595e0d0fbfb3119d7db1ff2e38f23f9","externalIds":{"CorpusId":231854135},"title":"Synthesizing Tabular Data using Conditional GAN"},{"paperId":"54232c6de4614862d3c8b0258d44209e70383c36","externalIds":{"CorpusId":237509895},"title":"Property Inference Attacks on Neural Networks using Dimension Reduction Representations"},{"paperId":"1a01a80840b3d6731c940233ee05c2bd4cb64691","externalIds":{"CorpusId":269913154},"title":"Property Inference in ReLU nets using Linear Interpolants"}]}