{"abstract":"Bug fixing is one of the most time-consuming and resource-intensive tasks in the software development life cycle. Automated Program Repair (APR) might be able to help in this process, but it still has to overcome many obstacles. Deep learning models have shown promise for automated program repair in recent years, but their effectiveness can depend on the representation of the source code used as input. In this paper, we conduct an experimental study to compare the performance of deep learning models on two popular programming languages, Java and JavaScript, using three different code representations: raw text, command sequences, and abstract syntax trees (ASTs). We also experiment with varying models, including T5, CodeT5, (for solving sequence-to-sequence tasks) RoBERTa, and GPTNeo (to encode/decode AST graph information). We evaluate the models on a set of real-world defects from open-source projects and compare the performance, and the repair patches generated by the models. Our results show that training on command sequence representation outperforms most other configurations. We achieve a best of 19.88% accuracy on the java-small dataset, and 11.87% on java-medium, using text representation. Using command sequence representation, we achieve 30.64% on java-small and 18.53% on the medium dataset. However, when representing the source with ast+text information, our models significantly underperform compared to other representations, achieving results below one percent. Our findings contribute to a better understanding of the strengths and limitations of deep learning models for automated program repair and provide practical guidance for their use in practice."}