{"references":[{"paperId":"f8359e7d74b2be343379472be3d2b452fcfa4801","externalIds":{"ArXiv":"2403.11807","DBLP":"journals/corr/abs-2403-11807","DOI":"10.48550/arXiv.2403.11807","CorpusId":268532288},"title":"How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments"},{"paperId":"1404b3cf9649ed6a933d06cb9ea3610ff8bc031c","externalIds":{"ArXiv":"2403.10249","DBLP":"journals/corr/abs-2403-10249","DOI":"10.48550/arXiv.2403.10249","CorpusId":268510267},"title":"A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges"},{"paperId":"84d5d280f726ddf94ba85621581c4fe5f243a04f","externalIds":{"ACL":"2024.emnlp-main.26","ArXiv":"2403.06769","DBLP":"conf/emnlp/ZhangH0LLWLC24","DOI":"10.18653/v1/2024.emnlp-main.26","CorpusId":268357081},"title":"Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"},{"paperId":"6a1d85d1a73d2b80f8a61db62e9b64299eb2dd7e","externalIds":{"DBLP":"journals/corr/abs-2403-05468","ArXiv":"2403.05468","DOI":"10.1109/TG.2024.3497601","CorpusId":268297162},"title":"Will GPT-4 Run DOOM?"},{"paperId":"fa0d056dd585eeffb4333cb55807d357808f8440","externalIds":{"ArXiv":"2403.05632","DBLP":"journals/corr/abs-2403-05632","DOI":"10.48550/arXiv.2403.05632","CorpusId":268349402},"title":"Can Large Language Models Play Games? A Case Study of A Self-Play Approach"},{"paperId":"789485978d69e248832df358ee0fb062012925b8","externalIds":{"ArXiv":"2402.17574","DBLP":"conf/acl/ZhangTWW0HTLZ024","DOI":"10.48550/arXiv.2402.17574","CorpusId":268032624},"title":"Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization"},{"paperId":"bb67e739b5056931e51eecfe2100a53031c04c19","externalIds":{"DBLP":"conf/acl/ChenHLHTH024","ArXiv":"2402.16499","DOI":"10.48550/arXiv.2402.16499","CorpusId":268032489},"title":"LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments"},{"paperId":"f85ec64b14494216702d5218f58e725224ad80aa","externalIds":{"DBLP":"conf/acl/Xia0RMZ0024","ArXiv":"2402.15813","DOI":"10.48550/arXiv.2402.15813","CorpusId":267938212},"title":"Measuring Bargaining Abilities of LLMs: A Benchmark and A Buyer-Enhancement Method"},{"paperId":"3e2ecfd1934a64582a6d2b5be20f18db78cc787d","externalIds":{"DBLP":"journals/corr/abs-2402-12348","ArXiv":"2402.12348","DOI":"10.48550/arXiv.2402.12348","CorpusId":267750698},"title":"GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations"},{"paperId":"11d4478587c4d2ecb195fe911809946928767657","externalIds":{"ArXiv":"2402.12327","DBLP":"conf/emnlp/WuPZLHKO0024","DOI":"10.18653/v1/2024.findings-emnlp.297","CorpusId":267750197},"title":"Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM Agents"},{"paperId":"ad4e02784491f9794f6abb76b8982c980f51a6ee","externalIds":{"DBLP":"journals/corr/abs-2402-06044","ArXiv":"2402.06044","DOI":"10.48550/arXiv.2402.06044","CorpusId":267617046},"title":"OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models"},{"paperId":"e98c08aff69258f5f8004197382b4f457b771a26","externalIds":{"DBLP":"journals/corr/abs-2402-06049","ArXiv":"2402.06049","DOI":"10.48550/arXiv.2402.06049","CorpusId":267617298},"title":"Limits of Large Language Models in Debating Humans"},{"paperId":"f503b95c0a64f6a84eb1d90e5ea1e094b1e1892b","externalIds":{"DBLP":"journals/corr/abs-2402-04049","ArXiv":"2402.04049","ACL":"2024.emnlp-main.16","DOI":"10.18653/v1/2024.emnlp-main.16","CorpusId":267499945},"title":"Systematic Biases in LLM Simulations of Debates"},{"paperId":"b6b6e59f3bfdda9d4a4dfe56c46b30706fd18cf3","externalIds":{"DBLP":"journals/corr/abs-2402-02330","ArXiv":"2402.02330","DOI":"10.48550/arXiv.2402.02330","CorpusId":267413027},"title":"Enhance Reasoning for Large Language Models in the Game Werewolf"},{"paperId":"26328d7c2796fc1d139719dd5e738c59aaa177a7","externalIds":{"ArXiv":"2402.01521","DBLP":"conf/naacl/ZhangMGWXLW25","DOI":"10.18653/v1/2025.naacl-long.370","CorpusId":267406499},"title":"K-Level Reasoning: Establishing Higher Order Beliefs in Large Language Models for Strategic Reasoning"},{"paperId":"0e0a513624426e017a125d0498235b8f32ce9aa5","externalIds":{"ArXiv":"2401.17749","DBLP":"journals/corr/abs-2401-17749","DOI":"10.48550/arXiv.2401.17749","CorpusId":267334921},"title":"SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models"},{"paperId":"0d370b2dde53ca0fc43d3dfefd5f032952fcb3c5","externalIds":{"DBLP":"conf/emnlp/HuaQH24","ArXiv":"2402.01737","DOI":"10.18653/v1/2024.findings-emnlp.473","CorpusId":267412096},"title":"Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues"},{"paperId":"32a5dcd8ef1b1c41bbb494a953dc4bb63e82b40d","externalIds":{"ArXiv":"2402.01704","CorpusId":267412585},"title":"Steering Language Models with Game-Theoretic Solvers"},{"paperId":"8f070e301979732e0dd73f6aa6170309cf73aa7d","externalIds":{"DBLP":"journals/corr/abs-2402-01680","ArXiv":"2402.01680","DOI":"10.48550/arXiv.2402.01680","CorpusId":267412980},"title":"Large Language Model based Multi-Agents: A Survey of Progress and Challenges"},{"paperId":"0e3c90f70019f7c736e3abd762c652e3e2561fec","externalIds":{"DBLP":"journals/corr/abs-2401-10568","ArXiv":"2401.10568","DOI":"10.48550/arXiv.2401.10568","CorpusId":267061073},"title":"CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents"},{"paperId":"deb7c1867cc5ec4ab51f67f84b7ffb8fc949ddf4","externalIds":{"ArXiv":"2401.06781","DBLP":"journals/corr/abs-2401-06781","DOI":"10.48550/arXiv.2401.06781","CorpusId":266999783},"title":"PokerGPT: An End-to-End Lightweight Solver for Multi-Player Texas Hold'em via Large Language Model"},{"paperId":"592ac35991e583fc37c26ee6659d2deb85142ad9","externalIds":{"DBLP":"journals/corr/abs-2312-11970","ArXiv":"2312.11970","DOI":"10.1057/s41599-024-03611-3","CorpusId":266362356},"title":"Large language models empowered agent-based modeling and simulation: a survey and perspectives"},{"paperId":"9f22f66cacac8eebc5728cd0a28513b5e75a9a58","externalIds":{"DBLP":"journals/corr/abs-2312-11865","ArXiv":"2312.11865","DOI":"10.48550/arXiv.2312.11865","CorpusId":266362531},"title":"Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach"},{"paperId":"34ad751c1e797975452c655e3912313044d1dd17","externalIds":{"DBLP":"journals/corr/abs-2312-11813","ArXiv":"2312.11813","DOI":"10.48550/arXiv.2312.11813","CorpusId":266362729},"title":"Urban Generative Intelligence (UGI): A Foundational Platform for Agents in Embodied City Environment"},{"paperId":"4768692b14a86edc398199a089e2e35ab271e2ca","externalIds":{"DBLP":"journals/corr/abs-2312-10256","ArXiv":"2312.10256","DOI":"10.48550/arXiv.2312.10256","CorpusId":266348837},"title":"Multi-agent Reinforcement Learning: A Comprehensive Survey"},{"paperId":"efc1a48aac58e743ac2c5e96994064240da4df67","externalIds":{"DBLP":"conf/aaai/FanCJ024","ArXiv":"2312.05488","DOI":"10.48550/arXiv.2312.05488","CorpusId":266163085},"title":"Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis"},{"paperId":"c36b4aec0c26f1ff5b3cf7e86c0b90f51575ebea","externalIds":{"DBLP":"journals/corr/abs-2312-00746","ArXiv":"2312.00746","DOI":"10.48550/arXiv.2312.00746","CorpusId":265551867},"title":"Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games"},{"paperId":"9ad3edeea4732cb44a26f39652a668d1a562b0cf","externalIds":{"DBLP":"journals/corr/abs-2311-17227","ArXiv":"2311.17227","DOI":"10.48550/arXiv.2311.17227","CorpusId":265498466},"title":"War and Peace (WarAgent): Large Language Model-based Multi-Agent Simulation of World Wars"},{"paperId":"1909ad17042a0d2af93898d427df0cef9d4483e3","externalIds":{"DBLP":"journals/corr/abs-2312-03720","ArXiv":"2312.03720","DOI":"10.48550/arXiv.2312.03720","CorpusId":266052011},"title":"Negotiating with LLMS: Prompt Hacks, Skill Gaps, and Reasoning Deficits"},{"paperId":"bc8d248fb86a3b6a285e8b9a6fe2c09e7f0b19c9","externalIds":{"ArXiv":"2311.13884","DBLP":"journals/corr/abs-2311-13884","DOI":"10.48550/arXiv.2311.13884","CorpusId":265445440},"title":"Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach"},{"paperId":"0aa150619e07fa41492517368beaaf8ae56fe061","externalIds":{"ArXiv":"2311.10227","DBLP":"journals/corr/abs-2311-10227","DOI":"10.48550/arXiv.2311.10227","CorpusId":265281627},"title":"Think Twice: Perspective-Taking Improves Large Language Models' Theory-of-Mind Capabilities"},{"paperId":"44d16a076c00ecada3d425203377e4ec951c4ed0","externalIds":{"DBLP":"journals/corr/abs-2311-10537","ArXiv":"2311.10537","DOI":"10.48550/arXiv.2311.10537","CorpusId":265281260},"title":"MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning"},{"paperId":"72273f7a050529fc71c7d45c0256d2b9754f56bb","externalIds":{"ArXiv":"2311.08562","DBLP":"conf/emnlp/XuHZR0KNF24","ACL":"2024.emnlp-main.416","DOI":"10.48550/arXiv.2311.08562","CorpusId":265212971},"title":"MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration"},{"paperId":"ac258100ebe178287ae4ae3dc7ac78f8c27e017d","externalIds":{"DBLP":"conf/icml/Xu000W24","ArXiv":"2310.18940","DOI":"10.48550/arXiv.2310.18940","CorpusId":264590387},"title":"Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game"},{"paperId":"ff406e2ab8fdcce6b051cad1ead794c928440f77","externalIds":{"ArXiv":"2310.14985","DBLP":"journals/corr/abs-2310-14985","ACL":"2024.emnlp-main.7","DOI":"10.48550/arXiv.2310.14985","CorpusId":264436387},"title":"LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"},{"paperId":"9b3cc162df43bc999d6cba219e8d9871c28fbdcc","externalIds":{"DBLP":"conf/acl/Li0L0L24","ArXiv":"2310.10436","DOI":"10.18653/v1/2024.acl-long.829","CorpusId":264146527},"title":"EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities"},{"paperId":"e17c58d7a48b6b811df023484161a3b9c03e0d6b","externalIds":{"DBLP":"journals/corr/abs-2310-10701","ArXiv":"2310.10701","DOI":"10.18653/v1/2023.emnlp-main.13","CorpusId":264172518},"title":"Theory of Mind for Multi-Agent Collaboration via Large Language Models"},{"paperId":"8460e51e6231c4573302ebd10ca765322fc1e3c3","externalIds":{"ArXiv":"2310.08901","DBLP":"journals/corr/abs-2310-08901","DOI":"10.48550/arXiv.2310.08901","CorpusId":264127980},"title":"Welfare Diplomacy: Benchmarking Language Model Cooperation"},{"paperId":"0e9a44ce661c3535d5ce747912540080324489f5","externalIds":{"ArXiv":"2310.05746","DBLP":"journals/corr/abs-2310-05746","DOI":"10.48550/arXiv.2310.05746","CorpusId":263831697},"title":"Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena"},{"paperId":"7f0d1740e74ce36424d64d608270077b64dfe7c0","externalIds":{"DBLP":"conf/naacl/AgasheFRW25","ArXiv":"2310.03903","DOI":"10.18653/v1/2025.findings-naacl.448","CorpusId":263830046},"title":"LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models"},{"paperId":"3aa13d6313d49dc634b28bde15fca4d3d3032694","externalIds":{"DBLP":"journals/corr/abs-2310-05976","ArXiv":"2310.05976","PubMedCentral":"10951268","DOI":"10.1038/s41598-024-55903-y","CorpusId":263830498,"PubMed":"38503778"},"title":"An evolutionary model of personality traits related to cooperative behavior using a large language model"},{"paperId":"b783168c885ecbae0fccdb46ec8e9afd0ef99b7f","externalIds":{"ArXiv":"2310.01320","DBLP":"journals/corr/abs-2310-01320","DOI":"10.48550/arXiv.2310.01320","CorpusId":263605971},"title":"Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation"},{"paperId":"e5ca92aa893b4eb2ddb1310ddb8e30a187ee4f97","externalIds":{"DBLP":"conf/nips/AbdelnabiGSSF24","ArXiv":"2309.17234","DOI":"10.52202/079017-2658","CorpusId":263310628},"title":"Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation"},{"paperId":"e8df1cf6742b50a15500b8dd3dde3942e9c91418","externalIds":{"DBLP":"conf/icml/WanFWM00024","ArXiv":"2309.17179","DOI":"10.48550/arXiv.2309.17179","CorpusId":263310590},"title":"Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training"},{"paperId":"c74e9642ec71c6dfaadd3b8638c110d4048ff53e","externalIds":{"DBLP":"journals/corr/abs-2309-17277","ArXiv":"2309.17277","DOI":"10.48550/arXiv.2309.17277","CorpusId":263310339},"title":"Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4"},{"paperId":"0c72450890a54b68d63baa99376131fda8f06cf9","externalIds":{"ArXiv":"2309.07864","DBLP":"journals/corr/abs-2309-07864","DOI":"10.48550/arXiv.2309.07864","CorpusId":261817592},"title":"The Rise and Potential of Large Language Model Based Agents: A Survey"},{"paperId":"17e8f71dfdfa03f5df6e5ed7b40ec3b396f17a79","externalIds":{"DBLP":"journals/corr/abs-2309-05898","ArXiv":"2309.05898","DOI":"10.48550/arXiv.2309.05898","CorpusId":261697307},"title":"Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing"},{"paperId":"24d52678c887331b9da0368e8a2f58bec07f7203","externalIds":{"DBLP":"journals/corr/abs-2309-04658","ArXiv":"2309.04658","DOI":"10.48550/arXiv.2309.04658","CorpusId":261681932},"title":"Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf"},{"paperId":"95264f2fd070e9ee21dd2d36196a69c91a63e852","externalIds":{"ArXiv":"2309.03736","CorpusId":261582775},"title":"TradingGPT: Multi-Agent System with Layered Memory and Distinct Characters for Enhanced Financial Trading Performance"},{"paperId":"f221eccdd96122a42c5e65532373e6974b30c20c","externalIds":{"ArXiv":"2308.15118","DBLP":"journals/corr/abs-2308-15118","DOI":"10.48550/arXiv.2308.15118","CorpusId":261276512},"title":"Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills"},{"paperId":"28c6ac721f54544162865f41c5692e70d61bccab","externalIds":{"DBLP":"journals/fcsc/WangMFZYZCTCLZWW24","ArXiv":"2308.11432","DOI":"10.1007/s11704-024-40231-1","CorpusId":261064713},"title":"A survey on large language model based autonomous agents"},{"paperId":"eb2e4aae96e77b81371039b57a0cfa8a1096e7ee","externalIds":{"DBLP":"journals/corr/abs-2308-10974","ArXiv":"2308.10974","DOI":"10.48550/arXiv.2308.10974","CorpusId":261064688},"title":"\"Guinea Pig Trials\" Utilizing GPT: A Novel Smart Agent-Based Modeling Approach for Studying Firm Competition and Collusion"},{"paperId":"6f28ca1e6c007c46cbc30aad531d800b8e6bc405","externalIds":{"DBLP":"journals/corr/abs-2308-10032","ArXiv":"2308.10032","DOI":"10.48550/arXiv.2308.10032","CorpusId":261048971},"title":"GameEval: Evaluating LLMs on Conversational Games"},{"paperId":"81b10e64133e775dab53153cc82277d276efe1f7","externalIds":{"DBLP":"conf/iclr/YaoHNLFXNC0AXMW24","ArXiv":"2308.02151","DOI":"10.48550/arXiv.2308.02151","CorpusId":260611249},"title":"Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"},{"paperId":"434b9f9bc71c935e4a46a1aff36a8cc4c22d9afa","externalIds":{"ACL":"2024.naacl-long.15","ArXiv":"2307.05300","DBLP":"conf/naacl/WangMW0WJ24","DOI":"10.18653/v1/2024.naacl-long.15","CorpusId":259765919},"title":"Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration"},{"paperId":"8fa022485e39788ddab1992cf96ed67783f34c10","externalIds":{"ArXiv":"2308.01404","DBLP":"journals/corr/abs-2308-01404","DOI":"10.48550/arXiv.2308.01404","CorpusId":260438869},"title":"Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models"},{"paperId":"f590cbb28e4994f62e94bf9400a9cb33e99922fa","externalIds":{"ArXiv":"2306.15448","DBLP":"journals/corr/abs-2306-15448","DOI":"10.48550/arXiv.2306.15448","CorpusId":259262573},"title":"Understanding Social Reasoning in Language Models with Language Models"},{"paperId":"b9a1189f2de7fd5e66551d7c425556e5642b823a","externalIds":{"DBLP":"journals/corr/abs-2306-09200","ArXiv":"2306.09200","DOI":"10.48550/arXiv.2306.09200","CorpusId":259165028},"title":"ChessGPT: Bridging Policy Learning and Language Modeling"},{"paperId":"f1a3cd5cc340f47e3e966709f7dfddef23460aa2","externalIds":{"ArXiv":"2305.19165","DBLP":"journals/corr/abs-2305-19165","DOI":"10.48550/arXiv.2305.19165","CorpusId":258968043},"title":"Strategic Reasoning with Language Models"},{"paperId":"3f98cf521222c65522200037c0eb95a17081b2dd","externalIds":{"PubMedCentral":"12283376","ArXiv":"2305.16867","DBLP":"journals/corr/abs-2305-16867","DOI":"10.1038/s41562-025-02172-y","CorpusId":258947115,"PubMed":"40341716"},"title":"Playing repeated games with large language models"},{"paperId":"de916e9e6f8841dbb73b35615f8d15eba2e9eaf7","externalIds":{"PubMedCentral":"10740389","ArXiv":"2305.12763","DOI":"10.1073/pnas.2316205120","CorpusId":258833561,"PubMed":"38085780"},"title":"The emergence of economic rationality of GPT"},{"paperId":"2e6b6de08f459e2165b11ed8d2103916966b0fcf","externalIds":{"ArXiv":"2305.10142","DBLP":"journals/corr/abs-2305-10142","DOI":"10.48550/arXiv.2305.10142","CorpusId":258740978},"title":"Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback"},{"paperId":"f6f6e7aabd6dc4ba159fb76ddc7735323241c9de","externalIds":{"ArXiv":"2305.07970","DOI":"10.1088/2632-072X/ada711","CorpusId":258685424},"title":"The machine psychology of cooperation: can GPT models operationalize prompts for altruism, cooperation, competitiveness, and selfishness in economic games?"},{"paperId":"5f8b29020b1724bd1fae229868581f31a4f9382a","externalIds":{"ArXiv":"2305.05516","CorpusId":258564218},"title":"GPT in Game Theory Experiments"},{"paperId":"ef4cb88b1635b34af15059567dfdf134f79797aa","externalIds":{"ArXiv":"2304.05351","DBLP":"journals/corr/abs-2304-05351","DOI":"10.48550/arXiv.2304.05351","CorpusId":258059831},"title":"The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges"},{"paperId":"5278a8eb2ba2429d4029745caf4e661080073c81","externalIds":{"DBLP":"conf/uist/ParkOCMLB23","ArXiv":"2304.03442","DOI":"10.1145/3586183.3606763","CorpusId":258040990},"title":"Generative Agents: Interactive Simulacra of Human Behavior"},{"paperId":"23678972c3423d12e738f8ab34dd0018d47fb151","externalIds":{"ArXiv":"2304.02868","DBLP":"journals/corr/abs-2304-02868","DOI":"10.48550/arXiv.2304.02868","CorpusId":257985065},"title":"Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions"},{"paperId":"e89ed6bb1864558e3889f5f2fb8931643c633479","externalIds":{"DOI":"10.1126/science.ade9097","CorpusId":253759631,"PubMed":"36413172"},"title":"Human-level play in the game of Diplomacy by combining language models with strategic reasoning"},{"paperId":"311fd5f6f114ae51f8cbd95a0da69d7b556d25f1","externalIds":{"ACL":"2022.emnlp-main.248","DBLP":"conf/emnlp/Sap0FC22","ArXiv":"2210.13312","DOI":"10.48550/arXiv.2210.13312","CorpusId":253098632},"title":"Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"d65a064eb837f838faf6ff67781b62450b92b159","externalIds":{"ArXiv":"2201.05320","DBLP":"conf/nips/TalmorYBBGCB21","MAG":"3193231083","CorpusId":237263476},"title":"CommonsenseQA 2.0: Exposing the Limits of AI through Gamification"},{"paperId":"98cb29c03a0882fde368db28ade214c57c3239d6","externalIds":{"DBLP":"journals/air/GronauerD22","MAG":"3156295478","DOI":"10.1007/s10462-021-09996-w","CorpusId":234833859},"title":"Multi-agent deep reinforcement learning: a survey"},{"paperId":"f13e41d24e5d0a68ca662c1b49de398a6fb68251","externalIds":{"ArXiv":"2106.15772","DBLP":"conf/acl/MiaoLS20","MAG":"3034643750","ACL":"2020.acl-main.92","DOI":"10.18653/v1/2020.acl-main.92","CorpusId":220047831},"title":"A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"c27db32efa8137cbf654902f8f728f338e55cd1c","externalIds":{"MAG":"2766447205","DBLP":"journals/nature/SilverSSAHGHBLB17","DOI":"10.1038/nature24270","CorpusId":205261034,"PubMed":"29052630"},"title":"Mastering the game of Go without human knowledge"},{"paperId":"498238a3bd5fd322fc3ce1572e33bbe3853a356f","externalIds":{"ArXiv":"1708.05866","DBLP":"journals/corr/abs-1708-05866","MAG":"3100789280","DOI":"10.1109/MSP.2017.2743240","CorpusId":4884302},"title":"Deep Reinforcement Learning: A Brief Survey"},{"paperId":"717872ad77899ce9841dc943e6b21fa3fd04fa62","externalIds":{"MAG":"2057014363","DOI":"10.1057/jma.2013.14","CorpusId":63491777},"title":"Predictive analytics: The power to predict who will click, buy, lie, or die"},{"paperId":"c37f1baac3c8ba30250084f067167ac3837cf6fd","externalIds":{"DBLP":"journals/tciaig/BrownePWLCRTPSC12","MAG":"2126316555","DOI":"10.1109/TCIAIG.2012.2186810","CorpusId":9316331},"title":"A Survey of Monte Carlo Tree Search Methods"},{"paperId":"caaa78232742994452f96363ab6c6a834ed462a4","externalIds":{"MAG":"2168222508","DOI":"10.1093/brain/awn279","CorpusId":9732641,"PubMed":"18971202"},"title":"Two systems for empathy: a double dissociation between emotional and cognitive empathy in inferior frontal gyrus versus ventromedial prefrontal lesions."},{"paperId":"53c758c0bcde5d846bc79415bc391d248c3fa052","externalIds":{"DBLP":"conf/atal/HoekJW05","MAG":"2054071520","DOI":"10.1145/1082473.1082497","CorpusId":12186720},"title":"A logic for strategic reasoning"},{"paperId":"e913e0a24f73f21ca11858c0eabc8625c7958e4a","externalIds":{"DOI":"10.2139/ssrn.4493398","CorpusId":259714625},"title":"Playing Games With GPT: What Can We Learn About a Large Language Model From Canonical Strategic Games?"},{"paperId":"3ca2296b4e9f33316e574cf14c166d2804198676","externalIds":{"DBLP":"journals/corr/abs-2310-17512","DOI":"10.48550/arXiv.2310.17512","CorpusId":264490541},"title":"CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents"},{"paperId":"85808d0b4b8988fd44020b35dfdda70b4f0076ca","externalIds":{"DBLP":"conf/emnlp/AhmadSMERM23","DOI":"10.18653/v1/2023.findings-emnlp.166","CorpusId":266167137},"title":"INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue Agent"},{"paperId":"207fff97b68777ddb382bb8bf0d997b2461ee128","externalIds":{"DBLP":"journals/corr/abs-2311-03220","DOI":"10.48550/arXiv.2311.03220","CorpusId":278732409},"title":"ALYMPICS: Language Agents Meet Game Theory"},{"paperId":"52c1502bd99ae5112c36be6d097655c000600ce7","externalIds":{"MAG":"2542129403","DOI":"10.7551/mitpress/7503.003.0076","CorpusId":63948832},"title":"TrueSkillâ„¢: A Bayesian Skill Rating System"},{"paperId":"17557958ec5775cbe0eee2c03d317d45c989dda7","externalIds":{"CorpusId":261140541,"PubMed":"16231555"},"title":"Abstract thinking."},{"paperId":"1ddbb81f41cf90593f307794ea1356833953e724","externalIds":{"DOI":"10.1002/0470018860.s00512","CorpusId":6100947,"PubMed":"15012459"},"title":"Deductive reasoning."}]}