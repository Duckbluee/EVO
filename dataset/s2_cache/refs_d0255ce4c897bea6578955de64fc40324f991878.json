{"references":[{"paperId":"7f319badb2d7e38ad14596d832ad18de34f7cb7e","externalIds":{"DBLP":"journals/csur/SunZXLCQXDLGWWCYRFHYLLL25","DOI":"10.1145/3729218","CorpusId":266362535},"title":"A Survey of Reasoning with Foundation Models: Concepts, Methodologies, and Outlook"},{"paperId":"61494e66cac2a3b9b846a5c934d478bbd8b8c319","externalIds":{"DBLP":"journals/corr/abs-2405-00208","ArXiv":"2405.00208","DOI":"10.48550/arXiv.2405.00208","CorpusId":269484740},"title":"A Primer on the Inner Workings of Transformer-based Language Models"},{"paperId":"34c0ac6c012f524e30f083b81b148f65c41c221e","externalIds":{"ArXiv":"2404.18824","DBLP":"journals/corr/abs-2404-18824","DOI":"10.48550/arXiv.2404.18824","CorpusId":269448637},"title":"Benchmarking Benchmark Leakage in Large Language Models"},{"paperId":"8b750488d139f9beba0815ff8f46ebe15ebb3e58","externalIds":{"ArXiv":"2404.14082","DBLP":"journals/corr/abs-2404-14082","DOI":"10.48550/arXiv.2404.14082","CorpusId":269293418},"title":"Mechanistic Interpretability for AI Safety - A Review"},{"paperId":"6c3b832b98c2236b7e652f2d41573db20ca053d1","externalIds":{"DBLP":"journals/corr/abs-2404-08382","ArXiv":"2404.08382","DOI":"10.48550/arXiv.2404.08382","CorpusId":269137252},"title":"Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think"},{"paperId":"cf36c0c47e1f1a9bb5285c638bdd77244113bbae","externalIds":{"DOI":"10.1016/j.tics.2024.01.011","CorpusId":268551442,"PubMed":"38508911"},"title":"Dissociating language and thought in large language models"},{"paperId":"3c585441b4607b34f8bf4e352ed6e36753fe21ce","externalIds":{"DBLP":"journals/corr/abs-2402-19450","ArXiv":"2402.19450","DOI":"10.48550/arXiv.2402.19450","CorpusId":268091179},"title":"Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap"},{"paperId":"97994e4526ef7eeea59190aa466fbab05fad9187","externalIds":{"DBLP":"journals/tmlr/DuttaSC024","ArXiv":"2402.18312","DOI":"10.48550/arXiv.2402.18312","CorpusId":268041831},"title":"How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning"},{"paperId":"6982dba1c01082571d5bda6bfeb2b4b4db4b81fa","externalIds":{"DBLP":"journals/corr/abs-2402-14856","ArXiv":"2402.14856","DOI":"10.48550/arXiv.2402.14856","CorpusId":267897735},"title":"Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning"},{"paperId":"2208e506f72518a16ea86dfa604995c12fa8e4ca","externalIds":{"ArXiv":"2402.08939","DBLP":"journals/corr/abs-2402-08939","CorpusId":267657940},"title":"Premise Order Matters in Reasoning with Large Language Models"},{"paperId":"798feda076ad710df65d509a7884bd15937c8056","externalIds":{"ACL":"2024.eacl-long.5","DBLP":"journals/corr/abs-2402-03927","ArXiv":"2402.03927","DOI":"10.48550/arXiv.2402.03927","CorpusId":267499939},"title":"Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs"},{"paperId":"42445823fb0156afddc8c72eaa5ee81dded5b965","externalIds":{"ACL":"2024.eacl-srw.17","DBLP":"conf/eacl/AhnVLLZY24","ArXiv":"2402.00157","DOI":"10.48550/arXiv.2402.00157","CorpusId":267365459},"title":"Large Language Models for Mathematical Reasoning: Progresses and Challenges"},{"paperId":"4d3b2ce84634a4ab0222c0dfe13daf6b3516529f","externalIds":{"DBLP":"conf/emnlp/Wan0YY0HJL24","ACL":"2024.emnlp-main.128","ArXiv":"2401.00757","DOI":"10.18653/v1/2024.emnlp-main.128","CorpusId":266693275},"title":"LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"},{"paperId":"18e20944d1d64e73fc40321f65c3ddd0ef6a7aca","externalIds":{"DBLP":"journals/corr/abs-2312-11720","ArXiv":"2312.11720","DOI":"10.48550/arXiv.2312.11720","CorpusId":266361931},"title":"Assessing Logical Reasoning Capabilities of Encoder-Only Transformer Models"},{"paperId":"5ee871537ae51e7e2e93d2a70fff5d100649a655","externalIds":{"DBLP":"journals/csur/LiuHZDLZHCJZH26","ArXiv":"2312.07622","DOI":"10.1145/3773985","CorpusId":266191124},"title":"Mathematical Language Models: A Survey"},{"paperId":"9dd3e84935b6f85a8d59487c8364e623cf6f7be4","externalIds":{"DBLP":"journals/corr/abs-2312-04333","ArXiv":"2312.04333","DOI":"10.48550/arXiv.2312.04333","CorpusId":266055397},"title":"Is Bigger and Deeper Always Better? Probing LLaMA Across Scales and Layers"},{"paperId":"dab4f70d75a04e62553e583f2450d9bb1f0ead46","externalIds":{"DBLP":"journals/corr/abs-2311-17438","ArXiv":"2311.17438","DOI":"10.48550/arXiv.2311.17438","CorpusId":265498895},"title":"CLOMO: Counterfactual Logical Modification with Large Language Models"},{"paperId":"02186caef0f02305f85ceaf188f2ed8773e39217","externalIds":{"ArXiv":"2311.00445","DBLP":"journals/corr/abs-2311-00445","ACL":"2024.naacl-long.466","DOI":"10.48550/arXiv.2311.00445","CorpusId":264832674},"title":"A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models"},{"paperId":"70ca99ac3c21f353b3db948004510a09fdebc4f2","externalIds":{"DBLP":"journals/corr/abs-2310-14491","ArXiv":"2310.14491","DOI":"10.48550/arXiv.2310.14491","CorpusId":264426404},"title":"Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models"},{"paperId":"0885471c0215b3c0d31c82518066913f7f738128","externalIds":{"ArXiv":"2310.08559","DBLP":"conf/iclr/QiuJLSPBWK0D024","DOI":"10.48550/arXiv.2310.08559","CorpusId":263909078},"title":"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement"},{"paperId":"f42f61a547c5996be6aee175145b0d74e6324dff","externalIds":{"ArXiv":"2309.15402","DBLP":"conf/acl/ChuCCYH0P00L24","DOI":"10.18653/v1/2024.acl-long.65","CorpusId":263153015},"title":"Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"},{"paperId":"73dd6fce2db3e34d1f87f8449b1e8bde78c31547","externalIds":{"DBLP":"journals/corr/abs-2309-13638","ArXiv":"2309.13638","DOI":"10.48550/arXiv.2309.13638","CorpusId":262464572},"title":"Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve"},{"paperId":"8eafec7014d08043517834b5a2ed26384f188873","externalIds":{"ArXiv":"2309.12288","DBLP":"journals/corr/abs-2309-12288","CorpusId":262083829},"title":"The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\""},{"paperId":"b9672ac98913c43fcb996b3def314789d1cc0cf4","externalIds":{"DBLP":"journals/corr/abs-2308-13067","ArXiv":"2308.13067","DOI":"10.48550/arXiv.2308.13067","CorpusId":261214555},"title":"Causal Parrots: Large Language Models May Talk Causality But Are Not Causal"},{"paperId":"4b4ba6a02148c9d6f78e95d8e0d927104c3e91a7","externalIds":{"ArXiv":"2308.00225","DBLP":"journals/corr/abs-2308-00225","DOI":"10.1162/tacl_a_00673","CorpusId":260351059},"title":"Instructed to Bias: Instruction-Tuned Language Models Exhibit Emergent Cognitive Bias"},{"paperId":"f8e99be4f9a01761fab74bade2c3c18de9fc686b","externalIds":{"DBLP":"journals/corr/abs-2307-02477","ArXiv":"2307.02477","ACL":"2024.naacl-long.102","DOI":"10.48550/arXiv.2307.02477","CorpusId":259341893},"title":"Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks"},{"paperId":"8ac0a5d4ee77fcb420aa4fbb999d26bae2d0b130","externalIds":{"ACL":"2023.naloma-1.1","DBLP":"journals/corr/abs-2306-12567","ArXiv":"2306.12567","DOI":"10.48550/arXiv.2306.12567","CorpusId":259224503},"title":"Evaluating Large Language Models with NeuBAROCO: Syllogistic Reasoning Ability and Human-like Biases"},{"paperId":"31d65e179b1d00484154b3525d93846dd82f23d8","externalIds":{"DBLP":"journals/tmlr/McKenzieLPPMPMK23","ArXiv":"2306.09479","DOI":"10.48550/arXiv.2306.09479","CorpusId":259188012},"title":"Inverse Scaling: When Bigger Isn't Better"},{"paperId":"438a0221379aacd53f4d8af3b44dfdb2cc3ddab0","externalIds":{"DBLP":"journals/corr/abs-2306-08189","ACL":"2023.starsem-1.10","ArXiv":"2306.08189","DOI":"10.48550/arXiv.2306.08189","CorpusId":259164714},"title":"Language models are not naysayers: an analysis of language models on negation benchmarks"},{"paperId":"1727c04a73ca205bf9fbfd56466f8e0da6d11433","externalIds":{"ArXiv":"2306.06548","DBLP":"journals/corr/abs-2306-06548","DOI":"10.48550/arXiv.2306.06548","CorpusId":259138322},"title":"Inductive reasoning in humans and large language models"},{"paperId":"0a94fbb5e1c93513523f00e75d672ef4553861f9","externalIds":{"ArXiv":"2306.05836","DBLP":"conf/iclr/Jin0LPSMDS24","DOI":"10.48550/arXiv.2306.05836","CorpusId":259129342},"title":"Can Large Language Models Infer Causation from Correlation?"},{"paperId":"7d97c17a75beb89f938eaac1d3ca60ac2245fb2e","externalIds":{"ArXiv":"2305.18654","DBLP":"journals/corr/abs-2305-18654","CorpusId":258967391},"title":"Faith and Fate: Limits of Transformers on Compositionality"},{"paperId":"9028fd54ecbbd58da6f3d86629b48bb95405fff2","externalIds":{"ArXiv":"2305.16572","DBLP":"conf/acl/LiYE23","ACL":"2023.acl-short.70","DOI":"10.48550/arXiv.2305.16572","CorpusId":258947371},"title":"Counterfactual reasoning: Testing language modelsâ€™ understanding of hypothetical scenarios"},{"paperId":"ea75117f34b168a20f2a4309ac2eb685ca6b1436","externalIds":{"ArXiv":"2305.17306","DBLP":"journals/corr/abs-2305-17306","DOI":"10.48550/arXiv.2305.17306","CorpusId":258959433},"title":"Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance"},{"paperId":"c58325547156a70cb27c148e5b57738ca9ce79aa","externalIds":{"DBLP":"conf/nips/SaparovPPJKK023","ArXiv":"2305.15269","DOI":"10.48550/arXiv.2305.15269","CorpusId":258865898},"title":"Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples"},{"paperId":"138a78320301b6a3500f7752146d1a560de3aa32","externalIds":{"DBLP":"conf/emnlp/00020CS23","ArXiv":"2305.14010","DOI":"10.48550/arXiv.2305.14010","CorpusId":258841172},"title":"IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions"},{"paperId":"d7784e9aee50148edcab64ffbeea713c19144171","externalIds":{"ArXiv":"2305.13160","DBLP":"conf/emnlp/WangY023","DOI":"10.18653/v1/2023.findings-emnlp.795","CorpusId":258833581},"title":"Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate"},{"paperId":"69bef4ab1018cc956a77c3ccdcaa57b124ab9fcc","externalIds":{"DBLP":"conf/emnlp/PrasadSZB23","ArXiv":"2304.10703","DOI":"10.48550/arXiv.2304.10703","CorpusId":258291731},"title":"ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness"},{"paperId":"85cc48276c69924d3e92ddb38facb7d92be9a4a6","externalIds":{"DBLP":"journals/corr/abs-2304-03439","ArXiv":"2304.03439","DOI":"10.48550/arXiv.2304.03439","CorpusId":258041354},"title":"Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4"},{"paperId":"5eab810cc5d90de1c52127d1a5824f0817f46c30","externalIds":{"DBLP":"journals/csur/YuZTW24","ArXiv":"2303.14725","DOI":"10.1145/3664194","CorpusId":257766470},"title":"Natural Language Reasoning, A Survey"},{"paperId":"8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c","externalIds":{"ArXiv":"2303.12712","DBLP":"journals/corr/abs-2303-12712","CorpusId":257663729},"title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4"},{"paperId":"63d0e5a8f195b1453006781d4d8a4eb7262652d9","externalIds":{"DBLP":"journals/corr/abs-2303-12023","ArXiv":"2303.12023","DOI":"10.48550/arXiv.2303.12023","CorpusId":257636734},"title":"Logical Reasoning over Natural Language as Knowledge Representation: A Survey"},{"paperId":"695d11cfd7838b313935fe5fc7938de3816e5c7c","externalIds":{"ArXiv":"2303.04229","DBLP":"journals/corr/abs-2303-04229","DOI":"10.48550/arXiv.2303.04229","CorpusId":257405404},"title":"Understanding Natural Language Understanding Systems. A Critical Analysis"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"2029349c55c1dba3493c5b3bd25152f18ba21ae2","externalIds":{"ArXiv":"2302.07842","DBLP":"journals/tmlr/MialonDLNPRRSDC23","CorpusId":256868474},"title":"Augmented Language Models: a Survey"},{"paperId":"3d68522abfadfc8ee6b7ec9edaaf91f1b2f38e5e","externalIds":{"DBLP":"journals/corr/abs-2302-00093","ArXiv":"2302.00093","DOI":"10.48550/arXiv.2302.00093","CorpusId":256459776},"title":"Large Language Models Can Be Easily Distracted by Irrelevant Context"},{"paperId":"c7a4946eb49bc6a9c01eaa79e84a35316595bd5a","externalIds":{"ACL":"2024.eacl-long.13","DBLP":"journals/corr/abs-2212-10923","ArXiv":"2212.10923","DOI":"10.48550/arXiv.2212.10923","CorpusId":254926851},"title":"Language Models as Inductive Reasoners"},{"paperId":"db4ab91d5675c37795e719e997a2827d3d83cd45","externalIds":{"ArXiv":"2212.10403","DBLP":"conf/acl/0009C23","DOI":"10.48550/arXiv.2212.10403","CorpusId":254877753},"title":"Towards Reasoning in Large Language Models: A Survey"},{"paperId":"6845bea94b2fb17d4377b3bb2bd10f73a959f9cc","externalIds":{"DBLP":"journals/corr/abs-2212-09597","ArXiv":"2212.09597","ACL":"2023.acl-long.294","DOI":"10.48550/arXiv.2212.09597","CorpusId":254854219},"title":"Reasoning with Language Model Prompting: A Survey"},{"paperId":"391246ce9c59d61c94cca3f8bef56c95542a4708","externalIds":{"ArXiv":"2212.07919","DBLP":"journals/corr/abs-2212-07919","DOI":"10.48550/arXiv.2212.07919","CorpusId":254685985},"title":"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning"},{"paperId":"0bfc05adcddd4fe5d1335d96cc313c41526d4558","externalIds":{"ArXiv":"2306.07622","PubMedCentral":"10766525","DBLP":"journals/ncs/HagendorffFK23","DOI":"10.1038/s43588-023-00527-x","CorpusId":259145108,"PubMed":"38177754"},"title":"Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT"},{"paperId":"3eed4de25636ac90f39f6e1ef70e3507ed61a2a6","externalIds":{"DBLP":"journals/cacm/Shanahan24","ArXiv":"2212.03551","DOI":"10.1145/3624724","CorpusId":254366666},"title":"Talking about Large Language Models"},{"paperId":"5a3b8d1dd09b6aa9aef6332559203dbf805bca36","externalIds":{"DOI":"10.1007/s11229-022-03981-8","CorpusId":254020580},"title":"Arbitrating norms for reasoning tasks"},{"paperId":"9b45af10429681249fafb07c3b6012ea4ce63ffe","externalIds":{"ACL":"2023.acl-long.32","DBLP":"journals/corr/abs-2210-12023","ArXiv":"2210.12023","DOI":"10.48550/arXiv.2210.12023","CorpusId":253080612},"title":"A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models"},{"paperId":"e32185936ab3b23f39b1dd93e1507e6d80a71776","externalIds":{"PubMedCentral":"10068812","ArXiv":"2210.13966","DBLP":"journals/corr/abs-2210-13966","DOI":"10.1073/pnas.2215907120","CorpusId":253107905,"PubMed":"36943882"},"title":"The debate over understanding in AIâ€™s large language models"},{"paperId":"e7028cd7ea838ab8294ecf26d5a2c0dbb8cfa81a","externalIds":{"DBLP":"journals/corr/abs-2210-01240","ArXiv":"2210.01240","DOI":"10.48550/arXiv.2210.01240","CorpusId":252693237},"title":"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought"},{"paperId":"290732e9fb08a29af8892a7c1f73c9d2a1b9d7db","externalIds":{"DBLP":"journals/corr/abs-2207-07051","ArXiv":"2207.07051","DOI":"10.48550/arXiv.2207.07051","CorpusId":250526626},"title":"Language models show human-like content effects on reasoning"},{"paperId":"395d89ba308890901ad19905f7556cab0a1a6a27","externalIds":{"DBLP":"conf/cogsci/KosoyCLCHHKRCG23","ArXiv":"2206.08353","DOI":"10.48550/arXiv.2206.08353","CorpusId":249712125},"title":"Towards Understanding How Machines Can Learn Causal Overhypotheses"},{"paperId":"6745381bfa99a3b979766cca05e91559f1b770e3","externalIds":{"ArXiv":"2206.10591","DBLP":"journals/corr/abs-2206-10591","DOI":"10.48550/arXiv.2206.10591","CorpusId":249926765},"title":"Can Foundation Models Talk Causality?"},{"paperId":"721a09d68364aef489fa593b446923df4c6df8f2","externalIds":{"ACL":"2022.emnlp-main.653","DBLP":"conf/emnlp/0001L022","ArXiv":"2205.12598","DOI":"10.18653/v1/2022.emnlp-main.653","CorpusId":249062828},"title":"RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"5e3a7235c730b512f0bb3004a6deb0c88ec9fc8e","externalIds":{"DBLP":"conf/ijcai/ZhangLMCB23","ArXiv":"2205.11502","DOI":"10.48550/arXiv.2205.11502","CorpusId":248986434},"title":"On the Paradox of Learning to Reason from Data"},{"paperId":"7ef9aafc68511afab5b287e62b754576ea37b4ce","externalIds":{"DBLP":"conf/cogsci/CollinsWFW022","ArXiv":"2205.05718","DOI":"10.48550/arXiv.2205.05718","CorpusId":248721753},"title":"Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks"},{"paperId":"9ffefdf1fcd780cb71450b0a7a29247c66aa87be","externalIds":{"DBLP":"conf/nips/YeD22","ArXiv":"2205.03401","CorpusId":252873674},"title":"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning"},{"paperId":"8342b592fe238f3d230e4959b06fd10153c45db1","externalIds":{"DBLP":"journals/corr/abs-2203-15556","ArXiv":"2203.15556","CorpusId":247778764},"title":"Training Compute-Optimal Large Language Models"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"eebdf7303256f081ab1f6a36ff0ea6126e4da484","externalIds":{"ArXiv":"2112.11941","DBLP":"conf/lrec/FrohbergB22","ACL":"2022.lrec-1.229","CorpusId":245385766},"title":"CRASS: A Novel Data Set and Benchmark to Test Counterfactual Reasoning of Large Language Models"},{"paperId":"57d1e7ac339e783898f2c3b1af55737cbeee9fc5","externalIds":{"DBLP":"conf/nips/HendrycksBKABTS21","ArXiv":"2103.03874","CorpusId":232134851},"title":"Measuring Mathematical Problem Solving With the MATH Dataset"},{"paperId":"ca2f1088d3e581b2c6c75cf0ebc96506d620f64d","externalIds":{"DBLP":"conf/fat/BenderGMS21","DOI":"10.1145/3442188.3445922","CorpusId":262580630},"title":"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ"},{"paperId":"47e799f83b0850f3d036a2e3a66bb337661b7e68","externalIds":{"DBLP":"conf/emnlp/RudingerSHBFBSC20","MAG":"3102749280","ACL":"2020.findings-emnlp.418","DOI":"10.18653/v1/2020.findings-emnlp.418","CorpusId":226283602},"title":"Thinking Like a Skeptic: Defeasible Inference in Natural Language"},{"paperId":"18df4b39a4f0907e7bbc9919ea630b7fd207049e","externalIds":{"MAG":"3093052501","DOI":"10.1016/j.cptl.2020.09.005","CorpusId":225139539,"PubMed":"33454077"},"title":"Using cognitive interviews and think-aloud protocols to understand thought processes."},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"e6c561d02500b2596a230b341a8eb8b921ca5bf2","externalIds":{"MAG":"3001279689","ArXiv":"2001.08361","DBLP":"journals/corr/abs-2001-08361","CorpusId":210861095},"title":"Scaling Laws for Neural Language Models"},{"paperId":"6c81c81c8986e2dfd70099ac183ffe424d11b8d5","externalIds":{"DOI":"10.1017/9781108770422.023","CorpusId":261157683},"title":"Intelligence and Reasoning"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"530a059cb48477ad1e3d4f8f4b153274c8997332","externalIds":{"ArXiv":"1910.10045","MAG":"2997428643","DBLP":"journals/inffus/ArrietaRSBTBGGM20","DOI":"10.1016/j.inffus.2019.12.012","CorpusId":204824113},"title":"Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"f6e6c948a2074e38e0a4e9099c0f63773c6013dd","externalIds":{"DOI":"10.7551/mitpress/11578.003.0012","CorpusId":4709500},"title":"Causality"},{"paperId":"f527bacebbbfc46719d50eed61a8b2114a39bb72","externalIds":{"MAG":"2903571680","DOI":"10.1126/science.aau9731","CorpusId":52133264},"title":"The Book of Why: The New Science of Cause and Effect"},{"paperId":"c3874d6fd1e32585d629ccca3f1e5c1acedeea5e","externalIds":{"MAG":"1997422744","PubMedCentral":"4408754","DOI":"10.3389/fnhum.2015.00222","CorpusId":14867520,"PubMed":"25964755"},"title":"How can we study reasoning in the brain?"},{"paperId":"c9407a9cedd7e9172630a6502d378f5e9293c403","externalIds":{"MAG":"2162915529","DOI":"10.1016/j.tics.2010.07.004","CorpusId":17552347,"PubMed":"20696611"},"title":"Associative processes in intuitive judgment"},{"paperId":"fb05f4fd1d629b8736c5f91842026acc80a6bdd4","externalIds":{"MAG":"2988698064","DOI":"10.1073/pnas.1012933107","CorpusId":15080556,"PubMed":"20956326"},"title":"Mental models and human reasoning"},{"paperId":"d90404168822c76494432ab056bc6f83295dd7a0","externalIds":{"MAG":"2517384421","DOI":"10.1086/644684","CorpusId":88600944},"title":"Behavior"},{"paperId":"de2a0f45534a1bb1ee8d4de87d3d3048e33b25b9","externalIds":{"MAG":"1574141395","DOI":"10.1093/acprof:oso/9780199551330.003.0028","CorpusId":142719284},"title":"How We Reason"},{"paperId":"d022f6d2c2ed802f114ed05d3c791555911c1952","externalIds":{"MAG":"1767411471","DOI":"10.1093/acprof:oso/9780195183115.001.0001","CorpusId":143316949},"title":"Causal Models: How People Think about the World and Its Alternatives"},{"paperId":"7d2492510cdb0e898936d0af29879a2450ac76f0","externalIds":{"DBLP":"journals/cogsci/HenstYJ02","MAG":"2103696010","DOI":"10.1207/s15516709cog2604_2","CorpusId":121876},"title":"Strategies in sentential reasoning"},{"paperId":"4b9b1822164b020b644718d06c3b731ccc0300f4","externalIds":{"MAG":"1982216731","DOI":"10.1207/S15327930PJE7702_5","CorpusId":143921880},"title":"Applications and Challenges in Dynamic Assessment"},{"paperId":"21883797913d26f5831bc6cbe12733b0f8e0a1cb","externalIds":{"MAG":"1996176994","DOI":"10.1037/0033-295X.107.4.852","CorpusId":33094993,"PubMed":"11089409"},"title":"On belief bias in syllogistic reasoning."},{"paperId":"0d21adbba3a679c95d52544a05cfc40a510da129","externalIds":{"MAG":"2119238414","DOI":"10.1111/1467-8624.00224","CorpusId":17245630,"PubMed":"11108092"},"title":"Detecting blickets: how young children use information about novel causal powers in categorization and induction."},{"paperId":"cc6df423198169a7703a77df5a7c969f822bb9a9","externalIds":{"MAG":"1488025282","CorpusId":142318739},"title":"Human Reasoning: The Psychology Of Deduction"},{"paperId":"30e53d76e09e54df8c583370812c268202d54050","externalIds":{"MAG":"1972712355","DOI":"10.1016/0010-0277(89)90019-X","CorpusId":13370929,"PubMed":"2486296"},"title":"The psychology of knights and knaves"},{"paperId":"dbdb10f066b857baa6e129f49b8d832c3f6267ae","externalIds":{"MAG":"105140810","DOI":"10.1126/science.185.4157.1124","CorpusId":6196452,"PubMed":"17835457"},"title":"Judgment under Uncertainty: Heuristics and Biases"},{"paperId":"5a77249d9aa23e579376fb9006ad9391b7268ef8","externalIds":{"MAG":"1976370403","DOI":"10.1038/223101A0","CorpusId":4155111,"PubMed":"5792422"},"title":"Approach to the Study of Human Reasoning"},{"paperId":"f69f508b2f7b6b0af709f858cab041ff175c687c","externalIds":{"DOI":"10.2139/ssrn.4507038","CorpusId":260023700},"title":"Stochastic Parrots or Intelligent Systems? A Perspective on True Depth of Understanding in LLMs"},{"paperId":"f30b720e34d405f200270a6ef2d09e98585fb4d1","externalIds":{"DBLP":"conf/nips/JinCLGKLBAKSS23","DOI":"10.48550/arXiv.2312.04350","CorpusId":268042280},"title":"CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models"},{"paperId":"06ecba2ef3241762257737eda815a8420a044ccc","externalIds":{"DBLP":"conf/inlg/BertolazziMMB23","ACL":"2023.inlg-main.11","DOI":"10.18653/v1/2023.inlg-main.11","CorpusId":262052409},"title":"ChatGPTâ€™s Information Seeking Strategy: Insights from the 20-Questions Game"},{"paperId":"58ba42ffc34dd24d6a77fe58c8973b3533c369cd","externalIds":{"DBLP":"journals/corr/abs-2306-09841","DOI":"10.48550/arXiv.2306.09841","CorpusId":259188006},"title":"Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views"},{"paperId":"7946939665d679486ee1e44a140def77562854fb","externalIds":{"DBLP":"journals/corr/abs-2306-10512","DOI":"10.48550/arXiv.2306.10512","CorpusId":271953982},"title":"Efficiently Measuring the Cognitive Ability of LLMs: An Adaptive Testing Perspective"},{"paperId":"3223ce7310bb1beeda7662dc314093f50ae2d696","externalIds":{"DOI":"10.4135/9781071881118","CorpusId":248188113},"title":"Deductive and Inductive Reasoning"},{"paperId":"4578717d5593b88e1c10555ce67a14be312b84b2","externalIds":{"DBLP":"conf/emnlp/RazeghiL0022","DOI":"10.18653/v1/2022.findings-emnlp.59","CorpusId":256631096},"title":"Impact of Pretraining Term Frequencies on Few-Shot Numerical Reasoning"},{"paperId":"122a4c6cf1952feff84648c06000bc93d9709637","externalIds":{"DOI":"10.1007/978-3-030-36233-1_4","CorpusId":241087621},"title":"Defeasible Reasoning"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"33b1b26482683129b9923f331873eb065c603dfd","externalIds":{"MAG":"1575922411","CorpusId":162009578},"title":"The Cambridge handbook of thinking and reasoning"},{"paperId":"8fc7d5a51521e925221c382a56b0ddde0125a478","externalIds":{"MAG":"105203805","DBLP":"books/el/RobinsonV01","CorpusId":34229137},"title":"Handbook of Automated Reasoning (in 2 volumes)"},{"paperId":"3f74be74110e78932249bcc8d4c36d887cbd33cd","externalIds":{"DOI":"10.1038/083518a0","CorpusId":3970659},"title":"The Philosophy of Mathematics"},{"paperId":"4636c8a4c0266e76deffd596d7ed32f1b742b696","externalIds":{"CorpusId":11678342},"title":"Journal of Economic Perspectivesâ€”Volume 19, Number 4â€”Fall 2005â€”Pages 25â€“42 Cognitive Reflection and Decision Making"}]}