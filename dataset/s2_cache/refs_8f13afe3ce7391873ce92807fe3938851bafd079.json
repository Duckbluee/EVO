{"references":[{"paperId":"396b5f4ac19f1c6c16569790c14ec6013a466563","externalIds":{"DBLP":"journals/corr/abs-2301-00012","ArXiv":"2301.00012","DOI":"10.48550/arXiv.2301.00012","CorpusId":255372423},"title":"GANExplainer: GAN-based Graph Neural Networks Explainer"},{"paperId":"972323904bcbd878abdb3fd21596255e87fa5541","externalIds":{"DBLP":"journals/nn/CaiZCFWQH25","ArXiv":"2212.07056","DOI":"10.48550/arXiv.2212.07056","CorpusId":254636157,"PubMed":"39733700"},"title":"On the Probability of Necessity and Sufficiency of Explaining Graph Neural Networks: A Lower Bound Optimization Approach"},{"paperId":"f50c92916832fba9e0e56fa781b0a03b3e07f3d4","externalIds":{"PubMedCentral":"10024712","DBLP":"journals/corr/abs-2208-09339","ArXiv":"2208.09339","DOI":"10.1038/s41597-023-01974-x","CorpusId":251710449,"PubMed":"36934095"},"title":"Evaluating explainability for graph neural networks"},{"paperId":"c559dc62c0d64295f9c0dfb5f322b3f30ddf44eb","externalIds":{"DBLP":"conf/log/AmaraYZHZSBS022","ArXiv":"2206.09677","DOI":"10.48550/arXiv.2206.09677","CorpusId":249889598},"title":"GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks"},{"paperId":"6958980a4c4946d6575ee0dcbdf4cf38af59294e","externalIds":{"ArXiv":"2204.11028","DBLP":"journals/corr/abs-2204-11028","DOI":"10.1109/TPAMI.2022.3170302","CorpusId":248376956,"PubMed":"35471869"},"title":"Reinforced Causal Explainer for Graph Neural Networks"},{"paperId":"f7231aee1e18428d6c0b314b5e1e65d6707e8747","externalIds":{"DBLP":"conf/nips/BajajCXPWLZ21","ArXiv":"2107.04086","CorpusId":235790538},"title":"Robust Counterfactual Explanations on Graph Neural Networks"},{"paperId":"49774cf91b00381501c960fc976e982c0eb51b68","externalIds":{"MAG":"3133543405","DOI":"10.3390/ELECTRONICS10050593","CorpusId":233834400},"title":"Evaluating the Quality of Machine Learning Explanations: A Survey on Methods and Metrics"},{"paperId":"123139463809b5acf98b95d4c8e958be334a32b5","externalIds":{"DBLP":"journals/corr/abs-2102-05152","ArXiv":"2102.05152","CorpusId":231861768},"title":"On Explainability of Graph Neural Networks via Subgraph Explorations"},{"paperId":"6ae2967bb0a5e57cc545176120a4845576e068a3","externalIds":{"DBLP":"journals/corr/abs-2012-15445","ArXiv":"2012.15445","DOI":"10.1109/TPAMI.2022.3204236","CorpusId":229923402,"PubMed":"36063508"},"title":"Explainability in Graph Neural Networks: A Taxonomic Survey"},{"paperId":"f807dbac4635dd5b34b151a2263542250923d40a","externalIds":{"DBLP":"journals/corr/abs-2012-03058","ArXiv":"2012.03058","MAG":"3111428390","CorpusId":227334656},"title":"BayLIME: Bayesian Local Interpretable Model-Agnostic Explanations"},{"paperId":"d9f5ec342df97e060b527a8bc18ae4e97401f246","externalIds":{"DBLP":"conf/nips/LuoCXYZC020","ArXiv":"2011.04573","MAG":"3104818889","CorpusId":226281363},"title":"Parameterized Explainer for Graph Neural Network"},{"paperId":"3443efc855cebd17d1512d1a703b6e9ee2e4da8b","externalIds":{"ArXiv":"2011.02260","MAG":"3097300053","DBLP":"journals/corr/abs-2011-02260","DOI":"10.1145/3535101","CorpusId":226246289},"title":"Graph Neural Networks in Recommender Systems: A Survey"},{"paperId":"a8ae2d8232db04d88cf622e5fabd11da3163aa8f","externalIds":{"DBLP":"conf/nips/VuT20","MAG":"3093206758","ArXiv":"2010.05788","CorpusId":222290499},"title":"PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks"},{"paperId":"a0d9ecc6562d4070afa81bd7f746184e13646b0e","externalIds":{"DBLP":"journals/pr/YangCCGL20","MAG":"3014513496","DOI":"10.1016/j.patcog.2020.107360","CorpusId":216436887},"title":"Graph-based neural networks for explainable image privacy inference"},{"paperId":"58e45600bc68e376776b6feead734651693b8757","externalIds":{"MAG":"3158353424","DBLP":"journals/tits/YuMMKF22","ArXiv":"2009.06435","DOI":"10.1109/TITS.2021.3074854","CorpusId":221655625},"title":"Scene-Graph Augmented Data-Driven Risk Assessment of Autonomous Vehicle Decisions"},{"paperId":"eab48b1608de885496f88f9c07520a5f47b2b5ae","externalIds":{"ArXiv":"2007.08790","MAG":"3043250478","DBLP":"journals/corr/abs-2007-08790","DOI":"10.1109/ICPR48806.2021.9412941","CorpusId":220633142},"title":"Explanation-Guided Training for Cross-Domain Few-Shot Classification"},{"paperId":"33de92aa482ab8631d99fcca12ab00819688a362","externalIds":{"MAG":"3042143383","DBLP":"conf/ijcai/0002C20","DOI":"10.24963/ijcai.2020/670","CorpusId":220483459},"title":"Explanation Perspectives from the Cognitive Sciences - A Survey"},{"paperId":"3fd8d36f540ee2f273e844aa391d8a1f89edcc99","externalIds":{"MAG":"3038757991","ArXiv":"2007.00119","DBLP":"journals/corr/abs-2007-00119","CorpusId":220280759},"title":"Graph Neural Networks Including Sparse Interpretability"},{"paperId":"c483beec0afae8d08f011182460095049025b8d1","externalIds":{"ArXiv":"2006.11371","DBLP":"journals/corr/abs-2006-11371","MAG":"3036453007","CorpusId":219965893},"title":"Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey"},{"paperId":"ab5dd33aec7671aae081b00d4b0ab085e220eb1e","externalIds":{"MAG":"3033838041","DBLP":"journals/corr/abs-2006-03774","CorpusId":219530856},"title":"SHADOWCAST: Controlling Network Properties to Explain Graph Generation"},{"paperId":"e4534c3164522d6314bcd163273cd33b3e2e601d","externalIds":{"MAG":"3033886298","DBLP":"journals/corr/abs-2006-03589","CorpusId":219435520},"title":"XAI for Graphs: Explaining Graph Neural Network Predictions by Identifying Relevant Walks"},{"paperId":"75c8466a0c1c3b9fe595efc83671984ef95bd679","externalIds":{"DBLP":"conf/kdd/YuanTHJ20","MAG":"3105503635","ArXiv":"2006.02587","DOI":"10.1145/3394486.3403085","CorpusId":219305237},"title":"XGNN: Towards Model-Level Explanations of Graph Neural Networks"},{"paperId":"7fd293b1984cac5900434ea796bbe74e05e6623a","externalIds":{"DBLP":"conf/aies/ZhangDR21","ArXiv":"2006.00305","MAG":"3032116791","DOI":"10.1145/3461702.3462562","CorpusId":219177300},"title":"RelEx: A Model-Agnostic Relational Model Explainer"},{"paperId":"422ffa95bd85c0f3e90c5b510f7f5e65daad7519","externalIds":{"ArXiv":"2005.13438","DBLP":"journals/corr/abs-2005-13438","MAG":"3028722312","CorpusId":218900738},"title":"InteractionNet: Modeling and Explaining of Noncovalent Protein-Ligand Interactions with Noncovalent Graph Neural Network and Layer-Wise Relevance Propagation"},{"paperId":"c0a060c1c6d00ab87d8731db6d0124df3dadc5b8","externalIds":{"DBLP":"conf/aaai/VinogradovaDM20","MAG":"3008362482","ArXiv":"2002.11434","DOI":"10.1609/aaai.v34i10.7244","CorpusId":211505709},"title":"Towards Interpretable Semantic Segmentation via Gradient-weighted Class Activation Mapping"},{"paperId":"502cce7207a00c4520e130116b9ff8c1a0ea559b","externalIds":{"DBLP":"conf/ijcai/ChakrabortiSK20","MAG":"3040802234","ArXiv":"2002.11697","DOI":"10.24963/ijcai.2020/669","CorpusId":211530946},"title":"The Emerging Landscape of Explainable Automated Planning & Decision Making"},{"paperId":"9b435ea80b6f90800339b3bffeafab6c990caa88","externalIds":{"MAG":"3102363003","ArXiv":"2002.08596","DBLP":"journals/corr/abs-2002-08596","DOI":"10.1002/widm.1379","CorpusId":211204832},"title":"Interpretability of machine learning‐based prediction models in healthcare"},{"paperId":"8819adc0f064d5293bd2b783a63e23f68109738a","externalIds":{"ArXiv":"2001.06216","MAG":"3000120900","DBLP":"journals/tkde/HuangYTSC23","DOI":"10.1109/TKDE.2022.3187455","CorpusId":210714016},"title":"GraphLIME: Local Interpretable Model Explanations for Graph Neural Networks"},{"paperId":"38f23fe236b152cd4983c8f30d305a568afd0d3e","externalIds":{"ArXiv":"1907.07374","DBLP":"journals/tnn/TjoaG21","MAG":"3094189037","DOI":"10.1109/TNNLS.2020.3027314","CorpusId":197430935,"PubMed":"33079674"},"title":"A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI"},{"paperId":"e5c703aba8af983c36fedf08c32a6978eadd91b9","externalIds":{"ArXiv":"1906.10263","MAG":"2955782190","DBLP":"journals/corr/abs-1906-10263","CorpusId":195584114},"title":"DLIME: A Deterministic Local Interpretable Model-Agnostic Explanations Approach for Computer-Aided Diagnosis Systems"},{"paperId":"e5bb5a9700491eec10c4e5982ccb5a3509a23ce1","externalIds":{"ArXiv":"1906.00537","MAG":"2947487104","DBLP":"journals/corr/abs-1906-00537","CorpusId":173990735},"title":"Incorporating Biological Knowledge with Factor Graph Neural Network for Interpretable Deep Learning"},{"paperId":"cb2d9b2f171da67f7b47ac3e0eb935a0de223354","externalIds":{"DBLP":"conf/cvpr/PopeKRMH19","MAG":"2979481854","DOI":"10.1109/CVPR.2019.01103","CorpusId":198904065},"title":"Explainability Methods for Graph Convolutional Neural Networks"},{"paperId":"62a8cdf9bccfd55006adc35e58ee29c7f1f33e93","externalIds":{"MAG":"2947030669","ArXiv":"1905.11577","DBLP":"journals/corr/abs-1905-11577","CorpusId":167217900},"title":"Towards Interpretable Sparse Graph Representation Learning with Laplacian Pooling"},{"paperId":"8fb202cdcfec3b0e7ba0e3f88949d6d923b48b2d","externalIds":{"DBLP":"journals/corr/abs-1905-13686","MAG":"3034371431","ArXiv":"1905.13686","CorpusId":173188615},"title":"Explainability Techniques for Graph Convolutional Networks"},{"paperId":"809f8352133dbeb880e2df8c122a00f6d11928b1","externalIds":{"MAG":"2939788146","PubMedCentral":"6472370","DOI":"10.1038/s41598-019-42557-4","CorpusId":121321182,"PubMed":"31000728"},"title":"Efficient Deep Network Architectures for Fast Chest X-Ray Tuberculosis Screening and Visualization"},{"paperId":"0b00413174f2474d72cfc5c3e248b958ddcc8ee1","externalIds":{"MAG":"2922124692","DBLP":"journals/corr/abs-1903-03894","CorpusId":73728733},"title":"GNN Explainer: A Tool for Post-hoc Explanation of Graph Neural Networks"},{"paperId":"21dff47a4142445f83016da0819ffe6dd2947f66","externalIds":{"MAG":"2891503716","DBLP":"journals/access/AdadiB18","DOI":"10.1109/ACCESS.2018.2870052","CorpusId":52965836},"title":"Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)"},{"paperId":"08d2a558ea2deb117dd8066e864612bf2899905b","externalIds":{"ArXiv":"1807.09975","MAG":"2951344071","DBLP":"conf/eccv/ShenLYCW18","DOI":"10.1007/978-3-030-01267-0_30","CorpusId":50785503},"title":"Person Re-identification with Deep Similarity-Guided Graph Neural Network"},{"paperId":"f7325d232c7ac7d2daaf6605377058db5b5b83cc","externalIds":{"MAG":"2951278035","DBLP":"journals/csur/GuidottiMRTGP19","ArXiv":"1802.01933","DOI":"10.1145/3236009","CorpusId":3342225},"title":"A Survey of Methods for Explaining Black Box Models"},{"paperId":"65364d3a2834c284854ebb8a569f63df6da72bc6","externalIds":{"ArXiv":"1712.02034","DBLP":"journals/corr/abs-1712-02034","MAG":"2771577156","CorpusId":3981178},"title":"SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for Predicting Chemical Properties"},{"paperId":"5582bebed97947a41e3ddd9bd1f284b73f1648c2","externalIds":{"MAG":"2962858109","DBLP":"conf/iccv/SelvarajuCDVPB17","ArXiv":"1610.02391","DOI":"10.1007/s11263-019-01228-7","CorpusId":15019293},"title":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"},{"paperId":"c0883f5930a232a9c1ad601c978caede29155979","externalIds":{"DBLP":"conf/naacl/Ribeiro0G16","MAG":"2516809705","ArXiv":"1602.04938","ACL":"N16-3020","DOI":"10.1145/2939672.2939778","CorpusId":13029170},"title":"“Why Should I Trust You?”: Explaining the Predictions of Any Classifier"},{"paperId":"17a273bbd4448083b01b5a9389b3c37f5425aac0","externalIds":{"MAG":"1787224781","PubMedCentral":"4498753","DOI":"10.1371/journal.pone.0130140","CorpusId":9327892,"PubMed":"26161953"},"title":"On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation"}]}