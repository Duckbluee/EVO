{"abstract":"Performance optimization of deep learning models is conducted either manually or through automatic architecture search, or a combination of both. On the other hand, their performance strongly depends on the target hardware and how successfully the models were trained. We propose to use a multi-dimensional Pareto frontier to re-deﬁne the efﬁciency measure of candidate deep learning models, where several variables such as training cost, inference latency, and accuracy play a relative role in deﬁning a dominant model. Furthermore, a random version of the multi-dimensional Pareto frontier is introduced to mitigate the uncertainty of accuracy, latency, and throughput of deep learning models in different experimental setups. These two comple-mentary methods can be combined to perform objective benchmarking of deep learning models. Our proposed method is applied to a wide range of deep image classiﬁcation models trained on ImageNet data. Our method combines competing variables with stochastic nature in a single relative efﬁciency measure. This allows ranking deep learning models that run efﬁciently on different hardware, and combining inference efﬁciency with training efﬁciency objectively."}