{"abstract":"Deep learning methods have achieved great success in medical image analysis domain. However, most of them suffer from slow convergency and high computing cost, which prevents their further widely usage in practical scenarios. Moreover, it has been proved that exploring and embedding context knowledge in deep network can significantly improve accuracy. To emphasize these tips, we present CDT-CAD, i.e., context-aware deformable transformers for end-to-end chest abnormality detection on X-Ray images. CDT-CAD first constructs an iterative context-aware feature extractor, which not only enlarges receptive fields to encode multi-scale context information via dilated context encoding blocks, but also captures unique and scalable feature variation patterns in wavelet frequency domain via frequency pooling blocks. Afterwards, a deformable transformer detector on the extracted context features is built to accurately classify disease categories and locate regions, where a small set of key points are sampled, thus leading the detector to focus on informative feature subspace and accelerate convergence speed. Through comparative experiments on Vinbig Chest and Chest Det 10 Datasets, CDT-CAD demonstrates its effectiveness in recognizing chest abnormities and outperforms 1.4% and 6.0% than the existing methods in <inline-formula><tex-math notation=\"LaTeX\">$AP_{5}0$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>A</mml:mi><mml:msub><mml:mi>P</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href=\"wan-ieq1-3258455.gif\"/></alternatives></inline-formula> and <inline-formula><tex-math notation=\"LaTeX\">$AR$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=\"wan-ieq2-3258455.gif\"/></alternatives></inline-formula> on VinBig dateset, and 0.9% and 2.1% on Chest Det-10 dataset, respectively."}