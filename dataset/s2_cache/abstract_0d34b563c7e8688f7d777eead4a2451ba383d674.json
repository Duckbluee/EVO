{"abstract":"Traditional recommendation models trained on observational interaction data have generated large impacts in a wide range of applications, it faces bias problems that cover users’ true intent and thus deteriorate the recommendation effectiveness. Existing methods track this problem as eliminating bias for the robust recommendation, e.g., by re-weighting training samples or learning disentangled representations. The disentangled representation methods as the state-of-the-art eliminate bias by revealing cause-effect of the bias generation. However, how to design the semantic-aware and unbiased representations for users’ true intents is largely unexplored. To bridge the gap, we are the first to propose an unbiased and semantic-aware disentanglement learning called CaDSI(Causal Disentanglement for Semantics-Aware Intent Learning) from a causal perspective. Particularly, CaDSI explicitly models the causal relations underlying recommendation task, and thus produces semantic-aware representations via disentangling users’ true intents aware of specific item context. Moreover, the causal intervention mechanism is designed to eliminate confounding bias stemming from context information, which further aligns the semantic-aware representation with users’ true intent. Extensive experiments and case studies both validate the robustness and interpretability of our proposed model."}