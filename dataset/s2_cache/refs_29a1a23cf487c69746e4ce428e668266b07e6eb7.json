{"references":[{"paperId":"2a832b34583332cbaae8cf02ee5f823c43f5689e","externalIds":{"ArXiv":"2505.15634","DBLP":"journals/corr/abs-2505-15634","DOI":"10.48550/arXiv.2505.15634","CorpusId":278782548},"title":"Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models"},{"paperId":"1a999485d84827ee1ddc874319527aa7b19eb4fd","externalIds":{"ArXiv":"2405.00557","DBLP":"conf/acl/LiuGCHGM0L00K25","DOI":"10.18653/v1/2025.acl-long.151","CorpusId":269484697},"title":"Mixture of insighTful Experts (MoTE): The Synergy of Reasoning Chains and Expert Mixtures in Self-Alignment"},{"paperId":"a30bd328bc36a3f75aa18f653919611b1a8ea23d","externalIds":{"DBLP":"conf/acl/JinXZRZL0TWM024","ArXiv":"2404.07103","DOI":"10.48550/arXiv.2404.07103","CorpusId":269033196},"title":"Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs"},{"paperId":"b804bac55ac4e9e8c30ef6aab765568f5332bc85","externalIds":{"DBLP":"conf/ichi/HanL0B24","ArXiv":"2403.13786","DOI":"10.1109/ICHI61247.2024.00057","CorpusId":268536800},"title":"Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts"},{"paperId":"ae06df762adcc4221162e83a737ea63cff47e65d","externalIds":{"ArXiv":"2403.12037","DBLP":"journals/corr/abs-2403-12037","DOI":"10.48550/arXiv.2403.12037","CorpusId":268532481},"title":"MineDreamer: Learning to Follow Instructions via Chain-of-Imagination for Simulated-World Control"},{"paperId":"33f365dcb70ce4b881c1420577d26ff5fde223c6","externalIds":{"DBLP":"journals/corr/abs-2403-07213","ArXiv":"2403.07213","DOI":"10.1145/3589334.3645420","CorpusId":268363902},"title":"Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits"},{"paperId":"dc256e179d4e8eff48879a40ddc414b15b0b2300","externalIds":{"DBLP":"journals/corr/abs-2403-05313","ArXiv":"2403.05313","DOI":"10.48550/arXiv.2403.05313","CorpusId":268297389},"title":"RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation"},{"paperId":"2199a5ac145edbc46db9fcbf97b01461a2367cda","externalIds":{"DBLP":"conf/emnlp/ZhangWTLXXWT24","ArXiv":"2403.02713","DOI":"10.48550/arXiv.2403.02713","CorpusId":268248442},"title":"Android in the Zoo: Chain-of-Action-Thought for GUI Agents"},{"paperId":"2046b2da23eb2f79744eb391d902da9cedf87947","externalIds":{"ArXiv":"2402.17944","DBLP":"journals/corr/abs-2402-17944","DOI":"10.48550/arXiv.2402.17944","CorpusId":268041519},"title":"Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey"},{"paperId":"5439a10e45bf1af937b1009348fb9582d9c3d640","externalIds":{"DBLP":"conf/naacl/YamadaCLHY025","ArXiv":"2402.09052","DOI":"10.48550/arXiv.2402.09052","CorpusId":267657705},"title":"L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects"},{"paperId":"e79671a83e25288fedd897e1c9e6152f70f7f52e","externalIds":{"DBLP":"journals/corr/abs-2402-09283","ArXiv":"2402.09283","ACL":"2024.naacl-long.375","DOI":"10.48550/arXiv.2402.09283","CorpusId":267658120},"title":"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey"},{"paperId":"756ea6f43ac19a5e26a168a602bef1081ce943e7","externalIds":{"ArXiv":"2402.07386","DBLP":"conf/cikm/0001BTFLZ024","DOI":"10.1145/3627673.3679608","CorpusId":267627600},"title":"Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy Induction from Limited Examples"},{"paperId":"7c6fb21071f4d693fa1bb116da97936255f6623e","externalIds":{"DBLP":"journals/corr/abs-2402-02648","ArXiv":"2402.02648","DOI":"10.48550/arXiv.2402.02648","CorpusId":267413120},"title":"Recursive Chain-of-Feedback Prevents Performance Degradation from Redundant Prompting"},{"paperId":"8fb92f51434543c4a8cd4980f84cf04552c712cc","externalIds":{"DBLP":"conf/coling/GaoDYTPGSCBW25","ArXiv":"2401.17464","DOI":"10.48550/arXiv.2401.17464","CorpusId":267334795},"title":"Efficient Tool Use with Chain-of-Abstraction Reasoning"},{"paperId":"eff9d7ed06f30f121d30ee13802a11f172ef66f4","externalIds":{"ArXiv":"2401.14295","DBLP":"journals/pami/BestaMZGPBNCKMGKNOMH25","DOI":"10.1109/TPAMI.2025.3598182","CorpusId":267211725,"PubMed":"40794507"},"title":"Demystifying Chains, Trees, and Graphs of Thoughts"},{"paperId":"ee5d700eeccfcfe54f9d497643bc55f8606390cd","externalIds":{"ArXiv":"2401.13527","DBLP":"journals/corr/abs-2401-13527","DOI":"10.48550/arXiv.2401.13527","CorpusId":267200257},"title":"SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation"},{"paperId":"a3ae8705daa21f4be6970d8c7685112e1e95b843","externalIds":{"ArXiv":"2401.12863","DBLP":"conf/aaai/MondalMPSR24","DOI":"10.48550/arXiv.2401.12863","CorpusId":267095090},"title":"KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning"},{"paperId":"0a8a776054a087118f4f9523994ef084b2b2469a","externalIds":{"ArXiv":"2401.10005","DBLP":"journals/corr/abs-2401-10005","DOI":"10.48550/arXiv.2401.10005","CorpusId":267034933},"title":"Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation"},{"paperId":"39e0bf77300bb6df8716ce83eb8a3f6a5e3d6b20","externalIds":{"DBLP":"conf/iclr/0002ZLEP0MFSLP24","ArXiv":"2401.04398","DOI":"10.48550/arXiv.2401.04398","CorpusId":266899992},"title":"Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding"},{"paperId":"5122bd001ec67d80543abe284bf7e0bf31da45d5","externalIds":{"DBLP":"journals/corr/abs-2401-04151","ArXiv":"2401.04151","DOI":"10.48550/arXiv.2401.04151","CorpusId":266899736},"title":"Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning"},{"paperId":"9f22f66cacac8eebc5728cd0a28513b5e75a9a58","externalIds":{"DBLP":"journals/corr/abs-2312-11865","ArXiv":"2312.11865","DOI":"10.48550/arXiv.2312.11865","CorpusId":266362531},"title":"Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach"},{"paperId":"46f9f7b8f88f72e12cbdb21e3311f995eb6e65c5","externalIds":{"ArXiv":"2312.10997","DBLP":"journals/corr/abs-2312-10997","CorpusId":266359151},"title":"Retrieval-Augmented Generation for Large Language Models: A Survey"},{"paperId":"0edcd6dd2e952523c35e77d0f9cce5927b97d63e","externalIds":{"ArXiv":"2312.10355","DBLP":"journals/corr/abs-2312-10355","DOI":"10.48550/arXiv.2312.10355","CorpusId":266348675},"title":"CoAScore: Chain-of-Aspects Prompting for NLG Evaluation"},{"paperId":"1aeb7c0d982750f16d1eaf898b0826d634d34af0","externalIds":{"DBLP":"journals/corr/abs-2312-07879","ArXiv":"2312.07879","DOI":"10.48550/arXiv.2312.07879","CorpusId":266191529},"title":"CoIE: Chain-of-Instruct Editing for Multi-Attribute Face Manipulation"},{"paperId":"3a56bc074b8f3f985599627404b70e16fc5bce1b","externalIds":{"DBLP":"conf/icml/0002LZCHSL0XI24","ArXiv":"2312.04474","DOI":"10.48550/arXiv.2312.04474","CorpusId":266051661},"title":"Chain of Code: Reasoning with a Language Model-Augmented Code Emulator"},{"paperId":"6489640b1d30a8a3e7cb906bb6557f1ccd0d799d","externalIds":{"DBLP":"journals/corr/abs-2311-09210","ACL":"2024.emnlp-main.813","ArXiv":"2311.09210","DOI":"10.48550/arXiv.2311.09210","CorpusId":265212816},"title":"Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"},{"paperId":"ec67d5f0e236f23c6b48b926f9e25db52194dd71","externalIds":{"ACL":"2024.naacl-long.219","ArXiv":"2311.07914","DBLP":"conf/naacl/AgrawalKA024","DOI":"10.18653/v1/2024.naacl-long.219","CorpusId":265158225},"title":"Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey"},{"paperId":"7059afa8c275391fedfeefceca258f3f6a6b063e","externalIds":{"ArXiv":"2311.09241","DBLP":"journals/corr/abs-2311-09241","DOI":"10.48550/arXiv.2311.09241","CorpusId":265220926},"title":"Chain of Images for Intuitively Reasoning"},{"paperId":"3f49bd6b95e254d82ce1ed1bd556a7a8f81a47db","externalIds":{"DBLP":"journals/corr/abs-2311-04915","ArXiv":"2311.04915","DOI":"10.19066/cogsci.2024.35.1.002","CorpusId":265066941},"title":"Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models"},{"paperId":"498564ba804249bac269a46416ac31159ace6695","externalIds":{"DBLP":"conf/emnlp/YangSWQWW023","ArXiv":"2310.20256","DOI":"10.48550/arXiv.2310.20256","CorpusId":264820234},"title":"PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection"},{"paperId":"a971cf525390508539ce44aa424a3435621b5b25","externalIds":{"DBLP":"conf/mm/XiMY23","DOI":"10.1145/3581783.3611898","CorpusId":264492173},"title":"Chain-of-Look Prompting for Verb-centric Surgical Triplet Recognition in Endoscopic Videos"},{"paperId":"f8b8f926bbfa327c86c40796131fe2695db81126","externalIds":{"DBLP":"journals/corr/abs-2310-16436","ArXiv":"2310.16436","DOI":"10.48550/arXiv.2310.16436","CorpusId":264451538},"title":"DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models"},{"paperId":"63d1b0175eadfd0021e0391f120e606505587777","externalIds":{"ArXiv":"2310.08992","DBLP":"journals/corr/abs-2310-08992","DOI":"10.48550/arXiv.2310.08992","CorpusId":264128082},"title":"CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules"},{"paperId":"12a4c41b087629548b07d0dadb9da05147fa4f81","externalIds":{"ArXiv":"2310.04959","DBLP":"journals/corr/abs-2310-04959","DOI":"10.48550/arXiv.2310.04959","CorpusId":263829198},"title":"Towards Better Chain-of-Thought Prompting Strategies: A Survey"},{"paperId":"79429814fd4d967b9277af2805c53f370e52ebb5","externalIds":{"ArXiv":"2310.03951","DBLP":"journals/corr/abs-2310-03951","DOI":"10.48550/arXiv.2310.03951","CorpusId":263831527},"title":"Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations"},{"paperId":"f42f61a547c5996be6aee175145b0d74e6324dff","externalIds":{"ArXiv":"2309.15402","DBLP":"conf/acl/ChuCCYH0P00L24","DOI":"10.18653/v1/2024.acl-long.65","CorpusId":263153015},"title":"Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"},{"paperId":"6ab33b17cd45e7cbd2cb9b0c5a2d56e5eac1c814","externalIds":{"ArXiv":"2309.11436","DBLP":"journals/corr/abs-2309-11436","DOI":"10.48550/arXiv.2309.11436","CorpusId":262053313},"title":"You Only Look at Screens: Multimodal Chain-of-Action Agents"},{"paperId":"dca4ed6d4db18216796336d647f8d4bdf197f039","externalIds":{"DBLP":"journals/corr/abs-2309-07918","ArXiv":"2309.07918","DOI":"10.48550/arXiv.2309.07918","CorpusId":261822943},"title":"Unified Human-Scene Interaction via Prompted Chain-of-Contacts"},{"paperId":"0c72450890a54b68d63baa99376131fda8f06cf9","externalIds":{"ArXiv":"2309.07864","DBLP":"journals/corr/abs-2309-07864","DOI":"10.48550/arXiv.2309.07864","CorpusId":261817592},"title":"The Rise and Potential of Large Language Model Based Agents: A Survey"},{"paperId":"6d928d835c31963ff32c5b5ec6e0dbd1cbadf2c9","externalIds":{"ACL":"2023.newsum-1.7","ArXiv":"2309.04269","DBLP":"journals/corr/abs-2309-04269","DOI":"10.18653/v1/2023.newsum-1.7","CorpusId":261660381,"PubMed":"39315281"},"title":"From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting"},{"paperId":"10955e63aa49fab146267949f8ebc9ebe8275183","externalIds":{"DBLP":"journals/corr/abs-2308-13259","ArXiv":"2308.13259","DOI":"10.48550/arXiv.2308.13259","CorpusId":261214582},"title":"Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for Knowledge-intensive Question Answering"},{"paperId":"f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f","externalIds":{"ArXiv":"2308.10792","DBLP":"journals/corr/abs-2308-10792","DOI":"10.1145/3777411","CorpusId":261049152},"title":"Instruction Tuning for Large Language Models: A Survey"},{"paperId":"9f859726b3d8dffd96a1f55de4122617751cc1b4","externalIds":{"ArXiv":"2308.09662","DBLP":"journals/corr/abs-2308-09662","DOI":"10.48550/arXiv.2308.09662","CorpusId":261030829},"title":"Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment"},{"paperId":"64e802ea8e9dbe247c31fb06184c04dbf9e55e4e","externalIds":{"ArXiv":"2308.06966","DBLP":"conf/aaai/LiMWHJ0X0J24","DOI":"10.48550/arXiv.2308.06966","CorpusId":260887693},"title":"EcomGPT: Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce"},{"paperId":"ec58a564fdda29e6a9a0a7bab5eeb4c290f716d7","externalIds":{"ArXiv":"2308.07201","DBLP":"journals/corr/abs-2308-07201","DOI":"10.48550/arXiv.2308.07201","CorpusId":260887105},"title":"ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"},{"paperId":"632a758099f412b13d0a8172830a3ac7ee5e0dd5","externalIds":{"DBLP":"journals/corr/abs-2307-08674","ArXiv":"2307.08674","DOI":"10.48550/arXiv.2307.08674","CorpusId":259937503},"title":"TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT"},{"paperId":"c7184f9a914dbfbad59faa5aeaf9ba7019dfcf74","externalIds":{"ArXiv":"2307.07697","DBLP":"conf/iclr/SunXTW0GNSG24","CorpusId":263333907},"title":"Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph"},{"paperId":"7a6a298efb965ce9a351a3212f6f536e94dbbb03","externalIds":{"ArXiv":"2306.14050","DBLP":"conf/acl/LiHYRC023","ACL":"2023.acl-long.150","DOI":"10.48550/arXiv.2306.14050","CorpusId":259251773},"title":"Symbolic Chain-of-Thought Distillation: Small Models Can Also “Think” Step-by-Step"},{"paperId":"9efa81ec4954b0859c47dad8f42edfaf8bced69b","externalIds":{"DBLP":"conf/acl/WangS0G24","ArXiv":"2306.06427","DOI":"10.48550/arXiv.2306.06427","CorpusId":259138909},"title":"Boosting Language Models Reasoning with Chain-of-Knowledge Prompting"},{"paperId":"50f44ef10335d59cec145b15effae20ff22c1fdb","externalIds":{"ArXiv":"2306.03901","DBLP":"journals/corr/abs-2306-03901","DOI":"10.48550/arXiv.2306.03901","CorpusId":259088875},"title":"ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory"},{"paperId":"8236010c2ecc94d826be6010ff187fdc000e7df6","externalIds":{"ArXiv":"2306.03872","DBLP":"conf/nips/LingFLHLMS23","CorpusId":259089245},"title":"Deductive Verification of Chain-of-Thought Reasoning"},{"paperId":"6289de84a02f0c27734f295ada565603ac958948","externalIds":{"DBLP":"conf/acl/JinL23","ArXiv":"2305.17812","DOI":"10.48550/arXiv.2305.17812","CorpusId":258960483},"title":"Tab-CoT: Zero-shot Tabular Chain of Thought"},{"paperId":"2502311c66b11b3d5551e13a0095f2b1a5c5455d","externalIds":{"DBLP":"conf/acl/InabaKCK23","ArXiv":"2305.16896","ACL":"2023.acl-short.130","DOI":"10.48550/arXiv.2305.16896","CorpusId":258947061},"title":"MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting"},{"paperId":"e468ed6b824e60f45ba9a20b034e4090c6630751","externalIds":{"DBLP":"conf/iclr/LiZCDJPB24","ArXiv":"2305.13269","CorpusId":263610099},"title":"Chain-of-Knowledge: Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources"},{"paperId":"ee2f334eb33f857b9976ddcfb9625cd785a4ae46","externalIds":{"DBLP":"journals/corr/abs-2305-13507","ArXiv":"2305.13507","DOI":"10.48550/arXiv.2305.13507","CorpusId":258840976},"title":"Multimodal Automated Fact-Checking: A Survey"},{"paperId":"b17db2508600f498cf36d8ea06716e238bebe3d7","externalIds":{"ArXiv":"2305.12147","DBLP":"conf/emnlp/LiuTCZZ023","DOI":"10.48550/arXiv.2305.12147","CorpusId":258832686},"title":"LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4"},{"paperId":"d0c69c309fbf1233b6351cd57484557c16f28427","externalIds":{"DBLP":"conf/emnlp/0003WMD0LXW23","ArXiv":"2305.11792","DOI":"10.18653/v1/2023.findings-emnlp.806","CorpusId":264146343},"title":"Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs"},{"paperId":"5cac6430bd379c9d2fe13137dfd6ae7721a2679f","externalIds":{"DBLP":"conf/emnlp/ZhangLZZWZQ23","ArXiv":"2305.11000","DOI":"10.48550/arXiv.2305.11000","CorpusId":258762683},"title":"SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities"},{"paperId":"629c441076da3f8185b1cf85e8036064b714e249","externalIds":{"DBLP":"conf/acl/ZhaoLJQB23","ACL":"2023.acl-long.320","ArXiv":"2305.03268","DOI":"10.48550/arXiv.2305.03268","CorpusId":258547173},"title":"Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework"},{"paperId":"aad167be3c902388ea625da4117fcae4325b8b7d","externalIds":{"ArXiv":"2305.02301","DBLP":"journals/corr/abs-2305-02301","DOI":"10.48550/arXiv.2305.02301","CorpusId":258461606},"title":"Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"},{"paperId":"d47b9407cf0938e9f15ce019031d7cd63b308a01","externalIds":{"ArXiv":"2304.14732","DBLP":"conf/www/XuPSCC24","DOI":"10.1145/3589334.3645363","CorpusId":267938726},"title":"Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks"},{"paperId":"690df0820f35a47e1ce44f90e6ddb4132aa09267","externalIds":{"DBLP":"journals/pami/ZhangHJL24","ArXiv":"2304.00685","DOI":"10.1109/TPAMI.2024.3369699","CorpusId":257913547,"PubMed":"38408000"},"title":"Vision-Language Models for Vision Tasks: A Survey"},{"paperId":"3aaf6a2cbad5850ad81ab5c163599cb3d523436f","externalIds":{"DBLP":"journals/corr/abs-2303-17651","ArXiv":"2303.17651","DOI":"10.48550/arXiv.2303.17651","CorpusId":257900871},"title":"Self-Refine: Iterative Refinement with Self-Feedback"},{"paperId":"00a9a469bb019bf33eeee438c110f704b71cda73","externalIds":{"ArXiv":"2303.10868","DBLP":"journals/corr/abs-2303-10868","DOI":"10.48550/arXiv.2303.10868","CorpusId":257632157},"title":"Retrieving Multimodal Information for Augmented Generation: A Survey"},{"paperId":"35922cd0d6b17e45320917338e9f98cb5c1a4f6f","externalIds":{"ArXiv":"2212.10001","DBLP":"conf/acl/WangM0S0Z023","ACL":"2023.acl-long.153","DOI":"10.48550/arXiv.2212.10001","CorpusId":254877569},"title":"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters"},{"paperId":"f208ea909fa7f54fea82def9a92fd81dfc758c39","externalIds":{"ArXiv":"2212.10509","DBLP":"journals/corr/abs-2212-10509","ACL":"2023.acl-long.557","DOI":"10.48550/arXiv.2212.10509","CorpusId":254877499},"title":"Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions"},{"paperId":"4f939f0751e5484f54089f6a97598e39afdcb3b5","externalIds":{"ArXiv":"2212.09420","ACL":"2023.acl-long.411","DBLP":"conf/acl/ZanCZLWGWL23","DOI":"10.18653/v1/2023.acl-long.411","CorpusId":258557362},"title":"Large Language Models Meet NL2Code: A Survey"},{"paperId":"6c943670dca38bfc7c8b477ae7c2d1fba1ad3691","externalIds":{"DBLP":"journals/tmlr/ChenM0C23","ArXiv":"2211.12588","CorpusId":253801709},"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"},{"paperId":"e070ff286709db28312e08b52b05539debe88146","externalIds":{"DBLP":"conf/emnlp/PressZMSSL23","ArXiv":"2210.03350","DOI":"10.48550/arXiv.2210.03350","CorpusId":252762102},"title":"Measuring and Narrowing the Compositionality Gap in Language Models"},{"paperId":"99832586d55f540f603637e458a292406a0ed75d","externalIds":{"DBLP":"conf/iclr/YaoZYDSN023","ArXiv":"2210.03629","CorpusId":252762395},"title":"ReAct: Synergizing Reasoning and Acting in Language Models"},{"paperId":"af7acf43d41a79c5639be23769895a2b3f0350c3","externalIds":{"DBLP":"conf/www/HuangKA23","ArXiv":"2209.04889","DOI":"10.1145/3543873.3587320","CorpusId":252199215},"title":"Chain of Explanation: New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"68f141724814839d556a989646194be88641b143","externalIds":{"ArXiv":"2112.11446","DBLP":"journals/corr/abs-2112-11446","CorpusId":245353475},"title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"},{"paperId":"b802df98ab31445df9770f0231b7e459b26f2fdd","externalIds":{"DBLP":"journals/spl/QiuHSTX24","DOI":"10.1109/LSP.2024.3377590","CorpusId":268495218},"title":"Chain-of-LoRA: Enhancing the Instruction Fine-Tuning Performance of Low-Rank Adaptation on Diverse Instruction Set"},{"paperId":"b5280ed2f9b3880fa505d93fbf140b9be8572d03","externalIds":{"DBLP":"conf/iclr/XiaoZWXWHFZZS024a","CorpusId":271745931},"title":"Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"},{"paperId":"0425c47e19b5f1fcc680967ebd6c6e7cebc0b768","externalIds":{"DBLP":"conf/naacl/Xia0HZM024","ACL":"2024.naacl-long.262","DOI":"10.18653/v1/2024.naacl-long.262","CorpusId":270514540},"title":"Aligning as Debiasing: Causality-Aware Alignment via Reinforcement Learning with Interventional Feedback"},{"paperId":"f2f93ca56be657f78e5bf4b0766996a19d5c2a16","externalIds":{"DBLP":"journals/corr/abs-2402-14382","DOI":"10.48550/arXiv.2402.14382","CorpusId":271430949},"title":"Enhancing Temporal Knowledge Graph Forecasting with Large Language Models via Chain-of-History Reasoning"},{"paperId":"4b6f83d69adeb44c6fe00bd3658f53395d8d154c","externalIds":{"DBLP":"journals/corr/abs-2403-16999","DOI":"10.48550/arXiv.2403.16999","CorpusId":268681119},"title":"Visual CoT: Unleashing Chain-of-Thought Reasoning in Multi-Modal Language Models"},{"paperId":"c7a66961ee07b0e9e792d3625c1b20d510f29429","externalIds":{"DBLP":"journals/corr/abs-2402-04236","DOI":"10.48550/arXiv.2402.04236","CorpusId":279415153},"title":"CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations"},{"paperId":"c2408a3a8da4f12d3eb156fe359a96b428e5aff1","externalIds":{"DBLP":"journals/corr/abs-2305-10276","DOI":"10.48550/arXiv.2305.10276","CorpusId":258740762},"title":"Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models"},{"paperId":"ac771182d1780c863954243809d1e144433919f9","externalIds":{"DBLP":"journals/corr/abs-2307-12966","DOI":"10.48550/arXiv.2307.12966","CorpusId":260356605},"title":"Aligning Large Language Models with Human: A Survey"},{"paperId":"69fb47e0ea1c30280d4450cbd9a1e992e7c9d503","externalIds":{"DBLP":"journals/corr/abs-2304-14732","DOI":"10.48550/arXiv.2304.14732","CorpusId":258418354},"title":"Search-in-the-Chain: Towards the Accurate, Credible and Traceable Content Generation for Complex Knowledge-intensive Tasks"},{"paperId":"5b2aa9b3912025db43315475c8eca164b876de4a","externalIds":{"DBLP":"journals/corr/abs-2309-15402","DOI":"10.48550/arXiv.2309.15402","CorpusId":281603643},"title":"A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"},{"paperId":"90ddd9efe3dcd7f9bb0f0d2dfe6b76ea53ddee8f","externalIds":{"CorpusId":278965010},"title":"Chain Of Reference prompting helps LLM to think like a lawyer"}]}