{"paperId":"005d19ea33f33e7b45b7a31cb36a81aec220299b","externalIds":{"ArXiv":"2405.13019","DBLP":"journals/corr/abs-2405-13019","DOI":"10.48550/arXiv.2405.13019","CorpusId":269982345},"title":"A Comprehensive Survey of Accelerated Generation Techniques in Large Language Models","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2405.13019, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2302799897","name":"Mahsa Khoshnoodi"},{"authorId":"2212131028","name":"Vinija Jain"},{"authorId":"2303111127","name":"Mingye Gao"},{"authorId":"2295206639","name":"Malavika Srikanth"},{"authorId":"2275226689","name":"Aman Chadha"}],"abstract":"Despite the crucial importance of accelerating text generation in large language models (LLMs) for efficiently producing content, the sequential nature of this process often leads to high inference latency, posing challenges for real-time applications. Various techniques have been proposed and developed to address these challenges and improve efficiency. This paper presents a comprehensive survey of accelerated generation techniques in autoregressive language models, aiming to understand the state-of-the-art methods and their applications. We categorize these techniques into several key areas: speculative decoding, early exiting mechanisms, and non-autoregressive methods. We discuss each category's underlying principles, advantages, limitations, and recent advancements. Through this survey, we aim to offer insights into the current landscape of techniques in LLMs and provide guidance for future research directions in this critical area of natural language processing."}