{"references":[{"paperId":"12e68a7b1969965f725f9b7a20f6abd91b391f70","externalIds":{"ArXiv":"2404.13648","DBLP":"conf/iclr/0002Z24","DOI":"10.48550/arXiv.2404.13648","CorpusId":269293487},"title":"Data-independent Module-aware Pruning for Hierarchical Vision Transformers"},{"paperId":"e4a90aafb60b1a9944f055afc9d903bc06b21a86","externalIds":{"DBLP":"journals/corr/abs-2405-05808","ArXiv":"2405.05808","DOI":"10.1609/aaai.v38i11.29108","CorpusId":268692653},"title":"Fast and Controllable Post-training Sparsity: Learning Optimal Sparsity Allocation with Global Constraint in Minutes"},{"paperId":"a2bc3451d0e09a3be77b0419cfe5a0e1282006b5","externalIds":{"DBLP":"conf/cvpr/WuGZLBZ0H24","ArXiv":"2403.14729","DOI":"10.1109/CVPR52733.2024.01530","CorpusId":268667388},"title":"Auto- Train-Once: Controller Network Guided Automatic Network Pruning from Scratch"},{"paperId":"9860df73f2dbfc0f3b54d87971af279e5502f002","externalIds":{"ArXiv":"2403.04861","DBLP":"journals/corr/abs-2403-04861","DOI":"10.48550/arXiv.2403.04861","CorpusId":268296813},"title":"A Survey of Lottery Ticket Hypothesis"},{"paperId":"3c6f2e0c5ff5dff6151c3e6489378a53318a75b4","externalIds":{"DBLP":"conf/acl/MenXZYWL0HC25","ArXiv":"2403.03853","DOI":"10.48550/arXiv.2403.03853","CorpusId":268253513},"title":"ShortGPT: Layers in Large Language Models are More Redundant Than You Expect"},{"paperId":"eb87c11618e2de4f1287320c22cedcc9ad1af761","externalIds":{"ArXiv":"2402.17946","DBLP":"conf/nips/BaiL0K024","DOI":"10.52202/079017-1468","CorpusId":268041812},"title":"SparseLLM: Towards Global Pruning of Pre-trained Language Models"},{"paperId":"a6f7485dfdf45320e82d84bcfdc51bcd52dff18b","externalIds":{"ArXiv":"2402.17177","DBLP":"journals/corr/abs-2402-17177","DOI":"10.48550/arXiv.2402.17177","CorpusId":268032569},"title":"Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models"},{"paperId":"94db8a625418800c8ae7b48157a9cad1c8129051","externalIds":{"DBLP":"journals/corr/abs-2402-13116","ArXiv":"2402.13116","DOI":"10.48550/arXiv.2402.13116","CorpusId":267760021},"title":"A Survey on Knowledge Distillation of Large Language Models"},{"paperId":"0ea8ceb4f6a759b07a5b871fd25cb5b7bf33acd8","externalIds":{"DBLP":"journals/corr/abs-2402-11700","ArXiv":"2402.11700","DOI":"10.1109/IJCNN64981.2025.11228532","CorpusId":267751193},"title":"Why Lift so Heavy? Slimming Large Language Models by Cutting Off the Layers"},{"paperId":"50caaa898eb3605a58a550c7aebacdc1cff3b6da","externalIds":{"DBLP":"journals/corr/abs-2402-16880","ArXiv":"2402.16880","DOI":"10.48550/arXiv.2402.16880","CorpusId":268032346},"title":"BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation"},{"paperId":"7d00e7337fbbccd0208361b4c204c75239a96521","externalIds":{"ArXiv":"2402.11187","DBLP":"conf/emnlp/YangC024","DOI":"10.48550/arXiv.2402.11187","CorpusId":267751181},"title":"LaCo: Large Language Model Pruning via Layer Collapse"},{"paperId":"2fe05b1f953da5dcf6ec5fe7bc72bfb3dbd9ea30","externalIds":{"ArXiv":"2402.09748","DBLP":"journals/corr/abs-2402-09748","DOI":"10.48550/arXiv.2402.09748","CorpusId":267682382},"title":"Model Compression and Efficient Inference for Large Language Models: A Survey"},{"paperId":"664e518fa4873e281180b7ead965608ae14b1aef","externalIds":{"ArXiv":"2402.09025","DBLP":"journals/corr/abs-2402-09025","DOI":"10.48550/arXiv.2402.09025","CorpusId":267657949},"title":"SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks"},{"paperId":"6f7f4f97890dae5cdee3d5df9ca932cae486e1ba","externalIds":{"ArXiv":"2402.05406","DBLP":"journals/corr/abs-2402-05406","DOI":"10.48550/arXiv.2402.05406","CorpusId":267547625},"title":"Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes"},{"paperId":"a091bf215c716a146140f81c751712db628c8e20","externalIds":{"ArXiv":"2402.03766","DBLP":"journals/corr/abs-2402-03766","DOI":"10.48550/arXiv.2402.03766","CorpusId":267500104},"title":"MobileVLM V2: Faster and Stronger Baseline for Vision Language Model"},{"paperId":"87667fd50710183951fd2206a929a25b4b970276","externalIds":{"DBLP":"journals/corr/abs-2402-02834","ArXiv":"2402.02834","DOI":"10.48550/arXiv.2402.02834","CorpusId":267413136},"title":"Shortened LLaMA: A Simple Depth Pruning for Large Language Models"},{"paperId":"c299a8f9e262562bb55942aea9b75646c96821a5","externalIds":{"DBLP":"journals/corr/abs-2402-01089","ArXiv":"2402.01089","DOI":"10.48550/arXiv.2402.01089","CorpusId":267406559},"title":"No Free Prune: Information-Theoretic Barriers to Pruning at Initialization"},{"paperId":"a7e7fa7ca4a32a92f578adf07c613088fa89f5b0","externalIds":{"ArXiv":"2401.15347","DBLP":"journals/corr/abs-2401-15347","DOI":"10.48550/arXiv.2401.15347","CorpusId":267312283},"title":"A Comprehensive Survey of Compression Algorithms for Language Models"},{"paperId":"7754ac3e8ff1286f17593159781487543cdddaba","externalIds":{"ArXiv":"2401.15024","DBLP":"conf/iclr/AshkboosCNHH24a","DOI":"10.48550/arXiv.2401.15024","CorpusId":267301573},"title":"SliceGPT: Compress Large Language Models by Deleting Rows and Columns"},{"paperId":"8ac21a1545a907fc64b54cde36bf41415608cd7d","externalIds":{"DBLP":"journals/corr/abs-2401-08092","ArXiv":"2401.08092","DOI":"10.48550/arXiv.2401.08092","CorpusId":267027735},"title":"A Survey of Resource-efficient LLM and Multimodal Foundation Models"},{"paperId":"78971568f764f3479b26c42844845ec99664298c","externalIds":{"ArXiv":"2312.17244","DBLP":"journals/corr/abs-2312-17244","DOI":"10.48550/arXiv.2312.17244","CorpusId":266573164},"title":"The LLM Surgeon"},{"paperId":"9ea8001d6eb52d14134ceede7f88b1d8fa8db41f","externalIds":{"DBLP":"conf/aaai/AnZYTW24","ArXiv":"2312.11983","DOI":"10.48550/arXiv.2312.11983","CorpusId":266362404},"title":"Fluctuation-based Adaptive Structured Pruning for Large Language Models"},{"paperId":"2141ed804636a1cf339d606cd03fd3b3e9582133","externalIds":{"DBLP":"conf/cvpr/LinYP0SH24","ArXiv":"2312.07533","DOI":"10.1109/CVPR52733.2024.02520","CorpusId":266174746},"title":"VILA: On Pre-training for Visual Language Models"},{"paperId":"ca53c1d1ba1a1386f860fa13d7729160571e1643","externalIds":{"DBLP":"journals/corr/abs-2310-18356","ArXiv":"2310.18356","DOI":"10.48550/arXiv.2310.18356","CorpusId":264590698},"title":"LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery"},{"paperId":"abdb0f9d1486dbb024c4bc9f8f9dc40464c58715","externalIds":{"DBLP":"journals/corr/abs-2310-06694","ArXiv":"2310.06694","DOI":"10.48550/arXiv.2310.06694","CorpusId":263830786},"title":"Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning"},{"paperId":"faab24bc6cd4a4dea6e82420d145f08445c05fc7","externalIds":{"ArXiv":"2310.05175","DBLP":"conf/icml/0006W0HWJLJPLBW24","DOI":"10.48550/arXiv.2310.05175","CorpusId":263829692},"title":"Outlier Weighed Layerwise Sparsity (OWL): A Missing Secret Sauce for Pruning LLMs to High Sparsity"},{"paperId":"cef2e06efd484520808dfbeeee2029c4d06bd799","externalIds":{"ArXiv":"2310.05015","DBLP":"journals/corr/abs-2310-05015","DOI":"10.48550/arXiv.2310.05015","CorpusId":263830468},"title":"Compresso: Structured Pruning with Collaborative Prompting Learns Compact Large Language Models"},{"paperId":"477da0209e093448a8370862540182a1a77602fe","externalIds":{"DBLP":"conf/iclr/SungYB24","ArXiv":"2310.02998","DOI":"10.48550/arXiv.2310.02998","CorpusId":263620656},"title":"ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models"},{"paperId":"77fde89a0f28cae77fd488ee3b641dee716e9c77","externalIds":{"ArXiv":"2310.02980","DBLP":"conf/iclr/AmosB024","DOI":"10.48550/arXiv.2310.02980","CorpusId":263620655},"title":"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"},{"paperId":"eb2c2330177f765038a2b17e2ee3498965865797","externalIds":{"DBLP":"journals/corr/abs-2308-13137","ArXiv":"2308.13137","DOI":"10.48550/arXiv.2308.13137","CorpusId":261214575},"title":"OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"},{"paperId":"374ebdc8240a35820cb7ab8bfca37e180e21b605","externalIds":{"DBLP":"journals/corr/abs-2308-12792","ArXiv":"2308.12792","DOI":"10.48550/arXiv.2308.12792","CorpusId":261100979},"title":"Sparks of Large Audio Models: A Survey and Outlook"},{"paperId":"338d8f3b199abcebc85f34016b0162ab3a9d5310","externalIds":{"DBLP":"journals/corr/abs-2308-07633","ArXiv":"2308.07633","DOI":"10.1162/tacl_a_00704","CorpusId":260900101},"title":"A Survey on Model Compression for Large Language Models"},{"paperId":"a03a940371c44daf1ff0373aa8bab3a79581db7c","externalIds":{"DBLP":"conf/cvpr/00020GW24","ArXiv":"2306.14525","DOI":"10.1109/CVPR52733.2024.01491","CorpusId":259251686},"title":"ParameterNet: Parameters are All You Need for Large-Scale Visual Pretraining of Mobile Networks"},{"paperId":"9f5408d8c08a2f7beb35cb16c6ccdcf67b3c7d3d","externalIds":{"DBLP":"conf/aaai/ShiNGZL0DY023","DOI":"10.1609/aaai.v37i2.25319","CorpusId":259733979},"title":"Memory-Oriented Structural Pruning for Efficient Image Restoration"},{"paperId":"7d22ad3573101337bca2091fb0114b377c4f3db6","externalIds":{"DBLP":"journals/corr/abs-2306-11695","ArXiv":"2306.11695","DOI":"10.48550/arXiv.2306.11695","CorpusId":259203115},"title":"A Simple and Effective Pruning Approach for Large Language Models"},{"paperId":"bc8428e270a5474cabfaff578d44955f757ccacd","externalIds":{"ArXiv":"2306.11222","DBLP":"journals/corr/abs-2306-11222","DOI":"10.48550/arXiv.2306.11222","CorpusId":259203385},"title":"LoSparse: Structured Compression of Large Language Models based on Low-Rank and Sparse Approximation"},{"paperId":"7e61acdfd6939532a628f3bed13658976d6b6fa4","externalIds":{"DBLP":"conf/icml/JaiswalLC0W23a","ArXiv":"2306.10460","DOI":"10.48550/arXiv.2306.10460","CorpusId":259203662},"title":"Instant Soup: Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models"},{"paperId":"f8edcce7e978936050f14823b44b3450338cff6b","externalIds":{"ArXiv":"2305.19549","DBLP":"conf/interspeech/JiangZLWCC0LYQ23","DOI":"10.48550/arXiv.2305.19549","CorpusId":258987626},"title":"Accurate and Structured Pruning for Efficient Automatic Speech Recognition"},{"paperId":"32ac52069e562d4f900afee70bdca63f53461481","externalIds":{"ArXiv":"2305.14314","DBLP":"conf/nips/DettmersPHZ23","DOI":"10.48550/arXiv.2305.14314","CorpusId":258841328},"title":"QLoRA: Efficient Finetuning of Quantized LLMs"},{"paperId":"017010b941d902a467f6d329ae5e74fd67e67912","externalIds":{"DBLP":"journals/corr/abs-2305-11627","ArXiv":"2305.11627","DOI":"10.48550/arXiv.2305.11627","CorpusId":258823276},"title":"LLM-Pruner: On the Structural Pruning of Large Language Models"},{"paperId":"6f75f34440e73095afea3dd407e37d95bb1968ef","externalIds":{"ArXiv":"2305.10924","DBLP":"conf/nips/FangMW23","DOI":"10.48550/arXiv.2305.10924","CorpusId":258762600},"title":"Structural Pruning for Diffusion Models"},{"paperId":"c9052f3ccd02c3a841c1ca9ebda6b24dfd847762","externalIds":{"DBLP":"conf/nips/ChoAN23","ArXiv":"2305.11203","DOI":"10.48550/arXiv.2305.11203","CorpusId":258823372},"title":"PDP: Parameter-free Differentiable Pruning is All You Need"},{"paperId":"8cb97eb1acb9db3e683ab531bdf7b81e68a0cd46","externalIds":{"DBLP":"journals/corr/abs-2305-02190","ArXiv":"2305.02190","DOI":"10.48550/arXiv.2305.02190","CorpusId":258461067},"title":"Rethinking Graph Lottery Tickets: Graph Sparsity Matters"},{"paperId":"b6da4e11e24da4e863bbc1c5c7bd6080d0906b98","externalIds":{"ArXiv":"2304.02840","DBLP":"conf/iclr/WangL023","DOI":"10.48550/arXiv.2304.02840","CorpusId":257985378},"title":"NTK-SAP: Improving neural network pruning by aligning training dynamics"},{"paperId":"c8f2aced926707fba8a0535a6df5b5823d394bac","externalIds":{"ArXiv":"2304.06632","DBLP":"journals/corr/abs-2304-06632","DOI":"10.48550/arXiv.2304.06632","CorpusId":258107993},"title":"AI-Generated Content (AIGC): A Survey"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"e60b6836b45ad0ae02a5fa663c8c31119f0c0a94","externalIds":{"DBLP":"journals/corr/abs-2303-04935","ArXiv":"2303.04935","DOI":"10.1109/CVPR52729.2023.02333","CorpusId":257427497},"title":"X-Pruner: eXplainable Pruning for Vision Transformers"},{"paperId":"3d60a54a47b346608430344ff37935d897a14c09","externalIds":{"DBLP":"conf/icml/NovaDS23","ArXiv":"2303.04185","DOI":"10.48550/arXiv.2303.04185","CorpusId":257404900},"title":"Gradient-Free Structured Pruning with Unlabeled Data"},{"paperId":"79dcd3843796fd552844cea6a0f244d5852fb9fb","externalIds":{"DBLP":"journals/pami/HeX24","ArXiv":"2303.00566","DOI":"10.1109/TPAMI.2023.3334614","CorpusId":257255597,"PubMed":"38015707"},"title":"Structured Pruning for Deep Convolutional Neural Networks: A Survey"},{"paperId":"a7d298cbbac81bd47396edbf6a97fbc1fa0cf5c6","externalIds":{"DBLP":"journals/tcad/TuliJ23","ArXiv":"2302.14705","DOI":"10.1109/TCAD.2023.3273992","CorpusId":257232385},"title":"AccelTran: A Sparsity-Aware Accelerator for Dynamic Inference With Transformers"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"ae3ac5509c445327a23431409624a1333aa825b0","externalIds":{"DBLP":"journals/corr/abs-2302-03773","ArXiv":"2302.03773","DOI":"10.48550/arXiv.2302.03773","CorpusId":256662734},"title":"What Matters In The Structured Pruning of Generative Language Models?"},{"paperId":"463910f5a3abaa8d41dbbeeedd49d5746c1ab6b8","externalIds":{"DBLP":"journals/corr/abs-2301-13741","ArXiv":"2301.13741","DOI":"10.48550/arXiv.2301.13741","CorpusId":256415903},"title":"UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers"},{"paperId":"da075ad0ec2c88335af85602a76a33e034536896","externalIds":{"DBLP":"journals/corr/abs-2301-12900","ArXiv":"2301.12900","DOI":"10.1109/CVPR52729.2023.01544","CorpusId":256390345},"title":"DepGraph: Towards Any Structural Pruning"},{"paperId":"3ea79430455304c782572dfb6ca3e5230b0351de","externalIds":{"DBLP":"conf/aaai/YinUSJ023","ArXiv":"2301.05345","DOI":"10.48550/arXiv.2301.05345","CorpusId":255825547},"title":"GOHSP: A Unified Framework of Graph and Optimization-based Heterogeneous Structured Pruning for Vision Transformer"},{"paperId":"1825493cc6a12c1a509b03593991653ff3c76c49","externalIds":{"DBLP":"journals/corr/abs-2301-05219","ArXiv":"2301.05219","DOI":"10.48550/arXiv.2301.05219","CorpusId":255749315},"title":"Why is the State of Neural Network Pruning so Confusing? On the Fairness, Comparison Setup, and Trainability in Network Pruning"},{"paperId":"909ad57ce8caa6b390a65ae09db352d27d8f3996","externalIds":{"DBLP":"journals/corr/abs-2301-00774","ArXiv":"2301.00774","DOI":"10.48550/arXiv.2301.00774","CorpusId":255372747},"title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"},{"paperId":"1e6f185444b099c60c4dee50c351387192779aee","externalIds":{"DBLP":"journals/sensors/SuiLZZYZT23","PubMedCentral":"9862432","DOI":"10.3390/s23020824","CorpusId":255798505,"PubMed":"36679624"},"title":"A Hardware-Friendly High-Precision CNN Pruning Method and Its FPGA Implementation"},{"paperId":"13cf75c5fb62db04e2485997b03be33e2125ace5","externalIds":{"DBLP":"conf/nips/ZhangYR0CHW022","ArXiv":"2210.04092","DOI":"10.48550/arXiv.2210.04092","CorpusId":252780187},"title":"Advancing Model Pruning via Bi-level Optimization"},{"paperId":"3de645f0c1993cd3f3374ad747640a1aa6658a82","externalIds":{"DBLP":"conf/iclr/PaulCLFGD23","ArXiv":"2210.03044","DOI":"10.48550/arXiv.2210.03044","CorpusId":252735281},"title":"Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?"},{"paperId":"15cfcb19cec6d02f28fc975b1bb254455e916d67","externalIds":{"DBLP":"journals/corr/abs-2207-00200","ArXiv":"2207.00200","DOI":"10.48550/arXiv.2207.00200","CorpusId":250244088},"title":"Studying the impact of magnitude pruning on contrastive learning methods"},{"paperId":"d451901a6a12c61179289cac7a4588a86c234112","externalIds":{"DBLP":"conf/aaai/0004HWCCC22","DOI":"10.1609/aaai.v36i3.20222","CorpusId":250294994},"title":"Width & Depth Pruning for Vision Transformers"},{"paperId":"4cbfa720b09abc0e1832cdb72ce67d1f10416c89","externalIds":{"DBLP":"conf/aaai/CaiAYYX22","DOI":"10.1609/aaai.v36i1.19888","CorpusId":250297625},"title":"Prior Gradient Mask Guided Pruning-Aware Fine-Tuning"},{"paperId":"76d40153acfbb35a7eb8272a4215854cafa10e78","externalIds":{"DBLP":"conf/icml/ZhangZLBHCZ22","ArXiv":"2206.12562","DOI":"10.48550/arXiv.2206.12562","CorpusId":250072480},"title":"PLATON: Pruning Large Transformer Models with Upper Confidence Bound of Weight Importance"},{"paperId":"7c337018654121e85ac3159a5217d663a8222064","externalIds":{"ArXiv":"2206.10369","DBLP":"conf/icml/GraesserEEC22","DOI":"10.48550/arXiv.2206.10369","CorpusId":249890186},"title":"The State of Sparse Training in Deep Reinforcement Learning"},{"paperId":"e58f79436b404c2af4ca786b54b32491ffcb985b","externalIds":{"DBLP":"journals/corr/abs-2206-00843","ArXiv":"2206.00843","DOI":"10.48550/arXiv.2206.00843","CorpusId":249282255},"title":"DepthShrinker: A New Compression Paradigm Towards Boosting Real-Hardware Efficiency of Compact Neural Networks"},{"paperId":"e040cc73c29e81fdbc5a8f9813d6bbce2b38aca4","externalIds":{"DBLP":"conf/cvpr/PanQLLH22","DOI":"10.1109/CVPRW56347.2022.00298","CorpusId":251034811},"title":"Momentum Contrastive Pruning"},{"paperId":"386aa2953670f46b3280f400b02435cf3fde3be7","externalIds":{"DBLP":"conf/cvpr/MengYSFS22","DOI":"10.1109/CVPR52688.2022.01194","CorpusId":249980132},"title":"Contrastive Dual Gating: Learning Sparse Features With Contrastive Learning"},{"paperId":"3df9709065c9167d91f3fdfa3e621737c7e2ef32","externalIds":{"DBLP":"conf/cvpr/ZouWFC22","DOI":"10.1109/CVPR52688.2022.00593","CorpusId":250056341},"title":"Dreaming to Prune Image Deraining Networks"},{"paperId":"ee22bad27bc21f90706afe4aad83e319e685d2e4","externalIds":{"PubMedCentral":"9098282","DOI":"10.1155/2022/7775419","CorpusId":248582470,"PubMed":"35571691"},"title":"Differentiable Network Pruning via Polarization of Probabilistic Channelwise Soft Masks"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"9e82736043eebe3f71eb86cbef6e2ac45306ece5","externalIds":{"ACL":"2022.acl-long.107","DBLP":"conf/acl/XiaZC22","ArXiv":"2204.00408","DOI":"10.48550/arXiv.2204.00408","CorpusId":247922354},"title":"Structured Pruning Learns Compact and Accurate Models"},{"paperId":"fb145e1e49d3269d8223c7710e22b45438613ff0","externalIds":{"DBLP":"journals/corr/abs-2204-09656","ArXiv":"2204.09656","DOI":"10.48550/arXiv.2204.09656","CorpusId":248266822},"title":"A Fast Post-Training Pruning Framework for Transformers"},{"paperId":"9365d464f67ba829ae18db0d260755720a0920b1","externalIds":{"DOI":"10.3390/electronics11060945","CorpusId":247604723},"title":"A Survey on Efficient Convolutional Neural Networks and Hardware Acceleration"},{"paperId":"4c69fdca6e8a1f10871ab9dc47f62c81ba7ead4a","externalIds":{"DBLP":"journals/corr/abs-2203-08243","ArXiv":"2203.08243","DOI":"10.48550/arXiv.2203.08243","CorpusId":247475977},"title":"Unified Visual Transformer Compression"},{"paperId":"6da9a81b75e7ad02867860753d1aa276673a3a77","externalIds":{"ACL":"2022.emnlp-main.279","DBLP":"conf/emnlp/KurticCNFKFGA22","ArXiv":"2203.07259","DOI":"10.48550/arXiv.2203.07259","CorpusId":247446572},"title":"The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"},{"paperId":"f9480350e1986957919d49f346ba20dcab8f5b71","externalIds":{"DBLP":"journals/corr/abs-2203-04570","ArXiv":"2203.04570","DOI":"10.48550/arXiv.2203.04570","CorpusId":247319015},"title":"CP-ViT: Cascade Vision Transformer Pruning via Progressive Sparsity Prediction"},{"paperId":"94d353a313021f2237afb28d93965c4767263352","externalIds":{"ArXiv":"2203.04248","DBLP":"journals/corr/abs-2203-04248","DOI":"10.48550/arXiv.2203.04248","CorpusId":247315014},"title":"Dual Lottery Ticket Hypothesis"},{"paperId":"ac9f413f99073d4286cbc666caa4904e006f3b7a","externalIds":{"PubMedCentral":"8914711","DBLP":"journals/sensors/ZhangWCLZ22","DOI":"10.3390/s22052022","CorpusId":247298472,"PubMed":"35271168"},"title":"A Pruning Method for Deep Convolutional Network Based on Heat Map Generation Metrics"},{"paperId":"9ab1a4ee690e9f00064c420b610dbdea7bc488bd","externalIds":{"ArXiv":"2202.10203","DBLP":"conf/cvpr/YanGLHS22","DOI":"10.1109/CVPR52688.2022.00021","CorpusId":247012032},"title":"Learning Bayesian Sparse Networks with Full Experience Replay for Continual Learning"},{"paperId":"be1210aa1ddbe7d6a654045a5aabbdc2a4827e6f","externalIds":{"DBLP":"journals/corr/abs-2202-08132","ArXiv":"2202.08132","CorpusId":246867209},"title":"Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients"},{"paperId":"e468f74ebffa8bbdd99bf8d0233822a1d2a9b430","externalIds":{"DBLP":"conf/icml/ChenCMWW22","ArXiv":"2202.04736","CorpusId":246706034},"title":"Coarsening the Granularity: Towards Structurally Sparse Lottery Tickets"},{"paperId":"821b08d595b6482e3d1f5bab6835b72d67ebd894","externalIds":{"DBLP":"journals/corr/abs-2202-02643","ArXiv":"2202.02643","CorpusId":246634950},"title":"The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training"},{"paperId":"a3b42a83669998f65df60d7c065a70d07ca95e99","externalIds":{"DBLP":"journals/corr/abs-2201-12086","ArXiv":"2201.12086","CorpusId":246411402},"title":"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"},{"paperId":"5ab70d95ca49702a3dd49b39d9396d8136b52311","externalIds":{"DBLP":"conf/cvpr/ChavanS0LCX22","ArXiv":"2201.00814","DOI":"10.1109/CVPR52688.2022.00488","CorpusId":245650313},"title":"Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space"},{"paperId":"b3ccbba3b77728cffc323d8d4bc3ada615e8e273","externalIds":{"DBLP":"conf/icmcs/HouK22","ArXiv":"2201.00043","DOI":"10.1109/ICME52920.2022.9859786","CorpusId":245650304},"title":"Multi-Dimensional Model Compression of Vision Transformer"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","externalIds":{"ArXiv":"2112.10752","DBLP":"journals/corr/abs-2112-10752","DOI":"10.1109/CVPR52688.2022.01042","CorpusId":245335280},"title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"08c2e7812ff224db1c877b4d14730d6288d529aa","externalIds":{"DBLP":"journals/corr/abs-2112-07198","ArXiv":"2112.07198","DOI":"10.1609/aaai.v36i10.21408","CorpusId":245131431},"title":"From Dense to Sparse: Contrastive Pruning for Better Pre-trained Language Model Compression"},{"paperId":"5c7280126811c12505460c0c9579c707ac0de070","externalIds":{"DBLP":"journals/corr/abs-2112-04905","ArXiv":"2112.04905","CorpusId":245005856},"title":"i-SpaSP: Structured Neural Pruning via Sparse Signal Recovery"},{"paperId":"6988237a7d8ffc226d21d897724543c915a159ee","externalIds":{"DBLP":"conf/cvpr/IofinovaPKA22","ArXiv":"2111.13445","DOI":"10.1109/CVPR52688.2022.01195","CorpusId":244709731},"title":"How Well Do Sparse ImageNet Models Transfer?"},{"paperId":"5b5f5ece7e73317ff1d66a6a79372c66ea960a2e","externalIds":{"DBLP":"journals/pami/HeCLPZTZ24","ArXiv":"2111.11802","DOI":"10.1109/TPAMI.2024.3355890","CorpusId":244488257,"PubMed":"38241113"},"title":"Pruning Self-Attentions Into Convolutional Layers in Single Path"},{"paperId":"9202a718ce05395b6e17d5301e3a2e8b1021f31b","externalIds":{"ArXiv":"2111.05754","DBLP":"journals/corr/abs-2111-05754","CorpusId":243938339},"title":"Prune Once for All: Sparse Pre-Trained Language Models"},{"paperId":"7ba86f4a666cb0ba04a4c5c11e0c751cc1fbc204","externalIds":{"DBLP":"conf/iclr/NonnenmacherPSR22","ArXiv":"2110.11395","CorpusId":239616317},"title":"SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning"},{"paperId":"e017fee16881ca23176a35034ec1dbce285a02b6","externalIds":{"DBLP":"journals/corr/abs-2110-08232","ArXiv":"2110.08232","DOI":"10.1109/CVPR52688.2022.01213","CorpusId":239009792},"title":"Fire Together Wire Together: A Dynamic Pruning Approach with Self-Supervised Mask Prediction"},{"paperId":"24fb91f134b9291f7535e7f6305a925a4f63440e","externalIds":{"DBLP":"journals/corr/abs-2110-05667","ArXiv":"2110.05667","CorpusId":238634794},"title":"Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity on Pruned Neural Networks"},{"paperId":"c051ee2ad7ac203a26fa8f50eb6312424c729b27","externalIds":{"DBLP":"conf/cvpr/YangYSMLK23","ArXiv":"2110.04869","DOI":"10.1109/CVPR52729.2023.01779","CorpusId":257833491},"title":"Global Vision Transformer Pruning with Hessian-Aware Saliency"},{"paperId":"7f7276a2b88e460972098b63362032db64613fd2","externalIds":{"DBLP":"journals/corr/abs-2110-02743","ArXiv":"2110.02743","CorpusId":238408284},"title":"Towards efficient end-to-end speech recognition with biologically-inspired neural networks"},{"paperId":"e52f20cb4dee2cec6152a4088f9847094feac199","externalIds":{"DBLP":"conf/iccv/Li0H021","DOI":"10.1109/ICCV48922.2021.00528","CorpusId":244477302},"title":"Dynamic Dual Gating Neural Networks"},{"paperId":"04f41d1ac8f43797103090c7c328fa80bfff09ac","externalIds":{"ArXiv":"2109.14960","DBLP":"journals/corr/abs-2109-14960","DOI":"10.1007/978-3-031-20083-0_8","CorpusId":238227092},"title":"Prune Your Model Before Distill It"},{"paperId":"2dcc6d63e840217306ecdef527ca66706eddc2cb","externalIds":{"DBLP":"journals/corr/abs-2108-00708","ArXiv":"2108.00708","CorpusId":235825363},"title":"Group Fisher Pruning for Practical Network Compression"},{"paperId":"2e1b34719554d130cfe7f5e6f2352cadec7b60a3","externalIds":{"ArXiv":"2108.00259","DBLP":"journals/tmlr/WolfeLWKK24","CorpusId":244921154},"title":"How Much Pre-training Is Enough to Discover a Good Subnetwork?"},{"paperId":"167200b99b69183968fc7b7c525fcae6bbc3812d","externalIds":{"DBLP":"journals/corr/abs-2107-01808","ArXiv":"2107.01808","CorpusId":235731684},"title":"Why is Pruning at Initialization Immune to Reinitializing and Shuffling?"},{"paperId":"2dbd1fc62f13cceb223f1caa70424cc3ccaeea4f","externalIds":{"DBLP":"journals/corr/abs-2107-00166","ArXiv":"2107.00166","CorpusId":235694458},"title":"Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?"},{"paperId":"439d158e3ab3910d836535dd1aec693f5c0420cf","externalIds":{"DBLP":"conf/iclr/LiuCACSMPWM22","ArXiv":"2106.14568","CorpusId":238856644},"title":"Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity"},{"paperId":"17f6f7c4973a7823364e17d501135c8f0673cab7","externalIds":{"DBLP":"journals/corr/abs-2106-10784","ArXiv":"2106.10784","CorpusId":235490108},"title":"iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients"},{"paperId":"a85ba5bb3e97c999f5f6dbc78f277b107af1dba2","externalIds":{"DBLP":"journals/corr/abs-2106-10404","ArXiv":"2106.10404","CorpusId":235490153},"title":"Sparse Training via Boosting Pruning Plasticity with Neuroregeneration"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"362635eb7cd72d4ca7414cb257dadbced12fbe8f","externalIds":{"DBLP":"journals/corr/abs-2106-05933","ArXiv":"2106.05933","CorpusId":235390847},"title":"PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition"},{"paperId":"d59324d2534051042ed575e98f656a9e5dfe041c","externalIds":{"ArXiv":"2106.04217","DBLP":"journals/corr/abs-2106-04217","DOI":"10.24963/ijcai.2022/477","CorpusId":235368271},"title":"Dynamic Sparse Training for Deep Reinforcement Learning"},{"paperId":"efbe9f591090018f78b42c84613c8afda9292fdb","externalIds":{"DBLP":"conf/nips/ChenCGYZW21","ArXiv":"2106.04533","CorpusId":235367934},"title":"Chasing Sparsity in Vision Transformers: An End-to-End Exploration"},{"paperId":"9efa13bc02bed2e41b3e425dd2ce15d7f2336714","externalIds":{"DBLP":"conf/cvpr/GaoH0H21","DOI":"10.1109/CVPR46437.2021.00915","CorpusId":235703417},"title":"Network Pruning via Performance Maximization"},{"paperId":"30101e7fb6310d0bfb2130ac627aeb090b0b50fc","externalIds":{"DBLP":"conf/cvpr/AghliR21","DOI":"10.1109/CVPRW53098.2021.00356","CorpusId":235719025},"title":"Combining Weight Pruning and Knowledge Distillation For CNN Compression"},{"paperId":"53c3ac3d3f454bf355fb1a1931e40da2fe1d650e","externalIds":{"DBLP":"conf/iclr/ChenZSC21","ArXiv":"2106.00134","CorpusId":231800078},"title":"GANs Can Play Lottery Tickets Too"},{"paperId":"3336270d6eaa8435f8382b30150c3e78ada194a8","externalIds":{"DBLP":"conf/cvpr/YaoPXZLZ21","ArXiv":"2105.12971","DOI":"10.1109/CVPR46437.2021.01004","CorpusId":235212488},"title":"Joint-DetNAS: Upgrade Your Detector with NAS, Pruning and Dynamic Distillation"},{"paperId":"e638b9e6ee09ab4fa748b748099e0f03d471d803","externalIds":{"DBLP":"conf/acl/LiangZCJLHZC20","ACL":"2021.acl-long.510","ArXiv":"2105.12002","DOI":"10.18653/v1/2021.acl-long.510","CorpusId":235186841},"title":"Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization"},{"paperId":"9c58550759a7aa9924228273f41ba946eee55aca","externalIds":{"ArXiv":"2105.11228","DBLP":"conf/cvpr/LiLLYWC0M0J21","DOI":"10.1109/CVPR46437.2021.00637","CorpusId":235166479},"title":"Towards Compact CNNs via Collaborative Compression"},{"paperId":"6421dd04bcd5eae9eae6f394e080ac6409dd8e6a","externalIds":{"ArXiv":"2105.10065","DBLP":"conf/icml/QianK21","CorpusId":235125498},"title":"A Probabilistic Approach to Neural Network Pruning"},{"paperId":"5a09edeb26f9f116f2c0503cd020f38fb943f79b","externalIds":{"ArXiv":"2105.06990","DBLP":"conf/acl/KovalevaKRR21","ACL":"2021.findings-acl.300","DOI":"10.18653/v1/2021.findings-acl.300","CorpusId":235313996},"title":"BERT Busters: Outlier Dimensions that Disrupt Transformers"},{"paperId":"dfe2efeea8889a1937be16538220f5e3477d42fb","externalIds":{"DBLP":"conf/iclr/LeH21","ArXiv":"2105.03193","CorpusId":234096198},"title":"Network Pruning That Matters: A Case Study on Retraining Variants"},{"paperId":"22299b440277b4bc887168a669408d5547c1461a","externalIds":{"DBLP":"journals/corr/abs-2104-11832","ArXiv":"2104.11832","DOI":"10.1609/aaai.v36i1.19945","CorpusId":233394482},"title":"Playing Lottery Tickets with Vision and Language"},{"paperId":"91ad4b4cf2df2c2029e860171e8dd8d5b391a40d","externalIds":{"DBLP":"journals/corr/abs-2104-08700","ArXiv":"2104.08700","DOI":"10.1109/TPAMI.2023.3311783","CorpusId":233297054,"PubMed":"37669203"},"title":"Lottery Jackpots Exist in Pre-Trained Models"},{"paperId":"93efaf8c27940aaef145d8bcbca957be634d26e5","externalIds":{"ArXiv":"2104.08500","CorpusId":233296620},"title":"Vision Transformer Pruning"},{"paperId":"417a7050b7d025a2be2b0465aa0da27d9a6ca6c1","externalIds":{"ArXiv":"2104.02244","DBLP":"conf/cvpr/LiuSL0PK21","DOI":"10.1109/CVPR46437.2021.01198","CorpusId":233033467},"title":"Content-Aware GAN Compression"},{"paperId":"38d315c946e24cb55fa2ad1f4765deadf43c34f9","externalIds":{"DBLP":"journals/corr/abs-2104-00432","ArXiv":"2104.00432","DOI":"10.1016/j.cviu.2022.103445","CorpusId":232478650},"title":"Anchor Pruning for Object Detection"},{"paperId":"5c0705d856eb18666db4318cf76416560764a856","externalIds":{"ArXiv":"2103.16547","DBLP":"conf/nips/ChenCWGLW21","CorpusId":232417266},"title":"The Elastic Lottery Ticket Hypothesis"},{"paperId":"a52d17eac54b145cbc2b2c823f32b9e76be2595d","externalIds":{"ArXiv":"2103.09377","DBLP":"conf/iclr/DiffenderferK21","CorpusId":232257635},"title":"Multi-Prize Lottery Ticket Hypothesis: Finding Accurate Binary Neural Networks by Pruning A Randomly Weighted Network"},{"paperId":"fa3bc410e0dd057642ecc484645acdbacfbe7d2e","externalIds":{"DBLP":"conf/ijcai/WangQBZF22","ArXiv":"2103.06460","DOI":"10.24963/ijcai.2022/786","CorpusId":247012121},"title":"Recent Advances on Neural Network Pruning at Initialization"},{"paperId":"aa1b109f7d3d7e64b5fc539ce7d2642fb8972c8d","externalIds":{"ArXiv":"2103.05861","DBLP":"journals/corr/abs-2103-05861","DOI":"10.1109/CVPR46437.2021.00498","CorpusId":232170293},"title":"Manifold Regularized Dynamic Network Pruning"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"6c48ed6999b3415e2a92386658bf2f74ddabc458","externalIds":{"DBLP":"conf/icml/0007YCSMJRT0W21","ArXiv":"2102.11068","CorpusId":235826360},"title":"Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?"},{"paperId":"1e11c7a586298625113f1bb0cdff505fe767a3a0","externalIds":{"ArXiv":"2102.07156","DBLP":"conf/iclr/TiwariBCG21","CorpusId":231925071},"title":"ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations"},{"paperId":"2028710190373ef893e3055c9113e04274a152d7","externalIds":{"ArXiv":"2102.06790","DBLP":"journals/corr/abs-2102-06790","CorpusId":231925028},"title":"A Unified Lottery Ticket Hypothesis for Graph Neural Networks"},{"paperId":"9d6acac70b2d1fdb861a08b00766ef263109cd7f","externalIds":{"ArXiv":"2102.00554","DBLP":"journals/jmlr/HoeflerABDP21","CorpusId":231740691},"title":"Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks"},{"paperId":"a9ad2d274451fe490c82cdd69c4537c80051e2fc","externalIds":{"ArXiv":"2101.10552","DBLP":"journals/corr/abs-2101-10552","CorpusId":231709226},"title":"A Unified Paths Perspective for Pruning at Initialization"},{"paperId":"2b8088253e2378fce001a090fe923b81e8dedf25","externalIds":{"ArXiv":"2101.03697","DBLP":"journals/corr/abs-2101-03697","MAG":"3120184084","DOI":"10.1109/CVPR46437.2021.01352","CorpusId":231572790},"title":"RepVGG: Making VGG-style ConvNets Great Again"},{"paperId":"d89415c26ee006b98c5e5800291d48a705676b35","externalIds":{"MAG":"3119460773","DOI":"10.1007/s40747-020-00248-y","CorpusId":234292017},"title":"Knowledge from the original network: restore a better pruned network with knowledge distillation"},{"paperId":"0c9d97d2ba489256d4f1760598dc2c7be6d90d96","externalIds":{"ACL":"2021.acl-long.171","ArXiv":"2101.00063","DBLP":"journals/corr/abs-2101-00063","DOI":"10.18653/v1/2021.acl-long.171","CorpusId":230438816},"title":"EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets"},{"paperId":"ad7ddcc14984caae308c397f1a589aae75d4ab71","externalIds":{"ArXiv":"2012.12877","DBLP":"journals/corr/abs-2012-12877","CorpusId":229363322},"title":"Training data-efficient image transformers & distillation through attention"},{"paperId":"400080a724d55bbdd3cfc1c54f0aae6af4ec7879","externalIds":{"DBLP":"conf/iclr/WangQZ021","MAG":"3111652984","ArXiv":"2012.09243","CorpusId":229297917},"title":"Neural Pruning via Growing Regularization"},{"paperId":"5f6fccc32953f57fe29b2316eb8351e84b0179dc","externalIds":{"MAG":"3111921445","DBLP":"journals/corr/abs-2012-06908","ArXiv":"2012.06908","DOI":"10.1109/CVPR46437.2021.01604","CorpusId":229152261},"title":"The Lottery Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models"},{"paperId":"e33cb496a7619e33d1f24501db6d62c1bd3923ec","externalIds":{"DBLP":"conf/cvpr/GirishMGCDS21","MAG":"3111265704","ArXiv":"2012.04643","DOI":"10.1109/CVPR46437.2021.00082","CorpusId":227739001},"title":"The Lottery Ticket Hypothesis for Object Recognition"},{"paperId":"8a8324928d849b4f5e2887eda75221258ad94a26","externalIds":{"ArXiv":"2012.00596","DBLP":"conf/cvpr/LiYNZLCS0KJC0YR21","MAG":"3184682079","DOI":"10.1109/CVPR46437.2021.01403","CorpusId":235458474},"title":"NPAS: A Compiler-aware Framework of Unified Network Pruning and Architecture Search for Beyond Real-Time Mobile Acceleration"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"ArXiv":"2010.11929","MAG":"3119786062","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"b285b90ab4d6d1d726efc726b92f4075363004e6","externalIds":{"ArXiv":"2010.10732","MAG":"3094522247","DBLP":"journals/corr/abs-2010-10732","CorpusId":224814108},"title":"SCOP: Scientific Control for Reliable Neural Network Pruning"},{"paperId":"9227d5897abbf297a34d447e94a802a714b8eab2","externalIds":{"DBLP":"conf/iclr/LeePMAS21","ArXiv":"2010.07611","CorpusId":234358843},"title":"Layer-adaptive Sparsity for the Magnitude-based Pruning"},{"paperId":"917b18b8dad23284c0a42f665f2ba1984fa360de","externalIds":{"DBLP":"conf/aaai/EvciIKD22","MAG":"3092446983","ArXiv":"2010.03533","DOI":"10.1609/aaai.v36i6.20611","CorpusId":222177996},"title":"Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win"},{"paperId":"12ff508431c627fa01aaaf5779d68b6336dec5d3","externalIds":{"ArXiv":"2010.02350","MAG":"3092574632","DBLP":"conf/aaai/KalibhatBF21","DOI":"10.1609/aaai.v35i9.16980","CorpusId":222142784},"title":"Winning Lottery Tickets in Deep Generative Models"},{"paperId":"c8ee7eb6d318c199839648e369c2a14aaae7a1b2","externalIds":{"DBLP":"journals/corr/abs-2010-03954","MAG":"3092382944","ArXiv":"2010.03954","CorpusId":222208626},"title":"A Survey on Deep Neural Network Compression: Challenges, Overview, and Solutions"},{"paperId":"08bfa4310f29b57f4f5e532beed5da91b3a5fe11","externalIds":{"MAG":"3100733577","DBLP":"journals/corr/abs-2009-14410","ArXiv":"2009.14410","CorpusId":222066961},"title":"Pruning Filter in Filter"},{"paperId":"77f6796b250eac27432d7c36449c57b7d689db49","externalIds":{"DBLP":"journals/corr/abs-2009-11839","ArXiv":"2009.11839","MAG":"3088399386","CorpusId":221879071},"title":"A Gradient Flow Framework For Analyzing Network Pruning"},{"paperId":"d8bc0d94f8db59078923f099083805c4a55c4a50","externalIds":{"ArXiv":"2009.11094","MAG":"3105979280","DBLP":"conf/nips/SuCCWG0L20","CorpusId":221857593},"title":"Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot"},{"paperId":"0932abfd0fb90e8a28f7bd195633c9891bfd7ecb","externalIds":{"DBLP":"journals/corr/abs-2009-08576","MAG":"3087194612","ArXiv":"2009.08576","CorpusId":221802286},"title":"Pruning Neural Networks at Initialization: Why are We Missing the Mark?"},{"paperId":"5102cd89499cba468348cef337fdadd58eae7023","externalIds":{"MAG":"3084930274","ArXiv":"2009.08065","DBLP":"conf/emnlp/LiKZ0LLD20","ACL":"2020.findings-emnlp.286","DOI":"10.18653/v1/2020.findings-emnlp.286","CorpusId":221761597},"title":"Efficient Transformer-based Large Scale Language Representations using Hardware-friendly Block Structured Pruning"},{"paperId":"e60ec0a55ebe875a0026784303b525013c896065","externalIds":{"ArXiv":"2008.11062","MAG":"3094786017","DBLP":"journals/corr/abs-2008-11062","DOI":"10.1007/978-3-030-58548-8_4","CorpusId":221293100},"title":"GAN Slimming: All-in-One GAN Compression by A Unified Optimization Framework"},{"paperId":"e87bf05c196c16554713ec16202d962a09568288","externalIds":{"DBLP":"journals/corr/abs-2008-08316","MAG":"3056296174","ArXiv":"2008.08316","DOI":"10.1109/TNNLS.2021.3088587","CorpusId":221172670,"PubMed":"34166205"},"title":"Data-Independent Structured Pruning of Neural Networks via Coresets"},{"paperId":"e71aed7a0680c8fc09733f1dcd0cd3f6bb9cb7aa","externalIds":{"MAG":"3104263050","DBLP":"conf/nips/ChenFC0ZWC20","ArXiv":"2007.12223","CorpusId":220768628},"title":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"},{"paperId":"36f5998c3aabbb6d2aec592881991d5c4ffb6d7c","externalIds":{"ArXiv":"2007.00389","DBLP":"journals/corr/abs-2007-00389","MAG":"3038185437","CorpusId":220280894},"title":"Single Shot Structured Pruning Before Training"},{"paperId":"863d7fdbdcd4bdb1b6eeb9c99ae144d236f03259","externalIds":{"DBLP":"journals/corr/abs-2006-13979","MAG":"3037057938","ArXiv":"2006.13979","DOI":"10.21437/interspeech.2021-329","CorpusId":220055837},"title":"Unsupervised Cross-lingual Representation Learning for Speech Recognition"},{"paperId":"49a049dc85e2380dde80501a984878341dd8efdf","externalIds":{"ArXiv":"2006.11477","DBLP":"conf/nips/BaevskiZMA20","MAG":"3036601975","CorpusId":219966759},"title":"wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations"},{"paperId":"5c126ae3421f05768d8edd97ecd44b1364e2c99a","externalIds":{"DBLP":"conf/nips/HoJA20","MAG":"3100572490","ArXiv":"2006.11239","CorpusId":219955663},"title":"Denoising Diffusion Probabilistic Models"},{"paperId":"6ea7201aad5d146ba481051d26b884d19a34af15","externalIds":{"MAG":"3036991069","ArXiv":"2006.10621","DBLP":"journals/corr/abs-2006-10621","CorpusId":219792934},"title":"On the Predictability of Pruning Across Scales"},{"paperId":"0b5c5571ab9dd88ebf010e8dc6898d8078d8e877","externalIds":{"DBLP":"journals/corr/abs-2006-09081","MAG":"3034290785","ArXiv":"2006.09081","CorpusId":219708931},"title":"Progressive Skeletonization: Trimming more fat from a network at initialization"},{"paperId":"706f756b71f0bf51fc78d98f52c358b1a3aeef8e","externalIds":{"MAG":"3035725276","DBLP":"journals/tkde/LiuZHMWZT23","ArXiv":"2006.08218","DOI":"10.1109/TKDE.2021.3090866","CorpusId":219687051},"title":"Self-Supervised Learning: Generative or Contrastive"},{"paperId":"3b0fb765716ef6861a84abffcbe40643857c613b","externalIds":{"DBLP":"journals/corr/abs-2006-05467","MAG":"3104688113","ArXiv":"2006.05467","CorpusId":219558821},"title":"Pruning neural networks without any data by iteratively conserving synaptic flow"},{"paperId":"486062ef49f412e641b2edf88f6005c01e0f1911","externalIds":{"DBLP":"conf/cvpr/HeDLZZ020","MAG":"3035467254","DOI":"10.1109/CVPR42600.2020.00208","CorpusId":219545631},"title":"Learning Filter Pruning Criteria for Deep Convolutional Neural Networks Acceleration"},{"paperId":"b672afc19364cc801b54543f4f87408ac2c41078","externalIds":{"DBLP":"journals/corr/abs-2006-12156","MAG":"3105391759","ArXiv":"2006.12156","CorpusId":219966475},"title":"Logarithmic Pruning is All You Need"},{"paperId":"0170fc76e934ee643f869df18fb617d5357e8b4e","externalIds":{"MAG":"3025165719","DBLP":"conf/interspeech/GulatiQCPZYHWZW20","ArXiv":"2005.08100","DOI":"10.21437/interspeech.2020-3015","CorpusId":218674528},"title":"Conformer: Convolution-augmented Transformer for Speech Recognition"},{"paperId":"66f0f35fc78bdf2af9de46093d49a428970cde2e","externalIds":{"MAG":"3099715410","DBLP":"conf/nips/Sanh0R20","ArXiv":"2005.07683","CorpusId":218665313},"title":"Movement Pruning: Adaptive Sparsity by Fine-Tuning"},{"paperId":"e6665dc56449f1b7d7e4e2c3db03b862b4ee02ed","externalIds":{"MAG":"3021291375","ArXiv":"2005.04275","DBLP":"journals/corr/abs-2005-04275","CorpusId":218581128},"title":"Pruning Algorithms to Accelerate Convolutional Neural Networks for Edge Applications: A Survey"},{"paperId":"3869d69ffa278de08aa251aa900d2a31efdf3adf","externalIds":{"DBLP":"conf/cvpr/GuoWLY20","MAG":"3035377608","ArXiv":"2005.03354","DOI":"10.1109/cvpr42600.2020.00161","CorpusId":218537870},"title":"DMCP: Differentiable Markov Channel Pruning for Neural Networks"},{"paperId":"91ac65431b2dc46919e1673fde67671c29446812","externalIds":{"MAG":"3022969335","ACL":"2020.emnlp-main.259","ArXiv":"2005.00561","DBLP":"conf/emnlp/PrasannaRR20","DOI":"10.18653/v1/2020.emnlp-main.259","CorpusId":218487454},"title":"When BERT Plays the Lottery, All Tickets Are Winning"},{"paperId":"573cf589caa7e131c17fa5c45fa817f3dce6cfa5","externalIds":{"DBLP":"journals/corr/abs-2005-06870","ArXiv":"2005.06870","MAG":"2995629810","CorpusId":209315655},"title":"Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers"},{"paperId":"c71da533053d79ad267b1d74814a43dda7c584fb","externalIds":{"MAG":"3035550813","DBLP":"conf/iclr/LinSBDJ20","ArXiv":"2006.07253","CorpusId":213729382},"title":"Dynamic Model Pruning with Feedback"},{"paperId":"159dc82a5ee901716b0154051988b5408acfc861","externalIds":{"MAG":"3016263386","DBLP":"journals/corr/abs-2004-04124","ArXiv":"2004.04124","ACL":"2020.coling-main.287","DOI":"10.18653/V1/2020.COLING-MAIN.287","CorpusId":215416219},"title":"LadaBERT: Lightweight Adaptation of BERT through Hybrid Model Compression"},{"paperId":"35bb6f9fce92e07dc3afb1a0b5883f40bafe1bac","externalIds":{"MAG":"3014403552","ArXiv":"2004.02164","DBLP":"journals/corr/abs-2004-02164","DOI":"10.1007/978-3-030-58580-8_35","CorpusId":214801986},"title":"DSA: More Efficient Budgeted Pruning via Differentiable Sparsity Allocation"},{"paperId":"9e096d124e27c6998ed5c8e429eba655d914fe22","externalIds":{"MAG":"3016413385","DBLP":"conf/eccv/LiGZGT20","ArXiv":"2003.13683","DOI":"10.1007/978-3-030-58598-3_36","CorpusId":214714457},"title":"DHP: Differentiable Meta Pruning via HyperNetworks"},{"paperId":"296adb9c495c3105924e3f9d9dc81ea2b224d3a6","externalIds":{"DBLP":"journals/corr/abs-2003-08935","MAG":"3011357794","ArXiv":"2003.08935","DOI":"10.1109/cvpr42600.2020.00804","CorpusId":213005191},"title":"Group Sparsity: The Hinge Between Filter Pruning and Decomposition for Network Compression"},{"paperId":"a1b8a8df281bbaec148a897927a49ea47ea31515","externalIds":{"MAG":"3009561768","DBLP":"journals/corr/abs-2003-04297","ArXiv":"2003.04297","CorpusId":212633993},"title":"Improved Baselines with Momentum Contrastive Learning"},{"paperId":"de66ada65cd9d36e46f1f8dd2c8be480180038ec","externalIds":{"DBLP":"conf/mlsys/BlalockOFG20","MAG":"3010156474","ArXiv":"2003.03033","CorpusId":212628335},"title":"What is the State of Neural Network Pruning?"},{"paperId":"850464c9006261bd632c4203f3e630db09a32faf","externalIds":{"MAG":"3010035731","DBLP":"journals/corr/abs-2003-02389","ArXiv":"2003.02389","CorpusId":212415013},"title":"Comparing Rewinding and Fine-tuning in Neural Network Pruning"},{"paperId":"89ff79e028c9778f729adf8397997067976d9100","externalIds":{"MAG":"3041544570","DBLP":"conf/nips/QiuS20","CorpusId":220425449},"title":"Train-by-Reconnect: Decoupling Locations of Weights from Their Values"},{"paperId":"53f5ab272f9d10047ece88f2cc957160e47f5ea9","externalIds":{"DBLP":"journals/corr/abs-2003-01794","ArXiv":"2003.01794","MAG":"3009043942","CorpusId":211990606},"title":"Good Subnetworks Provably Exist: Pruning via Greedy Forward Selection"},{"paperId":"8771679aac0e90371340bd8c657317f5be113e81","externalIds":{"MAG":"3008851394","DBLP":"journals/corr/abs-2002-11794","ArXiv":"2002.11794","CorpusId":211532277},"title":"Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers"},{"paperId":"3805147a98dab8f0c7667fed25490adbd2300fbd","externalIds":{"MAG":"3101114581","DBLP":"conf/nips/Sehwag0MJ20","CorpusId":220280941},"title":"HYDRA: Pruning Adversarially Robust Neural Networks"},{"paperId":"ad4fb74f6a9f110fc3c9037c379da939e6f1ecad","externalIds":{"MAG":"3034513523","DBLP":"journals/corr/abs-2002-10179","ArXiv":"2002.10179","DOI":"10.1109/cvpr42600.2020.00160","CorpusId":211258761},"title":"HRank: Filter Pruning Using High-Rank Feature Map"},{"paperId":"6d60d0dd613fb1bc9b6a52f6b3e8b65599cade5a","externalIds":{"ArXiv":"2002.08797","DBLP":"conf/iclr/HayouTDT21","CorpusId":235078790},"title":"Robust Pruning at Initialization"},{"paperId":"e08557d60dc47af675b48688a3524a7b0a6eac84","externalIds":{"MAG":"2995492258","DBLP":"conf/iclr/WangZG20","ArXiv":"2002.07376","CorpusId":211146532},"title":"Picking Winning Tickets Before Training by Preserving Gradient Flow"},{"paperId":"7af72a461ed7cda180e7eab878efd5f35d79bbf4","externalIds":{"DBLP":"conf/icml/ChenK0H20","MAG":"3034978746","ArXiv":"2002.05709","CorpusId":211096730},"title":"A Simple Framework for Contrastive Learning of Visual Representations"},{"paperId":"7fd582680ee61f6333a23bd0374f05cd6fd3dcb4","externalIds":{"DBLP":"journals/air/ChoudharyMGS20","MAG":"3004543888","DOI":"10.1007/s10462-020-09816-7","CorpusId":211062209},"title":"A comprehensive survey on model compression and acceleration"},{"paperId":"1bcf4553d841ad78cf51b4d3d48a61f9f3c71ebf","externalIds":{"DBLP":"conf/icml/MalachYSS20","ArXiv":"2002.00585","MAG":"3035615218","CorpusId":211010722},"title":"Proving the Lottery Ticket Hypothesis: Pruning is All You Need"},{"paperId":"910ea52dc13cc9a65d1a050aec794eb56a698229","externalIds":{"MAG":"3001468239","ArXiv":"2001.07710","DBLP":"journals/corr/abs-2001-07710","DOI":"10.1007/978-3-030-58601-0_37","CorpusId":210861079},"title":"An Image Enhancing Pattern-based Sparsity for Real-time Inference on Mobile Devices"},{"paperId":"d52e41a597e22d9b9a3f57e8e4832eb689b45ecb","externalIds":{"MAG":"2999514753","ArXiv":"2001.03554","DBLP":"journals/corr/abs-2001-03554","CorpusId":210157192},"title":"Pruning Convolutional Neural Networks with Self-Supervision"},{"paperId":"63a71de0dafc90910e37a2b07169ff486d9b5fe5","externalIds":{"MAG":"3030437843","DBLP":"conf/lrec/ArdilaBDKMHMSTW20","ArXiv":"1912.06670","ACL":"2020.lrec-1.520","CorpusId":209376338},"title":"Common Voice: A Massively-Multilingual Speech Corpus"},{"paperId":"3f06d02513a2763e472d2b5d5db08e9061081b9e","externalIds":{"DBLP":"journals/corr/abs-1912-05671","ArXiv":"1912.05671","MAG":"3035081900","CorpusId":209324341},"title":"Linear Mode Connectivity and the Lottery Ticket Hypothesis"},{"paperId":"fb7972f30812c7dd056d7943c3e3f00af022d607","externalIds":{"MAG":"2992221004","DBLP":"conf/cvpr/ChenDLCYL20","ArXiv":"1912.03458","DOI":"10.1109/CVPR42600.2020.01104","CorpusId":208910380},"title":"Dynamic Convolution: Attention Over Convolution Kernels"},{"paperId":"dc3863fce4d31a7544372953a4b7e4a2c10dc2b3","externalIds":{"DBLP":"journals/pami/LinJCTL19","MAG":"2894994475","DOI":"10.1109/TPAMI.2018.2873305","CorpusId":52915624,"PubMed":"30281439"},"title":"Holistic CNN Compression via Low-Rank Decomposition with Knowledge Transfer"},{"paperId":"91de019672d54141e957ce16b8d55e75f2273ae3","externalIds":{"DBLP":"journals/pami/ChenZ19","MAG":"2897295818","DOI":"10.1109/TPAMI.2018.2874634","CorpusId":206769698,"PubMed":"30296213"},"title":"Shallowing Deep Networks: Layer-Wise Pruning Based on Feature Representations"},{"paperId":"7a87ab984ca45aae2c5768d22cd6df3b5fd509f9","externalIds":{"MAG":"3034234149","DBLP":"journals/corr/abs-1911-13299","ArXiv":"1911.13299","DOI":"10.1109/CVPR42600.2020.01191","CorpusId":208512842},"title":"Whats Hidden in a Randomly Weighted Neural Network?"},{"paperId":"04f4e55e14150b7c48b0287ba77c7443df76ed45","externalIds":{"DBLP":"conf/aaai/BiskZLGC20","MAG":"2998617917","ArXiv":"1911.11641","DOI":"10.1609/AAAI.V34I05.6239","CorpusId":208290939},"title":"PIQA: Reasoning about Physical Commonsense in Natural Language"},{"paperId":"2e3002f131e1815bda7a10303eff97f79dea01ec","externalIds":{"ArXiv":"1911.11134","DBLP":"conf/icml/EvciGMCE20","MAG":"3035180000","CorpusId":208267757},"title":"Rigging the Lottery: Making All Tickets Winners"},{"paperId":"f3aeb282c47e857a1593867dd20b643e13119551","externalIds":{"MAG":"2991511252","DBLP":"journals/apin/ZhangYRO22","ArXiv":"1911.09817","DOI":"10.1007/s10489-021-02802-8","CorpusId":208248321},"title":"Graph pruning for model compression"},{"paperId":"c44f236d7ac551f3d18f1e024f2502d3fb6e1228","externalIds":{"DBLP":"conf/iclr/LiebenweinBLFR20","ArXiv":"1911.07412","MAG":"2995428361","CorpusId":208138363},"title":"Provable Filter Pruning for Efficient Neural Networks"},{"paperId":"83b8108014e3db4f46354a28ae68193f143c4e7e","externalIds":{"MAG":"3104216863","ACL":"2020.emnlp-main.496","ArXiv":"1910.04732","DBLP":"journals/corr/abs-1910-04732","DOI":"10.18653/v1/2020.emnlp-main.496","CorpusId":204009154},"title":"Structured Pruning of Large Language Models"},{"paperId":"5322b4232b234d0b1b06463fcbc0d1e20396de4e","externalIds":{"MAG":"2898170443","DBLP":"journals/pami/RaoLLZ19","DOI":"10.1109/TPAMI.2018.2878258","CorpusId":53105063,"PubMed":"30371355"},"title":"Runtime Network Routing for Efficient Image Classification"},{"paperId":"454655f4e14e3892bfb574bd283ac5d4184847f4","externalIds":{"ArXiv":"1909.12579","MAG":"2975721122","DBLP":"journals/corr/abs-1909-12579","DOI":"10.1609/AAAI.V34I07.6910","CorpusId":203591730},"title":"Pruning from Scratch"},{"paperId":"fe091b4b01d69753837fc0eb41301e350e95bac6","externalIds":{"MAG":"2971275988","DBLP":"journals/corr/abs-1909-12778","ArXiv":"1909.12778","CorpusId":202784725},"title":"Global Sparse Momentum SGD for Pruning Very Deep Neural Networks"},{"paperId":"99fc962a0609a8bc0dfb60721cfe62b984cc6b07","externalIds":{"DBLP":"journals/corr/abs-1909-12326","MAG":"2977090839","ArXiv":"1909.12326","DOI":"10.1109/TNNLS.2022.3166101","CorpusId":203592134,"PubMed":"35468066"},"title":"Model Pruning Enables Efficient Federated Learning on Edge Devices"},{"paperId":"de5c34fc56e1aa9aaf8ab58a668c655b942e70c8","externalIds":{"DBLP":"conf/iclr/YouL0FWCBWL20","ArXiv":"1909.11957","MAG":"2976872728","CorpusId":202888885},"title":"Drawing early-bird tickets: Towards more efficient training of deep networks"},{"paperId":"dfc7b58b67c31932b48586b3e23a43cc94695290","externalIds":{"DBLP":"conf/eccv/ChenLYK0G0020","MAG":"3090449556","DOI":"10.1007/978-3-030-58577-8_7","CorpusId":216080982},"title":"UNITER: UNiversal Image-TExt Representation Learning"},{"paperId":"d31f9db0bc89da6b4d11a6e61128d15655d351a5","externalIds":{"MAG":"2998342322","DBLP":"conf/aaai/MaGNL0MRW20","ArXiv":"1909.05073","DOI":"10.1609/AAAI.V34I04.5954","CorpusId":202558862},"title":"PCONV: The Missing but Desirable Sparsity in DNN Weight Pruning for Real-time Execution on Mobile Devices"},{"paperId":"bb3f24186972fbc6d8dcd3327dabe7da1e0e4ce8","externalIds":{"MAG":"2974893078","DBLP":"journals/corr/abs-1909-08174","ArXiv":"1909.08174","CorpusId":202660914},"title":"Gate Decorator: Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks"},{"paperId":"5fc35f49c0ae395de31a79ab9eca8836952d4c4a","externalIds":{"DBLP":"journals/corr/abs-1907-10804","ArXiv":"1907.10804","MAG":"2983484869","DOI":"10.1109/ICCV.2019.00333","CorpusId":198901367},"title":"Co-Evolutionary Compression for Unpaired Image Translation"},{"paperId":"60ed82ca3ec8fbfef4d52e98e49ab687ce501a0c","externalIds":{"MAG":"2956434358","ArXiv":"1907.04840","DBLP":"journals/corr/abs-1907-04840","CorpusId":195873969},"title":"Sparse Networks from Scratch: Faster Training without Losing Performance"},{"paperId":"e7907e7e7d470a12bdab5e6381ad12c4f832ea49","externalIds":{"DBLP":"journals/corr/abs-1906-06307","ArXiv":"1906.06307","MAG":"2951598131","CorpusId":189898449},"title":"A Signal Propagation Perspective for Pruning Neural Networks at Initialization"},{"paperId":"7139d823ad17ba2c958ec0f821c4bbcd69c92a69","externalIds":{"ArXiv":"1906.06110","DBLP":"journals/corr/abs-1906-06110","MAG":"2950630935","CorpusId":189897599},"title":"Towards Compact and Robust Deep Neural Networks"},{"paperId":"23d7d2aae6308a840a597e823ae8214278304c5a","externalIds":{"MAG":"2970866842","ArXiv":"1906.04358","DBLP":"conf/nips/GaierH19","CorpusId":184487309},"title":"Weight Agnostic Neural Networks"},{"paperId":"387e0b95d56e9ecec60a1037ddf7cc57b2851835","externalIds":{"MAG":"2948130861","DBLP":"journals/corr/abs-1906-02768","ArXiv":"1906.02768","CorpusId":174801567},"title":"Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP"},{"paperId":"c53ae5c2601de32c87dab796ab686c70e48c356f","externalIds":{"DBLP":"journals/corr/abs-1906-02773","MAG":"2970072941","ArXiv":"1906.02773","CorpusId":174801046},"title":"One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers"},{"paperId":"b39eec4d962bb1cae0156af6d7f34c1b6302dc51","externalIds":{"DBLP":"conf/cvpr/ZhaoNZZZT19","MAG":"2964266063","DOI":"10.1109/CVPR.2019.00289","CorpusId":196701027},"title":"Variational Convolutional Neural Network Pruning"},{"paperId":"a6f4917d043494d2ebaebe6b65cb35e6a07fda41","externalIds":{"DBLP":"conf/cvpr/MolchanovMTFK19","MAG":"2955419283","ArXiv":"1906.10771","DOI":"10.1109/CVPR.2019.01152","CorpusId":195657904},"title":"Importance Estimation for Neural Network Pruning"},{"paperId":"301c36778a8581a2526d674e7bd5472279f35e07","externalIds":{"MAG":"2945335799","DBLP":"conf/cvpr/LiWYFZL19","DOI":"10.1109/CVPR.2019.00410","CorpusId":181726313},"title":"Compressing Convolutional Neural Networks via Factorized Convolutional Filters"},{"paperId":"817e265620f2a62ed3171b2f7d57d56b9d601a1f","externalIds":{"MAG":"2945403477","DBLP":"journals/corr/abs-1905-09717","ArXiv":"1905.09717","CorpusId":162184071},"title":"Network Pruning via Transformable Architecture Search"},{"paperId":"07a64686ce8e43ac475a8d820a8a9f1d87989583","externalIds":{"MAG":"2951528897","DBLP":"journals/corr/abs-1905-09418","ACL":"P19-1580","ArXiv":"1905.09418","DOI":"10.18653/v1/P19-1580","CorpusId":162183964},"title":"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"},{"paperId":"443494580bfe0531ba91acf500ac95668e7a9502","externalIds":{"MAG":"2945783053","DBLP":"journals/corr/abs-1905-07785","ArXiv":"1905.07785","CorpusId":159040767},"title":"Sparse Transfer Learning via Winning Lottery Tickets"},{"paperId":"be941015db55266715d897899f7a240b289dacf5","externalIds":{"ArXiv":"1905.05934","MAG":"2954650510","DBLP":"journals/corr/abs-1905-05934","CorpusId":155089879},"title":"EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis"},{"paperId":"7b562cbab95a36ad2c8ba6130caacb333a1db020","externalIds":{"MAG":"2944355599","DBLP":"conf/icml/DingDGHY19","ArXiv":"1905.04748","CorpusId":152282651},"title":"Approximated Oracle Filter Pruning for Destructive CNN Width Optimization"},{"paperId":"f7c410ab241bc972cda2f47993124ea8483003b6","externalIds":{"DBLP":"conf/nips/ZhouLLY19","ArXiv":"1905.01067","MAG":"2970277060","CorpusId":145047837},"title":"Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask"},{"paperId":"b03c7ff961822183bab66b2e594415e585d3fd09","externalIds":{"ArXiv":"1905.10650","MAG":"2945767825","DBLP":"conf/nips/MichelLN19","CorpusId":166227946},"title":"Are Sixteen Heads Really Better than One?"},{"paperId":"9770fff7379a7ab9006b48939462354dda9a2053","externalIds":{"MAG":"2953271402","DBLP":"journals/corr/abs-1905-10044","ArXiv":"1905.10044","ACL":"N19-1300","DOI":"10.18653/v1/N19-1300","CorpusId":165163607},"title":"BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions"},{"paperId":"8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad","externalIds":{"MAG":"2946609015","DBLP":"journals/corr/abs-1905-07830","ACL":"P19-1472","ArXiv":"1905.07830","DOI":"10.18653/v1/P19-1472","CorpusId":159041722},"title":"HellaSwag: Can a Machine Really Finish Your Sentence?"},{"paperId":"4a77c93152fa1ea85439d897b0004615ef448f4d","externalIds":{"MAG":"3011514561","DBLP":"conf/cvpr/ChinDZM20","ArXiv":"1904.12368","DOI":"10.1109/cvpr42600.2020.00159","CorpusId":212726441},"title":"Towards Efficient Model Compression via Learned Global Ranking"},{"paperId":"bd3df472bc848083068a76e9ce2b2ab49543dc78","externalIds":{"MAG":"2924888702","ArXiv":"1903.10258","DBLP":"conf/iccv/LiuMZG0C019","DOI":"10.1109/ICCV.2019.00339","CorpusId":85498737},"title":"MetaPruning: Meta Learning for Automatic Neural Network Channel Pruning"},{"paperId":"dee5d062e70250572e50cda25f08d6a2c02b2bab","externalIds":{"MAG":"2951868790","DBLP":"journals/corr/abs-1903-09291","ArXiv":"1903.09291","DOI":"10.1109/CVPR.2019.00290","CorpusId":85459412},"title":"Towards Optimal Structured CNN Pruning via Generative Adversarial Learning"},{"paperId":"8e2c65ff58b28a076883c99b96840e19b5e0b916","externalIds":{"DBLP":"conf/icml/MostafaW19","MAG":"2907886210","ArXiv":"1902.05967","CorpusId":53556443},"title":"Parameter Efficient Training of Deep Convolutional Neural Networks by Dynamic Sparse Reparameterization"},{"paperId":"4ac62731b802c727f916e8deefda1a992991505d","externalIds":{"ArXiv":"1902.01996","MAG":"2913190747","DBLP":"journals/corr/abs-1902-01996","CorpusId":59606288},"title":"Are All Layers Created Equal?"},{"paperId":"689aabd92ed086f6485489e386ac3cd897e29f35","externalIds":{"MAG":"2950361085","ArXiv":"1901.07827","DBLP":"journals/corr/abs-1901-07827","CorpusId":59158854},"title":"Towards Compact ConvNets via Structure-Sparsity Regularized Filter Pruning"},{"paperId":"ea5dd6a3d8f210d05e53a7b6fa5e16f1b115f693","externalIds":{"MAG":"3152893301","DBLP":"journals/corr/abs-1812-08434","ArXiv":"1812.08434","DOI":"10.1016/J.AIOPEN.2021.01.001","CorpusId":56517517},"title":"Graph Neural Networks: A Review of Methods and Applications"},{"paperId":"45707ac4b40e4e52a22dc7255d68beb6ccaabeb7","externalIds":{"MAG":"2966256598","ArXiv":"1812.04368","DBLP":"conf/cvpr/LiLZLDWHJ19","DOI":"10.1109/CVPR.2019.00291","CorpusId":54580712},"title":"Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression"},{"paperId":"7133f2df88f307c54e9b4f2eae034aa956bd2445","externalIds":{"ArXiv":"1812.01803","DBLP":"conf/cvpr/Yang0019","MAG":"2932849458","DOI":"10.1109/CVPR.2019.01146","CorpusId":102352498},"title":"ECC: Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model"},{"paperId":"bb5bc0acea8d452a7999c512127b4f7b3acf8a6d","externalIds":{"MAG":"2951153470","ArXiv":"1811.00250","DBLP":"conf/cvpr/HeLWHY19","DOI":"10.1109/CVPR.2019.00447","CorpusId":102350938},"title":"Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration"},{"paperId":"a8fe949f73ad7c0ca5cdabed1a0493be72c4a598","externalIds":{"MAG":"2963094099","DBLP":"conf/nips/ZhuangTZLGWHZ18","ArXiv":"1810.11809","CorpusId":53102564},"title":"Discrimination-aware Channel Pruning for Deep Neural Networks"},{"paperId":"f789425a7af1d012675118d7d10cd50afad09074","externalIds":{"DBLP":"conf/nips/BannerNS19","MAG":"2970601456","CorpusId":59292009},"title":"Post training 4-bit quantization of convolutional networks for rapid-deployment"},{"paperId":"887a92f2079870b4d2f25eff2ad293124e25f52d","externalIds":{"DBLP":"conf/biocas/KalyanJSPC18","MAG":"2906425920","DOI":"10.1109/BIOCAS.2018.8584839","CorpusId":56719050},"title":"Unsupervised Synaptic Pruning Strategies for Restricted Boltzmann Machines"},{"paperId":"cf440ccce4a7a8681e238b4f26d5b95109add55d","externalIds":{"MAG":"2963247446","DBLP":"conf/iclr/LeeAT19","ArXiv":"1810.02340","CorpusId":52920837},"title":"SNIP: Single-shot Network Pruning based on Connection Sensitivity"},{"paperId":"a055b9917759dd75811edbc8500ca247b457c5b2","externalIds":{"MAG":"2963698820","ArXiv":"1810.05331","DBLP":"journals/corr/abs-1810-05331","CorpusId":52979229},"title":"Dynamic Channel Pruning: Feature Boosting and Suppression"},{"paperId":"4a1004ecd34118116344633c7cdcc34493c423ee","externalIds":{"MAG":"2951569836","DBLP":"conf/iclr/LiuSZHD19","ArXiv":"1810.05270","CorpusId":52978527},"title":"Rethinking the Value of Network Pruning"},{"paperId":"52ff452c2c38d082c07eb434996e07a8c242a692","externalIds":{"DBLP":"journals/corr/abs-1808-06866","ArXiv":"1808.06866","MAG":"2951977814","DOI":"10.24963/ijcai.2018/309","CorpusId":51608028},"title":"Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks"},{"paperId":"c1f457e31b611da727f9aef76c283a18157dfa83","externalIds":{"DBLP":"journals/corr/abs-1806-09055","MAG":"2810075754","ArXiv":"1806.09055","CorpusId":49411844},"title":"DARTS: Differentiable Architecture Search"},{"paperId":"7a84a692327534fd227fa1e07fcb3816b633c591","externalIds":{"MAG":"2809090039","ArXiv":"1806.07572","DBLP":"conf/nips/JacotHG18","CorpusId":49321232},"title":"Neural Tangent Kernel: Convergence and Generalization in Neural Networks"},{"paperId":"ebf35073e122782f685a0d6c231622412f28a53b","externalIds":{"MAG":"2799192307","DBLP":"conf/cvpr/AbdelhamedLB18","DOI":"10.1109/CVPR.2018.00182","CorpusId":52059988},"title":"A High-Quality Denoising Dataset for Smartphone Cameras"},{"paperId":"289b69ac9bc6b859ab05671f02b0a4f82280e88f","externalIds":{"DBLP":"conf/cvpr/TungM18","MAG":"2799197246","DOI":"10.1109/CVPR.2018.00821","CorpusId":49241074},"title":"CLIP-Q: Deep Network Compression Learning by In-parallel Pruning-Quantization"},{"paperId":"20f85256555ad612148e52f9363e52f9d661728b","externalIds":{"MAG":"2962943487","DBLP":"journals/corr/abs-1805-12514","ArXiv":"1805.12514","CorpusId":44124705},"title":"Scaling provable adversarial defenses"},{"paperId":"9309ddee47f24660690b5cb4be4fd1918189785f","externalIds":{"MAG":"2970604398","DBLP":"conf/nips/HuaZSZS19","ArXiv":"1805.12549","CorpusId":44116705},"title":"Channel Gating Neural Networks"},{"paperId":"a751b77a051da6761b284eed4c5b07037bc9ba88","externalIds":{"MAG":"3028304412","DBLP":"journals/pr/LuoW20","ArXiv":"1805.08941","DOI":"10.1016/j.patcog.2020.107461","CorpusId":43921311},"title":"AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference"},{"paperId":"6a9e5377bbf28b86a1dd8cd5802998c949a34ff3","externalIds":{"MAG":"2806412155","ACL":"L18-1275","DBLP":"conf/lrec/LisonTK18","CorpusId":21712915},"title":"OpenSubtitles2018: Statistical Rescoring of Sentence Alignments in Large, Noisy Parallel Corpora"},{"paperId":"e7da662ca8da8f7f7a39f2ead041fa9c77e5d90c","externalIds":{"DBLP":"conf/aaai/DingDHT18","MAG":"2788715907","DOI":"10.1609/aaai.v32i1.12262","CorpusId":19136556},"title":"Auto-Balanced Filter Pruning for Efficient Convolutional Neural Networks"},{"paperId":"451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c","externalIds":{"MAG":"2963310665","DBLP":"conf/emnlp/WangSMHLB18","ACL":"W18-5446","ArXiv":"1804.07461","DOI":"10.18653/v1/W18-5446","CorpusId":5034059},"title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"},{"paperId":"8f880afbfea328c496d1ab96a123bb57d4b506b5","externalIds":{"MAG":"2798170643","DBLP":"conf/eccv/ZhangYZTWFW18","ArXiv":"1804.03294","DOI":"10.1007/978-3-030-01237-3_12","CorpusId":4752389},"title":"A Systematic DNN Weight Pruning Framework using Alternating Direction Method of Multipliers"},{"paperId":"f7701c7662b28f53d82f01d4d05258c8fa0c18b5","externalIds":{"ArXiv":"1803.05729","DBLP":"journals/corr/abs-1803-05729","MAG":"2793035069","CorpusId":4854050},"title":"Exploring Linear Relationship in Feature Map Subspace for ConvNets Compression"},{"paperId":"21937ecd9d66567184b83eca3d3e09eb4e6fbd60","externalIds":{"ArXiv":"1803.03635","MAG":"2951099858","DBLP":"conf/iclr/FrankleC19","CorpusId":53388625},"title":"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"},{"paperId":"1717255b6aea01fe956cef998abbc3c399b5d7cf","externalIds":{"MAG":"2886851211","DBLP":"conf/eccv/HeLLWLH18","ArXiv":"1802.03494","DOI":"10.1007/978-3-030-01234-2_48","CorpusId":52048008},"title":"AMC: AutoML for Model Compression and Acceleration on Mobile Devices"},{"paperId":"dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4","externalIds":{"MAG":"2949261999","ArXiv":"1801.04381","DBLP":"conf/cvpr/SandlerHZZC18","DOI":"10.1109/CVPR.2018.00474","CorpusId":4555207},"title":"MobileNetV2: Inverted Residuals and Linear Bottlenecks"},{"paperId":"e60f693cb12132c7fffc34dc141bcc3c9dfd4961","externalIds":{"DBLP":"conf/cvpr/GordonENCWYC18","MAG":"2964217527","ArXiv":"1711.06798","DOI":"10.1109/CVPR.2018.00171","CorpusId":206596875},"title":"MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks"},{"paperId":"cc2bc56b30e283bc6e7193dd42e66e56658b4875","externalIds":{"MAG":"2963319203","DBLP":"journals/tc/DaiYJ19","ArXiv":"1711.02017","DOI":"10.1109/TC.2019.2914438","CorpusId":19098488},"title":"NeST: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm"},{"paperId":"3b4d671a8c7018c0b42673ba581e5ff3ae762d6c","externalIds":{"MAG":"2764043458","ArXiv":"1710.01878","DBLP":"conf/iclr/ZhuG18","CorpusId":27494814},"title":"To prune, or not to prune: exploring the efficacy of pruning for model compression"},{"paperId":"90a16f34d109b63d95ab4da2d491cbe3a1c8b656","externalIds":{"MAG":"2748428003","DBLP":"conf/iccv/LiuLSHYZ17","ArXiv":"1708.06519","DOI":"10.1109/ICCV.2017.298","CorpusId":5993328},"title":"Learning Efficient Convolutional Networks through Network Slimming"},{"paperId":"8a1ce657dd41a4f49990a4769000dc8049b83404","externalIds":{"MAG":"2950142842","DBLP":"conf/cvpr/ZhongYWSL18","DOI":"10.1109/CVPR.2018.00257","CorpusId":3866935},"title":"Practical Block-Wise Neural Network Architecture Generation"},{"paperId":"79cfb51a51fc093f66aac8e858afe2e14d4a1f20","externalIds":{"MAG":"2950100464","DBLP":"journals/corr/abs-1708-02002","DOI":"10.1109/ICCV.2017.324","CorpusId":47252984},"title":"Focal Loss for Dense Object Detection"},{"paperId":"049fd80f52c0b1fa4d532945d95a24734b62bdf3","externalIds":{"MAG":"2949698407","DBLP":"conf/iccv/LuoWL17","ArXiv":"1707.06342","DOI":"10.1109/ICCV.2017.541","CorpusId":11169209},"title":"ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression"},{"paperId":"ee53c9480132fc0d09b1192226cb2c460462fd6d","externalIds":{"ArXiv":"1707.06168","DBLP":"journals/corr/HeZS17","MAG":"2737121650","DOI":"10.1109/ICCV.2017.155","CorpusId":20157893},"title":"Channel Pruning for Accelerating Very Deep Neural Networks"},{"paperId":"6dbb9e4b2e3b67dc4e1634989511f67d41373dd0","externalIds":{"PubMedCentral":"6008460","ArXiv":"1707.04780","DBLP":"journals/corr/MocanuMSNGL17","MAG":"3101584733","DOI":"10.1038/s41467-018-04316-3","CorpusId":49310977,"PubMed":"29921910"},"title":"Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science"},{"paperId":"2adb616a77fe28b49be2a2d66cccf2d7400e4a04","externalIds":{"MAG":"2963382930","DBLP":"journals/corr/HuangW17aa","ArXiv":"1707.01213","DOI":"10.1007/978-3-030-01270-0_19","CorpusId":575794},"title":"Data-Driven Sparse Structure Selection for Deep Neural Networks"},{"paperId":"231af7dc01a166cac3b5b01ca05778238f796e41","externalIds":{"MAG":"2963981733","DBLP":"conf/nips/HeuselRUNH17","CorpusId":326772},"title":"GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"5ded2b8c64491b4a67f6d39ce473d4b9347a672e","externalIds":{"DBLP":"journals/corr/WilliamsNB17","MAG":"2963846996","ArXiv":"1704.05426","ACL":"N18-1101","DOI":"10.18653/v1/N18-1101","CorpusId":3432876},"title":"A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"},{"paperId":"1cc2f313bcb3b106af081f7031b924c9ad2662bd","externalIds":{"MAG":"2963847166","DBLP":"conf/iclr/NarangDSE17","ArXiv":"1704.05119","CorpusId":10135357},"title":"Exploring Sparsity in Recurrent Neural Networks"},{"paperId":"e3196bc12bcbf2eb51658f78e844517fb9a47b5d","externalIds":{"MAG":"2604998962","DBLP":"conf/cvpr/DongHYY17","ArXiv":"1703.08651","DOI":"10.1109/cvpr.2017.205","CorpusId":15541908},"title":"More is Less: A More Complicated Network with Less Inference Complexity"},{"paperId":"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e","externalIds":{"MAG":"3016211260","DBLP":"conf/cvpr/GoyalKSBP17","ArXiv":"1612.00837","DOI":"10.1007/s11263-018-1116-0","CorpusId":8081284},"title":"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"},{"paperId":"dfad8f616bd2a05c8cae5f61060f743f966ece85","externalIds":{"MAG":"2951856387","ArXiv":"1611.08050","DBLP":"conf/cvpr/CaoSWS17","DOI":"10.1109/CVPR.2017.143","CorpusId":16224674},"title":"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields"},{"paperId":"8acbe90d5b852dadea7810345451a99608ee54c7","externalIds":{"MAG":"2963073614","DBLP":"conf/cvpr/IsolaZZE17","ArXiv":"1611.07004","DOI":"10.1109/CVPR.2017.632","CorpusId":6200260},"title":"Image-to-Image Translation with Conditional Adversarial Networks"},{"paperId":"3db8730c203f88d7f08a6a99e8c02a077dc9b011","externalIds":{"DBLP":"conf/iclr/MolchanovTKAK17","MAG":"2707890836","CorpusId":17240902},"title":"Pruning Convolutional Neural Networks for Resource Efficient Inference"},{"paperId":"efbd381493bb9636f489b965a2034d529cd56bcd","externalIds":{"ArXiv":"1609.07843","MAG":"2525332836","DBLP":"journals/corr/MerityXBS16","CorpusId":16299141},"title":"Pointer Sentinel Mixture Models"},{"paperId":"c2a1cb1612ba21e067a5c3ba478a8d73b796b77a","externalIds":{"MAG":"2515385951","ArXiv":"1608.08710","DBLP":"conf/iclr/0022KDSG17","CorpusId":14089312},"title":"Pruning Filters for Efficient ConvNets"},{"paperId":"c220cdbcec6f92e4bc0f58c5fa6c1183105be1f9","externalIds":{"MAG":"2952924083","ArXiv":"1608.04493","DBLP":"conf/nips/GuoYC16","CorpusId":744803},"title":"Dynamic Network Surgery for Efficient DNNs"},{"paperId":"0c00a328fa7cd56ee60338c54e89bd48310db80b","externalIds":{"DBLP":"journals/corr/ZhangZCM016","MAG":"3099906833","ArXiv":"1608.03981","DOI":"10.1109/TIP.2017.2662206","CorpusId":996788,"PubMed":"28166495"},"title":"Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising"},{"paperId":"7601b995303f953955004db7b9b8b206c0e02ff8","externalIds":{"ArXiv":"1608.03665","DBLP":"journals/corr/WenWWCL16","MAG":"2513419314","CorpusId":2056019},"title":"Learning Structured Sparsity in Deep Neural Networks"},{"paperId":"05dd7254b632376973f3a1b4d39485da17814df5","externalIds":{"DBLP":"journals/corr/RajpurkarZLL16","MAG":"2963748441","ACL":"D16-1264","ArXiv":"1606.05250","DOI":"10.18653/v1/D16-1264","CorpusId":11816014},"title":"SQuAD: 100,000+ Questions for Machine Comprehension of Text"},{"paperId":"230579a14d54ae00073d6c3522ffcef313320be9","externalIds":{"ACL":"K16-1029","ArXiv":"1606.09274","MAG":"2963643655","DBLP":"journals/corr/SeeLM16","DOI":"10.18653/v1/K16-1029","CorpusId":2973141},"title":"Compression of Neural Machine Translation Models via Pruning"},{"paperId":"c8c494ee5488fe20e0aa01bddf3fc4632086d654","externalIds":{"DBLP":"journals/corr/CordtsORREBFRS16","MAG":"2953139137","ArXiv":"1604.01685","DOI":"10.1109/CVPR.2016.350","CorpusId":502946},"title":"The Cityscapes Dataset for Semantic Urban Scene Understanding"},{"paperId":"2e2b189f668cf2c06ebc44dc9b166648256cf457","externalIds":{"ArXiv":"1602.01528","MAG":"2950656546","DBLP":"journals/corr/HanLMPPHD16","DOI":"10.1145/3007787.3001163","CorpusId":1663491},"title":"EIE: Efficient Inference Engine on Compressed Deep Neural Network"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"13497bd108d4412d02050e646235f456568cf822","externalIds":{"MAG":"2949640717","DBLP":"journals/corr/AmodeiABCCCCCCD15","ArXiv":"1512.02595","CorpusId":11590585},"title":"Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin"},{"paperId":"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0","externalIds":{"DBLP":"conf/eccv/LiuAESRFB16","MAG":"2193145675","ArXiv":"1512.02325","DOI":"10.1007/978-3-319-46448-0_2","CorpusId":2141740},"title":"SSD: Single Shot MultiBox Detector"},{"paperId":"642d0f49b7826adcf986616f4af77e736229990f","externalIds":{"MAG":"2119144962","DBLP":"journals/corr/HanMD15","ArXiv":"1510.00149","CorpusId":2134321},"title":"Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"},{"paperId":"4dcdae25a5e33682953f0853ee4cf7ca93be58a9","externalIds":{"MAG":"967544008","DBLP":"journals/corr/YuZSSX15","ArXiv":"1506.03365","CorpusId":8317437},"title":"LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop"},{"paperId":"1ff9a37d766e3a4f39757f5e1b235a42dacf18ff","externalIds":{"DBLP":"conf/nips/HanPTD15","MAG":"2951882884","ArXiv":"1506.02626","CorpusId":2238772},"title":"Learning both Weights and Connections for Efficient Neural Network"},{"paperId":"424561d8585ff8ebce7d5d07de8dbf7aae5e7270","externalIds":{"MAG":"2953106684","ArXiv":"1506.01497","DBLP":"journals/pami/RenHG017","DOI":"10.1109/TPAMI.2016.2577031","CorpusId":10328909,"PubMed":"27295650"},"title":"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"},{"paperId":"6364fdaa0a0eccd823a779fcdd489173f938e91a","externalIds":{"MAG":"1901129140","DBLP":"journals/corr/RonnebergerFB15","ArXiv":"1505.04597","DOI":"10.1007/978-3-319-24574-4_28","CorpusId":3719281},"title":"U-Net: Convolutional Networks for Biomedical Image Segmentation"},{"paperId":"34038d9424ce602d7ac917a4e582d977725d4393","externalIds":{"DBLP":"conf/icassp/PanayotovCPK15","MAG":"1494198834","DOI":"10.1109/ICASSP.2015.7178964","CorpusId":2191379},"title":"Librispeech: An ASR corpus based on public domain audio books"},{"paperId":"0c908739fbff75f03469d13d4a1a07de3414ee19","externalIds":{"ArXiv":"1503.02531","MAG":"1821462560","DBLP":"journals/corr/HintonVD15","CorpusId":7200347},"title":"Distilling the Knowledge in a Neural Network"},{"paperId":"995c5f5e62614fcb4d2796ad2faab969da51713e","externalIds":{"MAG":"1836465849","ArXiv":"1502.03167","DBLP":"conf/icml/IoffeS15","CorpusId":5808102},"title":"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"},{"paperId":"6424b69f3ff4d35249c0bb7ef912fbc2c86f4ff4","externalIds":{"MAG":"1834627138","ArXiv":"1411.7766","DBLP":"journals/corr/LiuLWT14","DOI":"10.1109/ICCV.2015.425","CorpusId":459456},"title":"Deep Learning Face Attributes in the Wild"},{"paperId":"f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97","externalIds":{"MAG":"1591801644","ArXiv":"1409.2329","DBLP":"journals/corr/ZarembaSV14","CorpusId":17719760},"title":"Recurrent Neural Network Regularization"},{"paperId":"eb42cf88027de515750f230b23b1a057dc782108","externalIds":{"MAG":"2949429431","ArXiv":"1409.1556","DBLP":"journals/corr/SimonyanZ14a","CorpusId":14124313},"title":"Very Deep Convolutional Networks for Large-Scale Image Recognition"},{"paperId":"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd","externalIds":{"ArXiv":"1409.0575","DBLP":"journals/corr/RussakovskyDSKSMHKKBBF14","MAG":"2546241758","DOI":"10.1007/s11263-015-0816-y","CorpusId":2930547},"title":"ImageNet Large Scale Visual Recognition Challenge"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","externalIds":{"ArXiv":"1405.0312","DBLP":"conf/eccv/LinMBHPRDZ14","MAG":"2952122856","DOI":"10.1007/978-3-319-10602-1_48","CorpusId":14113767},"title":"Microsoft COCO: Common Objects in Context"},{"paperId":"e5ae8ab688051931b4814f6d32b18391f8d1fa8d","externalIds":{"MAG":"2950248853","DBLP":"conf/nips/DentonZBLF14","ArXiv":"1404.0736","CorpusId":7340116},"title":"Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation"},{"paperId":"44040913380206991b1991daf1192942e038fe31","externalIds":{"ACL":"Q14-1006","DBLP":"journals/tacl/YoungLHH14","MAG":"2185175083","DOI":"10.1162/tacl_a_00166","CorpusId":3104920},"title":"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions"},{"paperId":"99c970348b8f70ce23d6641e201904ea49266b6e","externalIds":{"ArXiv":"1312.6120","MAG":"2953334419","DBLP":"journals/corr/SaxeMG13","CorpusId":17272965},"title":"Exact solutions to the nonlinear dynamics of learning in deep linear neural networks"},{"paperId":"687bac2d3320083eb4530bf18bb8f8f721477600","externalIds":{"ACL":"D13-1170","DBLP":"conf/emnlp/SocherPWCMNP13","MAG":"2251939518","DOI":"10.18653/v1/d13-1170","CorpusId":990233},"title":"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"},{"paperId":"aa7bfd2304201afbb19971ebde87b17e40242e91","externalIds":{"MAG":"104184427","DBLP":"conf/icml/SutskeverMDH13","CorpusId":10940950},"title":"On the importance of initialization and momentum in deep learning"},{"paperId":"1e0b8416b9d2afb9b1ef87557958ef964cb4472b","externalIds":{"MAG":"2250357346","DBLP":"conf/lrec/RousseauDE12","ACL":"L12-1405","CorpusId":18166631},"title":"TED-LIUM: an Automatic Speech Recognition dedicated corpus"},{"paperId":"34a9478b3c3579182ec49de8012f5d7f3c046e4d","externalIds":{"DBLP":"conf/cvpr/FletcherVJ08","MAG":"2137842291","DOI":"10.1109/CVPR.2008.4587747","CorpusId":6924502},"title":"Robust statistics on Riemannian manifolds via the geometric median"},{"paperId":"46f30e94dd3d5902141c5fbe58d0bc9189545c76","externalIds":{"DBLP":"conf/cvpr/HadsellCL06","MAG":"2138621090","DOI":"10.1109/CVPR.2006.100","CorpusId":8281592},"title":"Dimensionality Reduction by Learning an Invariant Mapping"},{"paperId":"d98ef875e2cbde3e2cc8fad521e3cbfe1bddbd69","externalIds":{"MAG":"2138019504","DOI":"10.1111/j.1467-9868.2005.00532.x","CorpusId":6162124},"title":"Model selection and estimation in regression with grouped variables"},{"paperId":"f354310098e09c1e1dc88758fca36767fd9d084d","externalIds":{"MAG":"2134557905","DBLP":"conf/cvpr/LeCunHB04","DOI":"10.1109/CVPR.2004.144","CorpusId":712708},"title":"Learning methods for generic object recognition with invariance to pose and lighting"},{"paperId":"eae2e0fa72e898c289365c0af16daf57a7a6cf40","externalIds":{"MAG":"2133665775","DBLP":"journals/tip/WangBSS04","DOI":"10.1109/TIP.2003.819861","CorpusId":207761262,"PubMed":"15376593"},"title":"Image quality assessment: from error visibility to structural similarity"},{"paperId":"d7da009f457917aa381619facfa5ffae9329a6e9","externalIds":{"DBLP":"conf/acl/PapineniRWZ02","MAG":"2101105183","ACL":"P02-1040","DOI":"10.3115/1073083.1073135","CorpusId":11080756},"title":"Bleu: a Method for Automatic Evaluation of Machine Translation"},{"paperId":"2e9d221c206e9503ceb452302d68d10e293f2a10","externalIds":{"DBLP":"journals/neco/HochreiterS97","MAG":"2064675550","DOI":"10.1162/neco.1997.9.8.1735","CorpusId":1915014,"PubMed":"9377276"},"title":"Long Short-Term Memory"},{"paperId":"0d82c68980943718a306df67c3ed95f782e9f93a","externalIds":{"MAG":"2145085734","DBLP":"journals/tnn/Reed93","DOI":"10.1109/72.248452","CorpusId":35912477,"PubMed":"18276504"},"title":"Pruning algorithms-a survey"},{"paperId":"0b44fcbeea9415d400c5f5789d6b892b6f98daff","externalIds":{"MAG":"1632114991","DBLP":"journals/coling/MarcusSM94","ACL":"J93-2004","CorpusId":252796},"title":"Building a Large Annotated Corpus of English: The Penn Treebank"},{"paperId":"a42954d4b9d0ccdf1036e0af46d87a01b94c3516","externalIds":{"DBLP":"conf/nips/HassibiS92","MAG":"2125389748","CorpusId":7057040},"title":"Second Order Derivatives for Network Pruning: Optimal Brain Surgeon"},{"paperId":"ee24bc329932a780304dad25224f85b9a2ccc40b","externalIds":{"DOI":"10.1136/jramc-149-03-02","CorpusId":1386090},"title":"Recognition"},{"paperId":"182c6d1d30859f227dca3606c743e178e8ae6780","externalIds":{"CorpusId":261617225},"title":"Structural Pruning of Large Language Models via Neural Architecture Search"},{"paperId":"fda9a8f0664456dc4accb4018cfad2e6fde2d460","externalIds":{"DBLP":"conf/iclr/HoangLMW23","CorpusId":259298674},"title":"Revisiting Pruning at Initialization Through the Lens of Ramanujan Graph"},{"paperId":"d7db793f9824a179518a3eb4ea3bd8bc620f6b6f","externalIds":{"DBLP":"journals/corr/abs-2305-18403","DOI":"10.48550/arXiv.2305.18403","CorpusId":263887570},"title":"Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning"},{"paperId":"99e10eb07961b5947512bd448df180d32ca8b319","externalIds":{"DBLP":"journals/corr/abs-2312-05795","DOI":"10.48550/arXiv.2312.05795","CorpusId":270711576},"title":"Large Multimodal Model Compression via Efficient Pruning and Distillation at AntGroup"},{"paperId":"57a2f56f2f44de8ab892c4e8c3f1744530a55399","externalIds":{"DBLP":"conf/iclr/NarshanaMB23","CorpusId":253014786},"title":"DFPC: Data flow driven pruning of coupled channels without data"},{"paperId":"76579d7425474606583aa82e2b16702980b9a03a","externalIds":{"DBLP":"conf/nips/ZhenglZYTXRP22","CorpusId":258509611},"title":"SAViT: Structure-Aware Vision Transformer Pruning via Collaborative Optimization"},{"paperId":"e3d6c5286d2d305bc7d89dc515bdc19dd82cf27f","externalIds":{"DBLP":"journals/corr/abs-2207-12534","DOI":"10.48550/arXiv.2207.12534","CorpusId":251067207},"title":"Trainability Preserving Neural Structured Pruning"},{"paperId":"bfae416203629e4394379081c15cc02d9fdf1e79","externalIds":{"CorpusId":254223466},"title":"BAAT: Towards Sample-specific Backdoor Attack with Clean Labels"},{"paperId":"05e2ca9357bcf542a33b3f97310d9f477cd0776f","externalIds":{"DBLP":"conf/iclr/ChenZ0CW21a","CorpusId":235613443},"title":"Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning"},{"paperId":"d5513752425a079195656580e15857d34e4d6941","externalIds":{"DBLP":"conf/nips/ZhangJZZZRLWJD21","CorpusId":244958525},"title":"Validating the Lottery Ticket Hypothesis with Inertial Manifold Theory"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","externalIds":{"ArXiv":"2103.14030","DBLP":"conf/iccv/LiuL00W0LG21","DOI":"10.1109/ICCV48922.2021.00986","CorpusId":232352874},"title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"92e121c6e114fe3cfb89370df03847c66a9b4e28","externalIds":{"CorpusId":199370376},"title":"An Adversarial Winograd Schema Challenge at Scale"},{"paperId":"dd6d044696df5e4353ff7c92b8009e1201c85129","externalIds":{"CorpusId":233404466},"title":"Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"},{"paperId":"5d90f06bb70a0a3dced62413346235c02b1aa086","externalIds":{"MAG":"2945315962","CorpusId":18268744},"title":"Learning Multiple Layers of Features from Tiny Images"},{"paperId":"b365b8e45b7d81f081de44ac8f9eadf9144f3ca5","externalIds":{"MAG":"2135046866","DOI":"10.1111/J.2517-6161.1996.TB02080.X","CorpusId":16162039},"title":"Regression Shrinkage and Selection via the Lasso"},{"paperId":"e7297db245c3feb1897720b173a59fe7e36babb7","externalIds":{"MAG":"2114766824","DBLP":"conf/nips/CunDS89","CorpusId":7785881},"title":"Optimal Brain Damage"},{"paperId":"f4ea5a6ff3ffcd11ec2e6ed7828a7d41279fb3ad","externalIds":{"MAG":"2120972216","DBLP":"conf/nips/HansonP88","CorpusId":9344018},"title":"Comparing Biases for Minimal Network Construction with Back-Propagation"},{"paperId":"3a9b175324ba11bc0e16c0633912d897b2fac4e2","externalIds":{"CorpusId":4246903},"title":"International Journal of Computer Vision manuscript No. (will be inserted by the editor) The PASCAL Visual Object Classes (VOC) Challenge"}]}