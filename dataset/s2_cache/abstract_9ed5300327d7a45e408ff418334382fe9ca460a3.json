{"abstract":"In biomedical image analysis, developing architectures that effectively capture long-range dependencies is crucial. Traditional Convolutional Neural Networks (CNNs) are constrained by their local receptive fields, while Transformers, though proficient in global context integration, are computationally demanding for high-dimensional medical images. Here, we present nnMamba, a novel architecture that combines the strengths of CNNs with the long-range modeling capabilities of State Space Models (SSMs). We introduce the Mamba-In-Convolution with Channel-Spatial Siamese learning (MICCSS) block to model long-range voxel relationships. Additionally, we implement channel scaling and channel-sequential learning methods to enhance performance in dense prediction and classification tasks. Extensive experiments on seven datasets demonstrate that nnMamba outperforms current state-of-the-art methods in 3D image segmentation, classification, and landmark detection. nnMamba effectively integrates CNNs' local representation with SSMs' global con-text processing, establishing a new benchmark for long-range dependency modeling in medical image analysis. Code is available at https://github.com/lhaof/nnMamba."}