{"abstract":"This paper addresses an enrichment of translation-based knowledge graph embeddings. When new knowledge triples become available after a knowledge graph is embedded onto a vector space, the embedding should be enriched with the new triples, but without the triples used in training the embedding. The main challenge is that the enrichment of new triples should be accomplished without forgetting the knowledge of current embedding. This paper achieves the goal by minimizing a risk over the new triples penalized by rapid parameter change between old and new embedding models. The effectiveness of the proposed method is shown by learning a translation-based knowledge graph embedding trained incrementally using a series of knowledge triples. The experimental results from two tasks of knowledge graph embedding prove that the proposed method not only incorporates new knowledge of new triples into the existing embedding successfully but also preserves the knowledge of the current embedding."}