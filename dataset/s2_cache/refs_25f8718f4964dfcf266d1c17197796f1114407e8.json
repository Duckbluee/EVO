{"references":[{"paperId":"2c4b9e3c85876c71ea14229b8d3b59f2bc3cdf99","externalIds":{"ArXiv":"2407.01231","DBLP":"journals/corr/abs-2407-01231","DOI":"10.48550/arXiv.2407.01231","CorpusId":270869631},"title":"MIRAI: Evaluating LLM Agents for Event Forecasting"},{"paperId":"203c7916b8fd7634f25f257e3a424a5b49d7ab5f","externalIds":{"ArXiv":"2406.20094","DBLP":"journals/corr/abs-2406-20094","DOI":"10.48550/arXiv.2406.20094","CorpusId":270845490},"title":"Scaling Synthetic Data Creation with 1,000,000,000 Personas"},{"paperId":"b43eb24cfc1930fb9c7bace4b69cdf34fecfde3c","externalIds":{"ArXiv":"2406.12263","ACL":"2024.emnlp-main.716","DBLP":"journals/corr/abs-2406-12263","DOI":"10.18653/v1/2024.emnlp-main.716","CorpusId":270562926},"title":"Defending Against Social Engineering Attacks in the Age of LLMs"},{"paperId":"853513bf50bc9e8c77a0141776d15710a4673fe5","externalIds":{"DBLP":"conf/emnlp/HuangLS0024","ArXiv":"2406.11474","DOI":"10.48550/arXiv.2406.11474","CorpusId":270559708},"title":"How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment"},{"paperId":"46b639efb37210f5262916c8e80206ffafd1d840","externalIds":{"DBLP":"conf/nips/ZhangZSKETKM24","ArXiv":"2406.11741","DOI":"10.48550/arXiv.2406.11741","CorpusId":270561034},"title":"Transcendence: Generative Models Can Outperform The Experts That Train Them"},{"paperId":"74f5eab32da49f26e33f964ce4781275d4cfd730","externalIds":{"ArXiv":"2406.11036","DBLP":"journals/corr/abs-2406-11036","DOI":"10.48550/arXiv.2406.11036","CorpusId":270559825},"title":"garak: A Framework for Security Probing Large Language Models"},{"paperId":"8d5bc0b0ddca8740e4bec70231b7f0d12ded3d5d","externalIds":{"DBLP":"journals/corr/abs-2406-10162","ArXiv":"2406.10162","DOI":"10.48550/arXiv.2406.10162","CorpusId":270521305},"title":"Sycophancy to Subterfuge: Investigating Reward-Tampering in Large Language Models"},{"paperId":"c257ad02d088c5951258ca56feb311c75ef429ec","externalIds":{"ArXiv":"2406.09321","DBLP":"journals/corr/abs-2406-09321","DOI":"10.48550/arXiv.2406.09321","CorpusId":270440360},"title":"JailbreakEval: An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models"},{"paperId":"5971402c4cee5863b25c99405e886b673ade223c","externalIds":{"DBLP":"conf/nips/ParkFLK24","ArXiv":"2406.09329","DOI":"10.48550/arXiv.2406.09329","CorpusId":270440383},"title":"Is Value Learning Really the Main Bottleneck in Offline RL?"},{"paperId":"f590d8926dd12345a3bd22253461850f5ca4b3ed","externalIds":{"DBLP":"conf/nips/WangDDZSEZSK24","ArXiv":"2406.08673","DOI":"10.48550/arXiv.2406.08673","CorpusId":270440126},"title":"HelpSteer2: Open-source dataset for training top-performing reward models"},{"paperId":"c8c6c810d4fce999f47898c6b1cefe4b20313925","externalIds":{"ArXiv":"2406.05946","DBLP":"journals/corr/abs-2406-05946","DOI":"10.48550/arXiv.2406.05946","CorpusId":270371778},"title":"Safety Alignment Should Be Made More Than Just a Few Tokens Deep"},{"paperId":"2b3ad2fdd9d2013119232ee49e6d21eb08474b74","externalIds":{"DBLP":"conf/iclr/WangWAZZ25","ArXiv":"2406.04692","DOI":"10.48550/arXiv.2406.04692","CorpusId":270357878},"title":"Mixture-of-Agents Enhances Large Language Model Capabilities"},{"paperId":"32e086dd56041ddb63d9e9e210c29a7fdeabdb6d","externalIds":{"ArXiv":"2406.02061","DBLP":"journals/corr/abs-2406-02061","CorpusId":270226508},"title":"Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models"},{"paperId":"3637afb75e5b83803aff08a3ffdd35b02fa93775","externalIds":{"ArXiv":"2406.01288","DBLP":"journals/corr/abs-2406-01288","DOI":"10.48550/arXiv.2406.01288","CorpusId":270213981},"title":"Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses"},{"paperId":"5c97fb626bfa0ebc924eab30e588e3f4f2447b18","externalIds":{"DBLP":"journals/corr/abs-2405-17784","ArXiv":"2405.17784","DOI":"10.48550/arXiv.2405.17784","CorpusId":270067982},"title":"Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich Differentiable Simulation"},{"paperId":"55a66fc5e5246511c55c2c2d1d7a060709490030","externalIds":{"ArXiv":"2405.18634","DBLP":"journals/corr/abs-2405-18634","DOI":"10.48550/arXiv.2405.18634","CorpusId":270095253},"title":"A Theoretical Understanding of Self-Correction through In-context Alignment"},{"paperId":"1dcae23c009a115c488f83b91007705660222ea4","externalIds":{"DBLP":"journals/corr/abs-2405-17147","ArXiv":"2405.17147","DOI":"10.48550/arXiv.2405.17147","CorpusId":270062725},"title":"Large Language Models (LLMs): Deployment, Tokenomics and Sustainability"},{"paperId":"d81e8d1d3c8acbcf9755ef470098b9c02adf5963","externalIds":{"ArXiv":"2405.06624","DBLP":"journals/corr/abs-2405-06624","DOI":"10.48550/arXiv.2405.06624","CorpusId":269741228},"title":"Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems"},{"paperId":"7f575e1a8e4c465b31f8928ffd13ad48aa961789","externalIds":{"DBLP":"journals/corr/abs-2404-18231","ArXiv":"2404.18231","DOI":"10.48550/arXiv.2404.18231","CorpusId":269448713},"title":"From Persona to Personalization: A Survey on Role-Playing Language Agents"},{"paperId":"0d53dcd8ebe1dd44b43c71bbfbe9076b4ed12dd8","externalIds":{"ArXiv":"2404.16251","CorpusId":269362119},"title":"Prompt Leakage effect and defense strategies for multi-turn LLM interactions"},{"paperId":"cd3359ed7119210bfa0b34ba5796d1314a05e212","externalIds":{"DBLP":"journals/corr/abs-2404-14367","ArXiv":"2404.14367","DOI":"10.48550/arXiv.2404.14367","CorpusId":269293401},"title":"Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data"},{"paperId":"cf56a7b28fb27279b1c94fb920b5722cf50c8852","externalIds":{"DBLP":"journals/corr/abs-2404-16873","ArXiv":"2404.16873","DOI":"10.48550/arXiv.2404.16873","CorpusId":269430799},"title":"AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs"},{"paperId":"388de598bb3609fb793c0bd26c365e98139f00ce","externalIds":{"ArXiv":"2404.10552","DBLP":"journals/corr/abs-2404-10552","DOI":"10.48550/arXiv.2404.10552","CorpusId":269157491},"title":"Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning"},{"paperId":"084d9bf272608e1fb7ecde4c30224c3ffa850774","externalIds":{"DBLP":"conf/chi/GoyalCT24","ArXiv":"2404.04289","DOI":"10.1145/3613905.3650948","CorpusId":269004488},"title":"Designing for Human-Agent Alignment: Understanding what humans want from their agents"},{"paperId":"88d5634a52645f6b05a03536be1f26a2b9bba232","externalIds":{"DBLP":"conf/iclr/AndriushchenkoC25","ArXiv":"2404.02151","DOI":"10.48550/arXiv.2404.02151","CorpusId":268857047},"title":"Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks"},{"paperId":"d0255ce4c897bea6578955de64fc40324f991878","externalIds":{"ArXiv":"2404.01869","DBLP":"journals/corr/abs-2404-01869","DOI":"10.48550/arXiv.2404.01869","CorpusId":268857112},"title":"Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models - A Survey"},{"paperId":"1a0b041de82e18598ed5f7b962f23fa93204bc2b","externalIds":{"ArXiv":"2403.14988","DBLP":"journals/corr/abs-2403-14988","DOI":"10.48550/arXiv.2403.14988","CorpusId":268667150},"title":"Risk and Response in Large Language Models: Evaluating Key Threat Categories"},{"paperId":"fa0a3349205109703b556cdcd6d64dc9eb98f6bf","externalIds":{"DBLP":"journals/tmlr/ZhangZZYBB25","ArXiv":"2403.14508","DOI":"10.48550/arXiv.2403.14508","CorpusId":268554156},"title":"Constrained Reinforcement Learning with Smoothed Log Barrier Function"},{"paperId":"f9d649c05b63ae7e54cb221e99770320224dec52","externalIds":{"DBLP":"journals/corr/abs-2403-09743","ArXiv":"2403.09743","DOI":"10.48550/arXiv.2403.09743","CorpusId":268510243},"title":"The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions"},{"paperId":"b232f468de0b1d4ff1c2dfe5dbb03ec093160c48","externalIds":{"ArXiv":"2403.06634","DBLP":"journals/corr/abs-2403-06634","DOI":"10.48550/arXiv.2403.06634","CorpusId":268357903},"title":"Stealing Part of a Production Language Model"},{"paperId":"6e33594cb0af7def21d805046be3957ab9461cf4","externalIds":{"ArXiv":"2403.01479","DBLP":"journals/corr/abs-2403-01479","ACL":"2024.lrec-main.64","DOI":"10.48550/arXiv.2403.01479","CorpusId":268249001},"title":"Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation"},{"paperId":"5e71d0e85f65a1c0fb2af7bff281209122c58932","externalIds":{"ArXiv":"2402.17193","DBLP":"conf/iclr/0006LCF24","DOI":"10.48550/arXiv.2402.17193","CorpusId":268032247},"title":"When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method"},{"paperId":"26328d7c2796fc1d139719dd5e738c59aaa177a7","externalIds":{"ArXiv":"2402.01521","DBLP":"conf/naacl/ZhangMGWXLW25","DOI":"10.18653/v1/2025.naacl-long.370","CorpusId":267406499},"title":"K-Level Reasoning: Establishing Higher Order Beliefs in Large Language Models for Strategic Reasoning"},{"paperId":"6e2704025046be6dc29b71339994422f9a9cacf1","externalIds":{"DBLP":"journals/corr/abs-2402-01822","ArXiv":"2402.01822","DOI":"10.48550/arXiv.2402.01822","CorpusId":267412893},"title":"Building Guardrails for Large Language Models"},{"paperId":"74a2ef37466667c843b6322691c49b0475030cb0","externalIds":{"DBLP":"journals/csur/DasAW25","ArXiv":"2402.00888","DOI":"10.1145/3712001","CorpusId":267406814},"title":"Security and Privacy Challenges of Large Language Models: A Survey"},{"paperId":"e99e88257c01c4690ee5b4388a3b074da7911671","externalIds":{"ArXiv":"2401.12474","DBLP":"conf/acl/Lu0ZZ24","DOI":"10.18653/v1/2024.acl-long.423","CorpusId":267095369},"title":"Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment"},{"paperId":"600d9287efc4703bdb99ce39b5e8b37da0baa6f6","externalIds":{"ArXiv":"2312.01552","DBLP":"journals/corr/abs-2312-01552","DOI":"10.48550/arXiv.2312.01552","CorpusId":265608902},"title":"The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning"},{"paperId":"9045649163477319dafba4403dc915c3388dceda","externalIds":{"ArXiv":"2311.14876","DBLP":"conf/bigdataconf/SinghAN23","DOI":"10.1109/BigData59044.2023.10386814","CorpusId":265457196},"title":"Exploiting Large Language Models (LLMs) through Deception Techniques and Persuasion Principles"},{"paperId":"c0a822ac56e47b6e4b99d5552d2998647abe8234","externalIds":{"ArXiv":"2311.02462","DBLP":"conf/icml/MorrisSFWDFFL24","CorpusId":265033463},"title":"Position: Levels of AGI for Operationalizing Progress on the Path to AGI"},{"paperId":"386cebdba39d2d5f2862a9ab43a8d807f3863dae","externalIds":{"DBLP":"journals/corr/abs-2310-13639","ArXiv":"2310.13639","DOI":"10.48550/arXiv.2310.13639","CorpusId":264405839},"title":"Contrastive Preference Learning: Learning from Human Feedback without RL"},{"paperId":"f3460dc3ae5cfd41099d576a3bb77411e1fc2e3f","externalIds":{"DBLP":"journals/corr/abs-2310-12036","ArXiv":"2310.12036","DOI":"10.48550/arXiv.2310.12036","CorpusId":264288854},"title":"A General Theoretical Paradigm to Understand Learning from Human Preferences"},{"paperId":"b428e9e0e8ac36b3ae29a7ab9b9554c39cedb283","externalIds":{"DBLP":"conf/emnlp/RebedeaDSPC23","ArXiv":"2310.10501","DOI":"10.48550/arXiv.2310.10501","CorpusId":264146531},"title":"NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails"},{"paperId":"6d4bacb69923e1e94fb4de468b939ce6db32fb51","externalIds":{"DBLP":"conf/iclr/0009CMZYSZ24","ArXiv":"2310.01798","DOI":"10.48550/arXiv.2310.01798","CorpusId":263609132},"title":"Large Language Models Cannot Self-Correct Reasoning Yet"},{"paperId":"749d59f887c8ac83fd4f5178465e8b03e463358c","externalIds":{"DBLP":"journals/corr/abs-2309-15025","ArXiv":"2309.15025","DOI":"10.48550/arXiv.2309.15025","CorpusId":262824801},"title":"Large Language Model Alignment: A Survey"},{"paperId":"6988596f88276920a4e555cbe624e1431bc8a9f7","externalIds":{"DBLP":"conf/iclr/KothaSR24","ArXiv":"2309.10105","DOI":"10.48550/arXiv.2309.10105","CorpusId":262054014},"title":"Understanding Catastrophic Forgetting in Language Models via Implicit Inference"},{"paperId":"a9c75cf664f675a1b4034b0256ec3c5168e293df","externalIds":{"ArXiv":"2309.08532","CorpusId":262012566},"title":"EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers"},{"paperId":"bcfa73aedf1b2d1ee4f168e21298a37ac55a37f7","externalIds":{"DBLP":"journals/coling/GallegosRBTKDYZA24","ArXiv":"2309.00770","DOI":"10.1162/coli_a_00524","CorpusId":261530629},"title":"Bias and Fairness in Large Language Models: A Survey"},{"paperId":"7142e920b6b9355d9cbacc9450818f912eca138e","externalIds":{"ArXiv":"2308.05374","DBLP":"journals/corr/abs-2308-05374","DOI":"10.48550/arXiv.2308.05374","CorpusId":260775522},"title":"Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment"},{"paperId":"a37d5620210276e47cf0c9dd2898c2a82c9d0422","externalIds":{"DBLP":"journals/corr/abs-2308-03958","ArXiv":"2308.03958","DOI":"10.48550/arXiv.2308.03958","CorpusId":260704246},"title":"Simple synthetic data reduces sycophancy in large language models"},{"paperId":"47030369e97cc44d4b2e3cf1be85da0fd134904a","externalIds":{"DBLP":"journals/corr/abs-2307-15043","ArXiv":"2307.15043","CorpusId":260202961},"title":"Universal and Transferable Adversarial Attacks on Aligned Language Models"},{"paperId":"696d96c260cd4ce074ff68040e1e5c783234d7bd","externalIds":{"DBLP":"journals/corr/abs-2307-05543","ArXiv":"2307.05543","DOI":"10.1145/3600211.3604722","CorpusId":259837320},"title":"Typology of Risks of Generative Text-to-Image Models"},{"paperId":"a80d106b4536884af8da68078babc70086b1a607","externalIds":{"DBLP":"journals/corr/abs-2306-05949","ArXiv":"2306.05949","DOI":"10.48550/arXiv.2306.05949","CorpusId":259129374},"title":"Evaluating the Social Impact of Generative AI Systems in Systems and Society"},{"paperId":"db4cf9f6a653d5c15973e836c800ea47743251ae","externalIds":{"DBLP":"journals/corr/abs-2306-05499","ArXiv":"2306.05499","DOI":"10.48550/arXiv.2306.05499","CorpusId":259129807},"title":"Prompt Injection attack against LLM-integrated Applications"},{"paperId":"370e51386abb7b999728e08b74f0a77fbd064834","externalIds":{"ArXiv":"2306.02231","DBLP":"journals/corr/abs-2306-02231","DOI":"10.48550/arXiv.2306.02231","CorpusId":259075917},"title":"Fine-Tuning Language Models with Advantage-Induced Policy Alignment"},{"paperId":"7d97c17a75beb89f938eaac1d3ca60ac2245fb2e","externalIds":{"ArXiv":"2305.18654","DBLP":"journals/corr/abs-2305-18654","CorpusId":258967391},"title":"Faith and Fate: Limits of Transformers on Compositionality"},{"paperId":"0d1c76d45afa012ded7ab741194baf142117c495","externalIds":{"DBLP":"conf/nips/RafailovSMMEF23","ArXiv":"2305.18290","CorpusId":258959321},"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model"},{"paperId":"ebf3a59aacdd9982283d7f41229ee2a93800d6ef","externalIds":{"DBLP":"conf/nips/KangLBKH23","ArXiv":"2305.18395","DOI":"10.48550/arXiv.2305.18395","CorpusId":258967252},"title":"Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks"},{"paperId":"aa23bcf357fc4f890e0a97c27e254d14fbacd460","externalIds":{"ArXiv":"2305.16367","DBLP":"journals/nature/ShanahanMR23","DOI":"10.1038/s41586-023-06647-8","CorpusId":258947657,"PubMed":"37938776"},"title":"Role play with large language models"},{"paperId":"2f2a430ba6c93bcfaf4818316ff8a27b1e034b1a","externalIds":{"DBLP":"journals/corr/abs-2305-15594","ArXiv":"2305.15594","DOI":"10.48550/arXiv.2305.15594","CorpusId":258887717},"title":"Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models"},{"paperId":"fc50a6202e2f675604543c1ae4ef22ec74f61ad5","externalIds":{"ArXiv":"2305.13860","DBLP":"journals/corr/abs-2305-13860","DOI":"10.48550/arXiv.2305.13860","CorpusId":258841501},"title":"Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study"},{"paperId":"4f0c7f4df04f07609bdb67944af2a529d5a4517b","externalIds":{"DBLP":"journals/air/HuangRHJDWBMQZCZWXWFM24","ArXiv":"2305.11391","DOI":"10.1007/s10462-024-10824-0","CorpusId":258823083},"title":"A survey of safety and trustworthiness of large language models through the lens of verification and validation"},{"paperId":"2f3822eb380b5e753a6d579f31dfc3ec4c4a0820","externalIds":{"ArXiv":"2305.10601","DBLP":"journals/corr/abs-2305-10601","DOI":"10.48550/arXiv.2305.10601","CorpusId":258762525},"title":"Tree of Thoughts: Deliberate Problem Solving with Large Language Models"},{"paperId":"3db1219429c3f04e88347d41269bdc83c457fbf9","externalIds":{"ArXiv":"2305.08298","DBLP":"conf/emnlp/WeiHLCHTCLZ0L23","DOI":"10.48550/arXiv.2305.08298","CorpusId":258686712},"title":"Symbol tuning improves in-context learning in language models"},{"paperId":"7b418b7c5c3df1f22fa04a31727c945df8501556","externalIds":{"DBLP":"journals/corr/abs-2305-08005","ArXiv":"2305.08005","DOI":"10.48550/arXiv.2305.08005","CorpusId":258686688},"title":"Beyond the Safeguards: Exploring the Security Risks of ChatGPT"},{"paperId":"4e40eebc0797f3e62930b1cdb5f24e8085f6010b","externalIds":{"ArXiv":"2305.06212","DOI":"10.1109/TASLPRO.2025.3612842","CorpusId":258588141},"title":"Privacy-Preserving Parameter-Efficient Fine-Tuning for Large Language Model Services"},{"paperId":"aad167be3c902388ea625da4117fcae4325b8b7d","externalIds":{"ArXiv":"2305.02301","DBLP":"journals/corr/abs-2305-02301","DOI":"10.48550/arXiv.2305.02301","CorpusId":258461606},"title":"Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes"},{"paperId":"66cca7a055ee9278d0439654f474cbfa4135aff0","externalIds":{"ArXiv":"2305.01579","DBLP":"conf/naacl/HongKKMW24","DOI":"10.18653/v1/2024.findings-naacl.159","CorpusId":258437010},"title":"Why So Gullible? Enhancing the Robustness of Retrieval-Augmented Models against Counterfactual Noise"},{"paperId":"176e8c49c32f4c219857a1853998770927a598c6","externalIds":{"ArXiv":"2304.13994","DBLP":"journals/corr/abs-2304-13994","DOI":"10.48550/arXiv.2304.13994","CorpusId":258352262},"title":"SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish"},{"paperId":"131c6f328c11706de2c43cd16e0b7c5d5e610b6a","externalIds":{"DBLP":"journals/corr/abs-2304-13712","ArXiv":"2304.13712","DOI":"10.1145/3649506","CorpusId":258331833},"title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"},{"paperId":"025ca4c125d6ecabc816a56f160e5c992abc76d9","externalIds":{"DBLP":"journals/corr/abs-2304-05197","ArXiv":"2304.05197","DOI":"10.48550/arXiv.2304.05197","CorpusId":258060250},"title":"Multi-step Jailbreaking Privacy Attacks on ChatGPT"},{"paperId":"8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c","externalIds":{"ArXiv":"2303.12712","DBLP":"journals/corr/abs-2303-12712","CorpusId":257663729},"title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4"},{"paperId":"39444c55f07839ac6a0d1839472a982f8fb447bb","externalIds":{"PubMedCentral":"9995718","DOI":"10.1007/s00259-023-06172-w","CorpusId":257425466,"PubMed":"36892666"},"title":"Large language models (LLM) and ChatGPT: what will the impact on nuclear medicine be?"},{"paperId":"8b32aa33601514976d88fabcb060a5cd38d34006","externalIds":{"ArXiv":"2303.02861","DBLP":"journals/corr/abs-2303-02861","DOI":"10.48550/arXiv.2303.02861","CorpusId":257365136},"title":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"705e49afd92130f2bc1e0d4d0b1f6cb14e88803f","externalIds":{"DBLP":"conf/ccs/AbdelnabiGMEHF23","ArXiv":"2302.12173","DOI":"10.1145/3605764.3623985","CorpusId":258546941},"title":"Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection"},{"paperId":"25d4ffc9fb1b320137ea51612ad4fdb1fdfcee19","externalIds":{"DBLP":"journals/corr/abs-2302-10329","ArXiv":"2302.10329","DOI":"10.1145/3593013.3594033","CorpusId":257050680},"title":"Harms from Increasingly Agentic Algorithmic Systems"},{"paperId":"1d75f8de31bf47ec46fa5586056420ec8bc97e86","externalIds":{"ArXiv":"2302.00871","DBLP":"journals/corr/abs-2302-00871","DOI":"10.48550/arXiv.2302.00871","CorpusId":256503647},"title":"Using In-Context Learning to Improve Dialogue Safety"},{"paperId":"30c0cdc414f68211d5d0514df027cec22e005174","externalIds":{"DBLP":"conf/emnlp/Dong0DZMLXX0C0S24","ArXiv":"2301.00234","ACL":"2024.emnlp-main.64","DOI":"10.18653/v1/2024.emnlp-main.64","CorpusId":255372865},"title":"A Survey on In-context Learning"},{"paperId":"db4ab91d5675c37795e719e997a2827d3d83cd45","externalIds":{"ArXiv":"2212.10403","DBLP":"conf/acl/0009C23","DOI":"10.48550/arXiv.2212.10403","CorpusId":254877753},"title":"Towards Reasoning in Large Language Models: A Survey"},{"paperId":"e65b346d442e9962a4276dc1c1af2956d9d5f1eb","externalIds":{"DBLP":"journals/corr/abs-2212-10560","ArXiv":"2212.10560","ACL":"2023.acl-long.754","DOI":"10.48550/arXiv.2212.10560","CorpusId":254877310},"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions"},{"paperId":"a9e3e5dd7b30890553b7ae1c41f932e99192bb44","externalIds":{"ACL":"2023.acl-long.830","DBLP":"conf/acl/HoSY23","ArXiv":"2212.10071","DOI":"10.48550/arXiv.2212.10071","CorpusId":254877399},"title":"Large Language Models Are Reasoning Teachers"},{"paperId":"cef330bacf014d60daabbd489647b2006af130ca","externalIds":{"DBLP":"journals/corr/abs-2212-09251","ArXiv":"2212.09251","DOI":"10.48550/arXiv.2212.09251","CorpusId":254854519},"title":"Discovering Language Model Behaviors with Model-Written Evaluations"},{"paperId":"3cbffab9d7981da6662d474aaa056dcbd3c1701e","externalIds":{"ArXiv":"2212.09196","DBLP":"journals/corr/abs-2212-09196","DOI":"10.1038/s41562-023-01659-w","CorpusId":254854575,"PubMed":"37524930"},"title":"Emergent analogical reasoning in large language models"},{"paperId":"b58ef62a34bdbcd357824c9e58d89cbbcc0e2375","externalIds":{"DBLP":"conf/aaai/ZhangZ000T23","ArXiv":"2212.05727","DOI":"10.48550/arXiv.2212.05727","CorpusId":254564741},"title":"Evaluating Model-free Reinforcement Learning toward Safety-critical Tasks"},{"paperId":"18d750263f1dfe43374e8791cefa580a511c2098","externalIds":{"ArXiv":"2212.03363","DBLP":"conf/corl/HejnaS22","DOI":"10.48550/arXiv.2212.03363","CorpusId":253546930},"title":"Few-Shot Preference Learning for Human-in-the-Loop RL"},{"paperId":"8fd462f6248d5e3f1b6602697c09489086b5655f","externalIds":{"DBLP":"conf/acl/ShridharSS23","ArXiv":"2212.00193","DOI":"10.18653/v1/2023.findings-acl.441","CorpusId":258762841},"title":"Distilling Reasoning Capabilities into Smaller Language Models"},{"paperId":"75f4ebf6014a0997dcfed32f9cdaf483e1d9456a","externalIds":{"DOI":"10.1016/j.acra.2022.11.030","CorpusId":254718031,"PubMed":"36526532"},"title":"Transparency in Artificial Intelligence Research: a Systematic Review of Availability Items Related to Open Science in Radiology and Nuclear Medicine."},{"paperId":"4610ffb1b016acaa82a2065ffd1a3adbae1ce722","externalIds":{"DBLP":"journals/corr/abs-2211-01910","ArXiv":"2211.01910","DOI":"10.48550/arXiv.2211.01910","CorpusId":253265328},"title":"Large Language Models Are Human-Level Prompt Engineers"},{"paperId":"1bb6d5761903c7ac978188ae36e2648905e95dc5","externalIds":{"ArXiv":"2210.11399","DBLP":"conf/emnlp/TayWC0SSGZRCZMP23","DOI":"10.48550/arXiv.2210.11399","CorpusId":253018395},"title":"Transcending Scaling Laws with 0.1% Extra Compute"},{"paperId":"d381cb7901cb899ba4b1a5bc114bb5e694e11c12","externalIds":{"DBLP":"conf/ijcnlp/HanSCBF22","ArXiv":"2210.08758","ACL":"2022.aacl-main.6","DOI":"10.48550/arXiv.2210.08758","CorpusId":252918537},"title":"Systematic Evaluation of Predictive Fairness"},{"paperId":"bd6c0af91401c208ef478376c493408b69f51b8d","externalIds":{"ArXiv":"2210.05791","DBLP":"conf/aies/ShelbyRHMRNYGSG23","DOI":"10.1145/3600211.3604673","CorpusId":256697294},"title":"Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction"},{"paperId":"e070ff286709db28312e08b52b05539debe88146","externalIds":{"DBLP":"conf/emnlp/PressZMSSL23","ArXiv":"2210.03350","DOI":"10.48550/arXiv.2210.03350","CorpusId":252762102},"title":"Measuring and Narrowing the Compositionality Gap in Language Models"},{"paperId":"07955e96cbd778d0ae2a68f09d073b866dd84c2a","externalIds":{"ArXiv":"2210.02406","DBLP":"conf/iclr/KhotTFF0CS23","DOI":"10.48550/arXiv.2210.02406","CorpusId":252715485},"title":"Decomposed Prompting: A Modular Approach for Solving Complex Tasks"},{"paperId":"74eae12620bd1c1393e268bddcb6f129a5025166","externalIds":{"DBLP":"journals/corr/abs-2209-14375","ArXiv":"2209.14375","DOI":"10.48550/arXiv.2209.14375","CorpusId":252596089},"title":"Improving alignment of dialogue agents via targeted human judgements"},{"paperId":"004357dd9bbf3012c8fe0ccada4da401bf85dfff","externalIds":{"ArXiv":"2209.13085","DBLP":"journals/corr/abs-2209-13085","DOI":"10.48550/arXiv.2209.13085","CorpusId":252545256},"title":"Defining and Characterizing Reward Hacking"},{"paperId":"eef33138ee3fbef970c74697b46acf60462d690c","externalIds":{"ArXiv":"2209.00626","DBLP":"conf/iclr/NgoCM24","DOI":"10.48550/arXiv.2209.00626","CorpusId":251979524},"title":"The alignment problem from a deep learning perspective"},{"paperId":"f2c17758e74707d379b87372528221656d14b697","externalIds":{"DBLP":"conf/fat/WeidingerURGHMG22","DOI":"10.1145/3531146.3533088","CorpusId":249872629},"title":"Taxonomy of Risks posed by Language Models"},{"paperId":"1c07e314985161ec42ba895eb4869ffc5d360736","externalIds":{"DBLP":"journals/corr/abs-2206-13353","ArXiv":"2206.13353","DOI":"10.48550/arXiv.2206.13353","CorpusId":249146809},"title":"Is Power-Seeking AI an Existential Risk?"},{"paperId":"d304d0bdfa81fd10b187aa0e4f41d410eb19d6e3","externalIds":{"ACL":"2022.emnlp-main.410","ArXiv":"2205.12393","DBLP":"conf/emnlp/ScialomCM22","DOI":"10.18653/v1/2022.emnlp-main.410","CorpusId":252815378},"title":"Fine-tuned Language Models are Continual Learners"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"81986b8a3d3fe6c5be06fc4527953fb514ad12e8","externalIds":{"DBLP":"conf/naacl/ChenDPMISK22","ACL":"2022.naacl-main.260","ArXiv":"2205.01703","DOI":"10.48550/arXiv.2205.01703","CorpusId":248512524},"title":"Improving In-Context Few-Shot Learning via Self-Supervised Training"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"08aaaf7ae3d61875e7bcf5c1bb0df4f17066e300","externalIds":{"DBLP":"conf/sp/LiuSTAM022","DOI":"10.1109/sp46214.2022.9833579","CorpusId":248067917},"title":"Piccolo: Exposing Complex Backdoors in NLP Transformer Models"},{"paperId":"0286b2736a114198b25fb5553c671c33aed5d477","externalIds":{"ArXiv":"2204.05862","DBLP":"journals/corr/abs-2204-05862","DOI":"10.48550/arXiv.2204.05862","CorpusId":248118878},"title":"Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"8342b592fe238f3d230e4959b06fd10153c45db1","externalIds":{"DBLP":"journals/corr/abs-2203-15556","ArXiv":"2203.15556","CorpusId":247778764},"title":"Training Compute-Optimal Large Language Models"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"5d49c7401c5f2337c4cc88d243ae39ed659afe64","externalIds":{"DBLP":"journals/corr/abs-2202-03286","ACL":"2022.emnlp-main.225","ArXiv":"2202.03286","DOI":"10.18653/v1/2022.emnlp-main.225","CorpusId":246634238},"title":"Red Teaming Language Models with Language Models"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"10b9ca173c665e3f2c322c2d5ce9b9d433fe4629","externalIds":{"ArXiv":"2201.03544","DBLP":"conf/iclr/PanBS22","CorpusId":245837268},"title":"The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models"},{"paperId":"39c77e29a232a9fb62b3a3c89c50f487d73e27ce","externalIds":{"DBLP":"conf/nips/ZhangILJTC23","ArXiv":"2112.12938","CorpusId":245502053},"title":"Counterfactual Memorization in Neural Language Models"},{"paperId":"f9838a3be5c94bb2674a0e224de349b50e18f3c4","externalIds":{"DBLP":"journals/corr/abs-2112-08633","ACL":"2022.naacl-main.191","ArXiv":"2112.08633","DOI":"10.18653/v1/2022.naacl-main.191","CorpusId":245218561},"title":"Learning To Retrieve Prompts for In-Context Learning"},{"paperId":"80d0116d77beeded0c23cf48946d9d10d4faee14","externalIds":{"ArXiv":"2112.06905","DBLP":"journals/corr/abs-2112-06905","CorpusId":245124124},"title":"GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"},{"paperId":"fd1b829261ba04bb92e0ab60c4f6e7cea0d99fbf","externalIds":{"ArXiv":"2112.04359","DBLP":"journals/corr/abs-2112-04359","CorpusId":244954639},"title":"Ethical and social risks of harm from Language Models"},{"paperId":"2b76643e28f288d03f0dd5cbb01acf6c9c1c6969","externalIds":{"DBLP":"conf/aaai/YeMSWJS22","ArXiv":"2112.03695","DOI":"10.1609/aaai.v36i3.20219","CorpusId":244920778},"title":"Safe Distillation Box"},{"paperId":"3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e","externalIds":{"ArXiv":"2112.00861","DBLP":"journals/corr/abs-2112-00861","CorpusId":244799619},"title":"A General Language Assistant as a Laboratory for Alignment"},{"paperId":"47df3fd32d00220c85c2c51a571254fd99b2ecc7","externalIds":{"ArXiv":"2110.15943","ACL":"2022.naacl-main.201","DBLP":"journals/corr/abs-2110-15943","DOI":"10.18653/v1/2022.naacl-main.201","CorpusId":240288835},"title":"MetaICL: Learning to Learn In Context"},{"paperId":"d6045d2ccc9c09ca1671348de86d07da6bc28eea","externalIds":{"ArXiv":"2110.14168","DBLP":"journals/corr/abs-2110-14168","CorpusId":239998651},"title":"Training Verifiers to Solve Math Word Problems"},{"paperId":"17dd3555fd1ccf1141cf984347fa1b3fd6b009ca","externalIds":{"ArXiv":"2110.08207","DBLP":"journals/corr/abs-2110-08207","CorpusId":239009562},"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization"},{"paperId":"d3640eb3b542eaf36fee2261f037a6bf0d8eac9c","externalIds":{"DBLP":"conf/chi/WuTC22","ArXiv":"2110.01691","DOI":"10.1145/3491102.3517582","CorpusId":238353829},"title":"AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts"},{"paperId":"846f3770219dbdfe260c13070458deec909be914","externalIds":{"DOI":"10.1001/jamadermatol.2021.3129","CorpusId":237595110,"PubMed":"34550305"},"title":"Lack of Transparency and Potential Bias in Artificial Intelligence Data Sets and Algorithms: A Scoping Review."},{"paperId":"d64e57b9780f30f5b49bf620fdfb8584651b7f85","externalIds":{"DBLP":"journals/corr/abs-2109-07445","ArXiv":"2109.07445","DOI":"10.18653/v1/2021.findings-emnlp.210","CorpusId":237513578},"title":"Challenges in Detoxifying Language Models"},{"paperId":"77d956cdab4508d569ae5741549b78e715fd0749","externalIds":{"DBLP":"journals/corr/abs-2109-07958","ACL":"2022.acl-long.229","ArXiv":"2109.07958","DOI":"10.18653/v1/2022.acl-long.229","CorpusId":237532606},"title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods"},{"paperId":"10aa2be24951e6de76b630482a645d79354c4cde","externalIds":{"DBLP":"journals/corr/abs-2106-14574","ArXiv":"2106.14574","DOI":"10.1162/tacl_a_00425","CorpusId":235658325},"title":"Quantifying Social Biases in NLP: A Generalization and Empirical Comparison of Extrinsic Fairness Metrics"},{"paperId":"5f0f4a3fa3cff7ffcedabbc9ed0dad2dd71f7028","externalIds":{"ArXiv":"2106.05945","DBLP":"conf/nips/StantonIKAW21","CorpusId":235390933},"title":"Does Knowledge Distillation Really Work?"},{"paperId":"7571ed4cf1bbdcf891b576a0da12c910b1f0c72f","externalIds":{"MAG":"3170572542","DBLP":"conf/naacl/WallaceZFS21","ACL":"2021.naacl-main.13","DOI":"10.18653/V1/2021.NAACL-MAIN.13","CorpusId":233230124},"title":"Concealed Data Poisoning Attacks on NLP Models"},{"paperId":"06f5d950699f4e5484786e59177201463cbba254","externalIds":{"ArXiv":"2105.14111","DBLP":"conf/icml/LangoscoKSPK22","CorpusId":249954130},"title":"Goal Misgeneralization in Deep Reinforcement Learning"},{"paperId":"66c10bf1f11bc1b2d92204d8f8391d087f6de1c4","externalIds":{"DBLP":"journals/ijon/SuALPBL24","ArXiv":"2104.09864","DOI":"10.1016/j.neucom.2023.127063","CorpusId":233307138},"title":"RoFormer: Enhanced Transformer with Rotary Position Embedding"},{"paperId":"4a78f23be51f314240d17fa0a340785ee88bf032","externalIds":{"DBLP":"conf/www/YuF021","DOI":"10.1145/3442381.3449830","CorpusId":235324815},"title":"Cross-lingual Language Model Pretraining for Retrieval"},{"paperId":"0adec918885dff698acf359988ed79a543157f80","externalIds":{"DBLP":"journals/corr/abs-2104-08786","ArXiv":"2104.08786","ACL":"2022.acl-long.556","DOI":"10.18653/v1/2022.acl-long.556","CorpusId":233296494},"title":"Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"},{"paperId":"cbdb45fc16b0885905b91d84281c310e6cb49e9c","externalIds":{"ArXiv":"2104.08773","ACL":"2022.acl-long.244","DBLP":"conf/acl/MishraKBH22","DOI":"10.18653/v1/2022.acl-long.244","CorpusId":237421373},"title":"Cross-Task Generalization via Natural Language Crowdsourcing Instructions"},{"paperId":"ffdbd7f0b03b85747b001b4734d5ee31b5229aa4","externalIds":{"DBLP":"journals/corr/abs-2104-08691","ArXiv":"2104.08691","ACL":"2021.emnlp-main.243","DOI":"10.18653/v1/2021.emnlp-main.243","CorpusId":233296808},"title":"The Power of Scale for Parameter-Efficient Prompt Tuning"},{"paperId":"49f905eb03958c7cfae52ac759ea8978b8b2a6ea","externalIds":{"DBLP":"journals/corr/abs-2103-14659","ArXiv":"2103.14659","CorpusId":232404883},"title":"Alignment of Language Agents"},{"paperId":"50796b0f3edf9cb5ff1e447c298b33755378aa4f","externalIds":{"DBLP":"conf/acl/DuQLDQY022","ACL":"2022.acl-long.26","ArXiv":"2103.10360","DOI":"10.18653/v1/2022.acl-long.26","CorpusId":247519241},"title":"GLM: General Language Model Pretraining with Autoregressive Blank Infilling"},{"paperId":"ca2f1088d3e581b2c6c75cf0ebc96506d620f64d","externalIds":{"DBLP":"conf/fat/BenderGMS21","DOI":"10.1145/3442188.3445922","CorpusId":262580630},"title":"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ"},{"paperId":"c0e6cd2ec3bc9eb46c7d45bb708854da3327339e","externalIds":{"MAG":"3134678353","DOI":"10.20944/PREPRINTS202103.0049.V1","CorpusId":233832881},"title":"A Survey on Bias in Deep NLP"},{"paperId":"ce9ca56036307217ea565644d3d3bd74b879e045","externalIds":{"DBLP":"journals/tacl/SchickUS21","ArXiv":"2103.00453","DOI":"10.1162/tacl_a_00434","CorpusId":232075876},"title":"Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"},{"paperId":"f577654d9dd29d88c6db9ee39a4fd831573b8770","externalIds":{"DBLP":"journals/corr/abs-2102-02503","ArXiv":"2102.02503","CorpusId":231802467},"title":"Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models"},{"paperId":"59641c10ed7431a3cf841f308367dc2dc0281b74","externalIds":{"DBLP":"conf/acl-deelio/LiuSZDCC22","ArXiv":"2101.06804","ACL":"2022.deelio-1.10","DOI":"10.18653/v1/2022.deelio-1.10","CorpusId":231632658},"title":"What Makes Good In-Context Examples for GPT-3?"},{"paperId":"df7d26339adf4eb0c07160947b9d2973c24911ba","externalIds":{"DBLP":"journals/corr/abs-2012-07805","MAG":"3112689365","ArXiv":"2012.07805","CorpusId":229156229},"title":"Extracting Training Data from Large Language Models"},{"paperId":"b103e87c7727134927d3ffb06934a95c10c02fc0","externalIds":{"MAG":"3095319910","DBLP":"journals/mima/FloridiC20","DOI":"10.1007/s11023-020-09548-1","CorpusId":228954221},"title":"GPT-3: Its Nature, Scope, Limits, and Consequences"},{"paperId":"645bd6eadc247989abc5e0b0aa0be79ec8b11ea6","externalIds":{"MAG":"3089430725","DBLP":"journals/corr/abs-2010-00133","ArXiv":"2010.00133","ACL":"2020.emnlp-main.154","DOI":"10.18653/v1/2020.emnlp-main.154","CorpusId":222090785},"title":"CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models"},{"paperId":"399e7d8129c60818ee208f236c8dda17e876d21f","externalIds":{"MAG":"3088599783","ACL":"2020.findings-emnlp.301","DBLP":"journals/corr/abs-2009-11462","ArXiv":"2009.11462","DOI":"10.18653/v1/2020.findings-emnlp.301","CorpusId":221878771},"title":"RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"},{"paperId":"9ffcb3624f2637b5d0fe28c61ec8472293cfebc7","externalIds":{"MAG":"3032046549","DOI":"10.1017/XPS.2020.37","CorpusId":219800227},"title":"All the News Thatâ€™s Fit to Fabricate: AI-Generated Text as a Tool of Media Misinformation"},{"paperId":"053b1d7b97eb2c91fc3921d589c160b0923c70b1","externalIds":{"MAG":"3082115681","DBLP":"journals/corr/abs-2009-01325","ArXiv":"2009.01325","CorpusId":221665105},"title":"Learning to summarize from human feedback"},{"paperId":"65906e6027246ae9e4ecd18d6e019a24505c842e","externalIds":{"ArXiv":"2008.02275","MAG":"3047185145","DBLP":"journals/corr/abs-2008-02275","CorpusId":220968818},"title":"Aligning AI With Shared Human Values"},{"paperId":"044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3","externalIds":{"ArXiv":"2007.14062","DBLP":"journals/corr/abs-2007-14062","MAG":"3045733172","CorpusId":220831004},"title":"Big Bird: Transformers for Longer Sequences"},{"paperId":"02eaaf87f9cae34cca398fed146079e6eeb1f868","externalIds":{"MAG":"3034723486","ACL":"2020.acl-main.463","DBLP":"conf/acl/BenderK20","DOI":"10.18653/v1/2020.acl-main.463","CorpusId":211029226},"title":"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data"},{"paperId":"0272b14dd471fe7b81df703af1b71d7600b77215","externalIds":{"MAG":"3034786558","DBLP":"journals/corr/abs-2006-09359","ArXiv":"2006.09359","CorpusId":219708452},"title":"Accelerating Online Reinforcement Learning with Offline Datasets"},{"paperId":"c0b79e6a5fd88ef13aa4780df5aae0aaa6b2be87","externalIds":{"MAG":"3033529678","DBLP":"journals/corr/abs-2006-04768","ArXiv":"2006.04768","CorpusId":219530577},"title":"Linformer: Self-Attention with Linear Complexity"},{"paperId":"14b65a86c82e38fce0eb3506e0d4084ad5cdb583","externalIds":{"MAG":"3033187248","DBLP":"conf/iclr/HeLGC21","ArXiv":"2006.03654","CorpusId":219531210},"title":"DeBERTa: Decoding-enhanced BERT with Disentangled Attention"},{"paperId":"8c72389d79157324271b9bd13d61e7dcad22e382","externalIds":{"MAG":"3032574806","DBLP":"journals/corr/abs-2006-00998","ACL":"2020.acl-main.396","ArXiv":"2006.00998","DOI":"10.18653/v1/2020.acl-main.396","CorpusId":219176615},"title":"Toxicity Detection: Does Context Really Matter?"},{"paperId":"659bf9ce7175e1ec266ff54359e2bd76e0b7ff31","externalIds":{"DBLP":"conf/nips/LewisPPPKGKLYR020","MAG":"3027879771","ArXiv":"2005.11401","CorpusId":218869575},"title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"},{"paperId":"b3c73de96640ee858f83c3f0eda2a3d15d59b847","externalIds":{"DBLP":"conf/sp/PanZJY20","MAG":"3046764764","DOI":"10.1109/SP40000.2020.00095","CorpusId":220938739},"title":"Privacy Risks of General-Purpose Language Models"},{"paperId":"d27669c82faf78ea08cceaa0a171b540cccc304d","externalIds":{"ACL":"2020.emnlp-main.19","DBLP":"conf/emnlp/AinslieOACFPRSW20","MAG":"3105238007","DOI":"10.18653/v1/2020.emnlp-main.19","CorpusId":221845203},"title":"ETC: Encoding Long and Structured Inputs in Transformers"},{"paperId":"4ae52766028e69186052ea8f33a137fbbbdb986a","externalIds":{"MAG":"3035252911","ArXiv":"2004.04696","DBLP":"conf/acl/SellamDP20","ACL":"2020.acl-main.704","DOI":"10.18653/v1/2020.acl-main.704","CorpusId":215548699},"title":"BLEURT: Learning Robust Metrics for Text Generation"},{"paperId":"0e141942fa265142f41a2a26eb17b6005d3af29e","externalIds":{"MAG":"3017311573","DBLP":"journals/corr/abs-2004-09095","ACL":"2020.acl-main.560","ArXiv":"2004.09095","DOI":"10.18653/v1/2020.acl-main.560","CorpusId":215828350},"title":"The State and Fate of Linguistic Diversity and Inclusion in the NLP World"},{"paperId":"0e0eaa200bfe4cdaf15a18e9faccf4dd1d1c0f4c","externalIds":{"DBLP":"journals/corr/abs-2004-00053","ArXiv":"2004.00053","MAG":"3096738375","DOI":"10.1145/3372297.3417270","CorpusId":214743021},"title":"Information Leakage in Embedding Models"},{"paperId":"e6c561d02500b2596a230b341a8eb8b921ca5bf2","externalIds":{"MAG":"3001279689","ArXiv":"2001.08361","DBLP":"journals/corr/abs-2001-08361","CorpusId":210861095},"title":"Scaling Laws for Neural Language Models"},{"paperId":"7aa70e2c12c8ba2dcc828893adb8bb56e3766726","externalIds":{"ArXiv":"2001.09768","DBLP":"journals/corr/abs-2001-09768","MAG":"3002093512","DOI":"10.1007/s11023-020-09539-2","CorpusId":210920551},"title":"Artificial Intelligence, Values, and Alignment"},{"paperId":"782e7fba4dfa8e2095a71cfcf85995543f37ac75","externalIds":{"MAG":"3027379683","ArXiv":"1912.07942","DBLP":"conf/ccs/BeguelinWTRPOKB20","DOI":"10.1145/3372297.3417880","CorpusId":219450111},"title":"Analyzing Information Leakage of Updates to Natural Language Models"},{"paperId":"7c85ee8ddfc85943a15fe510e64e8d6333c38bc1","externalIds":{"MAG":"2996440722","DBLP":"journals/corr/abs-1912-06872","ArXiv":"1912.06872","CorpusId":209376875},"title":"Towards Robust Toxic Content Classification"},{"paperId":"68c1bf884f0fc0e86641466a1f1fa67e79f16a17","externalIds":{"ArXiv":"1911.03343","DBLP":"conf/acl/KassnerS20","MAG":"3034995113","ACL":"2020.acl-main.698","DOI":"10.18653/v1/2020.acl-main.698","CorpusId":218628691},"title":"Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly"},{"paperId":"2cf3bd0cc1382f35384e259d99e4f9744eeaed28","externalIds":{"MAG":"3106298483","ArXiv":"1911.02972","ACL":"2020.findings-emnlp.232","DBLP":"journals/corr/abs-1911-02972","DOI":"10.18653/v1/2020.findings-emnlp.232","CorpusId":207847640},"title":"Blockwise Self-Attention for Long Document Understanding"},{"paperId":"c0dabdc9036909e10c05628b395784078c0c8f6b","externalIds":{"MAG":"2988072049","DBLP":"conf/corl/GhasemipourZG19","ArXiv":"1911.02256","CorpusId":207880680},"title":"A Divergence Minimization Perspective on Imitation Learning Methods"},{"paperId":"c0ba20d689e3d09f35ff038358e1a1b4a10a82f9","externalIds":{"MAG":"2997607995","DBLP":"conf/emnlp/ChangPO19","CorpusId":209325068},"title":"Bias and Fairness in Natural Language Processing"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"a54b56af24bb4873ed0163b77df63b92bd018ddc","externalIds":{"DBLP":"journals/corr/abs-1910-01108","ArXiv":"1910.01108","MAG":"2978017171","CorpusId":203626972},"title":"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"},{"paperId":"ad14227e4f51276892ffc37aa43fd8750bb5eba8","externalIds":{"MAG":"2978455699","DBLP":"journals/corr/abs-1910-00177","ArXiv":"1910.00177","CorpusId":203610423},"title":"Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning"},{"paperId":"7a064df1aeada7e69e5173f7d4c8606f4470365b","externalIds":{"MAG":"2996428491","DBLP":"journals/corr/abs-1909-11942","ArXiv":"1909.11942","CorpusId":202888986},"title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"},{"paperId":"7a15950dc71079285a4eaf195de5aadd87c41b40","externalIds":{"MAG":"2973379954","DBLP":"journals/corr/abs-1909-08593","ArXiv":"1909.08593","CorpusId":202660943},"title":"Fine-Tuning Language Models from Human Preferences"},{"paperId":"c7462e0ee928f095a7fc40b91f1e7557d283ae8e","externalIds":{"DBLP":"journals/corr/abs-1908-09203","MAG":"2969958763","ArXiv":"1908.09203","CorpusId":201666234},"title":"Release Strategies and the Social Impacts of Language Models"},{"paperId":"0090023afc66cd2741568599057f4e82b566137c","externalIds":{"ArXiv":"1908.09635","MAG":"2969896603","DBLP":"journals/csur/MehrabiMSLG21","DOI":"10.1145/3457607","CorpusId":201666566},"title":"A Survey on Bias and Fairness in Machine Learning"},{"paperId":"3caf34532597683c980134579b156cd0d7db2f40","externalIds":{"ArXiv":"1908.07125","DBLP":"conf/emnlp/WallaceFKGS19","MAG":"2970290563","ACL":"D19-1221","DOI":"10.18653/v1/D19-1221","CorpusId":201698258},"title":"Universal Adversarial Triggers for Attacking and Analyzing NLP"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"ad7129af0644dbcafa9aa2f111cb76526ea444a1","externalIds":{"MAG":"2971008823","DBLP":"conf/nips/ZellersHRBFRC19","ArXiv":"1905.12616","CorpusId":168169824},"title":"Defending Against Neural Fake News"},{"paperId":"295065d942abca0711300b2b4c39829551060578","externalIds":{"MAG":"2936695845","ArXiv":"1904.09675","DBLP":"journals/corr/abs-1904-09675","CorpusId":127986044},"title":"BERTScore: Evaluating Text Generation with BERT"},{"paperId":"29ddc1f43f28af7c846515e32cc167bc66886d0c","externalIds":{"DBLP":"journals/corr/abs-1902-00751","ArXiv":"1902.00751","MAG":"2964303773","CorpusId":59599816},"title":"Parameter-Efficient Transfer Learning for NLP"},{"paperId":"13ff28f98474858d84c339e5301cb3bf468ac68b","externalIds":{"MAG":"2949952232","DBLP":"conf/naacl/ZampieriMNRFK19","ArXiv":"1902.09666","ACL":"N19-1144","DOI":"10.18653/v1/N19-1144","CorpusId":67856299},"title":"Predicting the Type and Target of Offensive Posts in Social Media"},{"paperId":"c4744a7c2bb298e4a52289a1e085c71cc3d37bc6","externalIds":{"ArXiv":"1901.02860","DBLP":"conf/acl/DaiYYCLS19","MAG":"2964110616","ACL":"P19-1285","DOI":"10.18653/v1/P19-1285","CorpusId":57759363},"title":"Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"},{"paperId":"01e96a94b155be1bfde39aae92ab340b8cb8a0ba","externalIds":{"DBLP":"conf/wmt/ShimanakaKK18","ACL":"W18-6456","MAG":"2903376039","DOI":"10.18653/v1/W18-6456","CorpusId":53246676},"title":"RUSE: Regressor Using Sentence Embeddings for Automatic Machine Translation Evaluation"},{"paperId":"42a3e7c85e46b6e6a135e3a1331fd86a2ba6394c","externalIds":{"MAG":"2886572631","PubMedCentral":"6231817","DOI":"10.2196/11510","CorpusId":52154422,"PubMed":"30181110"},"title":"Patient and Consumer Safety Risks When Using Conversational Assistants for Medical Information: An Observational Study of Siri, Alexa, and Google Assistant"},{"paperId":"88a4b0ec1392f2a7d974ecce41b04aa46d47b4a9","externalIds":{"ACL":"W18-5041","ArXiv":"1805.11762","DBLP":"conf/sigdial/LiuL18","MAG":"2951222010","DOI":"10.18653/v1/W18-5041","CorpusId":44117930},"title":"Adversarial Learning of Task-Oriented Neural Dialog Models"},{"paperId":"c8efcc854d97dfc2a42b83316a2109f9d166e43f","externalIds":{"MAG":"2963925437","DBLP":"journals/corr/abs-1803-02155","ACL":"N18-2074","ArXiv":"1803.02155","DOI":"10.18653/v1/N18-2074","CorpusId":3725815},"title":"Self-Attention with Relative Position Representations"},{"paperId":"1e077413b25c4d34945cc2707e17e46ed4fe784a","externalIds":{"ACL":"P18-1031","MAG":"2952772027","DBLP":"conf/acl/RuderH18","DOI":"10.18653/v1/P18-1031","CorpusId":40100965},"title":"Universal Language Model Fine-tuning for Text Classification"},{"paperId":"f492e48796bcdd9a37763a563f2230a9654603cc","externalIds":{"DBLP":"journals/corr/abs-1712-05181","ArXiv":"1712.05181","MAG":"2772604077","CorpusId":19971625},"title":"Rasa: Open Source Language Understanding and Dialogue Management"},{"paperId":"dce6f9d4017b1785979e7520fd0834ef8cf02f4b","externalIds":{"MAG":"2736601468","DBLP":"journals/corr/SchulmanWDRK17","ArXiv":"1707.06347","CorpusId":28695052},"title":"Proximal Policy Optimization Algorithms"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"7a4193d0b042643a8bb9ec262ed7f9d509bdb12e","externalIds":{"MAG":"2952192457","ArXiv":"1705.10528","DBLP":"journals/corr/AchiamHTA17","CorpusId":10647707},"title":"Constrained Policy Optimization"},{"paperId":"2e55ba6c97ce5eb55abd959909403fe8da7e9fe9","externalIds":{"DBLP":"journals/corr/KirkpatrickPRVD16","MAG":"2560647685","ArXiv":"1612.00796","DOI":"10.1073/pnas.1611835114","CorpusId":4704285,"PubMed":"28292907"},"title":"Overcoming catastrophic forgetting in neural networks"},{"paperId":"c6850869aa5e78a107c378d2e8bfa39633158c0c","externalIds":{"ArXiv":"1609.08144","MAG":"2525778437","DBLP":"journals/corr/WuSCLNMKCGMKSJL16","CorpusId":3603249},"title":"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"},{"paperId":"e86f71ca2948d17b003a5f068db1ecb2b77827f7","externalIds":{"DBLP":"journals/corr/AmodeiOSCSM16","ArXiv":"1606.06565","MAG":"2462906003","CorpusId":10242377},"title":"Concrete Problems in AI Safety"},{"paperId":"0c908739fbff75f03469d13d4a1a07de3414ee19","externalIds":{"ArXiv":"1503.02531","MAG":"1821462560","DBLP":"journals/corr/HintonVD15","CorpusId":7200347},"title":"Distilling the Knowledge in a Neural Network"},{"paperId":"449532187c94af3dd3aa55e16d2c50f7854d2199","externalIds":{"MAG":"1771410628","ArXiv":"1502.05477","DBLP":"conf/icml/SchulmanLAJM15","CorpusId":16046818},"title":"Trust Region Policy Optimization"},{"paperId":"f0c4b7568f378e652645232e66a1dab4c5b5293f","externalIds":{"MAG":"2169206416","DBLP":"journals/neco/ShenTSO14","ArXiv":"1311.2097","DOI":"10.1162/NECO_a_00600","CorpusId":9798309,"PubMed":"24708369"},"title":"Risk-Sensitive Reinforcement Learning"},{"paperId":"30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9","externalIds":{"MAG":"2294370754","DBLP":"conf/kdd/BucilaCN06","DOI":"10.1145/1150402.1150464","CorpusId":11253972},"title":"Model compression"},{"paperId":"7533d30329cfdbf04ee8ee82bfef792d08015ee5","externalIds":{"MAG":"2123301721","ACL":"W05-0909","DBLP":"conf/acl/BanerjeeL05","CorpusId":7164502},"title":"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"},{"paperId":"60b05f32c32519a809f21642ef1eb3eaf3848008","externalIds":{"MAG":"2154652894","ACL":"W04-1013","CorpusId":964287},"title":"ROUGE: A Package for Automatic Evaluation of Summaries"},{"paperId":"523b4ce1c2a1336962444abc1dec215756c2f3e6","externalIds":{"DBLP":"conf/icml/KakadeL02","MAG":"1575592356","CorpusId":31442909},"title":"Approximately Optimal Approximate Reinforcement Learning"},{"paperId":"d7da009f457917aa381619facfa5ffae9329a6e9","externalIds":{"DBLP":"conf/acl/PapineniRWZ02","MAG":"2101105183","ACL":"P02-1040","DOI":"10.3115/1073083.1073135","CorpusId":11080756},"title":"Bleu: a Method for Automatic Evaluation of Machine Translation"},{"paperId":"a20f0ce0616def7cc9a87446c228906cd5da093b","externalIds":{"DBLP":"conf/nips/SuttonMSM99","MAG":"2155027007","CorpusId":1211821},"title":"Policy Gradient Methods for Reinforcement Learning with Function Approximation"},{"paperId":"7d47ee5f84103529f84297c98c21dadb4742e3ff","externalIds":{"MAG":"2013784666","DOI":"10.1093/BIOMET/39.3-4.324","CorpusId":121987403},"title":"RANK ANALYSIS OF INCOMPLETE BLOCK DESIGNS THE METHOD OF PAIRED COMPARISONS"},{"paperId":"db1c39bedde04d48adc761fd7a928656294234d2","externalIds":{"DBLP":"journals/corr/abs-2406-01462","DOI":"10.48550/arXiv.2406.01462","CorpusId":282198019},"title":"Understanding Preference Fine-Tuning Through the Lens of Coverage"},{"paperId":"29c7f009df21d0112c48dec254ff80cc45fac3af","externalIds":{"DBLP":"conf/nips/SchaefferMK23","ArXiv":"2304.15004","DOI":"10.48550/arXiv.2304.15004","CorpusId":258418299},"title":"Are Emergent Abilities of Large Language Models a Mirage?"},{"paperId":"ea0d41514a41f8273f13b3b277e7fcbbc65a8549","externalIds":{"DBLP":"journals/corr/abs-2307-10236","DOI":"10.48550/arXiv.2307.10236","CorpusId":259991714},"title":"Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models"},{"paperId":"53d8b356551a2361020a948f64454a6d599af69f","externalIds":{"DBLP":"conf/acl/LiL20","ACL":"2021.acl-long.353","ArXiv":"2101.00190","DOI":"10.18653/v1/2021.acl-long.353","CorpusId":230433941},"title":"Prefix-Tuning: Optimizing Continuous Prompts for Generation"},{"paperId":"080df61ee1c15ff3c8e5d0d82d60bfd80e372e38","externalIds":{"ACL":"2021.acl-long.329","DBLP":"conf/acl/OusidhoumZFSY20","DOI":"10.18653/v1/2021.acl-long.329","CorpusId":236460108},"title":"Probing Toxic Content in Large Pre-Trained Language Models"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":"41105fb8515f9e351e891d1eabb31679a6a781c8","externalIds":{"CorpusId":16956257},"title":"on Pattern Analysis and Machine Intelligence"},{"paperId":"1c78be02663c4242d885462afcfdfd733c15e837","externalIds":{"CorpusId":270869855},"title":"Safe and Responsible Large Language Model Development"}]}