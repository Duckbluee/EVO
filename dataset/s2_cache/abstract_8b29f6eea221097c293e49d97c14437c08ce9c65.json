{"abstract":"In blasted rock slopes and underground openings, rock joints are visible in different forms. Rock joints are often exposed as planes confining rock blocks and visible as traces on a well-blasted, smooth rock mass surface. A realistic rock joint model should include both visual forms of joints in a rock mass: i.e., both joint traces and joint planes. Imaged-based 2D semantic segmentation using deep learning via the Convolutional Neural Network (CNN) has shown promising results in extracting joint traces in a rock mass. In 3D analysis, research studies using deep learning have demonstrated outperforming results in automatically extracting joint planes from an unstructured 3D point cloud compared to state-of-the-art methods. We discuss a pilot study using 3D true colour point cloud and their source and derived 2D images in this paper. In the study, we aim to implement and compare various CNN-based networks found in the literature for automatic extraction of joint traces from laser scanning and photogrammetry data. Extracted joint traces can then be clustered and connected to potential joint planes as joint objects in a discrete joint model. This can contribute to a more accurate estimation of rock joint persistence. The goal of the study is to compare the efficiency and accuracy between using 2D images and 3D point cloud as input data. Data are collected from two infrastructure projects with blasted rock slopes and tunnels in Norway."}