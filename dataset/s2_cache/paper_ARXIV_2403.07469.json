{"paperId":"37cd213f8550cb52611de72740a70eb5e2a9cb8c","externalIds":{"DBLP":"journals/tcsv/YuLWSHY24","ArXiv":"2403.07469","DOI":"10.1109/TCSVT.2023.3296889","CorpusId":260018145},"title":"A Comprehensive Survey of 3D Dense Captioning: Localizing and Describing Objects in 3D Scenes","openAccessPdf":{"url":"","status":"CLOSED","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2403.07469, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2029317446","name":"Ting Yu"},{"authorId":"2224372767","name":"Xiaojun Lin"},{"authorId":"47672591","name":"Shuhui Wang"},{"authorId":"153162646","name":"Weiguo Sheng"},{"authorId":"1689702","name":"Qingming Huang"},{"authorId":"2153201566","name":"Jun Yu"}],"abstract":"Three-Dimensional (3D) dense captioning is an emerging vision-language bridging task that aims to generate multiple detailed and accurate descriptions for 3D scenes. It presents significant potential and challenges due to its closer representation of the real world compared to 2D visual captioning, as well as complexities in data collection and processing of 3D point cloud sources. Despite the popularity and success of existing methods, there is a lack of comprehensive surveys summarizing the advancements in this field, which hinders its progress. In this paper, we provide a comprehensive review of 3D dense captioning, covering task definition, architecture classification, dataset analysis, evaluation metrics, and in-depth prosperity discussions. Based on a synthesis of previous literature, we refine a standard pipeline that serves as a common paradigm for existing methods. We also introduce a clear taxonomy of existing models, summarize technologies involved in different modules, and conduct detailed experiment analysis. Instead of a chronological order introduction, we categorize the methods into different classes to facilitate exploration and analysis of the differences and connections among existing techniques. We also provide a reading guideline to assist readers with different backgrounds and purposes in reading efficiently. Furthermore, we propose a series of promising future directions for 3D dense captioning by identifying challenges and aligning them with the development of related tasks, offering valuable insights and inspiring future research in this field. Our aim is to provide a comprehensive understanding of 3D dense captioning, foster further investigations, and contribute to the development of novel applications in multimedia and related domains."}