{"abstract":"One of the paradigms under which split learning (SL) is used is for the vertical federated learning (VFL) setting, where two or more parties build models over feature-partitioned data. However, to protect the private labels of one party, random noises are needed to perturb the backward derivatives (i.e., gradients w.r.t. forward activations), which incurs the privacy-utility tradeoff. In this work, we introduce ProjPert, a novel algorithm that searches for the optimal “perturbation knobs” for label protection in SL-based VFL. We formulate the problem of perturbation searching as how to minimize the impact on model quality given the desired privacy guarantee. Based on the problem, two solutions are introduced, where the first obtains the optimal perturbation via a simple but effective binary searching scheme, and the second heuristically approximates the optimality within a negligible error bound. Empirical results demonstrate that both our solutions are more effective in protecting the labels and achieve significantly better privacy-utility tradeoffs than state-of-the-art perturbation-based label protection methods. Furthermore, our heuristic solution is very efficient and incurs almost zero extra overhead in the overall running time, improving the usability in real-world applications."}