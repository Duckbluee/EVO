{"abstract":"The computing and memory demands from state-of-the-art neural networks have increased several orders of magnitude in just the last couple of years, and there's no end in sight. Traditional forms of scaling chip performance are necessary but far from sufficient to run the machine learning models of the future. In this talk, Cerebras Co-Founder and Chief Systems Architect Jean-Philippe Fricker will explore the fundamental properties of neural networks and why they are not well served by traditional architectures. He will examine how co-design can relax the traditional boundaries between technologies and enable designs specialized for neural networks with new architectural capabilities and performance. Finally, Jean-Philippe will explore this rich new design space using the Cerebras architecture as a case study, highlighting design principles and tradeoffs that enable the machine learning models of the future."}