{"references":[{"paperId":"4ce141033385e5efb2ed44a19be0558ae51de177","externalIds":{"DBLP":"journals/tnn/BiSSCXCL25","DOI":"10.1109/TNNLS.2025.3545101","CorpusId":277219728,"PubMed":"40117152"},"title":"MSAFF: Multi-Way Soft Attention Fusion Framework With the Large Foundation Models for the Diagnosis of Alzheimer’s Disease"},{"paperId":"deccbef42648a84311781132f6bbbd95f66d9609","externalIds":{"DBLP":"journals/tnn/HeLD25","DOI":"10.1109/TNNLS.2025.3548047","CorpusId":277220279,"PubMed":"40117155"},"title":"2-D Transformer: Extending Large Language Models to Long-Context With Few Memory"},{"paperId":"c73c6f510b7909a0e8fb16e4dfc5efe4be836989","externalIds":{"DBLP":"journals/tnn/WangXSSLBL25","DOI":"10.1109/TNNLS.2025.3539006","CorpusId":276681845,"PubMed":"40031545"},"title":"CPST-GAN: Conditional Probabilistic State Transition Generative Adversarial Network With the Biomedical Large Foundation Models"},{"paperId":"e771581b68aee0fcfe3fcbc062f185a1d9f6dbfc","externalIds":{"ArXiv":"2502.07987","DBLP":"journals/corr/abs-2502-07987","DOI":"10.48550/arXiv.2502.07987","CorpusId":276287750},"title":"Universal Adversarial Attack on Aligned Multimodal LLMs"},{"paperId":"ae88fb1e821d647e0e3083269842480a9d41db68","externalIds":{"ArXiv":"2502.05772","DBLP":"journals/corr/abs-2502-05772","DOI":"10.48550/arXiv.2502.05772","CorpusId":276250027},"title":"Effective Black-Box Multi-Faceted Attacks Breach Vision Large Language Model Guardrails"},{"paperId":"f94fe2776e4258650baffb9b0100518076aacdad","externalIds":{"DBLP":"journals/corr/abs-2502-02438","ArXiv":"2502.02438","DOI":"10.48550/arXiv.2502.02438","CorpusId":276106985},"title":"Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment"},{"paperId":"aa7d500086c0ad534dbe6a705003d794573d925a","externalIds":{"DBLP":"conf/uss/HuLLZQ0025","ArXiv":"2501.18624","DOI":"10.48550/arXiv.2501.18624","CorpusId":276079310},"title":"Membership Inference Attacks Against Vision-Language Models"},{"paperId":"932434af8caa1be91d54c9629697571cc083fa85","externalIds":{"DBLP":"journals/corr/abs-2501-13563","ArXiv":"2501.13563","DOI":"10.48550/arXiv.2501.13563","CorpusId":275820440},"title":"Black-Box Adversarial Attack on Vision Language Models for Autonomous Driving"},{"paperId":"f21f478706422e4cf320b5446ab89d8c6d6948ee","externalIds":{"ArXiv":"2501.04931","DBLP":"journals/corr/abs-2501-04931","DOI":"10.48550/arXiv.2501.04931","CorpusId":275405983},"title":"Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency"},{"paperId":"91a05f49a026f7055397eb3c274db60ca50371da","externalIds":{"DBLP":"journals/corr/abs-2412-17544","ArXiv":"2412.17544","DOI":"10.48550/arXiv.2412.17544","CorpusId":274981599},"title":"Retention Score: Quantifying Jailbreak Risks for Vision Language Models"},{"paperId":"68f9c37f3b27f8ffa50944cee92bf7583aec183a","externalIds":{"ArXiv":"2412.15206","DBLP":"journals/corr/abs-2412-15206","DOI":"10.48550/arXiv.2412.15206","CorpusId":274860038},"title":"AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models for Autonomous Driving"},{"paperId":"c1dece66333b002c026a23b5130b0c8690c824db","externalIds":{"DBLP":"journals/corr/abs-2412-08108","ArXiv":"2412.08108","DOI":"10.48550/arXiv.2412.08108","CorpusId":274638641},"title":"Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language Models Across Both Images and Text with a Single Perturbation"},{"paperId":"2dd1bfeaaa3e2759473a6180e8ddd51faa682157","externalIds":{"DBLP":"journals/corr/abs-2412-07575","ArXiv":"2412.07575","DOI":"10.1109/TNNLS.2025.3554656","CorpusId":274610010,"PubMed":"40202892"},"title":"Defending Against Neural Network Model Inversion Attacks via Data Poisoning"},{"paperId":"cde590385df184651ac0c5d209053b50a5616773","externalIds":{"DBLP":"journals/corr/abs-2412-05934","ArXiv":"2412.05934","DOI":"10.48550/arXiv.2412.05934","CorpusId":274597818},"title":"Heuristic-Induced Multimodal Risk Distribution Jailbreak Attack for Multimodal Large Language Models"},{"paperId":"c1a79fd7fdfffea07ad05d0357adda55802d3621","externalIds":{"ArXiv":"2412.02795","DBLP":"conf/wacv/0002SSL25","DOI":"10.1109/WACV61041.2025.00594","CorpusId":274464576},"title":"Hijacking Vision-and-Language Navigation Agents with Adversarial Environmental Attacks"},{"paperId":"ed1edc7bdfa7f9badb042a285d5e486ba0d48972","externalIds":{"ArXiv":"2412.00473","DBLP":"conf/acl/WangZWZH25","DOI":"10.48550/arXiv.2412.00473","CorpusId":274437489},"title":"Jailbreak Large Vision-Language Models Through Multi-Modal Linkage"},{"paperId":"b2eb421b4714537b68c544d96b5487d5f5296f20","externalIds":{"ArXiv":"2411.18275","DBLP":"journals/corr/abs-2411-18275","DOI":"10.48550/arXiv.2411.18275","CorpusId":274305982},"title":"Visual Adversarial Attack on Vision-Language Models for Autonomous Driving"},{"paperId":"a71ff0ca43d0e96a3111401c18d21773b9176de1","externalIds":{"ArXiv":"2411.13587","DBLP":"journals/corr/abs-2411-13587","DOI":"10.48550/arXiv.2411.13587","CorpusId":274165800},"title":"Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics"},{"paperId":"dee404382e5e8f0c2dc30df3c7537150fce1e70a","externalIds":{"ArXiv":"2411.11683","CorpusId":275213608},"title":"TrojanRobot: Physical-world Backdoor Attacks Against VLM-based Robotic Manipulation"},{"paperId":"fa1c8fadfc6c0cc2d08907521d96a41b5990bf14","externalIds":{"DBLP":"journals/corr/abs-2411-07559","ArXiv":"2411.07559","DOI":"10.48550/arXiv.2411.07559","CorpusId":273969547},"title":"Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for Black-box Multi-modal Large Language Models"},{"paperId":"62474020cdd6d106fa0d32c10335bc91e4d713c5","externalIds":{"ArXiv":"2411.01703","DBLP":"journals/corr/abs-2411-01703","DOI":"10.48550/arXiv.2411.01703","CorpusId":273811368},"title":"UniGuard: Towards Universal Safety Guardrails for Jailbreak Attacks on Multimodal Large Language Models"},{"paperId":"605f5a9b7603b3c1b6975ead63ec1ff28b68a4ba","externalIds":{"DBLP":"conf/mm/WangLQCJX24","ArXiv":"2410.06699","DOI":"10.1145/3664647.3680779","CorpusId":273229395},"title":"Break the Visual Perception: Adversarial Attacks Targeting Encoded Visual Tokens of Large Vision-Language Models"},{"paperId":"b1860fea94dd9ce24e7b9bae5a1459e25a3c23f3","externalIds":{"DBLP":"conf/cvpr/ZhangYMLYCSY25","ArXiv":"2410.05346","DOI":"10.1109/CVPR52734.2025.01853","CorpusId":274789008},"title":"Anyattack: Towards Large-scale Self-supervised Adversarial Attacks on Vision-language Models"},{"paperId":"9ed316c0e8e6e6901ada47d6bb8fe47a016e8c80","externalIds":{"DBLP":"journals/corr/abs-2409-13174","ArXiv":"2409.13174","DOI":"10.48550/arXiv.2409.13174","CorpusId":272770675},"title":"Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models"},{"paperId":"91d81bacaddffa17eff151b0f1c6ef6a60007caa","externalIds":{"DBLP":"journals/corr/abs-2409-10071","ArXiv":"2409.10071","DOI":"10.1109/IROS60139.2025.11246438","CorpusId":272689066},"title":"Towards Physically Realizable Adversarial Attacks in Embodied Vision Navigation"},{"paperId":"c12415ef93b23bdb9273445584b8fda37c6ae39b","externalIds":{"DBLP":"journals/tnn/NanZXY25","ArXiv":"2408.08704","DOI":"10.1109/TNNLS.2025.3558857","CorpusId":271892373,"PubMed":"40272956"},"title":"Beyond the Hype: A Dispassionate Look at Vision–Language Models in Medical Scenario"},{"paperId":"763cf8a095ef039c99cdcfc654132169443c56ee","externalIds":{"DBLP":"journals/corr/abs-2408-03554","ArXiv":"2408.03554","DOI":"10.48550/arXiv.2408.03554","CorpusId":271744893},"title":"Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection"},{"paperId":"668c2fc744f5b428dca6426319f45efc889c8e42","externalIds":{"DBLP":"journals/corr/abs-2407-15050","ArXiv":"2407.15050","DOI":"10.1145/3664647.3681379","CorpusId":271329140},"title":"Arondight: Red Teaming Large Vision Language Models with Auto-generated Multi-modal Jailbreak Prompts"},{"paperId":"4a67fa18306ab80d9cf205d3df55dec24a459f4e","externalIds":{"DBLP":"journals/corr/abs-2407-13111","ArXiv":"2407.13111","DOI":"10.48550/arXiv.2407.13111","CorpusId":271270554},"title":"PG-Attack: A Precision-Guided Adversarial Attack Framework Against Vision Foundation Models for Autonomous Driving"},{"paperId":"982093c7898baa2d7ebacc449bd91fa22f3e9694","externalIds":{"ArXiv":"2407.20242","CorpusId":271543751},"title":"BadRobot: Jailbreaking Embodied LLMs in the Physical World"},{"paperId":"aa506a9b9286eb648c17d5970a6482c894c84e8f","externalIds":{"ArXiv":"2407.09050","DBLP":"journals/corr/abs-2407-09050","DOI":"10.48550/arXiv.2407.09050","CorpusId":271161960},"title":"Refusing Safe Prompts for Multi-modal Large Language Models"},{"paperId":"eb7ee932cfcb3a79d8d383dbf9a5c6b418b3b45d","externalIds":{"DBLP":"conf/iros/IslamSSLK24","ArXiv":"2407.07392","DOI":"10.1109/IROS58592.2024.10802618","CorpusId":271088553},"title":"Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems"},{"paperId":"2a76b2797949fda3102a83213c6446e6716e002e","externalIds":{"DBLP":"conf/cvpr/LiangLPDLZCT25","ArXiv":"2406.18844","DOI":"10.1109/CVPR52734.2025.00885","CorpusId":270764501},"title":"Revisiting Backdoor Attacks against Large Vision-Language Models from Domain Shift"},{"paperId":"aab95a2479ae7a9dd168ef32314cd654ba8f590c","externalIds":{"DBLP":"journals/corr/abs-2406-14859","ACL":"2024.emnlp-main.973","ArXiv":"2406.14859","DOI":"10.48550/arXiv.2406.14859","CorpusId":270688678},"title":"From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking"},{"paperId":"4f27fc2ea3d3491deded642a5de247d167a03d15","externalIds":{"ArXiv":"2406.12814","DBLP":"conf/iclr/WuSKSFR25","CorpusId":270562791},"title":"Dissecting Adversarial Robustness of Multimodal LM Agents"},{"paperId":"1b937b3a6ce257a243bc1e1f44f4d1ef4cf79c8d","externalIds":{"ArXiv":"2406.06302","DBLP":"journals/corr/abs-2406-06302","DOI":"10.48550/arXiv.2406.06302","CorpusId":270371209},"title":"Unveiling the Safety of GPT-4o: An Empirical Study using Jailbreak Attacks"},{"paperId":"5d2bc3bf1fdf2b11ebb4f48de1c98918e39d95aa","externalIds":{"DBLP":"conf/nips/XiaCTGHXWFZZZWW24","ArXiv":"2406.06007","DOI":"10.48550/arXiv.2406.06007","CorpusId":270371398},"title":"CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models"},{"paperId":"27ce6603b7cd5a43f2ef9811b7775008a7d9602b","externalIds":{"ArXiv":"2405.17894","DBLP":"journals/corr/abs-2405-17894","DOI":"10.1145/3664647.3681092","CorpusId":270068400},"title":"White-box Multimodal Jailbreaks Against Large Vision-Language Models"},{"paperId":"80ad06205d9f301e3f60218eca315336329950f7","externalIds":{"DBLP":"conf/emnlp/ChakrabortySCAA24","ArXiv":"2406.02575","DOI":"10.48550/arXiv.2406.02575","CorpusId":270257791},"title":"Cross-Modal Safety Alignment: Is textual unlearning all you need?"},{"paperId":"6664b7619312427c668cfe34bb4e473726a39c1f","externalIds":{"ArXiv":"2405.20775","DBLP":"conf/aaai/Huang0ZZXAWLP25","DOI":"10.1609/aaai.v39i4.32396","CorpusId":270199448},"title":"Medical MLLM Is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models"},{"paperId":"991177a764b5a1d01d4466867238cb97104729fc","externalIds":{"ArXiv":"2405.20773","DBLP":"journals/corr/abs-2405-20773","DOI":"10.48550/arXiv.2405.20773","CorpusId":270199716},"title":"Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Characte"},{"paperId":"2caf6d57714c427063818503e7ec2c1b56899f91","externalIds":{"ArXiv":"2405.14169","DBLP":"journals/corr/abs-2405-14169","DOI":"10.48550/arXiv.2405.14169","CorpusId":269982647},"title":"Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography"},{"paperId":"a42df2cc7f85e133f2ea38b2bbd2cb2b21a0f904","externalIds":{"DBLP":"conf/sp/WangDZQLFWL24","DOI":"10.1109/SP54263.2024.00102","CorpusId":272434222},"title":"Transferable Multimodal Attack on Vision-Language Pre-training Models"},{"paperId":"51ed81d2a394ae395eb22285a7c57c03ae34f558","externalIds":{"DBLP":"journals/corr/abs-2405-09981","ArXiv":"2405.09981","DOI":"10.48550/arXiv.2405.09981","CorpusId":269791017},"title":"Adversarial Robustness for Visual Grounding of Multimodal Large Language Models"},{"paperId":"36cb4461ba326a99045f13ec90074838bbfdc27b","externalIds":{"DBLP":"conf/sigir/ZhangHB24","ArXiv":"2405.05524","DOI":"10.1145/3626772.3657781","CorpusId":269635558},"title":"Universal Adversarial Perturbations for Vision-Language Pre-trained Models"},{"paperId":"8f30f5081c7a6833e0e098ee2775a863ed53c832","externalIds":{"ArXiv":"2404.12916","DBLP":"journals/corr/abs-2404-12916","DOI":"10.48550/arXiv.2404.12916","CorpusId":269282538},"title":"Physical Backdoor Attack can Jeopardize Driving with Vision-Large-Language Models"},{"paperId":"084e4d013c43ca4686f0dac75b3495c6624545c8","externalIds":{"DBLP":"conf/cvpr/ZhangDZMS024","ArXiv":"2404.11207","DOI":"10.1109/CVPR52733.2024.02508","CorpusId":269187585},"title":"Exploring the Transferability of Visual Prompting for Multimodal Large Language Models"},{"paperId":"05f999abc2c60fdc8d043376aa2924177d4412c0","externalIds":{"ArXiv":"2404.10335","DBLP":"journals/tifs/GuoPJLG25","DOI":"10.1109/TIFS.2024.3518072","CorpusId":269157158},"title":"Efficient Generation of Targeted and Transferable Adversarial Examples for Vision-Language Models via Diffusion Models"},{"paperId":"e59689af068b7402a5d0349e2075dd6c3a721eca","externalIds":{"ArXiv":"2404.05264","DBLP":"journals/corr/abs-2404-05264","DOI":"10.1109/SMC54092.2024.10831129","CorpusId":269005062},"title":"Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security"},{"paperId":"526c88e301af88080ae4ecc3b65c9fc1f8f383f8","externalIds":{"DBLP":"journals/corr/abs-2404-03411","ArXiv":"2404.03411","DOI":"10.48550/arXiv.2404.03411","CorpusId":268889751},"title":"Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?"},{"paperId":"f019c9661b253ddb611e930348e20ddcd350a952","externalIds":{"ArXiv":"2404.03027","CorpusId":268889385},"title":"JailBreakV: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks"},{"paperId":"c44471e846846bde281779405a3b5c132fd60b00","externalIds":{"ArXiv":"2404.00282","DBLP":"journals/corr/abs-2404-00282","DOI":"10.1109/TNNLS.2024.3497992","CorpusId":268819406,"PubMed":"40030358"},"title":"Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods"},{"paperId":"674976623d89394587bba42539c6c99d700bce29","externalIds":{"ArXiv":"2403.09346","DBLP":"journals/tifs/ZhangSLMLQZZ25","DOI":"10.1109/TIFS.2024.3520306","CorpusId":268385213},"title":"B-AVIBench: Toward Evaluating the Robustness of Large Vision-Language Model on Black-Box Adversarial Visual-Instructions"},{"paperId":"2c030ad4be327dc3447e23ad68c303714c55cf14","externalIds":{"DBLP":"conf/eccv/LiGZZW24","ArXiv":"2403.09792","DOI":"10.48550/arXiv.2403.09792","CorpusId":268510101},"title":"Images are Achilles' Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models"},{"paperId":"3bb87d605856411c6f002d480fc29d355c3ba245","externalIds":{"DBLP":"journals/corr/abs-2403-09766","ArXiv":"2403.09766","DOI":"10.48550/arXiv.2403.09766","CorpusId":268510103},"title":"An Image Is Worth 1000 Lies: Adversarial Transferability across Prompts on Vision-Language Models"},{"paperId":"8a25739903cab07c74556b8c2d9743749e1be1e5","externalIds":{"DBLP":"conf/eccv/WangLLCX24","ArXiv":"2403.09513","DOI":"10.48550/arXiv.2403.09513","CorpusId":268385048},"title":"AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting"},{"paperId":"6a6d8794f77dcdabebbf80b8f79956f707f16eb9","externalIds":{"DBLP":"conf/eccv/GouCLHXLYKZ24","ArXiv":"2403.09572","DOI":"10.48550/arXiv.2403.09572","CorpusId":268384950},"title":"Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation"},{"paperId":"37149662dd8eb59fdc0fae23bce8edc16a51cd79","externalIds":{"DBLP":"journals/corr/abs-2403-02910","ArXiv":"2403.02910","DOI":"10.18653/v1/2025.naacl-long.360","CorpusId":268247968},"title":"ImgTrojan: Jailbreaking Vision-Language Models with ONE Image"},{"paperId":"3a391dfd536625e068f3888c817cc6cbe7fcea9c","externalIds":{"DBLP":"conf/cvpr/LiGQS24","ArXiv":"2403.01849","DOI":"10.1109/CVPR52733.2024.02304","CorpusId":268248016},"title":"One Prompt Word is Enough to Boost Adversarial Robustness for Pre-Trained Vision-Language Models"},{"paperId":"8b1378a728ac223309e5e4c6d2006654b2d469bf","externalIds":{"ArXiv":"2403.04786","DBLP":"journals/corr/abs-2403-04786","DOI":"10.48550/arXiv.2403.04786","CorpusId":268296800},"title":"Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models"},{"paperId":"f4f87904af97d7f567dd2f44930a73952ed4d5dd","externalIds":{"ArXiv":"2402.14899","CorpusId":267897862},"title":"Stop Reasoning! When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image"},{"paperId":"d30e33051496383a66b2a2ab1b961bc866afa409","externalIds":{"ArXiv":"2402.13851","DBLP":"journals/corr/abs-2402-13851","DOI":"10.48550/arXiv.2402.13851","CorpusId":267770333},"title":"VL-Trojan: Multimodal Instruction Backdoor Attacks against Autoregressive Visual Language Models"},{"paperId":"d42c94924fb0117e4fdb746c21071a950c2eb83a","externalIds":{"DBLP":"journals/corr/abs-2402-14859","ArXiv":"2402.14859","DOI":"10.48550/arXiv.2402.14859","CorpusId":267897828},"title":"The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative"},{"paperId":"531e5989b1a995cbf3aad41d5db2a9e894688d64","externalIds":{"ArXiv":"2402.10340","DBLP":"conf/iros/WuCXLGLSMB25","DOI":"10.1109/IROS60139.2025.11246863","CorpusId":267740494},"title":"On the Vulnerability of LLM/VLM-Controlled Robotics"},{"paperId":"9f12a20f62238f5206520e52e83e2ccd1da17f03","externalIds":{"ArXiv":"2402.08577","DBLP":"journals/corr/abs-2402-08577","DOI":"10.48550/arXiv.2402.08577","CorpusId":267637232},"title":"Test-Time Backdoor Attacks on Multimodal Large Language Models"},{"paperId":"b0ada492ba48e85016cbbfd95ec7180fb7e79648","externalIds":{"ArXiv":"2402.08567","DBLP":"conf/icml/GuZPDL00L24","DOI":"10.48550/arXiv.2402.08567","CorpusId":267637249},"title":"Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast"},{"paperId":"ec8e2b45c4601730015608a58e33409224a81228","externalIds":{"ArXiv":"2402.05935","DBLP":"conf/icml/LiuZQHLZGLJZSXH24","DOI":"10.48550/arXiv.2402.05935","CorpusId":267547619},"title":"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models"},{"paperId":"9e2524448155a93473d6d4fa2f3bef34b0ed9622","externalIds":{"DBLP":"conf/nips/XuYSSW0GH24","ArXiv":"2402.06659","DOI":"10.48550/arXiv.2402.06659","CorpusId":267627492},"title":"Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models"},{"paperId":"24253eb1c425de4c4e4c9946ed1b6eb5bdc8fba9","externalIds":{"DBLP":"journals/corr/abs-2402-02309","ArXiv":"2402.02309","DOI":"10.48550/arXiv.2402.02309","CorpusId":267413270},"title":"Jailbreaking Attack against Multimodal Large Language Model"},{"paperId":"f88bb3f172633a83d1a4c51c3e10c29166ceb734","externalIds":{"DBLP":"conf/ijcai/0086ZL0024","ArXiv":"2402.00357","DOI":"10.48550/arXiv.2402.00357","CorpusId":267365092},"title":"Safety of Multimodal Large Language Models on Images and Text"},{"paperId":"a6c03ddbec5456c1de836441365db92fef512589","externalIds":{"ArXiv":"2402.00626","DBLP":"journals/corr/abs-2402-00626","DOI":"10.48550/arXiv.2402.00626","CorpusId":267364929},"title":"Vision-LLMs Can Fool Themselves with Self-Generated Typographic Attacks"},{"paperId":"1524b7ff78755a3445d22400a8d6c75ba8c0cd65","externalIds":{"DBLP":"journals/corr/abs-2401-12915","ArXiv":"2401.12915","DOI":"10.48550/arXiv.2401.12915","CorpusId":267094801},"title":"Red Teaming Visual Language Models"},{"paperId":"61ea0a87eab0029de9f4f6032108cb8d94cca3ac","externalIds":{"DBLP":"conf/iclr/GaoBGX00024","ArXiv":"2401.11170","DOI":"10.48550/arXiv.2401.11170","CorpusId":267068279},"title":"Inducing High Energy-Latency of Large Vision-Language Models with Verbose Images"},{"paperId":"f21d0177e9374bb8579c1d9c71319f212f62b3d5","externalIds":{"DBLP":"journals/corr/abs-2401-11206","ArXiv":"2401.11206","ACL":"2024.emnlp-main.585","DOI":"10.48550/arXiv.2401.11206","CorpusId":267068598},"title":"InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance"},{"paperId":"411114f989a3d1083d90afd265103132fee94ebe","externalIds":{"DBLP":"journals/corr/abs-2401-04088","ArXiv":"2401.04088","DOI":"10.48550/arXiv.2401.04088","CorpusId":266844877},"title":"Mixtral of Experts"},{"paperId":"8d28d2ef602e8b518b7daecc39a0f2f8d2caaa09","externalIds":{"ACL":"2024.emnlp-main.895","DBLP":"journals/corr/abs-2401-02906","ArXiv":"2401.02906","DOI":"10.48550/arXiv.2401.02906","CorpusId":266818099},"title":"MLLM-Protector: Ensuring MLLM’s Safety without Hurting Performance"},{"paperId":"e424fb0d5a33900f26bcc607a34ed262b6900ffa","externalIds":{"DOI":"10.61969/jai.1311271","CorpusId":266113031},"title":"Google Bard Generated Literature Review: Metaverse"},{"paperId":"0f030a6dd9b3b227689baf9b01021abe65f58ca5","externalIds":{"ArXiv":"2312.10766","CorpusId":266359752},"title":"JailGuard: A Universal Detection Framework for LLM Prompt-based Attacks"},{"paperId":"91159f6d3d52e6cfed1e4d1c6e50d1b17086a910","externalIds":{"DBLP":"journals/corr/abs-2312-03777","ArXiv":"2312.03777","DOI":"10.1109/CVPR52733.2024.02325","CorpusId":266053515},"title":"On the Robustness of Large Multimodal Models Against Image Adversarial Attacks"},{"paperId":"b9401a81dca0bebfc1d602843ddc43ac1b4a3d1b","externalIds":{"ArXiv":"2312.01886","DBLP":"journals/corr/abs-2312-01886","DOI":"10.48550/arXiv.2312.01886","CorpusId":265609872},"title":"InstructTA: Instruction-Tuned Targeted Attack for Large Vision-Language Models"},{"paperId":"1a5a79b393b3f00eb5a47243ee031ad799d2f641","externalIds":{"DBLP":"conf/eccv/LiuZGLYQ24","ArXiv":"2311.17600","DOI":"10.1007/978-3-031-72992-8_22","CorpusId":265498692},"title":"MM-SafetyBench: A Benchmark for Safety Evaluation of Multimodal Large Language Models"},{"paperId":"73f082fc7df9f2b9f3bf7dafb7c4422bb7aae968","externalIds":{"ArXiv":"2311.16101","DBLP":"journals/corr/abs-2311-16101","DOI":"10.48550/arXiv.2311.16101","CorpusId":265456945},"title":"How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for Vision LLMs"},{"paperId":"d4be736226f60580bdf1d636fab6bf549a0d29ee","externalIds":{"DBLP":"journals/tnn/WangXMLJ25","DOI":"10.1109/TNNLS.2023.3331841","CorpusId":265349524,"PubMed":"37988204"},"title":"ActionCLIP: Adapting Language-Image Pretrained Models for Video Action Recognition"},{"paperId":"b6cf4579b59b51d7df416e096ad86c1e6a48b458","externalIds":{"ArXiv":"2311.11261","DBLP":"conf/eccv/ZhangMWQWJS24","DOI":"10.48550/arXiv.2311.11261","CorpusId":265295116},"title":"Adversarial Prompt Tuning for Vision-Language Models"},{"paperId":"391eaeb1092c2b145ff0e5a2fa61637a42921fce","externalIds":{"DBLP":"conf/cvpr/ChenSCJD24","ArXiv":"2311.10081","DOI":"10.1109/CVPR52733.2024.01350","CorpusId":265221232},"title":"DRESS : Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback"},{"paperId":"18a8b97d75a87e8fef07542d8875d4a62b553744","externalIds":{"DBLP":"journals/corr/abs-2311-09127","ArXiv":"2311.09127","DOI":"10.48550/arXiv.2311.09127","CorpusId":265212889},"title":"Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts"},{"paperId":"b78b5ce5f21f46d8149824463f8eebd6103d49aa","externalIds":{"ArXiv":"2311.05608","DBLP":"journals/corr/abs-2311-05608","DOI":"10.48550/arXiv.2311.05608","CorpusId":265067328},"title":"FigStep: Jailbreaking Large Vision-language Models via Typographic Visual Prompts"},{"paperId":"a7741b2753134653861ec0b82f617875c0ebd96e","externalIds":{"DBLP":"journals/corr/abs-2310-17389","ArXiv":"2310.17389","DOI":"10.48550/arXiv.2310.17389","CorpusId":264491114},"title":"ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation"},{"paperId":"1ddbd08ad8cf22a5c66c4242194c4286328533bf","externalIds":{"ArXiv":"2310.09478","DBLP":"journals/corr/abs-2310-09478","DOI":"10.48550/arXiv.2310.09478","CorpusId":264146906},"title":"MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning"},{"paperId":"124d4d374fbef2016fa9880489871a58a7450644","externalIds":{"ArXiv":"2310.03744","DBLP":"conf/cvpr/LiuLLL24","DOI":"10.1109/CVPR52733.2024.02484","CorpusId":263672058},"title":"Improved Baselines with Visual Instruction Tuning"},{"paperId":"ac5b4df0e398ca48388330ac5c795b6fe708793c","externalIds":{"DBLP":"journals/corr/abs-2310-03185","ArXiv":"2310.03185","DOI":"10.48550/arXiv.2310.03185","CorpusId":263671647},"title":"Misusing Tools in Large Language Models With Visual Adversarial Examples"},{"paperId":"2403c8e72a90d9c778970fc0812ecdcc58800c5d","externalIds":{"ArXiv":"2310.02224","DBLP":"journals/corr/abs-2310-02224","DOI":"10.48550/arXiv.2310.02224","CorpusId":263608643},"title":"Can Language Models be Instructed to Protect Personal Information?"},{"paperId":"54814744b42b06c855c97b23de1366e0bcbe775a","externalIds":{"ArXiv":"2309.17421","DBLP":"journals/corr/abs-2309-17421","DOI":"10.48550/arXiv.2309.17421","CorpusId":263310951},"title":"The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)"},{"paperId":"5fc1a3a49e8f1d106118b69d1d6be3b6caa23da0","externalIds":{"DBLP":"journals/corr/abs-2309-16609","ArXiv":"2309.16609","DOI":"10.48550/arXiv.2309.16609","CorpusId":263134555},"title":"Qwen Technical Report"},{"paperId":"9f4c17aebbb181756fab86ade02deadd90d5d4f9","externalIds":{"ArXiv":"2309.11751","DBLP":"journals/corr/abs-2309-11751","DOI":"10.48550/arXiv.2309.11751","CorpusId":262083772},"title":"How Robust is Google's Bard to Adversarial Image Attacks?"},{"paperId":"c8712e4631241c7e00fb405b16f23f7a35b8fa36","externalIds":{"ArXiv":"2309.03406","DBLP":"journals/corr/abs-2309-03406","DOI":"10.1109/ICCV51070.2023.02011","CorpusId":261582506},"title":"Distribution-Aware Prompt Tuning for Vision-Language Models"},{"paperId":"5bdaadb84db0cbf72aaebda9f55f4288b63c6e9b","externalIds":{"DBLP":"journals/corr/abs-2309-00236","ArXiv":"2309.00236","DOI":"10.48550/arXiv.2309.00236","CorpusId":261494235},"title":"Image Hijacks: Adversarial Images can Control Generative Models at Runtime"},{"paperId":"fc6a2f7478f68adefd69e2071f27e38aa1647f2f","externalIds":{"ArXiv":"2308.12966","CorpusId":261101015},"title":"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond"},{"paperId":"5690e35b8beab92a80055fe2530c29c24e495379","externalIds":{"ArXiv":"2308.10741","DBLP":"conf/iccvw/Schlarmann023","DOI":"10.1109/ICCVW60793.2023.00395","CorpusId":261048835},"title":"On the Adversarial Robustness of Multi-Modal Foundation Models"},{"paperId":"30cc95639cffca4ffa8c0eafbc502636c0c88fa5","externalIds":{"DBLP":"journals/corr/abs-2308-09936","ArXiv":"2308.09936","DOI":"10.48550/arXiv.2308.09936","CorpusId":261049015},"title":"BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions"},{"paperId":"7fbc502441d66daf1f53765d5d86a8dfba9ab0ce","externalIds":{"DBLP":"journals/corr/abs-2308-01390","ArXiv":"2308.01390","DOI":"10.48550/arXiv.2308.01390","CorpusId":261043320},"title":"OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"},{"paperId":"47030369e97cc44d4b2e3cf1be85da0fd134904a","externalIds":{"DBLP":"journals/corr/abs-2307-15043","ArXiv":"2307.15043","CorpusId":260202961},"title":"Universal and Transferable Adversarial Attacks on Aligned Language Models"},{"paperId":"92b9d8b8c81c4c53ea62000c0924500b2dd11bce","externalIds":{"ArXiv":"2307.14539","DBLP":"conf/iclr/Shayegani0A24","CorpusId":260203143},"title":"Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models"},{"paperId":"3fa3d818dedba25121faf777e09905ee96faa117","externalIds":{"ArXiv":"2307.10490","DBLP":"journals/corr/abs-2307-10490","DOI":"10.48550/arXiv.2307.10490","CorpusId":259991844},"title":"(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs"},{"paperId":"104b0bb1da562d53cbda87aec79ef6a2827d191a","externalIds":{"ArXiv":"2307.09288","DBLP":"journals/corr/abs-2307-09288","CorpusId":259950998},"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models"},{"paperId":"a35f1315e91513ff0bec0c488fe175214fd9636c","externalIds":{"DBLP":"journals/corr/abs-2307-02046","ArXiv":"2307.02046","DOI":"10.1109/TKDE.2024.3392335","CorpusId":259342486},"title":"Recommender Systems in the Era of Large Language Models (LLMs)"},{"paperId":"8724579d3f126e753a0451d98ff57b165f722e72","externalIds":{"ArXiv":"2306.15447","DBLP":"journals/corr/abs-2306-15447","DOI":"10.48550/arXiv.2306.15447","CorpusId":259262181},"title":"Are aligned neural networks adversarially aligned?"},{"paperId":"142e934dd5d6c53f877c30243d436255e3a0dde7","externalIds":{"ArXiv":"2306.13213","DBLP":"conf/aaai/QiHP0WM24","DOI":"10.1609/aaai.v38i19.30150","CorpusId":259244034},"title":"Visual Adversarial Examples Jailbreak Aligned Large Language Models"},{"paperId":"9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6","externalIds":{"ArXiv":"2306.08302","DBLP":"journals/corr/abs-2306-08302","DOI":"10.1109/TKDE.2024.3352100","CorpusId":259165563},"title":"Unifying Large Language Models and Knowledge Graphs: A Roadmap"},{"paperId":"073e4f0c3a66b7557abd053301b5104cdc582636","externalIds":{"DBLP":"journals/corr/abs-2306-06615","ArXiv":"2306.06615","DOI":"10.1109/TKDE.2024.3393356","CorpusId":259137456},"title":"Empowering Molecule Discovery for Molecule-Caption Translation With Large Language Models: A ChatGPT Perspective"},{"paperId":"8ecdbfe011b7189fa0ee49ffc4e42a93d728a371","externalIds":{"ArXiv":"2305.16934","DBLP":"conf/nips/ZhaoPDYLCL23","DOI":"10.48550/arXiv.2305.16934","CorpusId":258947177},"title":"On Evaluating Adversarial Robustness of Large Vision-Language Models"},{"paperId":"d3f79210b54e168c76b8c311488f42d7d1048b81","externalIds":{"DBLP":"journals/corr/abs-2305-16355","ArXiv":"2305.16355","ACL":"2023.tllm-1.2","DOI":"10.48550/arXiv.2305.16355","CorpusId":258947721},"title":"PandaGPT: One Model To Instruction-Follow Them All"},{"paperId":"8bd6a2a89503be083176f2cc26fabedb79238cbd","externalIds":{"ArXiv":"2305.06500","DBLP":"journals/corr/abs-2305-06500","DOI":"10.48550/arXiv.2305.06500","CorpusId":258615266},"title":"InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning"},{"paperId":"7dc6da87eaa6f830354feb2db14023cab8678c91","externalIds":{"DBLP":"journals/corr/abs-2305-05665","ArXiv":"2305.05665","DOI":"10.1109/CVPR52729.2023.01457","CorpusId":258564264},"title":"ImageBind One Embedding Space to Bind Them All"},{"paperId":"570079bbdd8758dfe865097e05719313c9c1301a","externalIds":{"ArXiv":"2304.15010","DBLP":"journals/corr/abs-2304-15010","DOI":"10.48550/arXiv.2304.15010","CorpusId":258418343},"title":"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model"},{"paperId":"ca6a2bc279be5a3349a22bfd6866ed633d18734b","externalIds":{"ArXiv":"2304.10592","DBLP":"conf/iclr/Zhu0SLE24","DOI":"10.48550/arXiv.2304.10592","CorpusId":258291930},"title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"},{"paperId":"a5036f31f0e629dc661f120b8c3b1f374d479ab8","externalIds":{"DBLP":"journals/corr/abs-2304-08485","ArXiv":"2304.08485","DOI":"10.48550/arXiv.2304.08485","CorpusId":258179774},"title":"Visual Instruction Tuning"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"86923a85225d18da6d7625e5768c0fc3f2a7299e","externalIds":{"ArXiv":"2303.06854","DBLP":"conf/nips/YangGM23","CorpusId":257496718},"title":"Robust Contrastive Language-Image Pretraining against Data Poisoning and Backdoor Attacks"},{"paperId":"bf58936a947e292b7d36050f6ad72eceadec5fbb","externalIds":{"DBLP":"conf/iccv/BansalYSGYC23","ArXiv":"2303.03323","DOI":"10.1109/ICCV51070.2023.00017","CorpusId":257364847},"title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"3f5b31c4f7350dc88002c121aecbdc82f86eb5bb","externalIds":{"DBLP":"journals/corr/abs-2301-12597","ArXiv":"2301.12597","DOI":"10.48550/arXiv.2301.12597","CorpusId":256390509},"title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"},{"paperId":"78281482c1fdad8e167bab39cc9955c73d58ae8f","externalIds":{"DBLP":"conf/cvpr/FangWXSWW0WC23","ArXiv":"2211.07636","DOI":"10.1109/CVPR52729.2023.01855","CorpusId":253510587},"title":"EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"},{"paperId":"a26623d52d24e03044a158cddad931ec5ab7304c","externalIds":{"DBLP":"journals/corr/abs-2211-05994","ArXiv":"2211.05994","DOI":"10.1109/TKDE.2023.3310002","CorpusId":253498934},"title":"A Survey of Knowledge Enhanced Pre-Trained Language Models"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"974c982737ec38e433eb51a33ad40504f8fdfd3b","externalIds":{"DBLP":"journals/tkde/LinWGHJL24","ArXiv":"2207.14539","DOI":"10.1109/TKDE.2023.3347513","CorpusId":251196876},"title":"Pre-Training General Trajectory Embeddings With Maximum Multi-View Entropy Coding"},{"paperId":"51003e10de33c80be270732eacc91ce741f1ae08","externalIds":{"DBLP":"journals/tnn/BortolussiCLPSW25","ArXiv":"2207.06154","DOI":"10.1109/TNNLS.2024.3386642","CorpusId":250491607,"PubMed":"38648123"},"title":"On the Robustness of Bayesian Neural Networks to Adversarial Attacks"},{"paperId":"d8a99539bd1939a75dea3bf89a1a07ae8d9c1609","externalIds":{"DBLP":"journals/tnn/PengHLCXC24","DOI":"10.1109/TNNLS.2022.3188569","CorpusId":250489686,"PubMed":"35830398"},"title":"Relation-Aggregated Cross-Graph Correlation Learning for Fine-Grained Image–Text Retrieval"},{"paperId":"95a03fd44f01d71bc2299d2fcec1778c9d8f27bd","externalIds":{"DBLP":"journals/tnn/ZhangFSW24","DOI":"10.1109/TNNLS.2022.3185320","CorpusId":250116447,"PubMed":"35767480"},"title":"Adaptive Semantic-Enhanced Transformer for Image Captioning"},{"paperId":"9b577729898ddd9b826b478761234d59f31b2803","externalIds":{"DBLP":"journals/tnn/HuaLDXL25","ArXiv":"2206.05658","DOI":"10.1109/TNNLS.2023.3330926","CorpusId":249626508,"PubMed":"38032779"},"title":"Improving Pretrained Language Model Fine-Tuning With Noise Stability Regularization"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","externalIds":{"DBLP":"journals/corr/abs-2204-14198","ArXiv":"2204.14198","CorpusId":248476411},"title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"ee46f533a393698aa2ffccc02807b7d799bb8e12","externalIds":{"DBLP":"journals/corr/abs-2204-07945","ArXiv":"2204.07945","DOI":"10.1109/TNNLS.2022.3165573","CorpusId":248228136,"PubMed":"35442894"},"title":"DR-GAN: Distribution Regularization for Text-to-Image Generation"},{"paperId":"c57293882b2561e1ba03017902df9fc2f289dea2","externalIds":{"ArXiv":"2204.06125","DBLP":"journals/corr/abs-2204-06125","DOI":"10.48550/arXiv.2204.06125","CorpusId":248097655},"title":"Hierarchical Text-Conditional Image Generation with CLIP Latents"},{"paperId":"411b07870690a9492aec0331e07ede019f3d6814","externalIds":{"DBLP":"journals/corr/abs-2204-00008","ArXiv":"2204.00008","DOI":"10.1109/CVPR52688.2022.01457","CorpusId":247922429},"title":"Improving Adversarial Transferability via Neuron Attribution-based Attacks"},{"paperId":"8342b592fe238f3d230e4959b06fd10153c45db1","externalIds":{"DBLP":"journals/corr/abs-2203-15556","ArXiv":"2203.15556","CorpusId":247778764},"title":"Training Compute-Optimal Large Language Models"},{"paperId":"759b5f58e58a76f79a7d845acd3169dc899d0ac2","externalIds":{"DBLP":"journals/corr/abs-2202-06687","ArXiv":"2202.06687","DOI":"10.1109/TNNLS.2023.3327962","CorpusId":246823759,"PubMed":"37943650"},"title":"Domain Adaptation via Prompt Learning"},{"paperId":"455869f88df82b07ef7d5ab0dab5c28c6620daa1","externalIds":{"DBLP":"conf/cvpr/ChenAG22","ArXiv":"2202.01993","DOI":"10.1109/CVPR52688.2022.01851","CorpusId":246607802},"title":"Grounding Answers for Visual Questions Asked by Visually Impaired People"},{"paperId":"a3b42a83669998f65df60d7c065a70d07ca95e99","externalIds":{"DBLP":"journals/corr/abs-2201-12086","ArXiv":"2201.12086","CorpusId":246411402},"title":"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","externalIds":{"ArXiv":"2112.10752","DBLP":"journals/corr/abs-2112-10752","DOI":"10.1109/CVPR52688.2022.01042","CorpusId":245335280},"title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"7002ae048e4b8c9133a55428441e8066070995cb","externalIds":{"ArXiv":"2112.10741","DBLP":"journals/corr/abs-2112-10741","CorpusId":245335086},"title":"GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"},{"paperId":"16f96476d1db4f1082a97f7d7dc6decfa1abec0e","externalIds":{"DBLP":"journals/corr/abs-2112-07668","ArXiv":"2112.07668","DOI":"10.1109/CVPR52688.2022.01494","CorpusId":245131534},"title":"Dual-Key Multimodal Backdoors for Visual Question Answering"},{"paperId":"b838395165ee6306b5a60e19e9a3422e21d55833","externalIds":{"ArXiv":"2111.10990","DBLP":"journals/pami/LiuH23","DOI":"10.1109/TPAMI.2022.3193449","CorpusId":244478370,"PubMed":"35877804"},"title":"Imperceptible Transfer Attack and Defense on 3D Point Cloud Classification"},{"paperId":"333212e246fb65f7c9d43862021e78f007c48449","externalIds":{"DBLP":"journals/corr/abs-2111-06091","ArXiv":"2111.06091","DOI":"10.1109/TNNLS.2022.3227717","CorpusId":243985875,"PubMed":"37015131"},"title":"A Survey of Visual Transformers"},{"paperId":"4481f897a0d8a753ccc27b8dd41add2d44e8f040","externalIds":{"DBLP":"journals/tnn/LiuZZJYL23","DOI":"10.1109/TNNLS.2021.3114188","CorpusId":239888789,"PubMed":"34695001"},"title":"An Empirical Study on Adaptive Inference for Pretrained Language Model"},{"paperId":"01b5412f3d17e90e09226d7c40ad4d4468a1414d","externalIds":{"ArXiv":"2106.13884","DBLP":"journals/corr/abs-2106-13884","CorpusId":235658331},"title":"Multimodal Few-Shot Learning with Frozen Language Models"},{"paperId":"7301d58eb8a750e44b7da5ab0266b134d1651237","externalIds":{"DBLP":"conf/cvpr/Wang021","ArXiv":"2103.15571","DOI":"10.1109/CVPR46437.2021.00196","CorpusId":232404127},"title":"Enhancing the Transferability of Adversarial Attacks through Variance Tuning"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"2cd605106b88c85d7d8b865b1ef0f8c8293debf1","externalIds":{"ArXiv":"2102.12092","DBLP":"conf/icml/RameshPGGVRCS21","MAG":"3170016573","CorpusId":232035663},"title":"Zero-Shot Text-to-Image Generation"},{"paperId":"c16835c8e535ebd9c10a550ca9455fe384a14449","externalIds":{"DBLP":"conf/icml/BrockDSS21","ArXiv":"2102.06171","CorpusId":231879922},"title":"High-Performance Large-Scale Image Recognition Without Normalization"},{"paperId":"8448010d9adad18bf36070c012770a10ecb21c76","externalIds":{"MAG":"3111919937","DBLP":"journals/corr/abs-2012-06337","ArXiv":"2012.06337","DOI":"10.1109/TNNLS.2022.3216981","CorpusId":228373690,"PubMed":"36355741"},"title":"Privacy and Robustness in Federated Learning: Attacks and Defenses"},{"paperId":"4899dffeca9285ecd47fad26a7790ab9998d56e6","externalIds":{"DBLP":"journals/tits/MuhammadULSA21","MAG":"3112288498","DOI":"10.1109/tits.2020.3032227","CorpusId":234540188},"title":"Deep Learning for Safe Autonomous Driving: Current Challenges and Future Directions"},{"paperId":"399e7d8129c60818ee208f236c8dda17e876d21f","externalIds":{"MAG":"3088599783","ACL":"2020.findings-emnlp.301","DBLP":"journals/corr/abs-2009-11462","ArXiv":"2009.11462","DOI":"10.18653/v1/2020.findings-emnlp.301","CorpusId":221878771},"title":"RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"},{"paperId":"86d302205a15aad287c82ecdb21ce36a72e6591b","externalIds":{"MAG":"3025305474","ArXiv":"2005.08087","DBLP":"journals/corr/abs-2005-08087","CorpusId":218673649},"title":"Universal Adversarial Perturbations: A Survey"},{"paperId":"18939eadc9c4460c8385e0591cde214a1ead067b","externalIds":{"MAG":"3034994123","ArXiv":"2003.01690","DBLP":"conf/icml/Croce020a","CorpusId":211818320},"title":"Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks"},{"paperId":"1c3677364ea592629848ba2c6bd087f22cc579ea","externalIds":{"DBLP":"reference/bio/Zhou15","DOI":"10.1007/978-1-4899-7488-4_293","CorpusId":9963037},"title":"Ensemble Learning"},{"paperId":"166c962e378eafc5b5b2ad980e222e1b17ee994e","externalIds":{"MAG":"2976017709","DBLP":"conf/iclr/ChengSCC0H20","ArXiv":"1909.10773","CorpusId":202734646},"title":"Sign-OPT: A Query-Efficient Hard-label Adversarial Attack"},{"paperId":"e1b41796b752d6fb6032bbad2f8998302209d79b","externalIds":{"DBLP":"journals/fcsc/DongYCSM20","MAG":"2970602317","DOI":"10.1007/s11704-019-8208-z","CorpusId":201667785},"title":"A survey on ensemble learning"},{"paperId":"0090023afc66cd2741568599057f4e82b566137c","externalIds":{"ArXiv":"1908.09635","MAG":"2969896603","DBLP":"journals/csur/MehrabiMSLG21","DOI":"10.1145/3457607","CorpusId":201666566},"title":"A Survey on Bias and Fairness in Machine Learning"},{"paperId":"0f1c5ff810cfa581dc0b2f786d1ced065e4c7fc1","externalIds":{"MAG":"2953030092","DBLP":"journals/tdsc/LiangQXOL21","DOI":"10.1109/TDSC.2019.2922958","CorpusId":196182136},"title":"Efficient and Secure Decision Tree Classification for Cloud-Assisted Online Diagnosis Services"},{"paperId":"d9f1f536c67e650992ec4afd66166740f860c99b","externalIds":{"MAG":"2953303875","DBLP":"journals/access/YurtseverLCT20","ArXiv":"1906.05113","DOI":"10.1109/ACCESS.2020.2983149","CorpusId":186206717},"title":"A Survey of Autonomous Driving: Common Practices and Emerging Technologies"},{"paperId":"e71cd563f3e97f58803e2c871a8ab179994cc23e","externalIds":{"MAG":"3017227509","DBLP":"journals/tnn/ChaturvediG21","ArXiv":"1906.04606","DOI":"10.1109/TNNLS.2020.2984972","CorpusId":184487960,"PubMed":"32310805"},"title":"Mimic and Fool: A Task-Agnostic Adversarial Attack"},{"paperId":"28ad018c39d1578bea84e7cedf94459e3dbe1e70","externalIds":{"DBLP":"conf/cvpr/MarinoRFM19","ArXiv":"1906.00067","MAG":"2947312908","DOI":"10.1109/CVPR.2019.00331","CorpusId":173991173},"title":"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"},{"paperId":"65fd9ded2c411d90bcf6d38132463797754d2d21","externalIds":{"MAG":"2915002466","ArXiv":"1905.07121","DBLP":"conf/icml/GuoGYWW19","CorpusId":86541092},"title":"Simple Black-box Adversarial Attacks"},{"paperId":"bbb9f5378eac3eb8245cbd0f998a95cef2954508","externalIds":{"DBLP":"journals/tmm/XiaoWDXP19","MAG":"2943885184","DOI":"10.1109/TMM.2019.2915033","CorpusId":164350363},"title":"Deep Hierarchical Encoder–Decoder Network for Image Captioning"},{"paperId":"49b64383fe36268410c430352637ed23b16820c5","externalIds":{"DBLP":"journals/corr/abs-1807-01697","MAG":"2963060032","ArXiv":"1903.12261","CorpusId":56657912},"title":"Benchmarking Neural Network Robustness to Common Corruptions and Perturbations"},{"paperId":"e24b8a9531573d284647239affc6c855505b0de4","externalIds":{"MAG":"2946331775","DBLP":"conf/ccs/HuangJNRT11","DOI":"10.1145/2046684.2046692","CorpusId":623013},"title":"Adversarial machine learning"},{"paperId":"fd3d94fac6a282414406716040b10c1746634ecd","externalIds":{"DBLP":"journals/tip/YangZABHSJ18","MAG":"2887712318","DOI":"10.1109/TIP.2018.2855422","CorpusId":51629981,"PubMed":"30010568"},"title":"Video Captioning by Adversarial LSTM"},{"paperId":"869fdb53a40290a3941fd6ab808835e9b5184d62","externalIds":{"MAG":"2893554781","DBLP":"journals/corr/abs-1810-00069","ArXiv":"1810.00069","CorpusId":52901134},"title":"Adversarial Attacks and Defences: A Survey"},{"paperId":"1879d6b29eee6efab8f6217a7a6f47ec04f25b3e","externalIds":{"ArXiv":"1809.04790","DBLP":"journals/tnn/0002L20","MAG":"2891828758","DOI":"10.1109/TNNLS.2019.2933524","CorpusId":52269752,"PubMed":"31722487"},"title":"Adversarial Examples: Opportunities and Challenges"},{"paperId":"51c741acb1cf73eaed1c0e496ccc150bd8926939","externalIds":{"MAG":"2886848602","DBLP":"journals/mti/BakatorR18","DOI":"10.3390/MTI2030047","CorpusId":52243686},"title":"Deep Learning and Medical Diagnosis: A Review of Literature"},{"paperId":"b862efa06baea0b032214675eb3c3645d5d69d46","externalIds":{"ArXiv":"1807.04457","DBLP":"journals/corr/abs-1807-04457","MAG":"2951006199","CorpusId":49672236},"title":"Query-Efficient Hard-label Black-box Attack: An Optimization-based Approach"},{"paperId":"a4d513cfc9d4902ef1a80198582f29b8ba46ac28","externalIds":{"MAG":"2787887017","ArXiv":"1802.07228","DBLP":"journals/corr/abs-1802-07228","DOI":"10.17863/CAM.22520","CorpusId":3385567},"title":"The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation"},{"paperId":"03a507a0876c7e1a26608358b1a9dd39f1eb08e0","externalIds":{"MAG":"2950473291","DBLP":"journals/corr/abs-1712-07107","ArXiv":"1712.07107","DOI":"10.1109/TNNLS.2018.2886017","CorpusId":21569987,"PubMed":"30640631"},"title":"Adversarial Examples: Attacks and Defenses for Deep Learning"},{"paperId":"2c20e7220269b28fb1935a83d0e7f2db330aa691","externalIds":{"ArXiv":"1712.03141","DBLP":"journals/corr/abs-1712-03141","MAG":"2963359529","DOI":"10.1016/j.patcog.2018.07.023","CorpusId":53107276},"title":"Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning"},{"paperId":"0c0f41d3162e76500d4639557ff4463bd246e395","externalIds":{"MAG":"2962980263","DBLP":"journals/tnn/YuYXFT18","ArXiv":"1708.03619","DOI":"10.1109/TNNLS.2018.2817340","CorpusId":6284110,"PubMed":"29993847"},"title":"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering"},{"paperId":"135bafc83e9a73c88e759f98a28edfdb5c02f81d","externalIds":{"DBLP":"journals/corr/ZhaoWYOC17","MAG":"2951685111","ArXiv":"1707.09457","ACL":"D17-1323","DOI":"10.18653/v1/D17-1323","CorpusId":1389483},"title":"Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints"},{"paperId":"7aa38b85fa8cba64d6a4010543f6695dbf5f1386","externalIds":{"DBLP":"conf/iclr/MadryMSTV18","MAG":"2952649158","ArXiv":"1706.06083","CorpusId":3488815},"title":"Towards Deep Learning Models Resistant to Adversarial Attacks"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"136dee73f203df2f4831994bf4f0c0a4ad2e764e","externalIds":{"MAG":"2952396876","DBLP":"journals/corr/TramerKPBM17","ArXiv":"1705.07204","CorpusId":21946795},"title":"Ensemble Adversarial Training: Attacks and Defenses"},{"paperId":"5c39e37022661f81f79e481240ed9b175dec6513","externalIds":{"MAG":"2594475271","ArXiv":"1702.08608","CorpusId":11319376},"title":"Towards A Rigorous Science of Interpretable Machine Learning"},{"paperId":"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e","externalIds":{"MAG":"3016211260","DBLP":"conf/cvpr/GoyalKSBP17","ArXiv":"1612.00837","DOI":"10.1007/s11263-018-1116-0","CorpusId":8081284},"title":"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"},{"paperId":"99e5a8c10cf92749d4a7c2949691c3a6046e499a","externalIds":{"ArXiv":"1611.02770","DBLP":"conf/iclr/LiuCLS17","MAG":"2570685808","CorpusId":17707860},"title":"Delving into Transferable Adversarial Examples and Black-box Attacks"},{"paperId":"e2a85a6766b982ff7c8980e57ca6342d22493827","externalIds":{"DBLP":"conf/iclr/KurakinGB17","ArXiv":"1611.01236","MAG":"2552767274","CorpusId":9059612},"title":"Adversarial Machine Learning at Scale"},{"paperId":"16aa01ca0834a924c25faad5d8bfef3fd1acfcfe","externalIds":{"DBLP":"conf/cvpr/Moosavi-Dezfooli17","MAG":"2543927648","ArXiv":"1610.08401","DOI":"10.1109/CVPR.2017.17","CorpusId":11558223},"title":"Universal Adversarial Perturbations"},{"paperId":"75a760c6bd5ae15e0fc489a074bc42bc1fc4e697","externalIds":{"DBLP":"journals/corr/Shalev-ShwartzS16a","MAG":"2530849036","ArXiv":"1610.03295","CorpusId":5136932},"title":"Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving"},{"paperId":"df40ce107a71b770c9d0354b78fdd8989da80d2f","externalIds":{"DBLP":"conf/sp/Carlini017","MAG":"2951755642","ArXiv":"1608.04644","DOI":"10.1109/SP.2017.49","CorpusId":2893830},"title":"Towards Evaluating the Robustness of Neural Networks"},{"paperId":"ccf6a69a7f33bcf052aa7def176d3b9de495beb7","externalIds":{"DBLP":"conf/nips/BolukbasiCZSK16","MAG":"2950018712","ArXiv":"1607.06520","CorpusId":1704893},"title":"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings"},{"paperId":"21a0b0fbdde1aee56fe10e69e897decaf21f43a6","externalIds":{"MAG":"2149479912","DBLP":"journals/focm/NesterovS17","DOI":"10.1007/s10208-015-9296-2","CorpusId":2147817},"title":"Random Gradient-Free Minimization of Convex Functions"},{"paperId":"11c9c31dff70de92ada9160c78ff8bb46b2912d6","externalIds":{"ArXiv":"1505.04870","DBLP":"conf/iccv/PlummerWCCHL15","MAG":"2568262903","DOI":"10.1007/s11263-016-0965-7","CorpusId":6941275},"title":"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"},{"paperId":"bee044c8e8903fb67523c1f8c105ab4718600cdb","externalIds":{"MAG":"2952181735","DBLP":"journals/corr/GoodfellowSS14","ArXiv":"1412.6572","CorpusId":6706414},"title":"Explaining and Harnessing Adversarial Examples"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","externalIds":{"ArXiv":"1405.0312","DBLP":"conf/eccv/LinMBHPRDZ14","MAG":"2952122856","DOI":"10.1007/978-3-319-10602-1_48","CorpusId":14113767},"title":"Microsoft COCO: Common Objects in Context"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","externalIds":{"DBLP":"conf/cvpr/DengDSLL009","MAG":"2108598243","DOI":"10.1109/CVPR.2009.5206848","CorpusId":57246310},"title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"26ebc279dbbbfabab68b613e557ebcb751dd81f7","externalIds":{"MAG":"1511039991","CorpusId":106859522},"title":"The Art of Deception: Controlling the Human Element of Security"},{"paperId":"3e13233616ba62ed0bc1f3147b4f42a2f10d1f44","externalIds":{"DBLP":"conf/eccv/TuCWZZHZYX24","DOI":"10.1007/978-3-031-72983-6_3","CorpusId":274024013},"title":"How Many Are in This Image A Safety Evaluation Benchmark for Vision LLMs"},{"paperId":"7f0afe1b627c627e05df73777722638e81879569","externalIds":{"DBLP":"conf/nips/LiuYQ0FT0024","DOI":"10.52202/079017-1652","CorpusId":276185020},"title":"Pandora's Box: Towards Building Universal Attackers against Real-World Large Vision-Language Models"},{"paperId":"220cbecab2fbafbffaf0b90c7bd6bcac009b713c","externalIds":{"DBLP":"conf/secrypt/MoghtadaieeFA24","DOI":"10.5220/0012863100003767","CorpusId":271164645},"title":"Membership Inference Attacks Against Indoor Location Models"},{"paperId":"5ddb51ae85deca14dc7fc8adc07305c22a1ebe0a","externalIds":{"DBLP":"journals/corr/abs-2308-12966","DOI":"10.48550/arXiv.2308.12966","CorpusId":263875678},"title":"Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities"},{"paperId":"6b17231df7cc4c30fa5e1ea7eb9df0d4875caeac","externalIds":{"DBLP":"journals/corr/abs-2312-10766","DOI":"10.48550/arXiv.2312.10766","CorpusId":271325522},"title":"A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection"},{"paperId":"144b8d9c10ea111598aa239100cd6ed5c6137b1c","externalIds":{"DOI":"10.37190/arc220310","CorpusId":269701869},"title":"Artificial intelligence as part of future practices in the architect’s work: MidJourney generative tool as part of a process of creating an architectural form"},{"paperId":"e7c642fbbe31fea90cf3c643c380e354c20d9aa4","externalIds":{"MAG":"2970987681","DBLP":"conf/nips/WangJLWJ19","CorpusId":202775285},"title":"Transferable Normalization: Towards Improving Transferability of Deep Neural Networks"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"}]}