{"paperId":"022b3d5f684dd6e1b74e0455b5b78a3986c8b69f","externalIds":{"DBLP":"journals/corr/abs-2205-07417","ArXiv":"2205.07417","DOI":"10.48550/arXiv.2205.07417","CorpusId":248811283},"title":"Transformers in 3D Point Clouds: A Survey","openAccessPdf":{"url":"http://arxiv.org/pdf/2205.07417","status":"GREEN","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2205.07417, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"137293231","name":"Dening Lu"},{"authorId":"47245198","name":"Qian Xie"},{"authorId":"1806122","name":"Mingqiang Wei"},{"authorId":"2430221","name":"Linlin Xu"},{"authorId":null,"name":"Jonathan Li"}],"abstract":"Transformers have been at the heart of the Natural Language Processing (NLP) and Computer Vision (CV) revolutions. The significant success in NLP and CV inspired exploring the use of Transformers in point cloud processing. However, how do Transformers cope with the irregularity and unordered nature of point clouds? How suitable are Transformers for different 3D representations (e.g., point- or voxel-based)? How competent are Transformers for various 3D processing tasks? As of now, there is still no systematic survey of the research on these issues. For the first time, we provided a comprehensive overview of increasingly popular Transformers for 3D point cloud analysis. We start by introducing the theory of the Transformer architecture and reviewing its applications in 2D/3D fields. Then, we present three different taxonomies (i.e., implementation-, data representation-, and task-based), which can classify current Transformer-based methods from multiple perspectives. Furthermore, we present the results of an investigation of the variants and improvements of the self-attention mechanism in 3D. To demonstrate the superiority of Transformers in point cloud analysis, we present comprehensive comparisons of various Transformer-based methods for classification, segmentation, and object detection. Finally, we suggest three potential research directions, providing benefit references for the development of 3D Transformers."}