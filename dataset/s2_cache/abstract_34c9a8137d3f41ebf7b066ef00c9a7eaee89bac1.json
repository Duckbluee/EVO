{"abstract":"Graph neural networks (GNNs) have become a practical paradigm for learning graph-structured data, which can generate node representations by recursively aggregating information from neighbor nodes. Recent works utilize self-supervised tasks to learn transferable knowledge from source domain graphs and improve the GNNs performance on target domain graphs. However, there are considerable low-quality and incorrect-labeled graphs in the source domain, which leads to the negative transfer problem in target domain graphs. To tackle this challenge, we propose RSS-GNN, a reinforced sample selection for GNNs transfer learning. The critical insight is that RSS-GNN attempts to use reinforcement learning (RL) to guide transfer learning and narrow the graph divergence between the source and the target domain. We leverage a selection distribution generator (SDG) to produce the probability for each graph and select high-quality graphs to train GNNs. We innovatively designed a reward mechanism to measure the quality of the selection process and employ the policy gradient to update SDG parameters. Extensive experiments demonstrate that our approach can be compatible with various GNNs frameworks and yields superior performance compared to state-of-the-art methods."}