{"abstract":"Source-free model adaptation (SFMA) plays an important role in robust robot automation, which aims to mitigate distributional inconsistency between source and target data while avoiding accessing source data. SFMA methods generally benefit from self-training, which can be prone to overfitting noisy pseudo labels. Previous methods used various techniques to filter out noisy predictions and improve self-training performance. Nonetheless, the filtering is heavily reliant on pre-defined thresholds and suffers from a class imbalance problem, resulting in a bias towards the majority classes and poor performance of the other classes. Aiming at this pitfall, this study proposes to combat the noisy pseudo labels via multi-level perturbation, which involves all the pseudo predictions in self-training. The proposed method introduces different perturbations at three different levels: input, feature, and model. These perturbations boost the diversity of training data and increase the difficulty of fitting pseudo labels, which avoids overfitting the noise without ignoring the minority classes. Besides, the proposed method helps mitigate the intra-domain gap by maximizing the consistency between the original predictions and the perturbed predictions. Experimental results on two domain adaptive segmentation benchmarks confirm the effectiveness of the proposed method, which outperforms state-of-the-art SFMA methods."}