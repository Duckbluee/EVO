{"references":[{"paperId":"028f32e1e00c47c7eadc2683835f9b82ebefdb22","externalIds":{"DBLP":"conf/mm/LiHWCH24","DOI":"10.1145/3664647.3681002","CorpusId":273642705},"title":"AerialGait: Bridging Aerial and Ground Views for Gait Recognition"},{"paperId":"948e1b6382a5ea54f72b38880b267ac6e7dbc978","externalIds":{"DBLP":"conf/miccai/ZhouLPFAY24","ArXiv":"2407.05726","DOI":"10.48550/arXiv.2407.05726","CorpusId":271051151},"title":"Gait Patterns as Biomarkers: A Video-Based Approach for Classifying Scoliosis"},{"paperId":"ebe299c6ab25b0f5a514eda38ec833beb4dd7d60","externalIds":{"DBLP":"conf/cvpr/Ma0CHHZ24","DOI":"10.1109/CVPR52733.2024.00063","CorpusId":272725064},"title":"Learning Visual Prompt for Gait Recognition"},{"paperId":"a41edc6680ac736b57e77808228f78a31b7a82c5","externalIds":{"ArXiv":"2404.04120","DBLP":"journals/corr/abs-2404-04120","DOI":"10.1109/IJCB62174.2024.10744428","CorpusId":268987651},"title":"Cross-Modality Gait Recognition: Bridging LiDAR and Camera Modalities for Human Identification"},{"paperId":"6edd8d55f35931f4d8f9130a5a6db430560309f9","externalIds":{"ArXiv":"2402.19122","DBLP":"journals/corr/abs-2402-19122","DOI":"10.1109/CVPR52733.2024.00027","CorpusId":268063326},"title":"BigGait: Learning Gait Representation You Want by Large Vision Models"},{"paperId":"806d3cd6af4036b314e9534f2c411069118ce5d2","externalIds":{"ArXiv":"2407.03632","DBLP":"journals/tip/DouZZJL25","DOI":"10.1109/TIP.2024.3360870","CorpusId":267722326,"PubMed":"38363666"},"title":"CLASH: Complementary Learning With Neural Architecture Search for Gait Recognition"},{"paperId":"ef60c7a8224783531317b9fe76c8edd3968add8a","externalIds":{"DBLP":"journals/corr/abs-2401-13531","ArXiv":"2401.13531","DOI":"10.48550/arXiv.2401.13531","CorpusId":267199880},"title":"QAGait: Revisit Gait Recognition from a Quality Perspective"},{"paperId":"e43e1d43f99b503ddb3450db87ee604cd893b1c1","externalIds":{"ArXiv":"2401.00271","DBLP":"journals/corr/abs-2401-00271","DOI":"10.48550/arXiv.2401.00271","CorpusId":266693917},"title":"HybridGait: A Benchmark for Spatial-Temporal Cloth-Changing Gait Recognition with Hybrid Explorations"},{"paperId":"450d8d35d3508af3c92b339064292df6c5312f04","externalIds":{"DBLP":"conf/aaai/Zou0XS0024","ArXiv":"2312.14404","DOI":"10.48550/arXiv.2312.14404","CorpusId":266520895},"title":"Cross-Covariate Gait Recognition: A Benchmark"},{"paperId":"a96161e23da158554902391d78014a155af981ff","externalIds":{"DBLP":"journals/corr/abs-2312-02290","ArXiv":"2312.02290","DOI":"10.1109/WACV57701.2024.00579","CorpusId":265658931},"title":"You Can Run but not Hide: Improving Gait Recognition with Intrinsic Occlusion Type Awareness"},{"paperId":"b460fe50ab5f44f6c5dfca5c1a27415bce06b61d","externalIds":{"DBLP":"journals/corr/abs-2311-13444","ArXiv":"2311.13444","DOI":"10.48550/arXiv.2311.13444","CorpusId":265352034},"title":"SkeletonGait: Gait Recognition Using Skeleton Maps"},{"paperId":"fcad06eb8444f2337dd4369b84e3e3ad16764366","externalIds":{"DBLP":"journals/pr/CastroDHMG24","DOI":"10.1016/j.patcog.2023.110171","CorpusId":265640382},"title":"AttenGait: Gait recognition with attention and rich modalities"},{"paperId":"ea23173c4d378275c43543d36fe0562cbe495b05","externalIds":{"DBLP":"conf/mm/WangHZLCHX23","DOI":"10.1145/3581783.3611840","CorpusId":264492808},"title":"LandmarkGait: Intrinsic Human Parsing for Gait Recognition"},{"paperId":"8e0f83cab54a97195676a24111d70db4175f052d","externalIds":{"DBLP":"conf/mm/WangH0CLH023","DOI":"10.1145/3581783.3612124","CorpusId":264492610},"title":"Causal Intervention for Sparse-View Gait Recognition"},{"paperId":"785fcecd694b8ff94b5942472f6843bdec0d6590","externalIds":{"DBLP":"conf/iccv/GuoJ23","DOI":"10.1109/ICCV51070.2023.01798","CorpusId":267021462},"title":"Physics-Augmented Autoencoder for 3D Skeleton-Based Gait Recognition"},{"paperId":"1a6fd33630303d785013ef95dfb1ab676e5d675e","externalIds":{"DBLP":"conf/icb/ZouXFYT23","ArXiv":"2312.14410","DOI":"10.1109/IJCB57857.2023.10449290","CorpusId":266521453},"title":"A Multi-Stage Adaptive Feature Fusion Neural Network for Multimodal Gait Recognition"},{"paperId":"7550968c83d97dcbded11e2039008a796b9a34c8","externalIds":{"DBLP":"conf/icb/WangSFHY23","DOI":"10.1109/IJCB57857.2023.10448817","CorpusId":268097044},"title":"PointGait: Boosting End-to-End 3D Gait Recognition with Point Clouds via Spatiotemporal Modeling"},{"paperId":"0ef4d20938d654292abed5700de6d9254ff17b0f","externalIds":{"DBLP":"journals/corr/abs-2308-16739","ArXiv":"2308.16739","DOI":"10.1145/3581783.3612052","CorpusId":261395515},"title":"Parsing is All You Need for Accurate Gait Recognition in the Wild"},{"paperId":"d32c48bd48b3e416b7a71ef52e3e1469916d9f4c","externalIds":{"DBLP":"conf/icb/SunFMHN23","ArXiv":"2308.13340","DOI":"10.1109/IJCB57857.2023.10448786","CorpusId":261214648},"title":"TriGait: Aligning and Fusing Skeleton and Silhouette Gait Data via a Tri-Branch Network"},{"paperId":"4c8594c411e9f53002e3863943190bcf3af39693","externalIds":{"DBLP":"conf/eccv/WangHHCLHZW24","ArXiv":"2308.11487","DOI":"10.48550/arXiv.2308.11487","CorpusId":261065198},"title":"Free Lunch for Gait Recognition: A Novel Relation Descriptor"},{"paperId":"081f883401a573bfedb37586d7ebd735daaa7d3c","externalIds":{"DBLP":"conf/fgr/CatrunaCR24b","ArXiv":"2308.10623","DOI":"10.1109/FG59268.2024.10581947","CorpusId":261048879},"title":"GaitPT: Skeletons are All You Need for Gait Recognition"},{"paperId":"46e25cde2740b54cba87fa896e5a0a18b55d0819","externalIds":{"DBLP":"journals/nca/SunLFN24","ArXiv":"2307.15981","DOI":"10.1007/s00521-024-09445-z","CorpusId":260334653},"title":"GaitASMS: gait recognition by adaptive structured spatial representation and multi-scale temporal aggregation"},{"paperId":"dd06611472c85856e5f6e5770cb136fd4f187699","externalIds":{"ArXiv":"2307.14713","DBLP":"journals/corr/abs-2307-14713","DOI":"10.1109/IJCB57857.2023.10449102","CorpusId":260203219},"title":"GaitMorph: Transforming Gait by Optimally Transporting Discrete Codes"},{"paperId":"ee65ab0c905cb1f534cd0050b187df966eaeefe9","externalIds":{"DBLP":"conf/iccv/WangLLW23","ArXiv":"2307.09856","DOI":"10.48550/arXiv.2307.09856","CorpusId":259982854},"title":"Hierarchical Spatio-Temporal Representation Learning for Gait Recognition"},{"paperId":"1f3d4f4a051e80ef4c16eec95bc7abf030cdc624","externalIds":{"DBLP":"conf/wacv/HabibBSBD24","ArXiv":"2307.06751","DOI":"10.1109/WACV57701.2024.00600","CorpusId":259847749},"title":"Watch Where You Head: A View-biased Domain Gap in Gait Recognition and Unsupervised Adaptation"},{"paperId":"2e12aced0a620194b6c68e1b193e8dab508a4b0d","externalIds":{"DBLP":"conf/eccv/DouZSYL22","ArXiv":"2306.03445","DOI":"10.1007/978-3-031-20065-6_21","CorpusId":253448299},"title":"MetaGait: Learning to Learn an Omni Sample Adaptive Representation for Gait Recognition"},{"paperId":"b1a6f0c2a13305349ac50ca4ef421686cbf0c798","externalIds":{"DBLP":"conf/icassp/LiZSZ23","DOI":"10.1109/ICASSP49357.2023.10096602","CorpusId":258544516},"title":"Gaitcotr: Improved Spatial-Temporal Representation for Gait Recognition with a Hybrid Convolution-Transformer Framework"},{"paperId":"46906033176d2451c15d31d7e88496f3c244057c","externalIds":{"DBLP":"conf/cvpr/DouZSYL023","ArXiv":"2306.03428","DOI":"10.1109/CVPR52729.2023.00540","CorpusId":259088614},"title":"GaitGCI: Generative Counterfactual Intervention for Gait Recognition"},{"paperId":"33fa9cef3ce06ff8e55ae33524f9c2a6dce957ac","externalIds":{"DBLP":"conf/cvpr/LiHZC0HZ23","DOI":"10.1109/CVPR52729.2023.01328","CorpusId":261080674},"title":"An In-Depth Exploration of Person Re-Identification and Gait Recognition in Cloth-Changing Conditions"},{"paperId":"8f23428b39e6eb32b9997d0bd02eda65ecbd32e7","externalIds":{"DBLP":"conf/cvpr/MaFZCHH23","DOI":"10.1109/CVPR52729.2023.02114","CorpusId":261080958},"title":"Dynamic Aggregated Network for Gait Recognition"},{"paperId":"9224d6b00155f4a99a224597a2b9cf0cce90fd30","externalIds":{"DBLP":"conf/cvpr/CuiK23","DOI":"10.1109/CVPR52729.2023.01721","CorpusId":259834653},"title":"Multi-modal Gait Recognition via Effective Spatial-Temporal Feature Fusion"},{"paperId":"d4f1fa05945803470281dd09180f64384f2c9f81","externalIds":{"DBLP":"journals/corr/abs-2304-07916","ArXiv":"2304.07916","DOI":"10.1109/IJCB57857.2023.10448634","CorpusId":258181177},"title":"GaitRef: Gait Recognition with Refined Sequential Skeletons"},{"paperId":"db6381d071a6e4e35e57f394ee8098a943e11c2b","externalIds":{"DBLP":"journals/tbbis/HouFC0H23","DOI":"10.1109/TBIOM.2022.3216857","CorpusId":253345283},"title":"A Comprehensive Study on the Evaluation of Silhouette-Based Gait Recognition"},{"paperId":"1a6cb0add0649e550e58ffef38cf5a9813af79bd","externalIds":{"DBLP":"conf/iccv/WangGLYZLZ023","ArXiv":"2303.14953","DOI":"10.48550/arXiv.2303.14953","CorpusId":257767433},"title":"DyGait: Exploiting Dynamic Representations for High-performance Gait Recognition"},{"paperId":"7c9d7342300a3ec72788c7617099c4d469b9f353","externalIds":{"ArXiv":"2303.05234","DBLP":"conf/iccv/FuMHHH23","DOI":"10.1109/ICCV51070.2023.01795","CorpusId":257427485},"title":"GPGait: Generalized Pose-based Gait Recognition"},{"paperId":"6e8c7180c2abf9a7e21f904b5171a1951e3f1f1d","externalIds":{"ArXiv":"2303.03301","DBLP":"journals/corr/abs-2303-03301","DOI":"10.48550/arXiv.2303.03301","CorpusId":257365830},"title":"Exploring Deep Models for Practical Gait Recognition"},{"paperId":"2e6c233c647f5e7cc4896535b47ffeca8542b84a","externalIds":{"DBLP":"journals/isci/ChenWZZZC23","DOI":"10.1016/j.ins.2023.03.145","CorpusId":257845190},"title":"GaitAMR: Cross-view gait recognition via aggregated multi-feature representation"},{"paperId":"842770e85920439bbfc0a8d1792e840ebf731da6","externalIds":{"DBLP":"journals/tbbis/HuangWHHLF23","DOI":"10.1109/TBIOM.2022.3211843","CorpusId":252809693},"title":"STAR: Spatio-Temporal Augmented Relation Network for Gait Recognition"},{"paperId":"db568120efec323751463f0dd79f459024609027","externalIds":{"ArXiv":"2212.09042","DBLP":"conf/wacv/ZhuZN23","DOI":"10.1109/WACV56688.2023.00097","CorpusId":254854313},"title":"Gait Recognition Using 3-D Human Body Shape Inference"},{"paperId":"6145537cf7824b78880fe95428fea966009542ff","externalIds":{"DBLP":"journals/corr/abs-2211-11155","ArXiv":"2211.11155","DOI":"10.48550/arXiv.2211.11155","CorpusId":253734306},"title":"From Indoor To Outdoor: Unsupervised Domain Adaptive Gait Recognition"},{"paperId":"6ba71ec368fbbff09bdf9935f4ede5e8a3af9520","externalIds":{"ArXiv":"2211.10598","DBLP":"journals/corr/abs-2211-10598","DOI":"10.1109/CVPR52729.2023.00108","CorpusId":253734591},"title":"LidarGait: Benchmarking 3D Gait Recognition with Point Clouds"},{"paperId":"5ef92bd01b01fdb42660c6ef2dd5580993d6d92b","externalIds":{"ArXiv":"2211.06597","DBLP":"journals/corr/abs-2211-06597","DOI":"10.1109/CVPR52729.2023.00936","CorpusId":253510828},"title":"OpenGait: Revisiting Gait Recognition Toward Better Practicality"},{"paperId":"b837ddcb3c0df2c0305d7cd0ef86fe82d459d7cf","externalIds":{"DBLP":"conf/icassp/PinyoanuntapongAWLC23","ArXiv":"2210.15491","DOI":"10.1109/ICASSP49357.2023.10096917","CorpusId":253157413},"title":"Gaitmixer: Skeleton-Based Gait Representation Learning Via Wide-Spectrum Multi-Axial Mixer"},{"paperId":"38dd185b1e47af3fd757e93a54cb8fa2d50afbf0","externalIds":{"ArXiv":"2210.11817","DBLP":"conf/icassp/LiGZSZ23","DOI":"10.1109/ICASSP49357.2023.10096571","CorpusId":255999860},"title":"Motion Matters: A Novel Motion Modeling for Cross-View Gait Feature Learning"},{"paperId":"3279563f02b4c21ceb5ae3ec54eac2ec2448f1ba","externalIds":{"DBLP":"conf/icip/ChenRCVP22","DOI":"10.1109/ICIP46576.2022.9897558","CorpusId":253331167},"title":"Gaitpoint: A Gait Recognition Network Based on Point Cloud Analysis"},{"paperId":"55ce333192d2b40f1014116e195a343e256c3f3c","externalIds":{"DBLP":"journals/tbbis/ChenWYZHZ22","DOI":"10.1109/TBIOM.2022.3213545","CorpusId":252858764},"title":"Gait Pyramid Attention Network: Toward Silhouette Semantic Relation Learning for Gait Recognition"},{"paperId":"f85ec60edfb1dd1bfd4f72e8b8efc683302ea475","externalIds":{"DBLP":"journals/tcsv/FuHZMXZ22","DOI":"10.1109/TCSVT.2022.3173263","CorpusId":248682169},"title":"Cross-Modal Cross-Domain Dual Alignment Network for RGB-Infrared Person Re-Identification"},{"paperId":"6826a21e4b22744392beb8067a027abdc83b638c","externalIds":{"DBLP":"journals/tcsv/HuangBGZYW22","DOI":"10.1109/TCSVT.2022.3175959","CorpusId":248901453},"title":"Enhanced Spatial-Temporal Salience for Cross-View Gait Recognition"},{"paperId":"53ab864d2a5182e2a517b9ad31a43c0d91d7c6e1","externalIds":{"ArXiv":"2209.11577","DBLP":"journals/corr/abs-2209-11577","DOI":"10.1109/TIFS.2023.3254449","CorpusId":252519246},"title":"Toward Complete-View and High-Level Pose-Based Gait Recognition"},{"paperId":"ce8d62e2bcc49fc8b31002158dcd9f4592c0c903","externalIds":{"DBLP":"journals/corr/abs-2209-00355","ArXiv":"2209.00355","DOI":"10.1145/3503161.3547897","CorpusId":251979780},"title":"Gait Recognition in the Wild with Multi-hop Temporal Switch"},{"paperId":"0049cd3930f0bfe3f5a899ea4d802dde4da90ad1","externalIds":{"DBLP":"journals/tomccap/ZhangDZZQHFL23","DOI":"10.1145/3517199","CorpusId":250925660},"title":"A Large-Scale Synthetic Gait Dataset Towards in-the-Wild Simulation and Comparison Study"},{"paperId":"515d5ba63ac535393d20fd5e7bc4d07698353ea8","externalIds":{"DBLP":"journals/corr/abs-2207-03608","ArXiv":"2207.03608","DOI":"10.1109/ICIP46576.2022.9897409","CorpusId":250407829},"title":"GAITTAKE: Gait Recognition by Temporal Attention and Keypoint-Guided Embedding"},{"paperId":"f7de125c24e87985d0cca0814ac2f7e9f5b82ef8","externalIds":{"DBLP":"journals/corr/abs-2206-13964","ArXiv":"2206.13964","DOI":"10.1109/TPAMI.2023.3312419","CorpusId":250089142,"PubMed":"37672380"},"title":"Learning Gait Representation From Massive Unlabelled Walking Videos: A Benchmark"},{"paperId":"b71b3feb903e9b07fc02e1896ae421e7e94aee5a","externalIds":{"DBLP":"journals/pami/SongHWW23","DOI":"10.1109/TPAMI.2022.3183288","CorpusId":249676544,"PubMed":"35704543"},"title":"CASIA-E: A Large Comprehensive Dataset for Gait Recognition"},{"paperId":"13b19a8ad23cde43a6abc7caaeb15bf1a123649f","externalIds":{"DBLP":"journals/ijon/LiaoLBY22","DOI":"10.1016/j.neucom.2022.06.048","CorpusId":249801988},"title":"PoseMapGait: A model-based gait recognition method with pose estimation maps and graph convolutional networks"},{"paperId":"1bc5fd23fbe3057a4a08d4373aeb90b6426cb5be","externalIds":{"DBLP":"conf/cvpr/ChaiLZLW22","DOI":"10.1109/CVPR52688.2022.01961","CorpusId":250563955},"title":"Lagrange Motion Analysis and View Embeddings for Improved Gait Recognition"},{"paperId":"8f1d841b100ba8f1b2babe7ea864077347fe4614","externalIds":{"DBLP":"journals/corr/abs-2306-04650","ArXiv":"2306.04650","DOI":"10.1109/TIP.2022.3164543","CorpusId":248526636,"PubMed":"35511849"},"title":"GaitMPL: Gait Recognition With Memory-Augmented Progressive Learning"},{"paperId":"e9adc3f0c2f1fb7035fa23c01ae54fcd3ab759c9","externalIds":{"DBLP":"journals/apin/LiGZQG23","DOI":"10.1007/s10489-022-03543-y","CorpusId":248456181},"title":"TransGait: Multimodal-based gait recognition with set transformer"},{"paperId":"98683a4e9c66edbd6f028191273c989dbae79158","externalIds":{"ArXiv":"2204.07855","DBLP":"conf/cvpr/TeepeGHHR22","DOI":"10.1109/CVPRW56347.2022.00163","CorpusId":248228012},"title":"Towards a Deeper Understanding of Skeleton-based Gait Recognition"},{"paperId":"8a33556a6c89087904ff9ed53c3c6c6a08fcc2dd","externalIds":{"DBLP":"journals/corr/abs-2204-02569","ArXiv":"2204.02569","DOI":"10.1109/CVPR52688.2022.01959","CorpusId":247996921},"title":"Gait Recognition in the Wild with Dense 3D Representations and A Benchmark"},{"paperId":"dca4bd200f307b2bac0aea1cc373c9dfce96df2c","externalIds":{"DBLP":"journals/tnn/HouLCH23","DOI":"10.1109/TNNLS.2022.3154723","CorpusId":247499176,"PubMed":"35294358"},"title":"Gait Quality Aware Network: Toward the Interpretability of Silhouette-Based Gait Recognition"},{"paperId":"0d37b9ee052912a7f003a5fef94d0bc7bf7b1b7d","externalIds":{"ArXiv":"2203.04038","DBLP":"conf/icb/ShenLZYHY23","DOI":"10.1109/IJCB57857.2023.10449112","CorpusId":247315654},"title":"Gait Recognition with Mask-based Regularization"},{"paperId":"acb1d00459293152ddb3f9e1fb41a650b40c243e","externalIds":{"ArXiv":"2203.03972","DBLP":"journals/corr/abs-2203-03972","DOI":"10.48550/arXiv.2203.03972","CorpusId":247315347},"title":"GaitEdge: Beyond Plain End-to-end Gait Recognition for Better Practicality"},{"paperId":"4e49bb246d0e3edce4a79c2d7efaa49143e229d6","externalIds":{"DBLP":"conf/accv/WangLGLZSZLY22","ArXiv":"2203.03966","DOI":"10.48550/arXiv.2203.03966","CorpusId":247315105},"title":"GaitStrip: Gait Recognition via Effective Strip-based Feature Representations and Multi-Level Framework"},{"paperId":"30588e3af857c20464313f5032410a61e460baff","externalIds":{"ArXiv":"2202.10645","DBLP":"conf/icassp/WangHF23","DOI":"10.1109/ICASSP49357.2023.10096986","CorpusId":247778996},"title":"Combining the Silhouette and Skeleton Data for Gait Recognition"},{"paperId":"a7cc9851d78bd718e17f6fca05efa16710344952","externalIds":{"ArXiv":"2202.07123","DBLP":"conf/iclr/MaQYR022","CorpusId":246861899},"title":"Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework"},{"paperId":"221c03cddea6aa49888aecbe9729cafd35234e05","externalIds":{"ArXiv":"2201.04806","DBLP":"journals/corr/abs-2201-04806","CorpusId":245906375},"title":"RealGait: Gait Recognition for Person Re-Identification"},{"paperId":"3018e7e3c54e7d3d90cca49e4eb41c5fcada382f","externalIds":{"ArXiv":"2201.03323","DBLP":"journals/corr/abs-2201-03323","DOI":"10.1145/3490235","CorpusId":245837108},"title":"Gait Recognition Based on Deep Learning: A Survey"},{"paperId":"e587d3e7976ef97ed7b732aa562838677cf4debd","externalIds":{"DBLP":"conf/sii/AhnNYIK22","DOI":"10.1109/SII52469.2022.9708899","CorpusId":246868561},"title":"2V-Gait: Gait Recognition using 3D LiDAR Robust to Changes in Walking Direction and Measurement Distance"},{"paperId":"b22009de0cda2e956d8422a3c52c82f6eeb9e523","externalIds":{"DBLP":"journals/pr/LiQZZCWH22","DOI":"10.1016/j.patcog.2021.108453","CorpusId":244762441},"title":"GaitSlice: A gait recognition model based on spatio-temporal slice features"},{"paperId":"b666f0573bf0ad68f61cf6eb9bee01136909e090","externalIds":{"DBLP":"journals/corr/abs-2110-13408","ArXiv":"2110.13408","DOI":"10.1007/s11042-023-15483-x","CorpusId":239885959},"title":"Learning rich features for gait recognition by integrating skeletons and silhouettes"},{"paperId":"5283abb18a063baa902be87bc2c3b5bc87c66069","externalIds":{"DBLP":"journals/corr/abs-2205-02692","DOI":"10.1109/iccv48922.2021.01452","CorpusId":244906176},"title":"Gait Recognition in the Wild: A Benchmark"},{"paperId":"7e47e336b24269cb3a1fcf148716cd61476d153b","externalIds":{"DBLP":"journals/corr/abs-2204-03270","DOI":"10.1109/ICCV48922.2021.01267","CorpusId":263869803},"title":"Context-Sensitive Temporal Feature Learning for Gait Recognition"},{"paperId":"df18f502bcdc38f0537f382fea9f79f1346faa79","externalIds":{"DBLP":"conf/iccvw/LiMXY21","DOI":"10.1109/ICCVW54120.2021.00456","CorpusId":244531528},"title":"End-to-end Model-based Gait Recognition using Synchronized Multi-view Pose Constraint"},{"paperId":"e42a386929b101e0f0ec47f89837a7fc47be6fe1","externalIds":{"DBLP":"conf/iccv/HuangXS0LH021","DOI":"10.1109/ICCV48922.2021.01465","CorpusId":275583411},"title":"3D Local Convolutional Neural Networks for Gait Recognition"},{"paperId":"1a5973613a7386fa545ec42585914852468b613d","externalIds":{"MAG":"3195029041","DBLP":"conf/icip/Delgado-EscanoC21","DOI":"10.1109/ICIP42928.2021.9506162","CorpusId":238705993},"title":"Multimodal Gait Recognition Under Missing Modalities"},{"paperId":"f7a3dd2bac90224148032ea04ef3f3e0d981dcb4","externalIds":{"DBLP":"journals/corr/abs-2108-11944","ArXiv":"2108.11944","DOI":"10.1109/ICCV48922.2021.01140","CorpusId":237303794},"title":"Probabilistic Modeling for Human Mesh Recovery"},{"paperId":"f0a5d2dde8e46f7f56f0af348e4e3bde500a2b04","externalIds":{"DBLP":"journals/corr/abs-2108-05524","MAG":"3193780740","ArXiv":"2108.05524","DOI":"10.1109/ICIP42928.2021.9506238","CorpusId":236986880},"title":"Silhouette-Based View-Embeddings for Gait Recognition Under Multiple Views"},{"paperId":"b65be5fa982ee404edad0f6300a94730abf135fd","externalIds":{"DBLP":"conf/icb/MuCMGLY21","DOI":"10.1109/IJCB52358.2021.9484347","CorpusId":236185206},"title":"ReSGait: The Real-Scene Gait Dataset"},{"paperId":"3eab98fdb2db7f8c0a4f3f0db4fa1dd14c866efb","externalIds":{"DBLP":"conf/icb/YuHWMRZALYXHZ21","DOI":"10.1109/IJCB52358.2021.9484377","CorpusId":236191003},"title":"HID 2021: Competition on Human Identification at a Distance 2021"},{"paperId":"8cda54e9f4cb828d5fde2cf31ef6f146738c1578","externalIds":{"DOI":"10.1109/IHMSC52134.2021.00057","CorpusId":238478908},"title":"Hybrid Silhouette-skeleton Body Representation for Gait Recognition"},{"paperId":"9b1d36c30c39fd664ed69feb781a4c3475c79c65","externalIds":{"MAG":"3159744142","DBLP":"journals/tbbis/HouLCH21","DOI":"10.1109/TBIOM.2021.3074963","CorpusId":235718296},"title":"Set Residual Network for Silhouette-Based Gait Recognition"},{"paperId":"4e5dff8d9db8ee21b636e9bf93a2fc96999079aa","externalIds":{"DBLP":"journals/corr/abs-2106-05304","ArXiv":"2106.05304","CorpusId":235390998},"title":"Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline"},{"paperId":"761a5e04002bd22acb4ace27f5a059f259b76777","externalIds":{"DBLP":"conf/cvpr/ZhangWL21","DOI":"10.1109/CVPR46437.2021.00898","CorpusId":235726536},"title":"Cross-View Gait Recognition with Deep Universal Linear Embeddings"},{"paperId":"aec0995282db7853a9df7d520a5bfc273fc6cc3b","externalIds":{"DBLP":"journals/tbbis/JainDE22","ArXiv":"2105.06625","DOI":"10.1109/tbiom.2021.3115465","CorpusId":234680292},"title":"Biometrics: Trust, But Verify"},{"paperId":"3f954ca2193ae5a0f233feb59439f25d354ff9be","externalIds":{"DBLP":"journals/inffus/AbdullakuttyEJ21","MAG":"3157352951","DOI":"10.1016/J.INFFUS.2021.04.015","CorpusId":235505948},"title":"A review of state-of-the-art in Face Presentation Attack Detection: From early development to advanced deep learning and multi-modal fusion methods"},{"paperId":"997eb30eb3d961ed5e44d4cad61241b3750764a2","externalIds":{"DBLP":"journals/corr/abs-2103-14811","ArXiv":"2103.14811","DOI":"10.1109/ICASSP39728.2021.9413894","CorpusId":232404549},"title":"Selfgait: A Spatiotemporal Representation Learning Method for Self-Supervised Gait Recognition"},{"paperId":"af09496ce98d49480916bd6f4cc91f5fd3ac1d90","externalIds":{"DBLP":"journals/pami/Sepas-Moghaddam23","ArXiv":"2102.09546","DOI":"10.1109/TPAMI.2022.3151865","CorpusId":231951722,"PubMed":"35167443"},"title":"Deep Gait Recognition: A Survey"},{"paperId":"347278d90b63937bd157b76ccd53f5e3296de225","externalIds":{"MAG":"3128099569","ArXiv":"2102.03247","DBLP":"journals/corr/abs-2102-03247","DOI":"10.1109/TPAMI.2021.3057879","CorpusId":231839737,"PubMed":"33560976"},"title":"GaitSet: Cross-View Gait Recognition Through Utilizing Gait As a Deep Set"},{"paperId":"a4b5823837f9297b7f4812b755871ac3f967478d","externalIds":{"DBLP":"journals/tip/ChenLWLLT21","DOI":"10.1109/TIP.2021.3055936","CorpusId":231873525,"PubMed":"33544673"},"title":"Multi-View Gait Image Generation for Cross-View Gait Recognition"},{"paperId":"2d46540db73e07af19b25a02fd4468d41e63f62d","externalIds":{"ArXiv":"2101.11228","DBLP":"journals/corr/abs-2101-11228","DOI":"10.1109/ICIP42928.2021.9506717","CorpusId":231719095},"title":"Gaitgraph: Graph Convolutional Network for Skeleton-Based Gait Recognition"},{"paperId":"823a7823d01ab3db8d73ed7a5e87bbe1b28d2394","externalIds":{"DBLP":"conf/cvpr/0014RDWYMXYU21","ArXiv":"2101.06543","DOI":"10.1109/CVPR46437.2021.00715","CorpusId":234767654},"title":"GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving"},{"paperId":"6ba79e8a54b340d32e300a72af0f8695f34d563e","externalIds":{"DBLP":"journals/corr/abs-2101-02458","MAG":"3129630843","ArXiv":"2101.02458","DOI":"10.1109/TMM.2021.3060280","CorpusId":230799459},"title":"Associated Spatio-Temporal Capsule Network for Gait Recognition"},{"paperId":"3e14e5a63f747f612d1717199fdb5182d63612e2","externalIds":{"DBLP":"journals/corr/abs-2101-01394","ArXiv":"2101.01394","CorpusId":230524077},"title":"VersatileGait: A Large-Scale Synthetic Gait Dataset with Fine-GrainedAttributes and Complicated Scenarios"},{"paperId":"1fa4e1f1d117af2e37052eedb26990ccd4867925","externalIds":{"DBLP":"journals/tcsv/XuMLYL21","MAG":"3008732063","DOI":"10.1109/TCSVT.2020.2975671","CorpusId":213662795},"title":"Cross-View Gait Recognition Using Pairwise Spatial Transformer Networks"},{"paperId":"eaa325943cbbfc1bbe0390e6c0d412717fbfc8d7","externalIds":{"DBLP":"journals/tip/WuTFLL21","MAG":"3107984108","DOI":"10.1109/TIP.2020.3039888","CorpusId":227251556,"PubMed":"33259300"},"title":"Condition-Aware Comparison Scheme for Gait Recognition"},{"paperId":"e66d10808b085cc8f4ecc2167a144000ea8d9ca4","externalIds":{"DBLP":"conf/iccv/LinZ021","ArXiv":"2011.01461","MAG":"3194184585","DOI":"10.1109/ICCV48922.2021.01438","CorpusId":237108355},"title":"Gait Recognition via Effective Global-Local Feature Representation and Local Temporal Aggregation"},{"paperId":"0c99fe0538124b87789f335b99d1a7c1f34f493e","externalIds":{"MAG":"3093251642","ArXiv":"2010.09092","DBLP":"journals/tbbis/Sepas-Moghaddam21","DOI":"10.1109/TBIOM.2020.3031470","CorpusId":224704875},"title":"View-Invariant Gait Recognition With Attentive Recurrent Learning of Partial Representations"},{"paperId":"814ee76aa7f7c81a3ae71e4e227fd05b88e34fdf","externalIds":{"DBLP":"journals/corr/abs-2010-09084","ArXiv":"2010.09084","MAG":"3092824234","DOI":"10.1109/ICPR48806.2021.9412517","CorpusId":224704594},"title":"Gait Recognition using Multi-Scale Partial Representation Transformation with Capsules"},{"paperId":"a7d3b24dd73d35f358da1265709dbcab848593a5","externalIds":{"MAG":"3093108399","DBLP":"conf/mm/LinZB20","DOI":"10.1145/3394171.3413861","CorpusId":222278506},"title":"Gait Recognition with Multiple-Temporal-Scale 3D Convolutional Neural Network"},{"paperId":"c190baf3b0c006b06ecf1ed13a15e061d88abf5c","externalIds":{"ArXiv":"2009.12516","DBLP":"conf/icb/LiaoAYLH20","MAG":"3119895582","DOI":"10.1109/IJCB48548.2020.9304910","CorpusId":221970279},"title":"Dense-View GEIs Set: View Space Covering for Gait Recognition based on Dense-View GAN"},{"paperId":"71179332cef9a5d0b9cabfd5ea8bb4ac49383ee9","externalIds":{"DBLP":"journals/tjs/ElharroussAAB21","MAG":"3082981339","DOI":"10.1007/s11227-020-03409-5","CorpusId":225296336},"title":"Gait recognition for person re-identification"},{"paperId":"c9dedbe434f9acacf3bea464386550814a5b6cad","externalIds":{"DBLP":"journals/ar/YamadaAMIK20","MAG":"3043038163","DOI":"10.1080/01691864.2020.1793812","CorpusId":221468514},"title":"Gait-based person identification using 3D LiDAR and long short-term memory deep networks"},{"paperId":"a5cff23d7b569a8a2b102a0c2c9dd1d0d9e96984","externalIds":{"DBLP":"journals/tbbis/AnYMWXYLY20","MAG":"3042230461","DOI":"10.1109/TBIOM.2020.3008862","CorpusId":222070432},"title":"Performance Evaluation of Model-Based Gait on Multi-View Very Large Population Database With Pose Sequences"},{"paperId":"2b88f9137442a1b8e0626c0d4ce78b128c12f453","externalIds":{"MAG":"3035400973","DBLP":"conf/cvpr/FanPC0HCHLH20","DOI":"10.1109/CVPR42600.2020.01423","CorpusId":219634265},"title":"GaitPart: Temporal Part-Based Model for Gait Recognition"},{"paperId":"0110160545753817688e8e87be40442e712414d1","externalIds":{"MAG":"3035040255","DBLP":"conf/cvpr/LiMXYR20","DOI":"10.1109/cvpr42600.2020.01332","CorpusId":219618471},"title":"Gait Recognition via Semi-supervised Disentangled Representation Learning to Identity and Covariate Features"},{"paperId":"ace7ab0314d45a1d8ebc8f28040eff709789c1d0","externalIds":{"ArXiv":"2003.06814","DBLP":"conf/iccv/YangDP00C021","DOI":"10.1109/ICCV48922.2021.00387","CorpusId":237108370},"title":"Towards Face Encryption by Generating Adversarial Identity Masks"},{"paperId":"9ba90347cdedd122a6fc8fd3baf1d15f3911e6c2","externalIds":{"MAG":"3010699833","PubMedCentral":"7090728","DOI":"10.1007/s12098-020-03263-6","CorpusId":212682222,"PubMed":"32166607"},"title":"A Review of Coronavirus Disease-2019 (COVID-19)"},{"paperId":"57e56f456d9c60daee91ce0fcb3dd6023291b7df","externalIds":{"MAG":"3107073427","DBLP":"journals/corr/abs-2003-04232","ArXiv":"2003.04232","DOI":"10.1007/978-3-030-58520-4_45","CorpusId":212633946},"title":"Hierarchical Kinematic Human Mesh Recovery"},{"paperId":"95668b1b4f4b2a696795175493d6074476fa8474","externalIds":{"MAG":"3010159475","DBLP":"journals/sensors/Delgado-EscanoC20","PubMedCentral":"7085678","DOI":"10.3390/s20051358","CorpusId":211832410,"PubMed":"32121668"},"title":"MuPeGâ€”The Multiple Person Gait Framework"},{"paperId":"7af72a461ed7cda180e7eab878efd5f35d79bbf4","externalIds":{"DBLP":"conf/icml/ChenK0H20","MAG":"3034978746","ArXiv":"2002.05709","CorpusId":211096730},"title":"A Simple Framework for Contrastive Learning of Visual Representations"},{"paperId":"9c558abd4a150341f72541a23ee4c8b519a12bbc","externalIds":{"MAG":"3005359536","DBLP":"journals/corr/abs-2002-03353","ArXiv":"2002.03353","CorpusId":211069040},"title":"Weakly Supervised Attention Pyramid Convolutional Neural Network for Fine-Grained Visual Classification"},{"paperId":"c511b70c99cef2398b4267e3a4e767c95bab371b","externalIds":{"MAG":"2977530922","DBLP":"journals/pr/LiaoYAH20","DOI":"10.1016/j.patcog.2019.107069","CorpusId":207757561},"title":"A model-based gait recognition method with body pose and human prior knowledge"},{"paperId":"a0451bbe27749d112a093c4e11b4f80b71b7bcd7","externalIds":{"DBLP":"journals/access/JunLLLK20","MAG":"3000884041","DOI":"10.1109/ACCESS.2020.2967845","CorpusId":210993270},"title":"Feature Extraction Using an RNN Autoencoder for Skeleton-Based Abnormal Gait Recognition"},{"paperId":"df70d0431418a0f122f72af94e4bca0846c19316","externalIds":{"MAG":"2966138416","DBLP":"journals/pr/SongHHJW19","DOI":"10.1016/J.PATCOG.2019.106988","CorpusId":201254866},"title":"GaitNet: An end-to-end network for gait based human identification"},{"paperId":"2fc4aa00333b068ae522a60dde1d801acc319300","externalIds":{"MAG":"2976448465","DOI":"10.1007/978-3-030-32040-9_38","CorpusId":204103235},"title":"Benchmark RGB-D Gait Datasets: A Systematic Review"},{"paperId":"4eb674f28de8dc28cdb5a69658be3c37b89d5164","externalIds":{"MAG":"2973839564","DBLP":"journals/ijns/WangY20","DOI":"10.1142/s0129065719500278","CorpusId":203701009,"PubMed":"31747820"},"title":"Human Gait Recognition Based on Frame-by-Frame Gait Energy Images and Convolutional Long Short-Term Memory"},{"paperId":"439aca3a3d4497f822b058ccabcbfc94a83c5ee9","externalIds":{"ArXiv":"1909.03051","DBLP":"journals/corr/abs-1909-03051","MAG":"2971975167","DOI":"10.1109/tpami.2020.2998790","CorpusId":202540963,"PubMed":"32750777"},"title":"On Learning Disentangled Representations for Gait Recognition"},{"paperId":"7e850e94fb69d9233ee944cb5053d3f3504f719d","externalIds":{"MAG":"2940710034","DBLP":"journals/pr/ZhangHWY19","DOI":"10.1016/J.PATCOG.2019.04.023","CorpusId":149498114},"title":"A comprehensive study on gait biometrics using a joint CNN-based method"},{"paperId":"550be5ba6540ab36a987ba66091c0a441e0c45b5","externalIds":{"DBLP":"journals/tcsv/TakemuraMMEY19","MAG":"2760814882","DOI":"10.1109/TCSVT.2017.2760835","CorpusId":67061497},"title":"On Input/Output Architectures for Convolutional Neural Network-Based Cross-View Gait Recognition"},{"paperId":"f34d9b612a9c95d8bf647145ade7685bd98bdb06","externalIds":{"MAG":"2802841625","DBLP":"journals/prl/BattistoneP19","DOI":"10.1016/J.PATREC.2018.05.004","CorpusId":125707578},"title":"TGLSTM: A time based graph deep learning approach to gait recognition"},{"paperId":"34894c37d7d9f3fbc073c6fb864307c5cc60cab3","externalIds":{"MAG":"2966783885","DBLP":"journals/mta/KwolekMKSJW19","DOI":"10.1007/s11042-019-07945-y","CorpusId":199408705},"title":"Calibrated and synchronized multi-view video and motion capture dataset for evaluation of gait recognition"},{"paperId":"83b404d692d8a1f587cf4498dc86e8b3ca2c04f0","externalIds":{"MAG":"2955783194","DOI":"10.2307/j.ctvjghvnn","CorpusId":198604106},"title":"The California Consumer Privacy Act (CCPA)"},{"paperId":"774b82552352df1befb4cec628fee1e3ca030fd4","externalIds":{"DBLP":"conf/cvpr/WangDSWZS019","MAG":"2947930228","DOI":"10.1109/CVPR.2019.00652","CorpusId":192656293},"title":"EV-Gait: Event-Based Robust Gait Recognition Using Dynamic Vision Sensors"},{"paperId":"11ea3caa073bda645e1b31f620275aeecbe134ee","externalIds":{"MAG":"2949024437","DBLP":"conf/cvpr/ZhangL00L19","DOI":"10.1109/CVPR.2019.00483","CorpusId":195439889},"title":"Learning Joint Gait Representation via Quintuplet Loss Minimization"},{"paperId":"16080ed82a2eb928b143793120aec650c1f2ec65","externalIds":{"DBLP":"journals/tifs/LiMXYR19","MAG":"2942010964","DOI":"10.1109/TIFS.2019.2912577","CorpusId":149607925},"title":"Joint Intensity Transformer Network for Gait Recognition Robust Against Clothing and Carrying Status"},{"paperId":"f6638068266fe436029b7e4b016c74273535aade","externalIds":{"MAG":"2963854019","DBLP":"journals/corr/abs-1904-04925","ArXiv":"1904.04925","DOI":"10.1109/CVPR.2019.00484","CorpusId":115147653},"title":"Gait Recognition via Disentangled Representation Learning"},{"paperId":"e1b0a23d1795d3e99864f6660e7ec8812c9a04e3","externalIds":{"MAG":"2917231990","DBLP":"journals/ijon/WangSHWW19","DOI":"10.1016/J.NEUCOM.2019.02.025","CorpusId":106407604},"title":"Learning view invariant gait features with Two-Stream GAN"},{"paperId":"6303bac53abd725c3b458190a6abe389a4a1e72d","externalIds":{"MAG":"2949962589","ArXiv":"1902.09212","DBLP":"journals/corr/abs-1902-09212","DOI":"10.1109/CVPR.2019.00584","CorpusId":67856425},"title":"Deep High-Resolution Representation Learning for Human Pose Estimation"},{"paperId":"9e8db1519245426f3a78752a3d8360484f4626b1","externalIds":{"DBLP":"journals/corr/abs-1812-08008","MAG":"2903831537","ArXiv":"1812.08008","DOI":"10.1109/TPAMI.2019.2929257","CorpusId":198169848,"PubMed":"31331883"},"title":"OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields"},{"paperId":"8b47b9c3c35b2b2a78bff7822605b3040f87d699","externalIds":{"MAG":"2990503944","DBLP":"journals/corr/abs-1812-03982","ArXiv":"1812.03982","DOI":"10.1109/ICCV.2019.00630","CorpusId":54463801},"title":"SlowFast Networks for Video Recognition"},{"paperId":"59c47e49d8211953b1acd68984650b807ce69a71","externalIds":{"DBLP":"conf/iccv/WangDHTH19","MAG":"2982232682","DOI":"10.1109/ICCV.2019.00078","CorpusId":198968250},"title":"Racial Faces in the Wild: Reducing Racial Bias by Information Maximization Adaptation Network"},{"paperId":"cd4e1e3454d1beb3ea63ae0544927d675220db68","externalIds":{"MAG":"2788751553","DBLP":"journals/ipsjtcva/TakemuraMMEY18","DOI":"10.1186/s41074-018-0039-6","CorpusId":3431445},"title":"Multi-view large population gait dataset and its performance evaluation for cross-view gait recognition"},{"paperId":"4113a002eeb2a5548ca5dce7276fcec93f2d7124","externalIds":{"MAG":"2908986711","DBLP":"conf/dicta/YaoKWZT18","DOI":"10.1109/DICTA.2018.8615802","CorpusId":58672426},"title":"Robust CNN-based Gait Verification and Identification using Skeleton Gait Energy Image"},{"paperId":"e5cf53498bcc848e6909c3255afd6082754415ba","externalIds":{"MAG":"2952959032","DBLP":"conf/aaai/ChaoHZF19","ArXiv":"1811.06186","DOI":"10.1609/aaai.v33i01.33018126","CorpusId":53424263},"title":"GaitSet: Regarding Gait as a Set for Cross-View Gait Recognition"},{"paperId":"86fcc504c5a5fd0c3a154ddd0af9ccd1e4554cc7","externalIds":{"MAG":"2888394219","DBLP":"journals/iet-bmt/RidaAA19","DOI":"10.1049/iet-bmt.2018.5063","CorpusId":56594831},"title":"Robust gait recognition: a comprehensive survey"},{"paperId":"0f50b7483f1b200ebf88c4dd7698de986399a0f3","externalIds":{"ArXiv":"1811.12231","DBLP":"journals/corr/abs-1811-12231","MAG":"2902617128","CorpusId":54101493},"title":"ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness"},{"paperId":"e3a10973ee4e3be5fc53bee96e4d8e56469e432a","externalIds":{"DBLP":"conf/iccv/ChanGZE19","MAG":"2984529706","ArXiv":"1808.07371","DOI":"10.1109/ICCV.2019.00603","CorpusId":52070144},"title":"Everybody Dance Now"},{"paperId":"cfb829a1cd8533e569090cd582b96ef8709533a9","externalIds":{"DBLP":"conf/ccbr/AnLYHY18","MAG":"2886790699","DOI":"10.1007/978-3-319-97909-0_15","CorpusId":51952267},"title":"Improving Gait Recognition with 3D Pose Estimation"},{"paperId":"a77e9f0bd205a7733431a6d1028f09f57f9f73b0","externalIds":{"MAG":"2809440592","DBLP":"journals/corr/abs-1806-07753","ArXiv":"1806.07753","DOI":"10.1007/s00521-020-04811-z","CorpusId":49318473},"title":"Multimodal feature fusion for CNN-based gait recognition: an empirical comparison"},{"paperId":"3daba93b1342f161bd26c06286873947ff81ffdc","externalIds":{"DBLP":"journals/ipsjtcva/UddinTMTLMY18","MAG":"2807624910","DOI":"10.1186/s41074-018-0041-z","CorpusId":44159390},"title":"The OU-ISIR Large Population Gait Database with real-life carried object and its performance evaluation"},{"paperId":"133000fa446dc445ba0a2930f9629ee19a62fb35","externalIds":{"MAG":"2805132626","CorpusId":54167028},"title":"General Data Protection Regulation (GDPR)"},{"paperId":"42f9a3cc1fa6a8ea980edfdbf3fa41ef18aa4d19","externalIds":{"DBLP":"journals/corr/abs-1804-08506","MAG":"2950577757","ArXiv":"1804.08506","DOI":"10.1016/j.neucom.2019.01.091","CorpusId":5039302},"title":"Person Identification from Partial Gait Cycle Using Fully Convolutional Neural Network"},{"paperId":"c2a5f27d97744bc1f96d7e1074395749e3c59bc8","externalIds":{"MAG":"2797752778","DBLP":"conf/aaai/FuWZSHWYH19","ArXiv":"1804.05275","DOI":"10.1609/aaai.v33i01.33018295","CorpusId":4882356},"title":"Horizontal Pyramid Matching for Person Re-identification"},{"paperId":"3aa21de1a7c97e0458e10ed5730ce160bb436caa","externalIds":{"DBLP":"conf/eccv/WangZLFLJ18","ArXiv":"1804.01654","MAG":"2951939877","DOI":"10.1007/978-3-030-01252-6_4","CorpusId":4633214},"title":"Pixel2Mesh: Generating 3D Mesh Models from Single RGB Images"},{"paperId":"6c572562a906f6c94d8f2e91895c161cbb0fa4cc","externalIds":{"MAG":"2788993238","DBLP":"conf/aaai/MaoLZZL18","ArXiv":"1803.02558","DOI":"10.1609/aaai.v32i1.12225","CorpusId":3727304},"title":"Multi-Channel Pyramid Person Matching Network for Person Re-Identification"},{"paperId":"1be42f20ff086a04092b4be73e105a318ffa4322","externalIds":{"DBLP":"journals/corr/abs-1802-08122","MAG":"2788012242","ArXiv":"1802.08122","DOI":"10.1109/CVPR.2018.00243","CorpusId":3458516},"title":"Harmonious Attention Network for Person Re-identification"},{"paperId":"15e0b9ba3389a7394c6a1d267b6e06f8758ab82b","externalIds":{"DBLP":"journals/ipsjtcva/XuMOLYL17","MAG":"2777027507","DOI":"10.1186/s41074-017-0035-2","CorpusId":8207532},"title":"The OU-ISIR Gait Database comprising the Large Population Dataset with Age and performance evaluation of age estimation"},{"paperId":"83deacfb7271717dfafbf10730d2c102dcb4b711","externalIds":{"MAG":"2765328347","DBLP":"conf/ccbr/LiaoCRYH17","DOI":"10.1007/978-3-319-69923-3_51","CorpusId":22095661},"title":"Pose-Based Temporal-Spatial Network (PTSN) for Gait Recognition with Carrying and Clothing Variations"},{"paperId":"3e88cd783a05a8daaa877b21023718536acd8e5c","externalIds":{"DBLP":"conf/mm/TongLFW17","MAG":"2766232393","DOI":"10.1145/3126686.3126753","CorpusId":23396816},"title":"Cross-View Gait Identification with Embedded Learning"},{"paperId":"024d037d46ae933c7e12fd16af61953c7161773a","externalIds":{"DBLP":"journals/corr/abs-1711-10305","MAG":"2761659801","ArXiv":"1711.10305","DOI":"10.1109/ICCV.2017.590","CorpusId":6070160},"title":"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks"},{"paperId":"fd5cbf72a0cc82542b543207a9d1ea382ca7cbcf","externalIds":{"ArXiv":"1709.08325","MAG":"2760299260","DBLP":"conf/iccv/SuLZX0T17","DOI":"10.1109/ICCV.2017.427","CorpusId":1068496},"title":"Pose-Driven Deep Convolutional Model for Person Re-identification"},{"paperId":"3fd129acc56e3899df5f99691eb3e412c0649af3","externalIds":{"MAG":"2757611655","DBLP":"conf/biosig/CastroMGTB17","DOI":"10.23919/BIOSIG.2017.8053503","CorpusId":3447700},"title":"Evaluation of Cnn Architectures for Gait Recognition Based on Optical Flow Maps"},{"paperId":"2b86919eb8073d9b0e137b23cc9a14fab8bc601b","externalIds":{"DBLP":"conf/cvpr/MakiharaSMLY17","MAG":"2745659361","DOI":"10.1109/CVPR.2017.718","CorpusId":26821493},"title":"Joint Intensity and Spatial Metric Learning for Robust Gait Recognition"},{"paperId":"557619ab0c146d5526df3c18c0663a269ecaa21b","externalIds":{"DBLP":"conf/cvpr/YuCRP17","MAG":"2739325416","DOI":"10.1109/CVPRW.2017.80","CorpusId":32781194},"title":"GaitGAN: Invariant Gait Feature Extraction Using Generative Adversarial Networks"},{"paperId":"8674494bd7a076286b905912d26d47f7501c4046","externalIds":{"DBLP":"conf/nips/QiYSG17","MAG":"2950697424","ArXiv":"1706.02413","CorpusId":1745976},"title":"PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space"},{"paperId":"e79baae76381deb001a72f2b0e63095be56a660c","externalIds":{"DBLP":"journals/ijon/YuCWSH17","MAG":"2587215467","DOI":"10.1016/j.neucom.2017.02.006","CorpusId":43107221},"title":"Invariant feature extraction for gait recognition using only one uniform model"},{"paperId":"092fabf9c3eeae3578ebec1a266a3beefd438e18","externalIds":{"DBLP":"conf/cores/KhanLFG17","MAG":"2611909418","DOI":"10.1007/978-3-319-59162-9_8","CorpusId":14022092},"title":"Gait Recognition Using Motion Trajectory Analysis"},{"paperId":"0fd2f1a6da7c0fe022d172119e1eb0b7d69ecb5a","externalIds":{"DBLP":"journals/corr/Mai0YJ17","MAG":"2594825861","ArXiv":"1703.00832","DOI":"10.1109/TPAMI.2018.2827389","CorpusId":4741938,"PubMed":"29993435"},"title":"On the Reconstruction of Face Images from Deep Face Templates"},{"paperId":"5f5164cf998a10d2bef37741adb562ab07fac413","externalIds":{"DBLP":"journals/pami/WuHWWT17","MAG":"2322772590","DOI":"10.1109/TPAMI.2016.2545669","CorpusId":5854795,"PubMed":"28113278"},"title":"A Comprehensive Study on Cross-View Gait Based Human Identification with Deep CNNs"},{"paperId":"76d2422cf5db5a6a96977fc42dcdd92422c27c21","externalIds":{"ArXiv":"1701.08398","MAG":"2584637367","DBLP":"journals/corr/ZhongZCL17","DOI":"10.1109/CVPR.2017.389","CorpusId":206595765},"title":"Re-ranking Person Re-identification with k-Reciprocal Encoding"},{"paperId":"edd846e76cacfba5be37da99c006e3ccc9b861b0","externalIds":{"MAG":"2953296820","ArXiv":"1612.01925","DBLP":"conf/cvpr/IlgMSKDB17","DOI":"10.1109/CVPR.2017.179","CorpusId":3759573},"title":"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks"},{"paperId":"d997beefc0922d97202789d2ac307c55c2c52fba","externalIds":{"MAG":"2950642167","DBLP":"conf/cvpr/QiSMG17","ArXiv":"1612.00593","DOI":"10.1109/CVPR.2017.16","CorpusId":5115938},"title":"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"},{"paperId":"5ed5f368aa5ee237828f058d883eec5d489e650b","externalIds":{"DBLP":"conf/icpr/FengLL16","MAG":"2609963459","DOI":"10.1109/ICPR.2016.7899654","CorpusId":6703188},"title":"Learning effective Gait features using LSTM"},{"paperId":"36eff562f65125511b5dfab68ce7f7a943c27478","externalIds":{"ArXiv":"1609.02907","MAG":"2519887557","DBLP":"journals/corr/KipfW16","CorpusId":3144218},"title":"Semi-Supervised Classification with Graph Convolutional Networks"},{"paperId":"2c080f9543febd770d6d1988508af339b4cb614d","externalIds":{"MAG":"2517225990","DBLP":"conf/icip/WolfBR16","DOI":"10.1109/ICIP.2016.7533144","CorpusId":2489166},"title":"Multi-view gait recognition using 3D convolutional neural networks"},{"paperId":"8d3cb44072b2bfcf62ebeed862b8618f400e9093","externalIds":{"MAG":"2515630407","DBLP":"conf/icip/WangSLZ16","DOI":"10.1109/ICIP.2016.7532940","CorpusId":35861515},"title":"Gait recognition based on 3D skeleton joints captured by kinect"},{"paperId":"6fd9e3cb0cf23c8ef4aa7065d9be407c45250bff","externalIds":{"DBLP":"conf/icml/LiuWYY16","MAG":"2963656735","ArXiv":"1612.02295","CorpusId":1829423},"title":"Large-Margin Softmax Loss for Convolutional Neural Networks"},{"paperId":"1a13b5dd42df52ffc89b80a133a7677aeebd788c","externalIds":{"MAG":"2510190030","DBLP":"conf/icb/ShiragaMMEY16","DOI":"10.1109/ICB.2016.7550060","CorpusId":12632343},"title":"GEINet: View-invariant gait recognition using a convolutional neural network"},{"paperId":"523fb3bacc9c56b5c621948c9488f923a3c950b9","externalIds":{"DBLP":"journals/ijon/NandyCC16","MAG":"2275720868","DOI":"10.1016/j.neucom.2016.01.002","CorpusId":45764977},"title":"Cloth invariant gait recognition using pooled segmented statistical features"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"d01379ebb53c66a4ccf5f4959d904dcf9e161e41","externalIds":{"MAG":"2951876403","DBLP":"journals/corr/VinyalsBK15","ArXiv":"1511.06391","CorpusId":260429228},"title":"Order Matters: Sequence to sequence for sets"},{"paperId":"cfc0a0306e4038765b8fed53df65e1c612ca12e8","externalIds":{"DBLP":"conf/coginfocom/GalinskaLKB15","MAG":"2279951213","DOI":"10.1109/COGINFOCOM.2015.7390657","CorpusId":38327174},"title":"A database of elementary human movements collected with RGB-D type camera"},{"paperId":"357da13fa9fdfffe3b62739002ed06060841cb3f","externalIds":{"DBLP":"journals/prl/ChattopadhyaySM15","MAG":"623540751","DOI":"10.1016/j.patrec.2015.06.004","CorpusId":19756670},"title":"Frontal gait recognition from occluded scenes"},{"paperId":"013d0acff1e5410fd9f6e15520d16f4ea02f03f6","externalIds":{"MAG":"1954814386","DBLP":"journals/tmm/WuHW15","DOI":"10.1109/TMM.2015.2477681","CorpusId":13205179},"title":"Learning Representative Deep Features for Image Set Analysis"},{"paperId":"52459d74aa67d7393843a7fee698df80aa6f9d9a","externalIds":{"MAG":"1570350587","DOI":"10.1002/047134608X.W8261","CorpusId":129119721},"title":"Gait Recognition: Databases, Representations, and Applications"},{"paperId":"f8e79ac0ea341056ef20f2616628b3e964764cfd","externalIds":{"ArXiv":"1506.02640","MAG":"2950099460","DBLP":"journals/corr/RedmonDGF15","DOI":"10.1109/CVPR.2016.91","CorpusId":206594738},"title":"You Only Look Once: Unified, Real-Time Object Detection"},{"paperId":"c2fb5b39428818d7ec8cc78e152e19c21b7db568","externalIds":{"DBLP":"conf/iccv/DosovitskiyFIHH15","MAG":"2951309005","ArXiv":"1504.06852","DOI":"10.1109/ICCV.2015.316","CorpusId":12552176},"title":"FlowNet: Learning Optical Flow with Convolutional Networks"},{"paperId":"5aa26299435bdf7db874ef1640a6c3b5a4a2c394","externalIds":{"DBLP":"journals/corr/SchroffKP15","MAG":"2096733369","ArXiv":"1503.03832","DOI":"10.1109/CVPR.2015.7298682","CorpusId":206592766},"title":"FaceNet: A unified embedding for face recognition and clustering"},{"paperId":"cd078486558ab140a527ed0767e1e993ba6115ca","externalIds":{"DBLP":"conf/aaai/AnderssonA15","MAG":"2209524052","DOI":"10.1609/aaai.v29i1.9212","CorpusId":348314},"title":"Person Identification Using Anthropometric and Gait Data from Kinect Sensor"},{"paperId":"5ce2ec48812400293e55b12d0ec9768b5ac3872d","externalIds":{"PubMedCentral":"4327057","DBLP":"journals/sensors/LvXWG15","MAG":"1998124261","DOI":"10.3390/s150100932","CorpusId":14543002,"PubMed":"25574935"},"title":"Class Energy Image Analysis for Video Sensor-Based Gait Recognition: A Review"},{"paperId":"c4860be9afe910b8beab7679c476e3363cfbce9b","externalIds":{"DBLP":"journals/prl/IwashitaOK14","MAG":"2057313557","DOI":"10.1016/j.patrec.2014.04.004","CorpusId":6936346},"title":"Identification of people walking along curved trajectories"},{"paperId":"e15cf50aa89fee8535703b9f9512fca5bfc43327","externalIds":{"DBLP":"journals/corr/SzegedyLJSRAEVR14","MAG":"2097117768","ArXiv":"1409.4842","DOI":"10.1109/CVPR.2015.7298594","CorpusId":206592484},"title":"Going deeper with convolutions"},{"paperId":"ed1308a9d8f4640ef6a4d68d602a19d3aac73147","externalIds":{"MAG":"2072861641","DBLP":"conf/est/IwashitaKS14","DOI":"10.1109/EST.2014.18","CorpusId":9099039},"title":"Gait Identification Using Invisible Shadows: Robustness to Appearance Changes"},{"paperId":"eb42cf88027de515750f230b23b1a057dc782108","externalIds":{"MAG":"2949429431","ArXiv":"1409.1556","DBLP":"journals/corr/SimonyanZ14a","CorpusId":14124313},"title":"Very Deep Convolutional Networks for Large-Scale Image Recognition"},{"paperId":"5b53549e997e8cd9916c8f4c5696dde6ea45dfe4","externalIds":{"MAG":"157180873","DBLP":"conf/ammds/Lopez-FernandezMPMM14","DOI":"10.1007/978-3-319-13323-2_3","CorpusId":30124319},"title":"The AVA Multi-View Dataset for Gait Recognition"},{"paperId":"f6ca89291af3748e0952659b66af81e4deb064d7","externalIds":{"MAG":"2065398867","DBLP":"conf/cvpr/MansurMAY14","DOI":"10.1109/CVPR.2014.323","CorpusId":4654853},"title":"Gait Recognition under Speed Transition"},{"paperId":"67dccc9a856b60bdc4d058d83657a089b8ad4486","externalIds":{"MAG":"2952186347","DBLP":"conf/nips/SimonyanZ14","ArXiv":"1406.2199","CorpusId":11797475},"title":"Two-Stream Convolutional Networks for Action Recognition in Videos"},{"paperId":"2a002ce457f7ab3088fbd2691734f1ce79f750c4","externalIds":{"MAG":"2113325037","DBLP":"conf/cvpr/ToshevS14","ArXiv":"1312.4659","DOI":"10.1109/CVPR.2014.214","CorpusId":206592152},"title":"DeepPose: Human Pose Estimation via Deep Neural Networks"},{"paperId":"d66181632cf64200ce0858ea969ec6ce8750691a","externalIds":{"DBLP":"conf/ccbr/YuWH13","MAG":"75119315","DOI":"10.1007/978-3-319-02961-0_52","CorpusId":26955210},"title":"A Large RGB-D Gait Dataset and the Baseline Algorithm"},{"paperId":"1b626828c5bb7eb1eae58887ddeefa0cc4ec97b5","externalIds":{"MAG":"2293736741","DBLP":"conf/iconip/HossainC13","DOI":"10.1007/978-3-642-42042-9_89","CorpusId":39462736},"title":"Multimodal Feature Learning for Gait Biometric Based Human Identity Recognition"},{"paperId":"960870523484a7f66cf8afbe833afd7d343b68f5","externalIds":{"DBLP":"conf/iciap/HadidGBN13","MAG":"2143261670","DOI":"10.1007/978-3-642-41184-7_1","CorpusId":13973106},"title":"Improving Gait Biometrics under Spoofing Attacks"},{"paperId":"37784b314b48664b362be3c38ae52def910a60ce","externalIds":{"MAG":"1980105143","DOI":"10.1117/12.2018145","CorpusId":18943412},"title":"Investigating gait recognition in the short-wave infrared (SWIR) spectrum: dataset and challenges"},{"paperId":"d6daaec16ac90de8f99640f687ad7e9e92a46840","externalIds":{"DBLP":"conf/icpr/HadidGKPBN12","MAG":"1667824631","CorpusId":18813381},"title":"Can gait biometrics be Spoofed?"},{"paperId":"2c522510bf73b6fe4bb49a089751a0fa57137070","externalIds":{"DBLP":"conf/eccv/BarbosaCBBM12","MAG":"1594368566","DOI":"10.1007/978-3-642-33863-2_43","CorpusId":13558466},"title":"Re-identification with RGB-D Sensors"},{"paperId":"d02ec45865408edbfbc36342cac652404aae817b","externalIds":{"MAG":"1988652596","DBLP":"journals/pr/ZhengHTT12","DOI":"10.1016/j.patcog.2012.03.008","CorpusId":11133058},"title":"A cascade fusion scheme for gait and cumulative foot pressure image recognition"},{"paperId":"4b8762d7637868b6ba0c97c95b2d4949d103ecdc","externalIds":{"DBLP":"journals/tifs/IwamaOMY12","MAG":"2018331988","DOI":"10.1109/TIFS.2012.2204253","CorpusId":4646924},"title":"The OU-ISIR Gait Database Comprising the Large Population Dataset and Performance Evaluation of Gait Recognition"},{"paperId":"55bc72e912c1db2c85dbbb6e4afe6eb7bbff89de","externalIds":{"DBLP":"journals/ipsjtcva/MakiharaMTHSMY12","MAG":"602341164","DOI":"10.2197/ipsjtcva.4.53","CorpusId":4633086},"title":"The OU-ISIR Gait Database Comprising the Treadmill Dataset"},{"paperId":"7996cbadf6901079d3979790f9cd7da287860e30","externalIds":{"DBLP":"conf/iciar/BorrasLI12","MAG":"2147815065","DOI":"10.1007/978-3-642-31298-4_12","CorpusId":45164056},"title":"Depth Information in Human Gait Analysis: An Experimental Study on Gender Recognition"},{"paperId":"5298f435adfea49af3ef5b56bfea31a63c6f59af","externalIds":{"DBLP":"journals/ieeemm/Zhang12","MAG":"2056898157","DOI":"10.1109/MMUL.2012.24","CorpusId":8629444},"title":"Microsoft Kinect Sensor and Its Effect"},{"paperId":"f1f28958c906bcc2d49b9df26b1ef541ad5d0210","externalIds":{"MAG":"2088557251","DBLP":"journals/tifs/MatovskiNMC12","DOI":"10.1109/TIFS.2011.2176118","CorpusId":17503046},"title":"The Effect of Time on Gait Recognition Performance"},{"paperId":"93918306666eeab29936cc0db9cfda2c6e08c965","externalIds":{"DOI":"10.11113/aej.v2.15350","CorpusId":204918941},"title":"DEVELOPMENT OF INDONESIAN GAIT DATABASE USING 2D OPTICAL MOTION ANALYZER SYSTEM"},{"paperId":"c64ff444c99213f1bcccc7f0b14df250be6bbca8","externalIds":{"DBLP":"conf/icb/SivapalanCDSF11","MAG":"2074852221","DOI":"10.1109/IJCB.2011.6117504","CorpusId":135334},"title":"Gait energy volumes and frontal gait recognition using depth images"},{"paperId":"d817c736190c41ab1b83ad41cf5a0075d5cee748","externalIds":{"MAG":"1982664635","DBLP":"conf/btas/MatovskiNMC10","DOI":"10.1109/BTAS.2010.5634547","CorpusId":14874855},"title":"The effect of time on the performance of gait biometrics"},{"paperId":"97cf80b7a06678e69c12d7834aa39473e66382e9","externalIds":{"MAG":"1980941928","DBLP":"conf/est/IwashitaBOK10","DOI":"10.1109/EST.2010.19","CorpusId":13426177},"title":"Person Identification from Spatio-temporal 3D Gait"},{"paperId":"402306460df79ededd3e8a492bfbc3093ddc8a29","externalIds":{"MAG":"1546677826","DBLP":"conf/eccv/WangZPYW10","DOI":"10.1007/978-3-642-15549-9_19","CorpusId":11056549},"title":"Chrono-Gait Image: A Novel Temporal Template for Gait Recognition"},{"paperId":"d335c623f30a290f3291554ec500a8ded69d03db","externalIds":{"MAG":"1971608200","DBLP":"conf/icpr/AqmarSF10","DOI":"10.1109/ICPR.2010.536","CorpusId":12748115},"title":"Robust Gait Recognition Against Speed Variation"},{"paperId":"91819c4a8924f37e5686c477c30a68529274b7f1","externalIds":{"DBLP":"journals/prl/ChenLZHT09","MAG":"2120861453","DOI":"10.1016/j.patrec.2009.04.012","CorpusId":8248202},"title":"Frame difference energy image for gait recognition with incomplete silhouettes"},{"paperId":"35058a8166a8fa4479167ba33b3010cc8c839f44","externalIds":{"DBLP":"journals/tip/YuTHJW09","MAG":"2152914237","DOI":"10.1109/TIP.2009.2020535","CorpusId":5548459,"PubMed":"19447706"},"title":"A Study on Gait-Based Gender Classification"},{"paperId":"13b3a1e7e0bd80bf38b444ce1568213ebe98d0df","externalIds":{"MAG":"1532499126","DBLP":"conf/ibpria/ChechikSSB09","DOI":"10.5555/1756006.1756042","CorpusId":2087262},"title":"Large Scale Online Learning of Image Similarity Through Ranking"},{"paperId":"f5e5f06291740f310fba893c3720e5e19db08dd9","externalIds":{"MAG":"2136467038","DOI":"10.1109/BCC.2007.4430542","CorpusId":12646},"title":"Boosting LDA with Regularization on MPCA Features for Gait Recognition"},{"paperId":"b4bd83748032ec0036b9638ca3c441c88f1300a8","externalIds":{"DBLP":"conf/autoid/GafurovSB07","MAG":"2102950522","DOI":"10.1109/AUTOID.2007.380623","CorpusId":1642451},"title":"Gait Authentication and Identification Using Wearable Accelerometer Sensor"},{"paperId":"749bb1ab22c792dc5c7782714df74c392939c8d1","externalIds":{"DBLP":"journals/pr/BoulgourisC07","MAG":"1972580115","DOI":"10.1016/j.patcog.2006.11.012","CorpusId":5598923},"title":"Human gait recognition based on matching of body components"},{"paperId":"7ac67ff0f59585ad3b31d22424c2cef72e20a27d","externalIds":{"MAG":"2060997642","DOI":"10.1007/s00221-006-0676-3","CorpusId":22725717,"PubMed":"16972073"},"title":"Gait asymmetry in patients with Parkinsonâ€™s disease and elderly fallers: when does the bilateral coordination of gait require attention?"},{"paperId":"0268d1744377ffbff48b014f513ea3e5e4a4dab1","externalIds":{"MAG":"2104335344","DBLP":"conf/icpr/YuTT06","DOI":"10.1109/ICPR.2006.67","CorpusId":1815453},"title":"A Framework for Evaluating the Effect of View Angle, Clothing and Carrying Condition on Gait Recognition"},{"paperId":"d59925a717564e8e14197e8dd6cd046ee0402100","externalIds":{"DBLP":"conf/icpr/TanHYT06","MAG":"2113408265","DOI":"10.1109/ICPR.2006.478","CorpusId":14165952},"title":"Efficient Night Gait Recognition Based on Template Matching"},{"paperId":"6b52647a6d4bd5efc12ff5835054f67ed71e2f50","externalIds":{"DBLP":"conf/IEEEares/GafurovHS06","MAG":"2138621439","DOI":"10.1109/ARES.2006.68","CorpusId":17873664},"title":"Gait recognition using acceleration from MEMS"},{"paperId":"540339c32eaf41962740583bfa415a5a0ff9d932","externalIds":{"MAG":"2126680226","DBLP":"journals/pami/HanB06","DOI":"10.1109/TPAMI.2006.38","CorpusId":765267,"PubMed":"16468626"},"title":"Individual recognition using gait energy image"},{"paperId":"de181f9110227324cc47bd3e561bcca8898a4840","externalIds":{"MAG":"2178205985","DBLP":"conf/iwbrs/VeresNC05","DOI":"10.1007/11569947_27","CorpusId":7027359},"title":"Model-based approaches for predicting gait changes over time"},{"paperId":"15c76155836f92874ed18461da43c9e904b84d76","externalIds":{"MAG":"2080718748","DOI":"10.1016/J.JBIOMECH.2004.05.002","CorpusId":1398308,"PubMed":"15652537"},"title":"A machine learning approach for automated recognition of movement patterns using basic, kinetic and kinematic gait data."},{"paperId":"bb6b14397f69bbfbc52cbd1a04bc6302a8b938d7","externalIds":{"MAG":"2151458682","DBLP":"journals/pami/SarkarPLVGB05","DOI":"10.1109/TPAMI.2005.39","CorpusId":7693282,"PubMed":"15688555"},"title":"The humanID gait challenge problem: data sets, performance, and analysis"},{"paperId":"7e4ee9c60bcb1896918ed7debef87f88429855f8","externalIds":{"DBLP":"conf/smc/Piccardi04","MAG":"2121274305","DOI":"10.1109/ICSMC.2004.1400815","CorpusId":12127129},"title":"Background subtraction techniques: a review"},{"paperId":"ea75c89abaa532b8bab8a3f1d95c010e192dff9b","externalIds":{"MAG":"2073471023","DOI":"10.1117/12.543107","CorpusId":14429337},"title":"Toward understanding the limits of gait recognition"},{"paperId":"bcf73131c2be397fa2105ac45df3ce1a55c07c2f","externalIds":{"MAG":"2126983449","DBLP":"journals/jvca/WaggN04","DOI":"10.1002/CAV.43","CorpusId":12953986},"title":"Automated markerless extraction of walking people using deformable contour models"},{"paperId":"fb57ac9a7b95ea8f6e75c45c5298d80a9d655545","externalIds":{"MAG":"2121680956","DBLP":"conf/cvpr/LiuMS04","DOI":"10.1109/CVPR.2004.242","CorpusId":13551845},"title":"Studies on silhouette quality and gait recognition"},{"paperId":"1d4d249897a0b50d1e3b9ac4adea7ed5c4e26976","externalIds":{"DBLP":"conf/fgr/WaggN04","MAG":"2154663802","DOI":"10.1109/AFGR.2004.1301502","CorpusId":8106765},"title":"On automated model-based extraction and analysis of gait"},{"paperId":"fda092dbc3dd26260c9129d481576f6c6125faa3","externalIds":{"MAG":"2115203491","DBLP":"journals/pr/YamNC04","DOI":"10.1016/j.patcog.2003.09.012","CorpusId":14234613},"title":"Automated person recognition by walking and running via model-based approaches"},{"paperId":"7635e2071dbea24e70bb170e480d24f868bbef7b","externalIds":{"DBLP":"conf/sac/QianSGP04","MAG":"2145343266","DOI":"10.1145/967900.968151","CorpusId":207750419},"title":"Similarity between Euclidean and cosine angle distance for nearest neighbor queries"},{"paperId":"9580c5e11fedd346a63390f10da9fd1425cd8d2c","externalIds":{"MAG":"2149516292","DBLP":"journals/pami/WangTNH03","DOI":"10.1109/TPAMI.2003.1251144","CorpusId":13874338},"title":"Silhouette Analysis-Based Gait Recognition for Human Identification"},{"paperId":"5ba0701ee3bc214a4df4c888e743ea52e5585ef5","externalIds":{"MAG":"2113740595","DBLP":"conf/icip/Phillips02","DOI":"10.1109/ICIP.2002.1037956","CorpusId":12516660},"title":"Human identification technical challenges"},{"paperId":"686d07173fd8280536fdc4e358aa240f3443d649","externalIds":{"MAG":"2129887056","DBLP":"conf/fgr/CollinsGS02","DOI":"10.1109/AFGR.2002.1004181","CorpusId":1049642},"title":"Silhouette-based human identification from body shape and gait"},{"paperId":"a3982539ce54c540d9fa58f86518a3b7dbd56768","externalIds":{"MAG":"2142532896","DBLP":"conf/fgr/KaleCKR02","DOI":"10.1109/AFGR.2002.1004176","CorpusId":6522426},"title":"Gait-based recognition of humans using continuous HMMs"},{"paperId":"a0b801702d278645dbca3356cd6e41a664ed3e80","externalIds":{"DBLP":"conf/fgr/PhillipsGSVB02","MAG":"2135340719","DOI":"10.1109/AFGR.2002.1004145","CorpusId":7323872},"title":"Baseline results for the challenge problem of HumanID using gait analysis"},{"paperId":"68d885a2de9217ba787b8c8e55089944bbc558ee","externalIds":{"MAG":"2135541996","DBLP":"conf/fgr/LeeG02","DOI":"10.1109/AFGR.2002.1004148","CorpusId":15390360},"title":"Gait analysis for recognition and classification"},{"paperId":"05ecbf2cd477ce1e1b12b2c1e78e4fc8dfdc08d2","externalIds":{"DBLP":"conf/cvpr/BobickJ01","MAG":"2146968264","DOI":"10.1109/CVPR.2001.990506","CorpusId":2200276},"title":"Gait recognition using static, activity-specific parameters"},{"paperId":"1dafef6c616186a0f583cd3aed0c87fc82a0fab2","externalIds":{"DBLP":"conf/avbpa/JohnsonB01","MAG":"2128233502","DOI":"10.1007/3-540-45344-X_44","CorpusId":15796248},"title":"A Multi-view Method for Gait Recognition Using Static Body Parameters"},{"paperId":"886431a362bfdbcc6dd518f844eb374950b9de86","externalIds":{"DBLP":"journals/pami/BobickD01","MAG":"2165715280","DOI":"10.1109/34.910878","CorpusId":2006961},"title":"The Recognition of Human Movement Using Temporal Templates"},{"paperId":"ccce1cf96f641b3581fba6f4ce2545f4135a15e3","externalIds":{"MAG":"1596717185","DBLP":"journals/npl/SuykensV99","DOI":"10.1023/A:1018628609742","CorpusId":207579947},"title":"Least Squares Support Vector Machine Classifiers"},{"paperId":"064bcff0a36f4fbf523cc557cfad623c3c8d0927","externalIds":{"MAG":"1542370073","CorpusId":12672},"title":"Gait Extraction and Description by Evidence-Gathering"},{"paperId":"2e9d221c206e9503ceb452302d68d10e293f2a10","externalIds":{"DBLP":"journals/neco/HochreiterS97","MAG":"2064675550","DOI":"10.1162/neco.1997.9.8.1735","CorpusId":1915014,"PubMed":"9377276"},"title":"Long Short-Term Memory"},{"paperId":"19f496acda8da2ef5c4c1bd8fa0b8b965ae7de8f","externalIds":{"DBLP":"conf/avbpa/CunadoNC97","MAG":"1564236611","DOI":"10.1007/BFb0015984","CorpusId":12012544},"title":"Using Gait as a Biometric, via Phase-weighted Magnitude Spectra"},{"paperId":"1eaaf3ee504e5e738af436934fec2d456046985e","externalIds":{"DBLP":"journals/prl/MuraseS96","MAG":"1975443308","DOI":"10.1016/0167-8655(95)00109-3","CorpusId":14297649},"title":"Moving object recognition in eigenspace representation: gait analysis and lip reading"},{"paperId":"57854a0e8309af7ad6f5d9612e20e2ba1a171a96","externalIds":{"DBLP":"conf/cvpr/NiyogiA94","MAG":"2161315665","DOI":"10.1109/CVPR.1994.323868","CorpusId":18566850},"title":"Analyzing and recognizing walking figures in XYT"},{"paperId":"b441dd8fb25eddbaf92bc9938afda69627a281ab","externalIds":{"MAG":"2913758415","DBLP":"journals/ac/Rosenfeld88","DOI":"10.1016/S0065-2458(08)60261-2","CorpusId":441278,"PubMed":"1891713"},"title":"Computer Vision"},{"paperId":"ee24bc329932a780304dad25224f85b9a2ccc40b","externalIds":{"DOI":"10.1136/jramc-149-03-02","CorpusId":1386090},"title":"Recognition"},{"paperId":"d7a7d0dff02c81484d9e208e8151a502e161b9df","externalIds":{"DBLP":"journals/tmm/LiHCFH24","DOI":"10.1109/TMM.2023.3312931","CorpusId":261615963},"title":"Gait Recognition With Drones: A Benchmark"},{"paperId":"6acf87f006cc9ddeee9491b879274a255c2a4e80","externalIds":{"DBLP":"journals/tmm/YaoKZWZ23","DOI":"10.1109/TMM.2022.3171961","CorpusId":248592376},"title":"Improving Disentangled Representation Learning for Gait Recognition Using Group Supervision"},{"paperId":"68de6796e9e8b3c45ec3c0d031ea29c8f294caf0","externalIds":{"DBLP":"journals/corr/abs-2303-05076","DOI":"10.48550/arXiv.2303.05076","CorpusId":268324712},"title":"GaitEditer: Attribute Editing for Gait Representation Learning"},{"paperId":"1ee871674dd6ba58f667c29ac2e0657184d5c610","externalIds":{"DBLP":"journals/tifs/HiroseNNB22","DOI":"10.1109/TIFS.2022.3206422","CorpusId":252288775},"title":"Anonymization of Human Gait in Video Based on Silhouette Deformation and Texture Transfer"},{"paperId":"7aa59547ee36dff6f223d299501e0f42a21ec686","externalIds":{"DBLP":"journals/corr/abs-2211-08007","DOI":"10.48550/arXiv.2211.08007","CorpusId":273180428},"title":"Uncertainty-aware Gait Recognition via Learning from Dirichlet Distribution-based Evidence"},{"paperId":"f005d8fda96809af792ee3f54cb5b7ccaae0aba4","externalIds":{"DBLP":"conf/bmvc/LinLZ21","DOI":"10.5244/c.35.134","CorpusId":249892866},"title":"GaitMask: Mask-based Model for Gait Recognition"},{"paperId":"9412c6c6768169ebb2428bad9c5be71664532852","externalIds":{"DBLP":"journals/tifs/Marin-JimenezCD21","DOI":"10.1109/tifs.2021.3132579","CorpusId":244873655},"title":"UGaitNet: Multimodal Gait Recognition With Missing Input Modalities"},{"paperId":"6bdea4e44f98aefc15828664a3cb24734b14f2c0","externalIds":{"MAG":"3097009184","DBLP":"conf/eccv/HouCLH20","DOI":"10.1007/978-3-030-58545-7_22","CorpusId":222245729},"title":"Gait Lateral Network: Learning Discriminative and Compact Representations for Gait Recognition"},{"paperId":"69f68f943c6905b116dd4902e59961c18a5e2e3c","externalIds":{"MAG":"3109072956","DBLP":"conf/accv/LiMXYYR20","DOI":"10.1007/978-3-030-69535-4_1","CorpusId":229383318},"title":"End-to-End Model-Based Gait Recognition"},{"paperId":"48bdf0d57c76f0e9a1b97dd454b857502b05e93f","externalIds":{"MAG":"3105506710","DBLP":"conf/eccv/XuM0Y020","DOI":"10.1007/978-3-030-58529-7_23","CorpusId":221821793},"title":"Gait Recognition from a Single Image Using a Phase-Aware Gait Cycle Reconstruction Network"},{"paperId":"fdca7486611a574d08aca45b83ba38486b2d83ab","externalIds":{"MAG":"2960957522","DBLP":"journals/tip/ZhangHYW20","DOI":"10.1109/TIP.2019.2926208","CorpusId":195894214,"PubMed":"31295113"},"title":"Cross-View Gait Recognition by Discriminative Feature Learning"},{"paperId":"59cf23817d3b1e48d8f3ad38d1df6a5551d5c1f2","externalIds":{"DBLP":"journals/tcsv/BenedekGNJ18","MAG":"2502226073","DOI":"10.1109/TCSVT.2016.2595331","CorpusId":22165395},"title":"Lidar-Based Gait Analysis and Activity Recognition in a 4D Surveillance System"},{"paperId":"678258aa137341dbe11e5dcb3ffa9ea376b88ec3","externalIds":{"MAG":"2511887655","CorpusId":63363784},"title":"Handbook Of Biometrics"},{"paperId":"b0158b26f01d5fa18aac51ece055cad9a12f6d87","externalIds":{"MAG":"2612627974","DBLP":"conf/bmvc/LiuYLZL16","DOI":"10.5244/C.30.82","CorpusId":26167987},"title":"Memory-based Gait Recognition"},{"paperId":"f216444d4f2959b4520c61d20003fa30a199670a","externalIds":{"MAG":"3091905774","CorpusId":13874643},"title":"Siamese Neural Networks for One-Shot Image Recognition"},{"paperId":"fbc6a61c684b32159c0a4f595c36f752c4fb2385","externalIds":{"MAG":"2497723524","DBLP":"reference/vision/X14p","DOI":"10.1007/978-0-387-31439-6_100108","CorpusId":1815007},"title":"Automatic Gait Recognition"},{"paperId":"bdeff833f3a7c035ff2987984317493d0a02f8d9","externalIds":{"DBLP":"journals/jvcir/0011GBSR14","MAG":"1984031350","DOI":"10.1016/j.jvcir.2013.02.006","CorpusId":17445139},"title":"The TUM Gait from Audio, Image and Depth (GAID) database: Multimodal recognition of subjects and traits"},{"paperId":"ae07c364c91a824b0a2d7ca43a99ae617be244a6","externalIds":{"CorpusId":249315339},"title":"THE TO THE EUROPEAN PARLIAMENT AND THE COUNCIL"},{"paperId":"98c29a3ef495fcd7c679785ada54152ab1e60863","externalIds":{"MAG":"2750880085","CorpusId":9926382},"title":"Gait Recognition in the Presence of Occlusion: A New Dataset and Baseline Algorithms"},{"paperId":"f5bf95c0103371f86bbd61785a24bd0742589bf2","externalIds":{"MAG":"1578729825","DOI":"10.1017/CBO9780511921056.014","CorpusId":58503984},"title":"On Acquisition and Analysis of a Dataset Comprising of Gait, Ear and Semantic data"},{"paperId":"837635f647c42d03812a7f4ab5f87c5a49372a0b","externalIds":{"MAG":"2542803194","DBLP":"conf/icdp/BashirXG09","DOI":"10.1049/IC.2009.0230","CorpusId":11176755},"title":"Gait recognition using Gait Entropy Image"},{"paperId":"a9dc9235bff272d3a62fcb3275d1139412fb78cc","externalIds":{"DBLP":"conf/snpd/MaWNQ07","DOI":"10.1109/SNPD.2007.307","CorpusId":5845393},"title":"Recognizing Humans Based on Gait Moment Image"},{"paperId":"4f93cd09785c6e77bf4bc5a788e079df524c8d21","externalIds":{"MAG":"1797462219","DOI":"10.1007/978-3-540-45240-9_46","CorpusId":45064783},"title":"On a Large Sequence-Based Human Gait Database"},{"paperId":"9a5ea367f0fb05805acaa84a402f5d036eea37dc","externalIds":{"MAG":"1928278792","DBLP":"conf/shape/CunHBB99","DOI":"10.1007/3-540-46805-6_19","CorpusId":37392765},"title":"Object Recognition with Gradient-Based Learning"},{"paperId":"dccdfea475faa2ecee679803a8b4177ea7b5384c","externalIds":{"MAG":"1558751150","CorpusId":14024984},"title":"Recognizing People by Their Gait: The Shape of Motion"},{"paperId":"0a995afa8d3c114b2b431c4e2737777a0e051bff","externalIds":{"MAG":"2082627290","DOI":"10.1016/0166-2236(92)90344-8","CorpusId":793980,"PubMed":"1374953"},"title":"Separate visual pathways for perception and action."},{"paperId":"933da0b68cd2b4e6533ee87a7e70073d1579c6f4","externalIds":{"CorpusId":258179138},"title":"GaitRef: Gait Recognition with Reï¬ned Sequential Skeletons"}]}