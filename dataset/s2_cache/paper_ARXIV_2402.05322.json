{"paperId":"60cd4e9f579b1324e8c30907055552bd0cb3dd32","externalIds":{"DBLP":"journals/corr/abs-2402-05322","ArXiv":"2402.05322","DOI":"10.48550/arXiv.2402.05322","CorpusId":267547824},"title":"Learning on Multimodal Graphs: A Survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2402.05322, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"1726114642","name":"Ciyuan Peng"},{"authorId":"2284040814","name":"Jiayuan He"},{"authorId":"2283308587","name":"Feng Xia"}],"abstract":"Multimodal data pervades various domains, including healthcare, social media, and transportation, where multimodal graphs play a pivotal role. Machine learning on multimodal graphs, referred to as multimodal graph learning (MGL), is essential for successful artificial intelligence (AI) applications. The burgeoning research in this field encompasses diverse graph data types and modalities, learning techniques, and application scenarios. This survey paper conducts a comparative analysis of existing works in multimodal graph learning, elucidating how multimodal learning is achieved across different graph types and exploring the characteristics of prevalent learning techniques. Additionally, we delineate significant applications of multimodal graph learning and offer insights into future directions in this domain. Consequently, this paper serves as a foundational resource for researchers seeking to comprehend existing MGL techniques and their applicability across diverse scenarios."}