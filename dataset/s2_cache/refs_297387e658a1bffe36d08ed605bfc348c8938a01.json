{"references":[{"paperId":"72ee22f4973522f70c46343a4e8b1cbcb346fa52","externalIds":{"DBLP":"conf/iclr/0004HHJDCS025","ArXiv":"2410.03825","DOI":"10.48550/arXiv.2410.03825","CorpusId":273186925},"title":"MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion"},{"paperId":"4f997c404e97087194d2df538deb82b2c5428c1e","externalIds":{"DBLP":"journals/corr/abs-2406-09756","ArXiv":"2406.09756","DOI":"10.48550/arXiv.2406.09756","CorpusId":270521424},"title":"Grounding Image Matching in 3D with MASt3R"},{"paperId":"2091dcd7c80bc27ba7d1fdc0087748bb1e293e2f","externalIds":{"DBLP":"conf/nips/YangKH0XFZ24","ArXiv":"2406.09414","DOI":"10.48550/arXiv.2406.09414","CorpusId":270440448},"title":"Depth Anything V2"},{"paperId":"644663735dde70b477a5f1c156c3724d24e11834","externalIds":{"DBLP":"journals/pami/TosiARPSMS24","DOI":"10.1109/TPAMI.2024.3411292","CorpusId":270335140,"PubMed":"38848234"},"title":"Neural Disparity Refinement"},{"paperId":"d1d9720d6430992910bc8b82a7c4d81b5b5bb38d","externalIds":{"DBLP":"conf/cvpr/PoggiT24","ArXiv":"2405.14873","DOI":"10.1109/CVPR52733.2024.01906","CorpusId":269983050},"title":"Federated Online Adaptation for Deep Stereo"},{"paperId":"2303c39bbe26d628ebe155e133c0d6d4be7323af","externalIds":{"DBLP":"conf/cvpr/BruckerWBH24","ArXiv":"2405.12759","DOI":"10.1109/CVPR52733.2024.02046","CorpusId":270381693},"title":"Cross-spectral Gated-RGB Stereo Depth Estimation"},{"paperId":"33c7152dfaf1a5d0b947f2efb9624036df35bd9d","externalIds":{"DBLP":"conf/icra/LiHXYZ24","ArXiv":"2404.07545","DOI":"10.1109/ICRA57147.2024.10611533","CorpusId":269043134},"title":"Stereo-LiDAR Depth Estimation with Deformable Propagation and Learned Disparity-Depth Conversion"},{"paperId":"48cc3efd0e4223fcaf1190a59ef4fc81f3df3dc3","externalIds":{"DBLP":"conf/cvpr/ChenLYZWQW24","ArXiv":"2404.06842","DOI":"10.1109/CVPR52733.2024.02623","CorpusId":269033418},"title":"MoCha-Stereo: Motif Channel Attention Network for Stereo Matching"},{"paperId":"f9fef9ef3d2b6a4e9a6a01aabdf35d65c19af2b2","externalIds":{"DBLP":"conf/aaai/0007ZST24","DOI":"10.1609/aaai.v38i4.28107","CorpusId":268678365},"title":"IINet: Implicit Intra-inter Information Fusion for Real-Time Stereo Matching"},{"paperId":"98d1f09c6ad0fadff7df5085365d25c6b01775b9","externalIds":{"DBLP":"conf/aaai/LiangL24","DOI":"10.1609/aaai.v38i4.28119","CorpusId":268678394},"title":"Any-Stereo: Arbitrary Scale Disparity Estimation for Iterative Stereo Matching"},{"paperId":"e222d4ace789a0377ef07f32660eb5b030aeddc5","externalIds":{"DBLP":"conf/3dim/FengCJLXY24","DOI":"10.1109/3DV62453.2024.00083","CorpusId":265033639},"title":"MC-Stereo: Multi-Peak Lookup and Cascade Search Range for Stereo Matching"},{"paperId":"a8b826b62bf20d267e4e86bed1e8ec0c4298957d","externalIds":{"DBLP":"conf/cvpr/GuanW024","ArXiv":"2403.11193","DOI":"10.1109/CVPR52733.2024.00522","CorpusId":268512998},"title":"Neural Markov Random Field for Stereo Matching"},{"paperId":"9950b34418398d7698b3b292d1d05e00f411cdaf","externalIds":{"ArXiv":"2403.07705","DBLP":"journals/corr/abs-2403-07705","DOI":"10.1109/CVPR52733.2024.01914","CorpusId":268363599},"title":"Robust Synthetic-to-Real Transfer for Stereo Matching"},{"paperId":"dccab080c48f9f0bbeba64143e271cc1c0d21442","externalIds":{"DBLP":"journals/corr/abs-2403-00486","ArXiv":"2403.00486","DOI":"10.1109/CVPR52733.2024.01863","CorpusId":268201876},"title":"Selective-Stereo: Adaptive Frequency Information Selection for Stereo Matching"},{"paperId":"d56a8a62764242daa18ee1d13cd1aa06323aaae7","externalIds":{"DBLP":"conf/cvpr/GongLGY024","ArXiv":"2402.19270","DOI":"10.1109/CVPR52733.2024.01961","CorpusId":268063505},"title":"Learning Intra-View and Cross-View Geometric Knowledge for Stereo Matching"},{"paperId":"afea54c7f17f4fac0f71bebed6bc782ed69d8bd0","externalIds":{"ArXiv":"2401.10891","DBLP":"conf/cvpr/YangKHXFZ24","DOI":"10.1109/CVPR52733.2024.00987","CorpusId":267061016},"title":"Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data"},{"paperId":"5a9337001bc71bef0bc4179246f529b1e968e5aa","externalIds":{"DBLP":"conf/wacv/ChenWZX24","DOI":"10.1109/WACV57701.2024.00302","CorpusId":268277996},"title":"Depth from Asymmetric Frame-Event Stereo: A Divide-and-Conquer Approach"},{"paperId":"dcc41338fa83ae84e3c7fc5e5766f51a09764ebb","externalIds":{"DBLP":"journals/corr/abs-2312-14650","ArXiv":"2312.14650","DOI":"10.1109/WACV57701.2024.00350","CorpusId":266520965},"title":"Global Occlusion-Aware Transformer for Robust Stereo Matching"},{"paperId":"5f82a81766cb78395a55b8fc697c2421a20f4a9e","externalIds":{"DBLP":"conf/cvpr/Wang0CCR24","ArXiv":"2312.14132","DOI":"10.1109/CVPR52733.2024.01956","CorpusId":266436038},"title":"DUSt3R: Geometric 3D Vision Made Easy"},{"paperId":"ac9868dc75a61c98f378de9395cf02fca35c9150","externalIds":{"DBLP":"conf/iccv/TianPWM0BTC23","DOI":"10.1109/ICCV51070.2023.00330","CorpusId":267021358},"title":"DPS-Net: Deep Polarimetric Stereo Depth Estimation"},{"paperId":"53903ac782c81d68afd5c6fc521407f924325194","externalIds":{"DBLP":"conf/iccv/ZengYY0J23","DOI":"10.1109/ICCV51070.2023.01682","CorpusId":267026417},"title":"Parameterized Cost Volume for Stereo Matching"},{"paperId":"548fb0685fc8637a0dcb7fd384a6cfb07a004aeb","externalIds":{"DBLP":"conf/iccv/0001PT0M23","ArXiv":"2309.12315","DOI":"10.1109/ICCV51070.2023.01693","CorpusId":262083814},"title":"Active Stereo Without Pattern Projector"},{"paperId":"cd8f2e24263be5065849ee2c278f028027a1d3e1","externalIds":{"DBLP":"journals/corr/abs-2309-04183","ArXiv":"2309.04183","DOI":"10.1109/WACV57701.2024.00852","CorpusId":261660461},"title":"Stereo Matching in Time: 100+ FPS Video Stereo Matching for Extended Reality"},{"paperId":"66f5b1bfb4bd8f6149ef68056b4a6ed8ab635222","externalIds":{"ArXiv":"2309.00933","DBLP":"journals/corr/abs-2309-00933","DOI":"10.1109/ICCV51070.2023.00863","CorpusId":261531380},"title":"Two-in-One Depth: Bridging the Gap Between Monocular and Binocular Self-supervised Depth Estimation"},{"paperId":"34b09cb2e80d9e33088fd8316ee3d7fec94b4603","externalIds":{"DBLP":"journals/pami/ChenLYTZRLXS23","DOI":"10.1109/TPAMI.2023.3305399","CorpusId":260924337,"PubMed":"37581967"},"title":"ActiveZero++: Mixed Domain Learning Stereo and Confidence-Based Depth Completion With Zero Annotation"},{"paperId":"d49ce0ade194f24446fad2566e22ac7d8e10fa89","externalIds":{"ArXiv":"2308.00728","DBLP":"conf/iccv/LouLCLC23","DOI":"10.1109/ICCV51070.2023.01630","CorpusId":260378744},"title":"ELFNet: Evidential Local-global Fusion for Stereo Matching"},{"paperId":"483dfec703b0e886e0885d4fcd61872149ea1e74","externalIds":{"ArXiv":"2307.16509","DBLP":"journals/pami/ShenSDZRZ23","DOI":"10.1109/TPAMI.2023.3300976","CorpusId":260334415,"PubMed":"37590113"},"title":"Digging Into Uncertainty-Based Pseudo-Label for Robust Stereo Matching"},{"paperId":"de26a4e4a84b58966e95c39af2c51b48b1de5af1","externalIds":{"DBLP":"conf/iccv/JingLXLLG0XJS23","ArXiv":"2307.14071","DOI":"10.1109/ICCV51070.2023.00307","CorpusId":260164562},"title":"Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching"},{"paperId":"ba1e480fac27dfbfc5366bc9de34b8cf2b9b00ba","externalIds":{"ArXiv":"2306.15612","DBLP":"conf/cvpr/XuXQFP24","DOI":"10.1109/CVPR52733.2024.00491","CorpusId":259262193},"title":"Adaptive Multi-Modal Cross-Entropy Loss for Stereo Matching"},{"paperId":"770bde4ecd78a05bd00c7e278c0d6f72206413ae","externalIds":{"DBLP":"conf/cvpr/RaoXHDHSL23","DOI":"10.1109/CVPR52729.2023.00526","CorpusId":260067885},"title":"Masked Representation Learning for Domain Generalized Stereo Matching"},{"paperId":"44cda7156cff5b7d76186c2a4659ea588bdaa826","externalIds":{"DBLP":"conf/cvpr/ChangYZ023","DOI":"10.1109/CVPR52729.2023.00922","CorpusId":260841643},"title":"Domain Generalized Stereo Matching via Hierarchical Visual Transformation"},{"paperId":"6abfefca29a9df4115c9d50b244a2f24523a8502","externalIds":{"DBLP":"conf/cvpr/ChaneyOWBHKKTD23","DOI":"10.1109/CVPRW59228.2023.00419","CorpusId":259380779},"title":"M3ED: Multi-Robot, Multi-Sensor, Multi-Environment Event Dataset"},{"paperId":"ccd1093b27268b4c823bb0b0a717bcc43a350e69","externalIds":{"DBLP":"conf/cvpr/SongKS23","DOI":"10.1109/CVPR52729.2023.01314","CorpusId":260813634},"title":"Unsupervised Deep Asymmetric Stereo Matching with Spatially-Adaptive Self-Similarity"},{"paperId":"e6e88ebb02b7ad2b7a3925ec532428ee2f371c06","externalIds":{"DBLP":"conf/cvpr/ChoCY23","DOI":"10.1109/CVPR52729.2023.01707","CorpusId":260098884},"title":"Learning Adaptive Dense Event Stereo from the Image Domain"},{"paperId":"ba837d7acf7eedf2f11249f8bf4347797289905a","externalIds":{"DBLP":"conf/cvpr/ShinPK23","DOI":"10.1109/CVPR52729.2023.00107","CorpusId":260068051},"title":"Deep Depth Estimation from Thermal Image"},{"paperId":"0b05a519117032b2563352aba06f1b1c0cba41b8","externalIds":{"DBLP":"conf/cvpr/ZhaoZZCY023","DOI":"10.1109/CVPR52729.2023.00134","CorpusId":260779095},"title":"High-Frequency Stereo Matching Network"},{"paperId":"9a3609dc821d66f1adc10f6b955dd845f4f051b8","externalIds":{"DBLP":"conf/icra/WuSCF23","DOI":"10.1109/ICRA48891.2023.10161385","CorpusId":259337785},"title":"Transparent Objects: A Corner Case in Stereo Matching"},{"paperId":"598b485c4c5ee527c6dff061d2eb1561c29114b7","externalIds":{"DBLP":"conf/cvpr/WalzBRWMH23","ArXiv":"2305.12955","DOI":"10.1109/CVPR52729.2023.01273","CorpusId":258832895},"title":"Gated Stereo: Joint Depth Estimation from Gated and Wide-Baseline Active Stereo Cues"},{"paperId":"9bb33e62076dc85f7d21f5e399dd56024600f8e1","externalIds":{"ArXiv":"2305.11566","DBLP":"conf/icra/ChangLXLLM23","DOI":"10.1109/ICRA48891.2023.10160441","CorpusId":259339464},"title":"StereoVAE: A lightweight stereo-matching system using embedded GPUs"},{"paperId":"478ed2da41f55e8617d3162755559670ee7a599a","externalIds":{"DBLP":"journals/corr/abs-2305-02296","ArXiv":"2305.02296","DOI":"10.1109/CVPR52729.2023.01271","CorpusId":258461331},"title":"DynamicStereo: Consistent Dynamic Depth from Stereo Videos"},{"paperId":"5b8566bab9eb181a276c89147ab7d57381e28b78","externalIds":{"DBLP":"conf/cvpr/ChenWM23","ArXiv":"2304.00152","DOI":"10.1109/CVPR52729.2023.01653","CorpusId":257913707},"title":"Learning the Distribution of Errors in Stereo Matching for Joint Disparity and Uncertainty Estimation"},{"paperId":"95e772ecc4fd13965773cfcd4637159cfbb25096","externalIds":{"DBLP":"journals/corr/abs-2303-17603","ArXiv":"2303.17603","DOI":"10.1109/CVPR52729.2023.00089","CorpusId":257833523},"title":"NeRF-Supervised Deep Stereo"},{"paperId":"697e176d66a17c0b24613b8513ab951dc4112c34","externalIds":{"DBLP":"journals/corr/abs-2303-06615","ArXiv":"2303.06615","DOI":"10.1109/CVPR52729.2023.02099","CorpusId":257495841},"title":"Iterative Geometry Encoding Volume for Stereo Matching"},{"paperId":"d8d099fb047a3a47579dadc23d346d1abb85aaec","externalIds":{"ArXiv":"2303.01943","DBLP":"conf/cvpr/MehlSJNB23","DOI":"10.1109/CVPR52729.2023.00482","CorpusId":257353456},"title":"Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene Flow, Optical Flow and Stereo"},{"paperId":"3e33b8de476310f0ef49bdfe944a5dd6a2beb91e","externalIds":{"DBLP":"journals/pami/RamirezCTPSMS24","ArXiv":"2301.08245","DOI":"10.1109/TPAMI.2023.3323858","CorpusId":256000106,"PubMed":"37819829"},"title":"Booster: A Benchmark for Depth From Images of Specular and Transparent Surfaces"},{"paperId":"2b6565652c252c3445977074c48a792fa64bab87","externalIds":{"ArXiv":"2211.13755","DBLP":"journals/corr/abs-2211-13755","DOI":"10.1109/IROS55552.2023.10341598","CorpusId":254017429},"title":"TemporalStereo: Efficient Spatial-Temporal Stereo Matching Network"},{"paperId":"27cbfd0197f77351c24c77bbff7b0ff45a2382fa","externalIds":{"ArXiv":"2211.10408","DBLP":"conf/iccv/Weinzaepfel00CA23","DOI":"10.1109/ICCV51070.2023.01647","CorpusId":253707968},"title":"CroCo v2: Improved Cross-view Completion Pre-training for Stereo Matching and Optical Flow"},{"paperId":"01c630e9ce06040b0f3f540dd3f7681f01e84a9d","externalIds":{"DBLP":"journals/corr/abs-2211-05783","ArXiv":"2211.05783","DOI":"10.1109/TPAMI.2023.3298645","CorpusId":253447268,"PubMed":"37490383"},"title":"Unifying Flow, Stereo and Depth Estimation"},{"paperId":"3575be3aca99b503b20c44898cb4e93a8ad5ae37","externalIds":{"ArXiv":"2211.00392","DBLP":"journals/corr/abs-2211-00392","DOI":"10.1109/WACV56688.2023.00579","CorpusId":253244567},"title":"Expansion of Visual Hints for Improved Generalization in Stereo Matching"},{"paperId":"3480639dd6d4609ed706f30d1a62dae555a70aab","externalIds":{"DBLP":"journals/corr/abs-2210-12785","ArXiv":"2210.12785","DOI":"10.48550/arXiv.2210.12785","CorpusId":253097710},"title":"An Improved RaftStereo Trained with A Mixed Dataset for the Robust Vision Challenge 2022"},{"paperId":"3fe123f4777bcb86d796de230b3767c15f28ed7d","externalIds":{"DBLP":"journals/corr/abs-2210-11719","ArXiv":"2210.11719","DOI":"10.48550/arXiv.2210.11719","CorpusId":253080413},"title":"Context-Enhanced Stereo Transformer"},{"paperId":"7a3dac7b04477bba03e42a485b7fea74877c6c0e","externalIds":{"DBLP":"journals/corr/abs-2209-08305","ArXiv":"2209.08305","DOI":"10.48550/arXiv.2209.08305","CorpusId":252367526},"title":"Active-Passive SimStereo - Benchmarking the Cross-Generalization Capabilities of Deep Learning-based Stereo Methods"},{"paperId":"32aa4645e97dc7075c454d8950814cc7b6aa2740","externalIds":{"ArXiv":"2207.13340","DBLP":"journals/corr/abs-2207-13340","DOI":"10.48550/arXiv.2207.13340","CorpusId":251104795},"title":"PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation"},{"paperId":"cd7c7a03edeb7fe7310a7e95d21c0eb2cab22526","externalIds":{"ArXiv":"2207.09796","DBLP":"journals/corr/abs-2207-09796","DOI":"10.48550/arXiv.2207.09796","CorpusId":250699094},"title":"EASNet: Searching Elastic and Accurate Network Architecture for Stereo Matching"},{"paperId":"405771deaaef87ba5b5ea9c3be0667f014abdf05","externalIds":{"DBLP":"conf/aaai/ChoY22","DOI":"10.1609/aaai.v36i1.19923","CorpusId":250290292},"title":"Event-Image Fusion Stereo Using Cross-Modality Feature Propagation"},{"paperId":"5dcd3ac0b26d0432598f1d66b14ed05057fc9dd4","externalIds":{"DBLP":"journals/corr/abs-2206-07047","ArXiv":"2206.07047","DOI":"10.1109/CVPR52688.2022.01549","CorpusId":249642179},"title":"RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation"},{"paperId":"87f07672a5751ed450fe499b8dbc06333c7c1bf7","externalIds":{"DBLP":"conf/cvpr/ZhangTFMZP22","DOI":"10.1109/CVPR52688.2022.01833","CorpusId":250552252},"title":"Continual Stereo Matching of Continuous Driving Scenes with Growing Architecture"},{"paperId":"a4726e8da6b04cf4b2e44613a7c9e60c4c641489","externalIds":{"DBLP":"conf/cvpr/RamirezTPSMS22","ArXiv":"2206.04671","DOI":"10.1109/CVPR52688.2022.02049","CorpusId":249538677},"title":"Open Challenges in Deep Stereo: the Booster Dataset"},{"paperId":"3155407163c4fbbafeaa963b1742dd4710b09375","externalIds":{"DBLP":"conf/cvpr/ZhangCZCZGL22","DOI":"10.1109/CVPR52688.2022.00848","CorpusId":250602271},"title":"Discrete time convolution for fast event-based stereo"},{"paperId":"7601da4e59cd7c4f8177590053c29ba890cbd71a","externalIds":{"DBLP":"conf/cvpr/NamIYC22","DOI":"10.1109/CVPR52688.2022.00602","CorpusId":249980412},"title":"Stereo Depth from Events Cameras: Concentrate and Focus on the Future"},{"paperId":"d01ebfcd8c885d023af01290f0bb1b8c716134d7","externalIds":{"DBLP":"conf/cvpr/ChenXCPZZ22","ArXiv":"2204.01429","DOI":"10.1109/CVPR52688.2022.01262","CorpusId":247939595},"title":"Degradation-agnostic Correspondence from Resolution-asymmetric Stereo"},{"paperId":"935fb74758e8ebb2ad85a80a00646ea24e7ee096","externalIds":{"ArXiv":"2204.00179","DBLP":"conf/cvpr/LiuYQ22","DOI":"10.1109/CVPR52688.2022.01267","CorpusId":247922809},"title":"GraftNet: Towards Domain Generalized Stereo Matching with a Broad-Spectrum and Task-Oriented Feature"},{"paperId":"a0468c6d980eb88962c72a19864320a93f782ca8","externalIds":{"DBLP":"journals/ral/BaiXCWZG22","DOI":"10.1109/LRA.2022.3152830","CorpusId":247231064},"title":"Faster-LIO: Lightweight Tightly Coupled Lidar-Inertial Odometry Using Parallel Sparse Incremental Voxels"},{"paperId":"c71dd23cc8671d321d799dd3b1792581bf5a56e5","externalIds":{"DBLP":"conf/cvpr/LiWXCYYLFL22","ArXiv":"2203.11483","DOI":"10.1109/CVPR52688.2022.01578","CorpusId":247596980},"title":"Practical Stereo Matching via Cascaded Recurrent Network with Adaptive Correlation"},{"paperId":"7fca094dce2855f22d25c0d6e1d6cd4423236038","externalIds":{"ArXiv":"2203.10887","DBLP":"conf/cvpr/ZhangW00HC00HH22","DOI":"10.1109/CVPR52688.2022.01266","CorpusId":247593817},"title":"Revisiting Domain Generalized Stereo Matching Networks from a Feature Consistency Perspective"},{"paperId":"1ffa8d09044c93bd7278ee2a70fb09ddd7bc5d48","externalIds":{"ArXiv":"2203.10493","DBLP":"journals/corr/abs-2203-10493","DOI":"10.1109/CVPR52688.2022.00179","CorpusId":247594866},"title":"Depth Estimation by Combining Binocular Stereo and Monocular Structured-Light"},{"paperId":"16ac5b3b7e853381adce95c31d6e45b7455fa0bd","externalIds":{"DBLP":"journals/corr/abs-2203-04554","ArXiv":"2203.04554","DOI":"10.1109/CVPR52688.2022.00198","CorpusId":247318814},"title":"ChiTransformer: Towards Reliable Stereo from Cues"},{"paperId":"a6626b96ccc44f50e918c3f39c52191b4fc22bc3","externalIds":{"DBLP":"journals/corr/abs-2203-02146","ArXiv":"2203.02146","DOI":"10.1109/CVPR52688.2022.01264","CorpusId":247244811},"title":"Attention Concatenation Volume for Accurate and Efficient Stereo Matching"},{"paperId":"5223a5a9f83d13f4d7411eb8253ac3c8c1421372","externalIds":{"DBLP":"journals/tnn/RaoDSH23","DOI":"10.1109/TNNLS.2022.3146306","CorpusId":246748961,"PubMed":"35143404"},"title":"Rethinking Training Strategy in Stereo Matching"},{"paperId":"60e69982ef2920596c6f31d6fd3ca5e9591f3db6","externalIds":{"ArXiv":"2201.05989","DBLP":"journals/tog/MullerESK22","DOI":"10.1145/3528223.3530127","CorpusId":246016186},"title":"Instant neural graphics primitives with a multiresolution hash encoding"},{"paperId":"ad5e78b00a2b6218bac096e62fd4d11ef447b0d2","externalIds":{"DBLP":"journals/corr/abs-2201-02263","ArXiv":"2201.02263","DOI":"10.1109/CVPR52688.2022.01268","CorpusId":245827816},"title":"ITSA: An Information-Theoretic Approach to Automatic Shortcut Avoidance and Domain Generalization in Stereo Matching Networks"},{"paperId":"31065a23bd5cef0d20753d3d5e01c277f7edc35c","externalIds":{"ArXiv":"2112.02772","DBLP":"journals/corr/abs-2112-02772","DOI":"10.1109/CVPR52688.2022.01269","CorpusId":244908376},"title":"ActiveZero: Mixed Domain Learning for Active Stereovision with Zero Annotation"},{"paperId":"654849305b95c6ee30b91130f69b9b09a6327602","externalIds":{"ArXiv":"2112.01011","DBLP":"conf/aaai/LiuYL22","DOI":"10.1609/aaai.v36i2.20056","CorpusId":244799407},"title":"Local Similarity Pattern and Cost Self-Reassembling for Deep Stereo Matching Networks"},{"paperId":"5d916f1c8930c1e7b25a7e86d9650f9f833e858e","externalIds":{"DBLP":"conf/cvpr/LiuLXLL022","ArXiv":"2111.10502","DOI":"10.1109/CVPR52688.2022.00570","CorpusId":244478531},"title":"CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation"},{"paperId":"d2dcff2aa10cc515ad0f9b0af6a0836511d697b4","externalIds":{"DBLP":"conf/3dim/AleottiTRPSMS21","ArXiv":"2110.15367","DOI":"10.1109/3DV53792.2021.00031","CorpusId":240288624},"title":"Neural Disparity Refinement for Arbitrary Resolution Stereo"},{"paperId":"4a2f353375fe1edbffc6b155888da83ff5bf172b","externalIds":{"DBLP":"conf/iccv/IYC21","DOI":"10.1109/ICCV48922.2021.00422","CorpusId":244306440},"title":"Event-Intensity Stereo: Estimating Depth by the Best of Both Worlds"},{"paperId":"3c1c378a72aad6d8ca5d86fe55aba7850f7cc92b","externalIds":{"DBLP":"conf/iccv/MaoLLDWKL21","DOI":"10.1109/ICCV48922.2021.00625","CorpusId":244305177},"title":"UASNet: Uncertainty Adaptive Sampling Network for Deep Stereo Matching"},{"paperId":"8a36a59a910947d3244fd4cec1013ef9587c61cb","externalIds":{"DBLP":"conf/iccv/ChenY0X0ZDZH21","DOI":"10.1109/ICCV48922.2021.01524","CorpusId":244101888},"title":"Revealing the Reciprocal Relations between Self-Supervised Stereo and Monocular Depth Estimation"},{"paperId":"09c8d8249d9e61dace9bd1e0b3cd8042a7ef365d","externalIds":{"ArXiv":"2109.07547","DBLP":"journals/corr/abs-2109-07547","DOI":"10.1109/3DV53792.2021.00032","CorpusId":237532221},"title":"RAFT-Stereo: Multilevel Recurrent Field Transforms for Stereo Matching"},{"paperId":"2e381658496d103d48949d32438169766da20940","externalIds":{"DBLP":"conf/wacv/ShamsafarWRZ22","ArXiv":"2108.09770","DOI":"10.1109/WACV51458.2022.00075","CorpusId":237267197},"title":"MobileStereoNet: Towards Lightweight Deep Networks for Stereo Matching"},{"paperId":"8b3c29efafc830ee3e68ac4295a2cb4503ca6099","externalIds":{"DBLP":"conf/iros/BangunharcanaCL21","ArXiv":"2108.05773","DOI":"10.1109/IROS51168.2021.9635909","CorpusId":236986830},"title":"Correlate-and-Excite: Real-Time Stereo Matching via Guided Cost Volume Excitation"},{"paperId":"9db33f93c5db253d324392ebc79f6714b72f6832","externalIds":{"MAG":"3170263653","DBLP":"conf/icmcs/WangZYDZ021","DOI":"10.1109/ICME51207.2021.9428423","CorpusId":236273594},"title":"IRS: A Large Naturalistic Indoor Robotics Stereo Dataset to Train Deep Models for Disparity and Surface Normal Estimation"},{"paperId":"aa7ff7cf95a893436117a5bf737cc4d6c70d387d","externalIds":{"DBLP":"conf/cvpr/ChiWHGY21","DOI":"10.1109/CVPR46437.2021.00249","CorpusId":235692314},"title":"Feature-Level Collaboration: Joint Unsupervised Learning of Optical Flow, Stereo Depth and Camera Motion"},{"paperId":"a3ff5cb5d3e2a43e4dda4b9e26f385776a703a7a","externalIds":{"ArXiv":"2104.07516","DBLP":"conf/cvpr/YaoJDLW21","DOI":"10.1109/CVPR46437.2021.00603","CorpusId":233241135},"title":"A Decomposition Model for Stereo Matching"},{"paperId":"440a7f34cbcf302e62da3fdb7172e8b0c86773f0","externalIds":{"DBLP":"conf/iros/YuanZWZTWC21","ArXiv":"2104.04170","DOI":"10.1109/IROS51168.2021.9636616","CorpusId":233204670},"title":"Stereo Matching by Self-supervision of Multiscopic Vision"},{"paperId":"55db23c0f61de1a739f6e8f8708357acfdd6ece2","externalIds":{"DBLP":"journals/corr/abs-2104-04314","ArXiv":"2104.04314","DOI":"10.1109/CVPR46437.2021.01369","CorpusId":233204703},"title":"CFNet: Cascade and Fused Cost Volume for Robust Stereo Matching"},{"paperId":"5b95063f3ecdb8883550120c44d98f7e0e783f4f","externalIds":{"DBLP":"journals/corr/abs-2104-03866","ArXiv":"2104.03866","DOI":"10.1109/CVPR46437.2021.00883","CorpusId":233182047},"title":"SMD-Nets: Stereo Mixture Density Networks"},{"paperId":"828e4f2c570657042b7d77b48423b08265163635","externalIds":{"MAG":"3146873565","DBLP":"journals/pami/PoggiTBMM22","DOI":"10.1109/TPAMI.2021.3070917","CorpusId":232432191,"PubMed":"33819150"},"title":"On the Synergies Between Machine Learning and Binocular Stereo for Depth Estimation From Images: A Survey"},{"paperId":"40445acd38043b43ffb4c7da5cf445882b6c6a8a","externalIds":{"DBLP":"journals/corr/abs-2103-10768","ArXiv":"2103.10768","DOI":"10.1109/ICRA48506.2021.9561621","CorpusId":232290628},"title":"There and Back Again: Self-supervised Multispectral Correspondence Estimation"},{"paperId":"a810620659eee14561b69b6c02733f95ab87b027","externalIds":{"DBLP":"journals/corr/abs-2103-07798","ArXiv":"2103.07798","DOI":"10.1109/IROS51168.2021.9635869","CorpusId":232233731},"title":"ORStereo: Occlusion-Aware Recurrent Stereo Matching for 4K-Resolution Images"},{"paperId":"ceab4559736c6ba710191b12ed7f6123b2f85131","externalIds":{"DBLP":"journals/corr/abs-2103-06011","ArXiv":"2103.06011","DOI":"10.1109/LRA.2021.3068942","CorpusId":232170230},"title":"DSEC: A Stereo Event Camera Dataset for Driving Scenarios"},{"paperId":"037440ca869cde871cf311374f4d792bffc63d7d","externalIds":{"DBLP":"journals/corr/abs-2103-02396","ArXiv":"2103.02396","DOI":"10.1109/CVPR46437.2021.01643","CorpusId":232104918},"title":"S3: Learnable Sparse Signal Superdensity for Guided Depth Estimation"},{"paperId":"f359525cd645d367bc97e4a55c3e2746e9d0dbdc","externalIds":{"ArXiv":"2101.00431","DBLP":"journals/pami/PoggiKTKAMSM22","DOI":"10.1109/TPAMI.2021.3069706","CorpusId":230433678,"PubMed":"33798066"},"title":"On the Confidence of Stereo Matching in a Deep-Learning Era: A Quantitative Evaluation"},{"paperId":"2e9f7a9004bfc925deebb1741239315fd2ee888e","externalIds":{"ArXiv":"2101.01601","DBLP":"journals/corr/abs-2101-01601","DOI":"10.1109/CVPR46437.2021.01231","CorpusId":235692111},"title":"Bilateral Grid Learning for Stereo Matching Networks"},{"paperId":"590073947a4cd7cb2f1c8840076e047a35704fb9","externalIds":{"DBLP":"journals/corr/abs-2012-00726","MAG":"3107284470","ArXiv":"2012.00726","DOI":"10.1109/CVPR46437.2021.00827","CorpusId":227238664},"title":"RAFT-3D: Scene Flow using Rigid-Motion Embeddings"},{"paperId":"81a4381176c4e01355bf03ca8147cd83ddae01d4","externalIds":{"MAG":"3108808148","DBLP":"journals/corr/abs-2011-13117","ArXiv":"2011.13117","DOI":"10.1109/CVPR46437.2021.00570","CorpusId":227209167},"title":"Polka Lines: Learning Structured Illumination and Reconstruction for Active Stereo"},{"paperId":"e4ac49aa6f1d7ea8bfa3b09b4642bc2ec68ca5a0","externalIds":{"DBLP":"journals/corr/abs-2011-08332","ArXiv":"2011.08332","MAG":"3098234389","DOI":"10.1109/CVPR46437.2021.00549","CorpusId":226975921},"title":"EffiScene: Efficient Per-Pixel Rigidity Inference for Unsupervised Joint Learning of Optical Flow, Depth, Camera Pose and Motion Segmentation"},{"paperId":"75bcdf04827cd230d88b70c622dce8868eb50a3b","externalIds":{"DBLP":"journals/corr/abs-2011-02910","ArXiv":"2011.02910","MAG":"3096678291","DOI":"10.1109/ICCV48922.2021.00614","CorpusId":226254259},"title":"Revisiting Stereo Depth Estimation From a Sequence-to-Sequence Perspective with Transformers"},{"paperId":"ec2fcacad9406315be5944777e4deed947b507aa","externalIds":{"DBLP":"conf/nips/ChengZHDCLDG20","MAG":"3093769466","ArXiv":"2010.13501","CorpusId":225072923},"title":"Hierarchical Neural Architecture Search for Deep Stereo Matching"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"ArXiv":"2010.11929","MAG":"3119786062","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"a246bc9066d2466794191afe994aad90a5eef5c5","externalIds":{"ArXiv":"2010.07347","DBLP":"journals/corr/abs-2010-07347","MAG":"3093265072","DOI":"10.1109/3DV50981.2020.00046","CorpusId":222378414},"title":"Matching-space Stereo Networks for Cross-domain Generalization"},{"paperId":"956a6580b18663b2cecb0410caefd80284058e78","externalIds":{"MAG":"3108103523","DBLP":"journals/corr/abs-2008-07130","ArXiv":"2008.07130","DOI":"10.1007/978-3-030-58621-8_36","CorpusId":221219239},"title":"Reversing the cycle: self-supervised deep stereo through enhanced monocular distillation"},{"paperId":"039154f8e22f55c5b53de1caf95825dd77708129","externalIds":{"MAG":"3047247464","DBLP":"journals/corr/abs-2008-01484","ArXiv":"2008.01484","DOI":"10.1007/978-3-030-58452-8_42","CorpusId":220961565},"title":"Learning Stereo from Single Images"},{"paperId":"9b9aad31f9442fac06a1ad7e7f5ca186dcdd1d3c","externalIds":{"DBLP":"journals/chinaf/BaoWXGHZ20","MAG":"3048548052","DOI":"10.1007/s11432-019-2803-x","CorpusId":221110870},"title":"InStereo2K: a large real dataset for stereo matching in indoor scenes"},{"paperId":"da7ee7672f2326ee17e0fc80f4a6a6ac9d671b12","externalIds":{"DBLP":"conf/cvpr/TankovichH0KFB21","ArXiv":"2007.12140","MAG":"3045038724","DOI":"10.1109/CVPR46437.2021.01413","CorpusId":220713313},"title":"HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching"},{"paperId":"d7be355589181cdd5014b683014a111e6bc28b41","externalIds":{"ArXiv":"2007.05233","MAG":"3040934998","DBLP":"journals/pami/PoggiTTMS22","DOI":"10.1109/TPAMI.2021.3075815","CorpusId":220486326,"PubMed":"33909558"},"title":"Continual Adaptation for Deep Stereo"},{"paperId":"a6ae0c4588789696f3e68919e6318fda341b791d","externalIds":{"ArXiv":"2007.03085","DBLP":"journals/corr/abs-2007-03085","MAG":"3103907518","CorpusId":220381395},"title":"Wasserstein Distances for Stereo Disparity Estimation"},{"paperId":"3756219baa15849222d3b52bef86d3581701e0ba","externalIds":{"DBLP":"conf/eccv/ShenDSRZZ22","ArXiv":"2006.12797","DOI":"10.1007/978-3-031-19824-3_17","CorpusId":253523827},"title":"PCW-Net: Pyramid Combination and Warping Cost Volume for Stereo Matching"},{"paperId":"a62615a1fb205ad506fc373dd4681bf21c730fc5","externalIds":{"ArXiv":"2006.02535","DBLP":"journals/corr/abs-2006-02535","MAG":"3093569132","DOI":"10.1109/TPAMI.2020.3032602","CorpusId":219303641,"PubMed":"33079659"},"title":"A Survey on Deep Learning Techniques for Stereo-Based Depth Estimation"},{"paperId":"b131d255bf8bff6c4bac765c57190e2f448b2b2b","externalIds":{"MAG":"3034960559","DBLP":"conf/cvpr/LiuRZLL20","DOI":"10.1109/cvpr42600.2020.00210","CorpusId":219616244},"title":"Visually Imbalanced Stereo Matching"},{"paperId":"0b65f2867f56c8010c327e1d8c43cba8b9feee50","externalIds":{"MAG":"3034237717","DBLP":"conf/cvpr/YangWL20","DOI":"10.1109/cvpr42600.2020.01290","CorpusId":219964148},"title":"WaveletStereo: Learning Wavelet Coefficients of Disparity Map in Stereo Matching"},{"paperId":"807091b2365948ea98abb4ad9df3b4a362bdd409","externalIds":{"MAG":"3034976873","DBLP":"conf/cvpr/BadkiTKKSG20","ArXiv":"2005.07274","DOI":"10.1109/cvpr42600.2020.00167","CorpusId":218665575},"title":"Bi3D: Stereo Depth Estimation via Binary Classifications"},{"paperId":"399f60140092c6736cb0de7a3db1226052b9748a","externalIds":{"MAG":"3034548607","DBLP":"conf/cvpr/LiuYSWL20","ArXiv":"2005.01927","DOI":"10.1109/cvpr42600.2020.01277","CorpusId":218502570},"title":"StereoGAN: Bridging Synthetic-to-Real Domain Gap by Joint Optimization of Domain Translation and Stereo Matching"},{"paperId":"08d0d89966f71ac7ae01b8193f7f30f5c275ba59","externalIds":{"MAG":"3089784422","DBLP":"conf/icra/ChaiWT20","DOI":"10.1109/ICRA40945.2020.9196894","CorpusId":221847899},"title":"Deep Depth Fusion for Black, Transparent, Reflective and Texture-Less Objects"},{"paperId":"ae2b91fd09d6856ea4306fc3a3807ccf0e0ddfaf","externalIds":{"DBLP":"conf/cvpr/XuZ20","MAG":"3018359716","ArXiv":"2004.09548","DOI":"10.1109/cvpr42600.2020.00203","CorpusId":216036364},"title":"AANet: Adaptive Aggregation Network for Efficient Stereo Matching"},{"paperId":"146d462e7372d985dc1e6cf18a1543ada451ee09","externalIds":{"DBLP":"conf/cvpr/SongYZ00S21","ArXiv":"2004.04627","MAG":"3015696844","DOI":"10.1109/CVPR46437.2021.01019","CorpusId":215548243},"title":"AdaStereo: A Simple and Efficient Approach for Adaptive Stereo Matching"},{"paperId":"f74cbc54f7ed069c7726ff96156358522c4a67b3","externalIds":{"MAG":"3014605797","DBLP":"journals/corr/abs-2004-02138","ArXiv":"2004.02138","DOI":"10.1109/cvpr42600.2020.00668","CorpusId":214802751},"title":"Flow2Stereo: Effective Self-Supervised Learning of Optical Flow and Stereo Matching"},{"paperId":"34981c96dda64943625404cdb2deda296af75842","externalIds":{"DBLP":"journals/corr/abs-2003-14338","MAG":"3014771270","ArXiv":"2003.14338","DOI":"10.1109/IROS45743.2020.9341801","CorpusId":214727835},"title":"TartanAir: A Dataset to Push the Limits of Visual SLAM"},{"paperId":"3230e2d6b4671cc03974af2219c6d3270e6fac70","externalIds":{"MAG":"3013965544","DBLP":"conf/ijcai/Teed021","ArXiv":"2003.12039","DOI":"10.1007/978-3-030-58536-5_24","CorpusId":214667893},"title":"RAFT: Recurrent All-Pairs Field Transforms for Optical Flow"},{"paperId":"0b825239dec85ffc01069d765bba3872ecb0b037","externalIds":{"MAG":"3013428964","DBLP":"journals/corr/abs-2003-11172","ArXiv":"2003.11172","CorpusId":214641061},"title":"Holopix50k: A Large-Scale In-the-wild Stereo Image Dataset"},{"paperId":"9644761690ddb388e0b4b25f50842b3d48123af1","externalIds":{"ArXiv":"2003.10758","DBLP":"journals/corr/abs-2003-10758","MAG":"3091300680","DOI":"10.1109/ICRA40945.2020.9197031","CorpusId":214623210},"title":"FADNet: A Fast and Accurate Network for Disparity Estimation"},{"paperId":"c6e57b2d36a4231cef82d7e0e27413ae4bb4dee5","externalIds":{"MAG":"3003576934","DBLP":"journals/corr/abs-2001-10773","ArXiv":"2001.10773","CorpusId":210942959},"title":"Virtual KITTI 2"},{"paperId":"f88fb3a3ef31ecd9a00c7bd800cbd8f9bdb2f704","externalIds":{"ArXiv":"1912.06378","DBLP":"journals/corr/abs-1912-06378","MAG":"3034530552","DOI":"10.1109/CVPR42600.2020.00257","CorpusId":209370711},"title":"Cascade Cost Volume for High-Resolution Multi-View Stereo and Stereo Matching"},{"paperId":"d7114510b721d356ba9a39c121e6de0773762661","externalIds":{"DBLP":"conf/iccp/ZhuWKD21","MAG":"2993192313","ArXiv":"1912.01584","DOI":"10.1109/ICCP51581.2021.9466265","CorpusId":208547736},"title":"EventGAN: Leveraging Large Scale Image Datasets for Event Cameras"},{"paperId":"2a2b3ac844e98072015eab18cca4b54c95b2b039","externalIds":{"DBLP":"conf/eccv/ZhangQYPWT20","MAG":"2989650669","ArXiv":"1911.13287","DOI":"10.1007/978-3-030-58536-5_25","CorpusId":208512761},"title":"Domain-invariant Stereo Matching Networks"},{"paperId":"6a775d40093d0cca245d2922d5b5417524b1ac1e","externalIds":{"MAG":"2990108166","DBLP":"conf/cvpr/KusupatiCCS20","ArXiv":"1911.10444","DOI":"10.1109/cvpr42600.2020.00226","CorpusId":208267850},"title":"Normal Assisted Stereo Depth Estimation"},{"paperId":"b0f6398a583258d6aacd5600906b02e7efaa1810","externalIds":{"DBLP":"conf/aaai/AleottiPTM20","MAG":"2991389044","ArXiv":"1911.10090","DOI":"10.1609/AAAI.V34I07.6613","CorpusId":208248373},"title":"Learning End-To-End Scene Flow by Distilling Single Tasks Knowledge"},{"paperId":"e0164f8d961cd6457b9dab9d020fc88e733b0fbb","externalIds":{"MAG":"2978385796","DBLP":"journals/corr/abs-1910-00541","ArXiv":"1910.00541","DOI":"10.1109/ICRA40945.2020.9196784","CorpusId":203610363},"title":"Real-Time Semantic Stereo Matching"},{"paperId":"6642bd52f24596ca57e253fc2b9387904572788b","externalIds":{"DBLP":"conf/iccv/ChenCC19","MAG":"2983735215","DOI":"10.1109/ICCV.2019.00909","CorpusId":273164097},"title":"On the Over-Smoothing Problem of CNN Based Disparity Estimation"},{"paperId":"1ef98dd2520136be3fda1549ff68a65e172ce14a","externalIds":{"DBLP":"journals/corr/abs-1910-12361","MAG":"2984858187","ArXiv":"1910.12361","DOI":"10.1109/ICCV.2019.00329","CorpusId":203598154},"title":"SENSE: A Shared Encoder Network for Scene-Flow Estimation"},{"paperId":"de2501bec09edc968f9ed2dabc1bd885ccc3020f","externalIds":{"MAG":"2991514044","DBLP":"conf/iccv/WuWZWJ19","DOI":"10.1109/ICCV.2019.00758","CorpusId":202235763},"title":"Semantic Stereo Matching With Pyramid Cost Volumes"},{"paperId":"67fc98119edf2debefd3a533a374429b1836aa10","externalIds":{"DBLP":"conf/iccv/DuggalWMHU19","ArXiv":"1909.05845","MAG":"2972703007","DOI":"10.1109/ICCV.2019.00448","CorpusId":202565789},"title":"DeepPruner: Learning Efficient Stereo Matching via Differentiable PatchMatch"},{"paperId":"56881c9f3e83d8231b43492bedb80bbbab6ef6c2","externalIds":{"ArXiv":"1909.03751","DBLP":"conf/aaai/0005C0YYLY20","MAG":"2971834956","DOI":"10.1609/AAAI.V34I07.6991","CorpusId":202540128},"title":"Adaptive Unimodal Cost Volume Filtering for Deep Stereo Matching"},{"paperId":"7bd83b055702bc178aa26def5b6df463f8eab7b9","externalIds":{"MAG":"2955639361","DBLP":"journals/corr/abs-1907-01341","ArXiv":"1907.01341","DOI":"10.1109/TPAMI.2020.3019967","CorpusId":195776274,"PubMed":"32853149"},"title":"Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer"},{"paperId":"630c9e9594ae79f82bea1c55ed7eb6db52f0e47f","externalIds":{"MAG":"2998281665","DBLP":"journals/pami/RebecqRKS21","ArXiv":"1906.07165","DOI":"10.1109/TPAMI.2019.2963386","CorpusId":189998802,"PubMed":"31902754"},"title":"High Speed and High Dynamic Range Video with an Event Camera"},{"paperId":"6f1ecfb639b9e89460c4d1f71ced86f9a9b86ee2","externalIds":{"ArXiv":"1906.06310","DBLP":"conf/iclr/YouWCGPHCW20","MAG":"2996166203","CorpusId":189898655},"title":"Pseudo-LiDAR++: Accurate Depth for 3D Object Detection in Autonomous Driving"},{"paperId":"cdbef23475c744f0e8ebb62dd9ced57948e2442c","externalIds":{"MAG":"2994987678","ArXiv":"1912.06704","DBLP":"journals/corr/abs-1912-06704","DOI":"10.1109/CVPR.2019.00566","CorpusId":196183868},"title":"Hierarchical Deep Stereo Matching on High-Resolution Images"},{"paperId":"a0d16012e3583001ae1491192df60df30fbadba8","externalIds":{"DBLP":"journals/corr/abs-1905-07287","MAG":"3011943395","ArXiv":"1905.07287","DOI":"10.1109/ICCVW.2019.00262","CorpusId":158047123},"title":"CNN-Based Cost Volume Analysis as Confidence Measure for Dense Matching"},{"paperId":"d8ac764827588bf34d01581e68c15ff34416004b","externalIds":{"DBLP":"conf/icra/ZhangRVJ20","ArXiv":"1905.02744","MAG":"2944127276","DOI":"10.1109/ICRA40945.2020.9196628","CorpusId":147703832},"title":"LiStereo: Generate Dense Depth Maps from LIDAR and Stereo Imagery"},{"paperId":"015e49ab287e5610191c4b61d6e00c862a5677eb","externalIds":{"MAG":"2969048092","DBLP":"conf/icra/ZhanOY019","DOI":"10.1109/ICRA.2019.8793573","CorpusId":199541780},"title":"DSNet: Joint Learning for Scene Segmentation and Disparity Estimation"},{"paperId":"dd971c07879e1ce12b06991319528c06280eeb9b","externalIds":{"MAG":"2939877207","DBLP":"journals/corr/abs-1904-08405","ArXiv":"1904.08405","DOI":"10.5167/UZH-185139","CorpusId":118684904,"PubMed":"32750812"},"title":"Event-Based Vision: A Survey"},{"paperId":"83b8f369a1d02c0d0ca117b667d0ace46510cdc5","externalIds":{"MAG":"2937045595","ArXiv":"1904.06587","DBLP":"conf/cvpr/ZhangPYT19","DOI":"10.1109/CVPR.2019.00027","CorpusId":119304432},"title":"GA-Net: Guided Aggregation Net for End-To-End Stereo Matching"},{"paperId":"a1a19aaddf57c0546357d890d9269092ba0afb26","externalIds":{"MAG":"2962974533","DBLP":"conf/cvpr/Park0WZ19","ArXiv":"1903.07291","DOI":"10.1109/CVPR.2019.00244","CorpusId":81981856},"title":"Semantic Image Synthesis With Spatially-Adaptive Normalization"},{"paperId":"c814fa74ed76a761fd71f5d9c9eadde15a5af249","externalIds":{"MAG":"2950836025","DBLP":"conf/cvpr/GuoYYWL19","ArXiv":"1903.04025","DOI":"10.1109/CVPR.2019.00339","CorpusId":73729084},"title":"Group-Wise Correlation Stereo Network"},{"paperId":"268491f50a4d9e8691582b4821e37c737d753907","externalIds":{"MAG":"2921772171","ArXiv":"1903.04939","DBLP":"conf/wacv/YeeC20","DOI":"10.1109/WACV45572.2020.9093273","CorpusId":75136697},"title":"Fast Deep Stereo with 2D Convolutional Processing of Cost Signatures"},{"paperId":"1b5ea52c7ef8c88569a4be6c2a413c73bd542014","externalIds":{"MAG":"2950089863","DBLP":"conf/aaai/LiangGLWS19","ArXiv":"1903.01078","DOI":"10.1609/AAAI.V33I01.33018706","CorpusId":67856454},"title":"Unsupervised Cross-spectral Stereo Matching by Learning to Synthesize"},{"paperId":"7b4ac890f9635d839a043adce0c23090aa8a02f9","externalIds":{"DBLP":"conf/cvpr/YinDY19","MAG":"2904131599","ArXiv":"1812.06264","DOI":"10.1109/CVPR.2019.00620","CorpusId":56366093},"title":"Hierarchical Discrete Distribution Decomposition for Match Density Estimation"},{"paperId":"87727ace13caf990e6aca5176e32cd21b032c712","externalIds":{"ArXiv":"1810.11408","MAG":"2968164956","DBLP":"conf/icra/WangLHWMCW19","DOI":"10.1109/ICRA.2019.8794003","CorpusId":53082511},"title":"Anytime Stereo Image Depth Estimation on Mobile Devices"},{"paperId":"98333bedec446377cac57d63140ce0d4e79c097d","externalIds":{"MAG":"2896992269","DBLP":"journals/corr/abs-1810-05424","ArXiv":"1810.05424","DOI":"10.1109/CVPR.2019.00028","CorpusId":52978720},"title":"Real-Time Self-Adaptive Deep Stereo"},{"paperId":"3175307e30b0fa05b43d5d1f63bc963265f791f9","externalIds":{"DBLP":"journals/pami/ChengWY20","MAG":"2894788161","ArXiv":"1810.02695","DOI":"10.1109/TPAMI.2019.2947374","CorpusId":52934534,"PubMed":"31634121"},"title":"Learning Depth with Convolutional Spatial Propagation Network"},{"paperId":"908a00e5738336e2a7d96653ea35578f0c82dcfd","externalIds":{"DBLP":"conf/3dim/BatsosM18","MAG":"2896174833","DOI":"10.1109/3DV.2018.00036","CorpusId":52987834},"title":"RecResNet: A Recurrent Residual CNN Architecture for Disparity Map Enhancement"},{"paperId":"cc225ddfbfa6cdbc3748a6f6f04dc1cf3cd5d96d","externalIds":{"MAG":"2887479417","ArXiv":"1808.01838","DBLP":"journals/corr/abs-1808-01838","DOI":"10.1007/978-3-030-01258-8_38","CorpusId":51930833},"title":"Occlusions, Motion and Depth Boundaries with a Generic Network for Disparity, Optical Flow or Scene Flow Estimation"},{"paperId":"92de2ed3805968d6d95da4fa9c44423ef50a6a37","externalIds":{"DBLP":"journals/corr/abs-1807-11699","MAG":"2886944874","ArXiv":"1807.11699","DOI":"10.1007/978-3-030-01234-2_39","CorpusId":51891703},"title":"SegStereo: Exploiting Semantic Information for Disparity Estimation"},{"paperId":"0c1a6ccfe2b507d6edaa856c1e00b29dc1307d5b","externalIds":{"MAG":"2883040756","DBLP":"journals/corr/abs-1807-08865","ArXiv":"1807.08865","DOI":"10.1007/978-3-030-01267-0_35","CorpusId":50773155},"title":"StereoNet: Guided Hierarchical Refinement for Real-Time Edge-Aware Depth Prediction"},{"paperId":"216f1a83594799807806fdef4f079d86e039326c","externalIds":{"MAG":"2898306585","ArXiv":"1807.06009","DBLP":"journals/corr/abs-1807-06009","DOI":"10.1007/978-3-030-01237-3_48","CorpusId":49867520},"title":"ActiveStereoNet: End-to-End Self-Supervised Learning for Active Stereo Systems"},{"paperId":"c5fcc36768428185c0ec0f04c82c9204c9ba962c","externalIds":{"MAG":"2798881637","DBLP":"conf/cvpr/ZhiPHN18","DOI":"10.1109/CVPR.2018.00205","CorpusId":29158639},"title":"Deep Material-Aware Cross-Spectral Stereo Matching"},{"paperId":"18610275bd5b5b8a12182b9d347b69f35524404c","externalIds":{"DBLP":"conf/cvpr/BatsosCM18","MAG":"2963537624","ArXiv":"1804.01967","DOI":"10.1109/CVPR.2018.00220","CorpusId":4606944},"title":"CBMV: A Coalesced Bidirectional Matching Volume for Disparity Estimation"},{"paperId":"316b1b9d96149e7bb3d9d6afc0295881c6123cc8","externalIds":{"ArXiv":"1803.08669","MAG":"2963619659","DBLP":"journals/corr/abs-1803-08669","DOI":"10.1109/CVPR.2018.00567","CorpusId":4252896},"title":"Pyramid Stereo Matching Network"},{"paperId":"3f659a3eef224889f142c46ef94f6cdcc69f5fe1","externalIds":{"MAG":"2963277791","DBLP":"conf/accv/SongZHF18","ArXiv":"1803.05196","DOI":"10.1007/978-3-030-20873-8_2","CorpusId":3871029},"title":"EdgeStereo: A Context Integrated Residual Pyramid Network for Stereo Matching"},{"paperId":"f1e92f09209c7f50e05599c7551520ca129a6de4","externalIds":{"MAG":"2785582094","DBLP":"journals/corr/abs-1801-10202","ArXiv":"1801.10202","DOI":"10.1109/LRA.2018.2800793","CorpusId":3416874},"title":"The Multivehicle Stereo Event Camera Dataset: An Event Camera Dataset for 3D Perception"},{"paperId":"dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4","externalIds":{"MAG":"2949261999","ArXiv":"1801.04381","DBLP":"conf/cvpr/SandlerHZZC18","DOI":"10.1109/CVPR.2018.00474","CorpusId":4555207},"title":"MobileNetV2: Inverted Residuals and Linear Bottlenecks"},{"paperId":"33389b1da844f13aba317e8b16c814888c26c827","externalIds":{"MAG":"2794981464","DBLP":"conf/cvpr/LiangFGLCQZZ18","DOI":"10.1109/CVPR.2018.00297","CorpusId":4399373},"title":"Learning for Disparity Estimation Through Feature Constancy"},{"paperId":"ebf0615fc4d98cf1dbe527c79146ce1e50dce9af","externalIds":{"MAG":"2767621168","DBLP":"conf/corl/DosovitskiyRCLK17","ArXiv":"1711.03938","CorpusId":5550767},"title":"CARLA: An Open Urban Driving Simulator"},{"paperId":"a6aed23dd9b6cde15f026b1c0d3f868093a6e15a","externalIds":{"DBLP":"conf/iccv/PoggiTM17","MAG":"2777632355","DOI":"10.1109/ICCV.2017.559","CorpusId":2143511},"title":"Quantitative Evaluation of Confidence Measures in a Machine Learning World"},{"paperId":"439f205642eaebafa95047be9933a3872aa66553","externalIds":{"MAG":"2951441592","DBLP":"journals/corr/abs-1708-09204","ArXiv":"1708.09204","DOI":"10.1109/ICCVW.2017.108","CorpusId":31762881},"title":"Cascade Residual Learning: A Two-Stage Convolutional Neural Network for Stereo Matching"},{"paperId":"e4972e6af450a5ba6b648684d6953e789bfc18c3","externalIds":{"DBLP":"conf/cvpr/TreibleSSKOPSK17","MAG":"2741160171","DOI":"10.1109/CVPR.2017.22","CorpusId":237658},"title":"CATS: A Color and Thermal Stereo Benchmark"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"0ba19bb88c856b880d198f4b6e9dcf8144657df8","externalIds":{"DBLP":"conf/iccv/KendallMDH17","MAG":"2951179855","ArXiv":"1703.04309","DOI":"10.1109/ICCV.2017.17","CorpusId":2658860},"title":"End-to-End Learning of Geometry and Context for Deep Stereo Regression"},{"paperId":"879c01bcb4a969bcf81d64f3b0519570cd96eb42","externalIds":{"MAG":"2953232546","DBLP":"conf/cvpr/ShakedW17","ArXiv":"1701.00165","DOI":"10.1109/CVPR.2017.730","CorpusId":11020309},"title":"Improved Stereo Matching with Constant Highway Networks and Reflective Confidence Learning"},{"paperId":"659c3023420f4b6274f03a40ee76c6aa1c54cfb0","externalIds":{"MAG":"2584471766","DBLP":"conf/cvpr/GidarisK17","ArXiv":"1612.04770","DOI":"10.1109/CVPR.2017.760","CorpusId":3104625},"title":"Detect, Replace, Refine: Deep Structured Prediction for Pixel Wise Labeling"},{"paperId":"e90e01ee452d1184c65713ce84c468092dfb080e","externalIds":{"DBLP":"conf/3dim/PoggiM16a","MAG":"2561219336","DOI":"10.1109/3DV.2016.61","CorpusId":22459064},"title":"Learning a General-Purpose Confidence Measure Based on O(1) Features and a Smarter Aggregation Strategy for Semi Global Matching"},{"paperId":"4463dc4a32b948f0230f3b782cbfecaf1c9e5b1d","externalIds":{"DBLP":"conf/cvpr/GodardAB17","MAG":"2520707372","ArXiv":"1609.03677","DOI":"10.1109/CVPR.2017.699","CorpusId":206596513},"title":"Unsupervised Monocular Depth Estimation with Left-Right Consistency"},{"paperId":"e517a34dbacfba588e6480f110e4c27665686819","externalIds":{"MAG":"2440384215","DBLP":"conf/cvpr/LuoSU16","DOI":"10.1109/CVPR.2016.614","CorpusId":10845625},"title":"Efficient Deep Learning for Stereo Matching"},{"paperId":"e944b414e9f601a6008076bd43b91d382090adbc","externalIds":{"DBLP":"conf/cvpr/GaidonWCV16","MAG":"2949907962","ArXiv":"1605.06457","DOI":"10.1109/CVPR.2016.470","CorpusId":1203247},"title":"VirtualWorlds as Proxy for Multi-object Tracking Analysis"},{"paperId":"1ced31e02234bc3d1092ffb2c7442ffbd51cb309","externalIds":{"DBLP":"journals/corr/MayerIHFCDB15","MAG":"2259424905","ArXiv":"1512.02134","DOI":"10.1109/CVPR.2016.438","CorpusId":206594275},"title":"A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation"},{"paperId":"bb6d5d134981fe8dbd283d422a7d149119bc0f06","externalIds":{"DBLP":"conf/iccv/ChenS0YH15","MAG":"2214868166","DOI":"10.1109/ICCV.2015.117","CorpusId":3174691},"title":"A Deep Visual Correspondence Embedding Model for Stereo Matching Costs"},{"paperId":"ad3e7515c61ccdc2c36887e7d4929c78904881db","externalIds":{"ArXiv":"1510.05970","MAG":"1772650917","DBLP":"journals/jmlr/ZbontarL16","CorpusId":6913648},"title":"Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches"},{"paperId":"b9a7b80a405782d13270d6e8c516b595dec34529","externalIds":{"DBLP":"conf/cvpr/ParkY15","MAG":"1939746761","DOI":"10.1109/CVPR.2015.7298605","CorpusId":1355432},"title":"Leveraging stereo matching with learning-based confidence measures"},{"paperId":"6364fdaa0a0eccd823a779fcdd489173f938e91a","externalIds":{"MAG":"1901129140","DBLP":"journals/corr/RonnebergerFB15","ArXiv":"1505.04597","DOI":"10.1007/978-3-319-24574-4_28","CorpusId":3719281},"title":"U-Net: Convolutional Networks for Biomedical Image Segmentation"},{"paperId":"7eb017381d264a542f6a0f20cd953cd00c06e846","externalIds":{"MAG":"63091017","DBLP":"conf/dagm/ScharsteinHKKNWW14","DOI":"10.1007/978-3-319-11752-2_3","CorpusId":14915763},"title":"High-Resolution Stereo Datasets with Subpixel-Accurate Ground Truth"},{"paperId":"4d0fc815dced9db3954ed21060e9894e1555ee3d","externalIds":{"MAG":"2296228853","DBLP":"conf/rss/ZhangS14","DOI":"10.15607/RSS.2014.X.007","CorpusId":18612391},"title":"LOAM: Lidar Odometry and Mapping in Real-time"},{"paperId":"248d372355bb752ad6c05f4e84ee44aaeb47b68f","externalIds":{"DBLP":"conf/cvpr/SpyropoulosKM14","MAG":"2125602726","DOI":"10.1109/CVPR.2014.210","CorpusId":218500984},"title":"Learning to Detect Ground Control Points for Improving the Accuracy of Stereo Matching"},{"paperId":"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62","externalIds":{"MAG":"1513100184","DBLP":"conf/eccv/ButlerWSB12","DOI":"10.1007/978-3-642-33783-3_44","CorpusId":4637111},"title":"A Naturalistic Open Source Movie for Optical Flow Evaluation"},{"paperId":"f420a1dbb06acbe945a242527b6ba8ca54c0abf6","externalIds":{"DBLP":"journals/scw/Schulze11","MAG":"2037412278","DOI":"10.1007/s00355-010-0475-4","CorpusId":1927244},"title":"A new monotonic, clone-independent, reversal symmetric, and condorcet-consistent single-winner election method"},{"paperId":"1c97127f828705328bceb6c5a50e2b1aefbb28ff","externalIds":{"MAG":"1912649600","DBLP":"conf/accv/GeigerRU10","DOI":"10.1007/978-3-642-19315-6_3","CorpusId":5535646},"title":"Efficient Large-Scale Stereo Matching"},{"paperId":"65392fe95f877fb9b43bde9fa9f0e212d23ea663","externalIds":{"MAG":"2033209267","DOI":"10.1117/1.2183668","CorpusId":120454412},"title":"Long-range three-dimensional imaging using range-gated laser radar images"},{"paperId":"d2f78c2b2b325d72f359d4c797c9aab6a8e60942","externalIds":{"MAG":"2104974755","DBLP":"journals/ijcv/ScharsteinS02","DOI":"10.1023/A:1014573219977","CorpusId":195859047},"title":"A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms"},{"paperId":"b32db9ed04910f1c94b5833f178c55a2b276b572","externalIds":{"DBLP":"conf/iccv/VedulaBRCK99","MAG":"2098500213","DOI":"10.1109/ICCV.1999.790293","CorpusId":276246328},"title":"Three-dimensional scene flow"},{"paperId":"b288673205c479d0a019d45f85c2716fe1f85096","externalIds":{"MAG":"1674866864","DBLP":"conf/eccv/ZabihW94","DOI":"10.1007/BFB0028345","CorpusId":703552},"title":"Non-parametric Local Transforms for Computing Visual Correspondence"},{"paperId":"64fefc40e288f2e3a4dab55991a13cbe8ef2a5b5","externalIds":{"DOI":"10.1177/003591577406701006","CorpusId":209362770},"title":"Perspective"},{"paperId":"3a522614e9d3ce79f8ecc06981a445c5e3482c0d","externalIds":{"DBLP":"conf/eccv/ChoY22","DOI":"10.1007/978-3-031-19824-3_28","CorpusId":253513043},"title":"Selection and Cross Similarity for Event-Image Deep Stereo"},{"paperId":"9922e05968561213a1d7d03cc0e03a50749ec507","externalIds":{"DBLP":"conf/accv/ZhaoZZZYO22","DOI":"10.1007/978-3-031-26319-4_1","CorpusId":257407018},"title":"EAI-Stereo: Error Aware Iterative Network for Stereo Matching"},{"paperId":"6345ec67d6312f95824b132fd2322de8e3cff7bd","externalIds":{"DBLP":"conf/accv/YinDCCSXXFDL22","DOI":"10.1007/978-3-031-26319-4_6","CorpusId":257406718},"title":"LSMD-Net: LiDAR-Stereo Fusion with Mixture Density Network for Depth Sensing"},{"paperId":"b49cb81c84850464c54a80bfe676b696cf6c3030","externalIds":{"DBLP":"conf/nips/00030H22","CorpusId":253305469},"title":"Revisiting Non-Parametric Matching Cost Volumes for Robust and Generalizable Stereo Matching"},{"paperId":"70c8469ea5ecf5e93d1df4151b2199ada13e3f01","externalIds":{"DBLP":"conf/accv/CaiQFSLLL22","DOI":"10.1007/978-3-031-26313-2_38","CorpusId":254128997},"title":"PBCStereo: A Compressed Stereo Network with Pure Binary Convolutional Operations"},{"paperId":"2caf53ad2202f3264c38ed8f05ec66a955a77fdc","externalIds":{"DBLP":"conf/accv/WangWSLS20","MAG":"3106572840","DOI":"10.1007/978-3-030-69525-5_11","CorpusId":229614734},"title":"Faster Self-adaptive Deep Stereo"},{"paperId":"bae0f086d513d6366ac4f7cbf3c8bbd9467a67d5","externalIds":{"DBLP":"conf/accv/ChenXQCB20","MAG":"3107004957","DOI":"10.1007/978-3-030-69525-5_7","CorpusId":229641568},"title":"SGNet: Semantics Guided Deep Stereo Matching"},{"paperId":"6cb751731656404708475b78a20c63049d8f61d4","externalIds":{"DBLP":"conf/eccv/XingQDCL20","MAG":"3095920191","DOI":"10.1007/978-3-030-58604-1_21","CorpusId":226239716},"title":"MABNet: A Lightweight Stereo Network Based on Multibranch Adjustable Bottleneck Module"},{"paperId":"b34886f677afe1689f751130849c715f18665f4c","externalIds":{"DBLP":"conf/accv/ChangCC20","MAG":"3110517830","DOI":"10.1007/978-3-030-69525-5_22","CorpusId":229631208},"title":"Attention-Aware Feature Aggregation for Real-Time Stereo Matching on Edge Devices"},{"paperId":"8b6bd623a19a0f2219fa637cafd7658c8797ffe6","externalIds":{"CorpusId":261618265},"title":"International Journal of Computer Vision"},{"paperId":"34b9635d7779e219e9d60e0d3d33919ca9bc123c","externalIds":{"DBLP":"journals/jnca/Togt03","DOI":"10.1016/S1084-8045(02)00061-9","CorpusId":761710},"title":"Publisher's Note"},{"paperId":"d4ca18249446328c86d9da295a21c679aea1ed77","externalIds":{"CorpusId":14616022},"title":"Mixture Density Networks"}]}