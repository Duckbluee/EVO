{"abstract":"Deep neural networks (DNNs) have became one of the most high performing tools in a broad range\n\nof machine learning areas. However, the multilayer non-linearity of the network architectures prevent\n\nus from gaining a better understanding of the models’ predictions. Gradient based attribution\n\nmethods (e.g., Integrated Gradient (IG)) that decipher input features’ contribution to the prediction\n\ntask have been shown to be highly effective yet requiring a reference input as the anchor for explaining\n\nmodel’s output. The performance of DNN model interpretation can be quite inconsistent with\n\nregard to the choice of references. Here we propose an Adversarial Gradient Integration (AGI) method\n\nthat integrates the gradients from adversarial examples to the target example along the curve of steepest\n\nascent to calculate the resulting contributions from all input features. Our method doesn’t rely on\n\nthe choice of references, hence can avoid the ambiguity and inconsistency sourced from the reference\n\nselection. We demonstrate the performance of our AGI method and compare with competing methods\n\nin explaining image classification results. Code is available from https://github.com/pd90506/AGI."}