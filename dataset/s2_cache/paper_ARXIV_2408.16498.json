{"paperId":"64c3f98b3f0163582e327ba275004208da17220e","externalIds":{"ArXiv":"2408.16498","DBLP":"journals/corr/abs-2408-16498","DOI":"10.48550/arXiv.2408.16498","CorpusId":272146327},"title":"A Survey on Evaluating Large Language Models in Code Generation Tasks","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2408.16498, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2317982741","name":"Liguo Chen"},{"authorId":"2316907209","name":"Qi Guo"},{"authorId":"2286992173","name":"Hongrui Jia"},{"authorId":"2293666521","name":"Zhengran Zeng"},{"authorId":"2318537747","name":"Xin Wang"},{"authorId":"2311739865","name":"Yijiang Xu"},{"authorId":"2318122701","name":"Jian Wu"},{"authorId":"2108024279","name":"Yidong Wang"},{"authorId":"2264968677","name":"Qing Gao"},{"authorId":"2273553706","name":"Jindong Wang"},{"authorId":"145235149","name":"Wei Ye"},{"authorId":"2145402928","name":"Shikun Zhang"}],"abstract":"This paper provides a comprehensive review of the current methods and metrics used to evaluate the performance of Large Language Models (LLMs) in code generation tasks. With the rapid growth in demand for automated software development, LLMs have demonstrated significant potential in the field of code generation. The paper begins by reviewing the historical development of LLMs and their applications in code generation. Next, it details various methods and metrics for assessing the code generation capabilities of LLMs, including code correctness, efficiency, readability, and evaluation methods based on expert review and user experience. The paper also evaluates the widely used benchmark datasets, identifying their limitations and proposing directions for future improvements. Specifically, the paper analyzes the performance of code generation models across different tasks by combining multiple evaluation metrics, such as code compilation/interpretation success rates, unit test pass rates, and performance and efficiency metrics, to comprehensively assess the practical application of LLMs in code generation. Finally, the paper discusses the challenges faced in evaluating LLMs in code generation, particularly how to ensure the comprehensiveness and accuracy of evaluation methods and how to adapt to the evolving practices of software development. These analyses and discussions provide valuable insights for further optimizing and improving the application of LLMs in code generation tasks."}