{"references":[{"paperId":"a77493bdbf9f980020987d5a6a78efc03f1db09e","externalIds":{"ArXiv":"2311.18373","DBLP":"journals/corr/abs-2311-18373","DOI":"10.1007/s44267-024-00071-w","CorpusId":265506316},"title":"A survey on deep learning for polyp segmentation: techniques, challenges and future trends"},{"paperId":"cd66f658f590318eef277436c6b3d5b16cd76d17","externalIds":{"DBLP":"journals/titb/MazumdarCSJK25","DOI":"10.1109/JBHI.2023.3328962","CorpusId":264843639,"PubMed":"37906497"},"title":"Optimizing Pix2Pix GAN With Attention Mechanisms for AI-Driven Polyp Segmentation in IoMT-Enabled Smart Healthcare"},{"paperId":"7796fbe6e15eeb2c27a5275db9d550233bd749ad","externalIds":{"DBLP":"conf/icip/WangWQSCCL23","DOI":"10.1109/ICIP49359.2023.10223054","CorpusId":261764404},"title":"Pyramid Transformer Driven Multibranch Fusion for Polyp Segmentation in Colonoscopic Video Images"},{"paperId":"59a3c6fac6d36874eb519346d3c2c8837252bcf7","externalIds":{"DBLP":"journals/tmi/JainAGMSOJK23","DOI":"10.1109/TMI.2023.3320151","CorpusId":263229227,"PubMed":"37768798"},"title":"CoInNet: A Convolution-Involution Network With a Novel Statistical Attention for Automatic Polyp Segmentation"},{"paperId":"aa159871f1be4b58eb04fb39e88e97d8a8ba1fe8","externalIds":{"ArXiv":"2308.06665","DBLP":"conf/ipmi/WangC23","DOI":"10.1007/978-3-031-34048-2_20","CorpusId":259205245},"title":"Unsupervised Adaptation of Polyp Segmentation Models via Coarse-to-Fine Self-Supervision"},{"paperId":"1a86d8144bbe64de5c1ff105edc7ae47993cc39b","externalIds":{"DBLP":"journals/corr/abs-2307-10912","ArXiv":"2307.10912","DOI":"10.48550/arXiv.2307.10912","CorpusId":259991738},"title":"WeakPolyp: You Only Look Bounding Box for Polyp Segmentation"},{"paperId":"842c1f431259124308f2b34fe4ef2b86186417d8","externalIds":{"DBLP":"journals/corr/abs-2307-12033","ArXiv":"2307.12033","DOI":"10.1109/IJCNN54540.2023.10191896","CorpusId":260125855},"title":"Self-Supervised and Semi-Supervised Polyp Segmentation using Synthetic Data"},{"paperId":"da4fbb146eed390fbacc17a78da086c1c6e5dfd0","externalIds":{"ArXiv":"2306.00451","DBLP":"journals/corr/abs-2306-00451","DOI":"10.48550/arXiv.2306.00451","CorpusId":258999273},"title":"S2ME: Spatial-Spectral Mutual Teaching and Ensemble Learning for Scribble-supervised Polyp Segmentation"},{"paperId":"bcda1ff495b8a79f916b5c1183e2f5cb5ffe3d95","externalIds":{"DBLP":"journals/titb/WangAPLZLM24","DOI":"10.1109/JBHI.2023.3273728","CorpusId":258566316,"PubMed":"37155397"},"title":"An Efficient Multi-Task Synergetic Network for Polyp Segmentation and Classification"},{"paperId":"ba08a5769b3e1c2d7cbe5e667a9e66206b470f7c","externalIds":{"DBLP":"journals/titb/JinHZL23","DOI":"10.1109/JBHI.2023.3272168","CorpusId":258437630,"PubMed":"37126617"},"title":"FEGNet: A Feedback Enhancement Gate Network for Automatic Polyp Segmentation"},{"paperId":"325080bc48c000eabb08d8bd25a09c9739bdd4b2","externalIds":{"DBLP":"journals/corr/abs-2304-13973","ArXiv":"2304.13973","DOI":"10.48550/arXiv.2304.13973","CorpusId":258352259},"title":"SkinSAM: Empowering Skin Cancer Segmentation with Segment Anything Model"},{"paperId":"2e5a1c689a0ed2f8b9b07eb64795c5d3c6608b4a","externalIds":{"DBLP":"conf/isbi/HaithamiALJ23","DOI":"10.1109/ISBI53787.2023.10230421","CorpusId":261433889},"title":"Enhancing Polyp Segmentation Generalizability by Minimizing Images’ Total Variation"},{"paperId":"34bc61432ef0ad6347b280248699ffc2ca12f7b1","externalIds":{"DBLP":"conf/isbi/SuXYHC23","DOI":"10.1109/ISBI53787.2023.10230470","CorpusId":261435522},"title":"An Accurate Polyp Segmentation Framework via Feature Secondary Fusion"},{"paperId":"e1955ab4d398399c72112da38e8ec72049710ddf","externalIds":{"DBLP":"conf/isbi/XiongLL23","DOI":"10.1109/ISBI53787.2023.10230716","CorpusId":261434797},"title":"Unpaired Image-to-Image Translation Based Domain Adaptation for Polyp Segmentation"},{"paperId":"6dfd90de105645661f3a79776f198f592d302488","externalIds":{"DBLP":"conf/isbi/SuDDYHC23","DOI":"10.1109/ISBI53787.2023.10230390","CorpusId":261434023},"title":"Go To The Right: A Real-Time and Accurate Polyp Segmentation Model for Practical Use"},{"paperId":"38d741adc1f902f29dc89bc36c2406204cac2ef4","externalIds":{"ArXiv":"2304.07583","DBLP":"journals/corr/abs-2304-07583","DOI":"10.48550/arXiv.2304.07583","CorpusId":258179568},"title":"Can SAM Segment Polyps?"},{"paperId":"72570016bbb28e8fb15ab4667eb84887f5dd35ad","externalIds":{"ArXiv":"2304.06790","DBLP":"journals/corr/abs-2304-06790","DOI":"10.48550/arXiv.2304.06790","CorpusId":258170322},"title":"Inpaint Anything: Segment Anything Meets Image Inpainting"},{"paperId":"2f575ecd4a4b6395dec56f5a8dafa229d17046c7","externalIds":{"ArXiv":"2304.04709","DBLP":"journals/corr/abs-2304-04709","DOI":"10.48550/arXiv.2304.04709","CorpusId":258048579},"title":"Can SAM Segment Anything? When SAM Meets Camouflaged Object Detection"},{"paperId":"7470a1702c8c86e6f28d32cfa315381150102f5b","externalIds":{"DBLP":"conf/iccv/KirillovMRMRGXW23","ArXiv":"2304.02643","DOI":"10.1109/ICCV51070.2023.00371","CorpusId":257952310},"title":"Segment Anything"},{"paperId":"f9286992b50f4d6cda8991cec731ae8e3aca145e","externalIds":{"DBLP":"journals/corr/abs-2304-01830","ArXiv":"2304.01830","DOI":"10.1109/CVPR52729.2023.02248","CorpusId":257921777},"title":"Learning to Name Classes for Vision and Language Models"},{"paperId":"db38ce5052231d7f9e6f632b64b9f3684d26348a","externalIds":{"DBLP":"journals/pr/WangZLZHY23","DOI":"10.1016/j.patcog.2023.109596","CorpusId":258003498},"title":"GSAL: Geometric structure adversarial learning for robust medical image segmentation"},{"paperId":"bc393223a1384e56b29cd70d6bcdb225c58c5735","externalIds":{"DBLP":"journals/corr/abs-2303-10894","ArXiv":"2303.10894","DOI":"10.48550/arXiv.2303.10894","CorpusId":257631617},"title":"M2SNet: Multi-scale in Multi-scale Subtraction Network for Medical Image Segmentation"},{"paperId":"f99848477b7f69d8847a68360eea4c38cc55e171","externalIds":{"DBLP":"journals/corr/abs-2303-07428","ArXiv":"2303.07428","DOI":"10.48550/arXiv.2303.07428","CorpusId":257505203},"title":"TransNetR: Transformer-based Residual Network for Polyp Segmentation with Multi-Center Out-of-Distribution Testing"},{"paperId":"54d111e169c14621b4f5d2411729db8c8e0018b9","externalIds":{"DBLP":"journals/pr/ZhouZHGYFS23","DOI":"10.1016/j.patcog.2023.109555","CorpusId":257769803},"title":"Cross-level Feature Aggregation Network for Polyp Segmentation"},{"paperId":"1f0003582dad3dd6ebbe216a85d72c80a20517be","externalIds":{"PubMedCentral":"9953705","DBLP":"journals/sensors/ELKarazleRTC23","DOI":"10.3390/s23031225","CorpusId":256217392,"PubMed":"36772263"},"title":"Detection of Colorectal Polyps from Colonoscopy Using Machine Learning: A Survey on Modern Techniques"},{"paperId":"3db5d75f4eac3d79128558993e9a5490c32c1f82","externalIds":{"ArXiv":"2301.04904","DBLP":"conf/miccai/ZhangLWFGWL22","DOI":"10.1007/978-3-031-16437-8_10","CorpusId":252369334},"title":"Lesion-Aware Dynamic Kernel for Polyp Segmentation"},{"paperId":"b6dbc6e7f676e0e52f0d649ef9ccad9f97a64677","externalIds":{"DBLP":"journals/tcsv/ShiZTZ23","DOI":"10.1109/TCSVT.2022.3197643","CorpusId":251464922},"title":"Polyp-Mixer: An Efficient Context-Aware MLP-Based Paradigm for Polyp Segmentation"},{"paperId":"c27dcfd2e6bbe0954eeb06c9b72f4937778ec4bb","externalIds":{"DBLP":"conf/wacv/RahmanM23","DOI":"10.1109/WACV56688.2023.00616","CorpusId":256661575},"title":"Medical Image Segmentation via Cascaded Attention Decoding"},{"paperId":"fcf6a797dc1d02dab1dd7c5e056e23509ffb4779","externalIds":{"DBLP":"conf/miccai/WeiHLCZL22","ArXiv":"2212.03498","DOI":"10.1007/978-3-031-16437-8_7","CorpusId":252369433},"title":"BoxPolyp: Boost Generalized Polyp Segmentation Using Extra Coarse Bounding Box Annotations"},{"paperId":"cd53b4c3ad92c2bf32bcffed7fe6f05d1035d463","externalIds":{"DBLP":"conf/bibm/XiaoCWYZ22","DOI":"10.1109/BIBM55620.2022.9995022","CorpusId":255420181},"title":"ICBNet: Iterative Context-Boundary Feedback Network for Polyp Segmentation"},{"paperId":"da091a3a4b30aca5c97d50392235b03f73c38322","externalIds":{"DBLP":"conf/bibm/ChenLXYZFZG22","DOI":"10.1109/BIBM55620.2022.9995402","CorpusId":255418056},"title":"Single-Modality Endoscopic Polyp Segmentation via Random Color Reversal Synthesis and Two-Branched Learning"},{"paperId":"1da282b5dc641bd1b714b4ad1c5dbafc8c4ca850","externalIds":{"DBLP":"conf/bibm/XuQLZSZZW22","DOI":"10.1109/BIBM55620.2022.9995646","CorpusId":255420172},"title":"Temporal Correlation Network for Video Polyp Segmentation"},{"paperId":"ad2d04b17caafe4c8b349b275244a1eee71f6d8c","externalIds":{"DBLP":"conf/bibm/HuangTZLH22","DOI":"10.1109/BIBM55620.2022.9995247","CorpusId":255404310},"title":"TransMixer: A Hybrid Transformer and CNN Architecture for Polyp Segmentation"},{"paperId":"d95def7c56453df7a2c2b53dbe7bebc52a9dbec8","externalIds":{"DBLP":"conf/bibm/ChenWJTZL22","DOI":"10.1109/BIBM55620.2022.9995217","CorpusId":255417272},"title":"CLD-Net: Complement Local Detail For Medical Small-Object Segmentation"},{"paperId":"eaae9b109034756f572a3d86680320f8e194ed76","externalIds":{"DBLP":"journals/cbm/LiuHLF22","DOI":"10.1016/j.compbiomed.2022.106304","CorpusId":253707613,"PubMed":"36401969"},"title":"DBMF: Dual Branch Multiscale Feature Fusion Network for polyp segmentation"},{"paperId":"9a5fa030a243f6bc5696b52f08fd11d0b50f9b83","externalIds":{"DBLP":"journals/cbm/WuLLYJZ22","DOI":"10.1016/j.compbiomed.2022.106274","CorpusId":253467327,"PubMed":"36375412"},"title":"MSRAformer: Multiscale spatial reverse attention network for polyp segmentation"},{"paperId":"a42b091adaf29b06a092b67192ac07cb93312f2a","externalIds":{"DBLP":"conf/iclr/MenonV23","ArXiv":"2210.07183","DOI":"10.48550/arXiv.2210.07183","CorpusId":252872997},"title":"Visual Classification via Description from Large Language Models"},{"paperId":"ea7cd18c8fe2d5bb7b5e5c7e8e87978ee0967f09","externalIds":{"DBLP":"journals/cbm/ZhangFZZZS22","DOI":"10.1016/j.compbiomed.2022.106173","CorpusId":252749165,"PubMed":"36257278"},"title":"HSNet: A hybrid semantic network for polyp segmentation"},{"paperId":"7deb9d24525b2ac811a036cc183c414424e29954","externalIds":{"DBLP":"journals/tnn/DuWLWM24","DOI":"10.1109/TNNLS.2022.3204090","CorpusId":252382347,"PubMed":"36121961"},"title":"SwinPA-Net: Swin Transformer-Based Multiscale Feature Pyramid Aggregation Network for Medical Image Segmentation"},{"paperId":"cb126a0d2f499f492854800ca25575b137380c67","externalIds":{"DBLP":"journals/vc/JinHJZ23","DOI":"10.1007/s00371-022-02630-y","CorpusId":251790603},"title":"Polyp segmentation with convolutional MLP"},{"paperId":"8d732f0ecb290c022de6ad9061bebe377b00b5d9","externalIds":{"DBLP":"conf/miua/SandersonM22","ArXiv":"2208.08352","DOI":"10.1007/978-3-031-12053-4_65","CorpusId":251137716},"title":"FCN-Transformer Feature Fusion for Polyp Segmentation"},{"paperId":"12ce75423d741945429356d54c69ec7a346d7b1c","externalIds":{"DBLP":"conf/ijcai/LiXZFZ0LG22","DOI":"10.24963/ijcai.2022/155","CorpusId":250631462},"title":"TCCNet: Temporally Consistent Context-Free Network for Semi-supervised Video Polyp Segmentation"},{"paperId":"f25d9e5cdc98bcece7d4d2e90b0e156b2ac36fbd","externalIds":{"DBLP":"journals/pr/LinWXGCM22","DOI":"10.1016/j.patcog.2022.108917","CorpusId":250964985},"title":"BSCA-Net: Bit Slicing Context Attention network for polyp segmentation"},{"paperId":"7b0c9748406ab21ea2f5a0dac5285cd81a489349","externalIds":{"DBLP":"conf/ijcai/DuXM22","DOI":"10.24963/ijcai.2022/123","CorpusId":250633763},"title":"ICGNet: Integration Context-based Reverse-Contour Guidance Network for Polyp Segmentation"},{"paperId":"04d25be466f9b8689729610abca27d586c59ebb7","externalIds":{"DBLP":"journals/corr/abs-2206-00806","ArXiv":"2206.00806","DOI":"10.1109/TMI.2023.3236037","CorpusId":249282198,"PubMed":"37018671"},"title":"XBound-Former: Toward Cross-Scale Boundary Modeling in Transformers"},{"paperId":"b077fe179edb6e72ce6bf665f1feb5f7971a6734","externalIds":{"ArXiv":"2205.04280","DBLP":"conf/miccai/TomarJBA22","DOI":"10.48550/arXiv.2205.04280","CorpusId":248571575,"PubMed":"36780239"},"title":"TGANet: Text-guided attention for improved polyp segmentation"},{"paperId":"593f2babfaa34fb402befc1db05e9b0ea7d7933f","externalIds":{"DBLP":"journals/cbm/SongLF22","DOI":"10.1016/j.compbiomed.2022.105476","CorpusId":248430049,"PubMed":"35483226"},"title":"Attention based multi-scale parallel network for polyp segmentation"},{"paperId":"c05d18f89932196b907813f3a107792632afda79","externalIds":{"ArXiv":"2204.10607","DBLP":"journals/corr/abs-2204-10607","DOI":"10.1109/TPAMI.2023.3243080","CorpusId":248366527,"PubMed":"37022837"},"title":"Federated Learning Via Inexact ADMM"},{"paperId":"2b813b99601b255d6554ad41cd97153986ea3cc0","externalIds":{"DBLP":"journals/tcyb/WuZZWWQ23","DOI":"10.1109/TCYB.2022.3162873","CorpusId":248156747,"PubMed":"35417366"},"title":"PolypSeg+: A Lightweight Context-Aware Network for Real-Time Polyp Segmentation"},{"paperId":"767ed65f7675ca9ca77c3c70d5e3ad8692c6653d","externalIds":{"DBLP":"journals/mia/YangGCY22","DOI":"10.1016/j.media.2022.102457","CorpusId":248148656,"PubMed":"35461016"},"title":"Source free domain adaptation for medical image segmentation with fourier style mining"},{"paperId":"0cdf3bbb2b9ad2b3e79fb0f848a71c3b29b2f202","externalIds":{"DBLP":"conf/isbi/YaoHWZPH22","DOI":"10.1109/ISBI52829.2022.9761699","CorpusId":248407497},"title":"Scheme And Dataset for Evaluating Computer-Aided Polyp Detection System in Colonoscopy"},{"paperId":"b66aa350653544351d56d1cd2740cfe2cc8d40d2","externalIds":{"DBLP":"conf/isbi/HuyHNDBT22","DOI":"10.1109/ISBI52829.2022.9761671","CorpusId":248407569},"title":"Adversarial Contrastive Fourier Domain Adaptation for Polyp Segmentation"},{"paperId":"624eb5680f4198f2c1fd7afdf0f981bc810a1ba7","externalIds":{"ArXiv":"2203.14291","DBLP":"journals/ijautcomp/JiXCFZCG22","DOI":"10.1007/s11633-022-1371-y","CorpusId":247762957},"title":"Video Polyp Segmentation: A Deep Learning Perspective"},{"paperId":"699505159adb14bcb2dbadb90f8d31e0c4cd6a4a","externalIds":{"DBLP":"journals/tmi/SongCZSXCFPZ22","DOI":"10.1109/TMI.2022.3162111","CorpusId":247677987,"PubMed":"35324437"},"title":"Global and Local Feature Reconstruction for Medical Image Segmentation"},{"paperId":"dac5ad2509fe9886d25ad1dd75bf5b6c6c5e48ed","externalIds":{"DBLP":"journals/corr/abs-2203-03635","ArXiv":"2203.03635","DOI":"10.48550/arXiv.2203.03635","CorpusId":247315667},"title":"Stepwise Feature Fusion: Local Guides Global"},{"paperId":"ba637c4f1a170f1e2dadeadb71a63cf2b9a46de2","externalIds":{"DBLP":"journals/cvm/GuoLLCH23","ArXiv":"2202.09741","DOI":"10.1007/s41095-023-0364-2","CorpusId":247011300},"title":"Visual attention network"},{"paperId":"b7c060cf11fea4c1e6583ca6a7b10bad63c70aa7","externalIds":{"DBLP":"journals/mia/GuoCLY22","DOI":"10.1016/j.media.2022.102394","CorpusId":246990421,"PubMed":"35219939"},"title":"Non-equivalent images and pixels: Confidence-aware resampling with meta-learning mixup for polyp segmentation"},{"paperId":"c392e5ce09a12398e9318e43ba1fe57cdf4ef264","externalIds":{"ArXiv":"2201.00767","DBLP":"conf/miip/QiuWZXF022","DOI":"10.1117/12.2606785","CorpusId":245650769},"title":"BDG-Net: boundary distribution guided network for accurate polyp segmentation"},{"paperId":"13fab6dbb9d0f3eaac0b45a52c140165ae25b8b6","externalIds":{"DBLP":"journals/ijon/XiaPLHMZD22","DOI":"10.1016/j.neucom.2021.12.093","CorpusId":245682770},"title":"GAN-based anomaly detection: A review"},{"paperId":"a3f67542e94dc86a41c20cae1f04ad021f7e7593","externalIds":{"DBLP":"journals/pami/DongCSFD24","DOI":"10.1109/TPAMI.2021.3128560","CorpusId":244269630,"PubMed":"34784271"},"title":"Where and How to Transfer: Knowledge Aggregation-Induced Transferability Perception for Unsupervised Domain Adaptation"},{"paperId":"6419160675cfb2999a9a7cb5ca226383f3b21db0","externalIds":{"DBLP":"journals/corr/abs-2111-06394","ArXiv":"2111.06394","CorpusId":243986028},"title":"The Emergence of Objectness: Learning Zero-Shot Segmentation from Videos"},{"paperId":"dd6bd5d06543d958dcf3123a3354a92c6abdb3b6","externalIds":{"DBLP":"conf/embc/WangALLHL21","DOI":"10.1109/EMBC46164.2021.9630787","CorpusId":244836940,"PubMed":"34891860"},"title":"EMS-Net: Enhanced Multi-Scale Network for Polyp Segmentation"},{"paperId":"58e666f49eedebae1127c3f436166a7c525ce1c3","externalIds":{"DBLP":"journals/corr/abs-2110-14775","ArXiv":"2110.14775","DOI":"10.5244/c.35.26","CorpusId":240070834},"title":"BI-GCN: Boundary-Aware Input-Dependent Graph Convolution Network for Biomedical Image Segmentation"},{"paperId":"9f3a1f69caf884774272a3350e06e08d898898e8","externalIds":{"DBLP":"conf/iccv/WuCW021","DOI":"10.1109/ICCV48922.2021.00347","CorpusId":244476877},"title":"Collaborative and Adversarial Learning of Focused and Dispersive Representations for Semi-supervised Polyp Segmentation"},{"paperId":"449f71549f63efe258b12ce33e7501834e4e7d9c","externalIds":{"DBLP":"conf/iccv/ZhangLWPYJLLL21","DOI":"10.1109/ICCV48922.2021.00158","CorpusId":244708602},"title":"Dynamic Context-Sensitive Filtering Network for Video Salient Object Detection"},{"paperId":"81018a7a3d33379d9350ec9704f573bcf4d77505","externalIds":{"ArXiv":"2109.01303","DBLP":"journals/mia/TianLPCLVSC23","DOI":"10.1016/j.media.2023.102930","CorpusId":244527705,"PubMed":"37657364"},"title":"Self-supervised pseudo multi-class pre-training for unsupervised anomaly detection and segmentation in medical images"},{"paperId":"66b92a2250d9b899c03c3f2699a40e18e56bcd51","externalIds":{"DBLP":"journals/corr/abs-2108-06932","ArXiv":"2108.06932","DOI":"10.26599/AIR.2023.9150015","CorpusId":237091379},"title":"Polyp-PVT: Polyp Segmentation with Pyramid Vision Transformers"},{"paperId":"97326c0468e4e412630b4db7cea9d0f8ac4dc475","externalIds":{"ArXiv":"2108.07368","DBLP":"journals/corr/abs-2108-07368","DOI":"10.1117/1.JMI.10.1.014005","CorpusId":237142155,"PubMed":"36820234"},"title":"CaraNet: context axial reverse attention network for segmentation of small medical objects"},{"paperId":"f36ff155a741f4c404fcac9de1d47e53aa99e71b","externalIds":{"DBLP":"conf/miccai/ZhaoZL21","ArXiv":"2108.05082","DOI":"10.1007/978-3-030-87193-2_12","CorpusId":236976302},"title":"Automatic Polyp Segmentation via Multi-scale Subtraction Network"},{"paperId":"e0d677dec0248e4673fae079b6479fce96133f5b","externalIds":{"DBLP":"journals/cvm/JiFFWSS23","ArXiv":"2108.03151","DOI":"10.1007/s41095-021-0262-4","CorpusId":236950747},"title":"Full-duplex strategy for video object segmentation"},{"paperId":"b3b3cb0dca8200dc64971020b39e036e64d72416","externalIds":{"DBLP":"journals/corr/abs-2108-00882","ArXiv":"2108.00882","DOI":"10.1007/978-3-030-87193-2_66","CorpusId":236772551},"title":"Shallow Attention Network for Polyp Segmentation"},{"paperId":"061218e8c8e2bb4e31ea6aaf6ab5e681fd2787aa","externalIds":{"DBLP":"journals/mia/GuoYY21","DOI":"10.1016/j.media.2021.102196","CorpusId":236959142,"PubMed":"34365142"},"title":"Dynamic-weighting hierarchical segmentation network for medical images"},{"paperId":"f75cddf2d42ed01b34686704eb3504becef67442","externalIds":{"ArXiv":"2107.10224","DBLP":"conf/iclr/ChenXGCLL22","CorpusId":236154781},"title":"CycleMLP: A MLP-like Architecture for Dense Prediction"},{"paperId":"ba4a1a82cf7fca1f28436468778f5a6b2757f1dd","externalIds":{"DBLP":"conf/isvc/LanAHLTTS21","ArXiv":"2107.05023","DOI":"10.1007/978-3-030-90436-4_2","CorpusId":235794836},"title":"NeoUNet: Towards accurate colon polyp segmentation and neoplasm detection"},{"paperId":"3ba7ca920b6ac0a7cabe227a0be20b8fdc5b9d53","externalIds":{"DBLP":"journals/corr/abs-2107-04805","ArXiv":"2107.04805","DOI":"10.1007/978-3-030-87196-3_31","CorpusId":235795755},"title":"Few-Shot Domain Adaptation with Polymorphic Transformers"},{"paperId":"40445de181e1f014d71afb0612df837b87837f00","externalIds":{"DBLP":"conf/mm/KimL021","ArXiv":"2107.02368","DOI":"10.1145/3474085.3475375","CorpusId":235743002},"title":"UACANet: Uncertainty Augmented Context Attention for Polyp Segmentation"},{"paperId":"04b1726d004f40834adde7554d938fb9b4308c40","externalIds":{"DBLP":"journals/corr/abs-2107-00283","ArXiv":"2107.00283","CorpusId":235614237},"title":"DivergentNets:Medical Image Segmentation by Network Ensemble"},{"paperId":"67040b931c1a384426c44ae73f9553e97f08cf6a","externalIds":{"ArXiv":"2106.13797","DBLP":"journals/cvm/WangXLFSLLLS22","DOI":"10.1007/s41095-022-0274-8","CorpusId":235652212},"title":"PVT v2: Improved baselines with Pyramid Vision Transformer"},{"paperId":"6d6fa46fc88dc20d41326ec7fe51f8fbc5d6cb76","externalIds":{"ArXiv":"2106.04463","PubMedCentral":"9902556","DOI":"10.1038/s41597-023-01981-y","CorpusId":256599957,"PubMed":"36746950"},"title":"A multi-centre polyp detection and segmentation dataset for generalisability assessment"},{"paperId":"96bb5e0ee886b499e5d6d64b4636bc7be343ccc0","externalIds":{"DBLP":"journals/pami/OzaSVP24","ArXiv":"2105.13502","DOI":"10.1109/TPAMI.2022.3217046","CorpusId":235247842,"PubMed":"37030853"},"title":"Unsupervised Domain Adaptation of Object Detectors: A Survey"},{"paperId":"ec561a375a100097f00fcf4924a2c14a9a7735e7","externalIds":{"DBLP":"journals/corr/abs-2105-09511","ArXiv":"2105.09511","DOI":"10.24963/ijcai.2021/112","CorpusId":234790361},"title":"Medical Image Segmentation using Squeeze-and-Expansion Transformers"},{"paperId":"7ca83bac3e9836d4088101e53bfceddfdeadd7ff","externalIds":{"DBLP":"conf/aaai/WuZWW021","DOI":"10.1609/aaai.v35i4.16398","CorpusId":235306610},"title":"Precise Yet Efficient Semantic Calibration and Refinement in ConvNets for Real-time Polyp Segmentation from Colonoscopy Videos"},{"paperId":"492ed313c743b58ba64751ebddaba0638e8939d8","externalIds":{"DBLP":"conf/miccai/JiCFCFJS21","ArXiv":"2105.08468","DOI":"10.1007/978-3-030-87193-2_14","CorpusId":234763220},"title":"Progressively Normalized Self-Attention Network for Video Polyp Segmentation"},{"paperId":"75808111f4b554d3d99563c8f2b22359bc011c45","externalIds":{"DBLP":"journals/corr/abs-2105-07451","ArXiv":"2105.07451","DOI":"10.1109/JBHI.2021.3138024","CorpusId":234741839,"PubMed":"34941539"},"title":"MSRF-Net: A Multi-Scale Residual Fusion Network for Biomedical Image Segmentation"},{"paperId":"456bcad8aff8bead3c025b2082034f4c0d4129f4","externalIds":{"DBLP":"journals/cbm/YeungSSR21","PubMedCentral":"8505797","ArXiv":"2105.07467","DOI":"10.1016/j.compbiomed.2021.104815","CorpusId":235593280,"PubMed":"34507156"},"title":"Focus U-Net: A novel dual attention-gated CNN for polyp segmentation during colonoscopy"},{"paperId":"72a689110cec86bc8f7333af47fab48453b55c88","externalIds":{"MAG":"3048643568","DOI":"10.1109/JSEN.2020.3015831","CorpusId":226614841},"title":"ABC-Net: Area-Boundary Constraint Network With Dynamical Feature Selection for Colorectal Polyp Segmentation"},{"paperId":"f788b9123975ef7bd0eafd624c9033cf9bf0e66d","externalIds":{"DBLP":"journals/titb/YangGZIY21","DOI":"10.1109/JBHI.2021.3077271","CorpusId":233743000,"PubMed":"33945490"},"title":"Mutual-Prototype Adaptation for Cross-Domain Polyp Segmentation"},{"paperId":"8775dd7a4f3582de8d1b196865495df73638931c","externalIds":{"ArXiv":"2105.00999","DBLP":"conf/crv/PatelBW21","DOI":"10.1109/CRV52889.2021.00032","CorpusId":233481533,"PubMed":"34368816"},"title":"Enhanced U-Net: A Feature Enhancement Network for Polyp Segmentation"},{"paperId":"4331665000e51a80f15d06d4c94911c1a3ed4d5d","externalIds":{"DBLP":"journals/pami/HongC22","MAG":"3159481909","DOI":"10.1109/TPAMI.2021.3129809","CorpusId":235575346,"PubMed":"34813467"},"title":"Communication-Efficient Randomized Algorithm for Multi-Kernel Online Federated Learning"},{"paperId":"7d1ad6705dab9763c69a299bef9d518f2e7534ce","externalIds":{"DBLP":"conf/isbi/DongZCH21","DOI":"10.1109/ISBI48211.2021.9433859","CorpusId":235208525},"title":"Asymmetric Attention Upsampling: Rethinking Upsampling For Biological Image Segmentation"},{"paperId":"8f8f73f0f208302546c825ed474432389ed63be4","externalIds":{"DBLP":"journals/corr/abs-2104-00298","ArXiv":"2104.00298","CorpusId":232478903},"title":"EfficientNetV2: Smaller Models and Faster Training"},{"paperId":"81c35b12898c7f46115547b70f628f966ed73c50","externalIds":{"DBLP":"journals/corr/abs-2103-17235","ArXiv":"2103.17235","DOI":"10.1109/TNNLS.2022.3159394","CorpusId":232427946,"PubMed":"35333723"},"title":"FANet: A Feedback Attention Network for Improved Biomedical Image Segmentation"},{"paperId":"e775e649d815a02373eac840cf5e33a04ff85c95","externalIds":{"ArXiv":"2103.15808","DBLP":"conf/iccv/WuXCLDY021","DOI":"10.1109/ICCV48922.2021.00009","CorpusId":232417787},"title":"CvT: Introducing Convolutions to Vision Transformers"},{"paperId":"3e6a450bb72bc00c4426d5a5f217c3328a30082d","externalIds":{"DBLP":"conf/isbi/YinLMG22","ArXiv":"2103.06725","DOI":"10.1109/ISBI52829.2022.9761402","CorpusId":232185627},"title":"Duplex Contextual Relation Network For Polyp Segmentation"},{"paperId":"73d5dbfebca74e5ef8a7333c842a2a9ee5c07fd6","externalIds":{"DBLP":"journals/corr/abs-2103-06877","ArXiv":"2103.06877","DOI":"10.1109/CVPR46437.2021.00098","CorpusId":232185264},"title":"Fast and Accurate Model Scaling"},{"paperId":"0c5ed0c30375703306f36d341d31772f3bd5af47","externalIds":{"DBLP":"conf/miccai/TianPLCSVSC21","ArXiv":"2103.03423","DOI":"10.1007/978-3-030-87240-3_13","CorpusId":232135090},"title":"Constrained Contrastive Distribution Learning for Unsupervised Anomaly Detection and Localisation in Medical Images"},{"paperId":"8fb1c04dab87ca6c116495e4d03c46c9547e4ec3","externalIds":{"DBLP":"journals/corr/abs-2102-12122","ArXiv":"2102.12122","DOI":"10.1109/ICCV48922.2021.00061","CorpusId":232035922},"title":"Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions"},{"paperId":"eb20e67ee20cd4122f3812b695b79a3220f2fe4a","externalIds":{"DBLP":"conf/miccai/ZhangLH21","ArXiv":"2102.08005","DOI":"10.1007/978-3-030-87193-2_2","CorpusId":231933932},"title":"TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation"},{"paperId":"d7b055c6eb3c0f4decb29f14e4c4f52c50501d1f","externalIds":{"DBLP":"journals/pami/LiuJZCQHS24","ArXiv":"2102.01936","DOI":"10.1109/TPAMI.2023.3322743","CorpusId":236140678,"PubMed":"37812559"},"title":"A Bayesian Federated Learning Framework With Online Laplace Approximation"},{"paperId":"714c601ddc560f6d5133c502b8948b0b218bf9a8","externalIds":{"DBLP":"journals/sensors/SafarovW21","PubMedCentral":"7922083","DOI":"10.3390/s21041441","CorpusId":232100232,"PubMed":"33669539"},"title":"A-DenseUNet: Adaptive Densely Connected UNet for Polyp Segmentation in Colonoscopy Images with Atrous Convolution"},{"paperId":"3658ada81a0c4e520a85f9b32d802b32e4c8989a","externalIds":{"ArXiv":"2101.07172","DBLP":"journals/corr/abs-2101-07172","CorpusId":231632860},"title":"HarDNet-MSEG: A Simple Encoder-Decoder Polyp Segmentation Neural Network that Achieves over 0.9 Mean Dice and 86 FPS"},{"paperId":"36c2082e87b44e42d8f3fda2ce4fbc8920cee98b","externalIds":{"DBLP":"journals/titb/JhaSJLJHR21","ArXiv":"2107.12435","DOI":"10.1109/JBHI.2021.3049304","CorpusId":230781566,"PubMed":"33400658"},"title":"A Comprehensive Study on Colorectal Polyp Segmentation With ResUNet++, Conditional Random Field and Test-Time Augmentation"},{"paperId":"7f575a0661bf6396cdbb92db763ffcd566142d87","externalIds":{"PubMedCentral":"7825313","DOI":"10.3390/healthcare9010054","CorpusId":231301966,"PubMed":"33419018"},"title":"TMD-Unet: Triple-Unet with Multi-Scale Input Features and Dense Skip Connection for Medical Image Segmentation"},{"paperId":"41d96e594de2ab2d3c041227db255794debe2f11","externalIds":{"DBLP":"conf/icpr/TomarJAJJRH20","ArXiv":"2012.15245","DOI":"10.1007/978-3-030-68793-9_23","CorpusId":229923137},"title":"DDANet: Dual Decoder Attention Network for Automatic Polyp Segmentation"},{"paperId":"ad7ddcc14984caae308c397f1a589aae75d4ab71","externalIds":{"ArXiv":"2012.12877","DBLP":"journals/corr/abs-2012-12877","CorpusId":229363322},"title":"Training data-efficient image transformers & distillation through attention"},{"paperId":"8874ba7215ccdd176f92bf23ea1338922c2c99ac","externalIds":{"DBLP":"journals/tmi/GuoYLY21","DOI":"10.1109/TMI.2020.3046843","CorpusId":229692479,"PubMed":"33360986"},"title":"Learn to Threshold: ThresholdNet With Confidence-Guided Manifold Mixup for Polyp Segmentation"},{"paperId":"fc1364e1bcf04b11c0921dcdc4e41fa197d4295c","externalIds":{"DBLP":"conf/icarm/HuangWCZL20","MAG":"3089898702","DOI":"10.1109/ICARM49381.2020.9195281","CorpusId":221847822},"title":"Real-time Colonoscopy Image Segmentation Based on Ensemble Knowledge Distillation"},{"paperId":"0d238bfffee8d5496469f9d69c9acb86d6eb24fc","externalIds":{"MAG":"3209840785","DOI":"10.3390/app10238501","CorpusId":229439450},"title":"PICCOLO White-Light and Narrow-Band Imaging Colonoscopic Dataset: A Performance Comparative of Models and Datasets"},{"paperId":"ebd51b549e6fcbcaabfb6b464d5bce3b2797f4c6","externalIds":{"DBLP":"conf/miccai/PuyalBBATKLMS20","MAG":"3091342696","DOI":"10.1007/978-3-030-59725-2_29","CorpusId":222137610},"title":"Endoscopic Polyp Segmentation Using a Hybrid 2D/3D CNN"},{"paperId":"c7c4c25a5d6a92d386125fa6ff4d259f461ef775","externalIds":{"ArXiv":"2301.04799","DBLP":"conf/miccai/ZhangLLCQY20","MAG":"3090492687","DOI":"10.1007/978-3-030-59725-2_25","CorpusId":222136567},"title":"Adaptive Context Selection for Polyp Segmentation"},{"paperId":"f4caafa1acf1ea6f157622f466ce9671f703233f","externalIds":{"MAG":"3091630951","DBLP":"conf/miccai/ZhongWWWQ20","DOI":"10.1007/978-3-030-59725-2_28","CorpusId":222135706},"title":"PolypSeg: An Efficient Context-Aware Network for Polyp Segmentation from Colonoscopy Videos"},{"paperId":"25f696bdf01c125c416bbbaf6f85d8afd887bede","externalIds":{"DBLP":"journals/artmed/Sanchez-Peralta20","MAG":"3046792513","DOI":"10.1016/j.artmed.2020.101923","CorpusId":221698095,"PubMed":"32972656"},"title":"Deep learning to find colorectal polyps in colonoscopy: A systematic literature review"},{"paperId":"9149e52d5c2b1a3f344997aa42c1eb8d53296d9d","externalIds":{"MAG":"3046240927","DOI":"10.1016/j.gie.2020.07.060","CorpusId":225487785,"PubMed":"32745531"},"title":"Development of a computer-aided detection system for colonoscopy and a publicly accessible large colonoscopy video database (with video)."},{"paperId":"2b44200f8ac47e9b359ce74503774bb7085aa6a1","externalIds":{"DBLP":"conf/miccai/XieCLSMZ20","MAG":"3095725246","ArXiv":"2007.11180","DOI":"10.1007/978-3-030-59713-9_50","CorpusId":220686470},"title":"MI^2GAN: Generative Adversarial Network for Medical Image Domain Adaptation using Mutual Information Constraint"},{"paperId":"89c6badea0d7bf834d4c069517116dd99c4cc0fd","externalIds":{"MAG":"3092344722","DBLP":"journals/corr/abs-2006-11392","ArXiv":"2006.11392","DOI":"10.1007/978-3-030-59725-2_26","CorpusId":219966949},"title":"PraNet: Parallel Reverse Attention Network for Polyp Segmentation"},{"paperId":"61af9ff6ec3dbb5299455746a1c63588ccf62cf8","externalIds":{"MAG":"3081752372","ArXiv":"2006.04868","DBLP":"journals/corr/abs-2006-04868","DOI":"10.1109/CBMS49503.2020.00111","CorpusId":219559325},"title":"DoubleU-Net: A Deep Convolutional Neural Network for Medical Image Segmentation"},{"paperId":"e2516fd1e61fa16bce4bc3a14b6010e0748daa8a","externalIds":{"MAG":"3028954669","DBLP":"journals/titb/WangCZCQFZL21","DOI":"10.1109/JBHI.2020.2997760","CorpusId":219751980,"PubMed":"32750912"},"title":"Multi-Scale Context-Guided Deep Network for Automated Lesion Segmentation With Endoscopy Images of Gastrointestinal Tract"},{"paperId":"297a7a3a95b860d3f535fff914558c9f980716e9","externalIds":{"MAG":"2997217064","DBLP":"conf/aaai/GuWW0CL20","DOI":"10.1609/AAAI.V34I07.6718","CorpusId":213642576},"title":"Pyramid Constrained Self-Attention Network for Fast Video Salient Object Detection"},{"paperId":"605584617d68cba8db5e07fed70826042bb9d5c5","externalIds":{"DBLP":"conf/isbi/FengLWCCCW20","MAG":"3028134148","DOI":"10.1109/ISBI45749.2020.9098492","CorpusId":218895152},"title":"SSN: A Stair-Shape Network for Real-Time Polyp Segmentation in Colonoscopy Images"},{"paperId":"952df0a104d1697eaf556ae3eb779342c5076fde","externalIds":{"MAG":"2997487053","DBLP":"journals/corr/abs-2003-04253","ArXiv":"2003.04253","DOI":"10.1109/TIP.2020.3013162","CorpusId":212633918,"PubMed":"32784135"},"title":"MATNet: Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation"},{"paperId":"7fd582680ee61f6333a23bd0374f05cd6fd3dcb4","externalIds":{"DBLP":"journals/air/ChoudharyMGS20","MAG":"3004543888","DOI":"10.1007/s10462-020-09816-7","CorpusId":211062209},"title":"A comprehensive survey on model compression and acceleration"},{"paperId":"131329a5142fad8e0efa475d017b2a7a8c1f297a","externalIds":{"MAG":"3082604781","PubMedCentral":"7455694","DOI":"10.1038/s41597-020-00622-y","CorpusId":221365970,"PubMed":"32859981"},"title":"HyperKvasir, a comprehensive multi-class image and video dataset for gastrointestinal endoscopy"},{"paperId":"42b0a8f757e45462e627e57f9af7e9849dcdacdf","externalIds":{"MAG":"2994754739","ArXiv":"1912.05074","DBLP":"journals/tmi/ZhouSTL20","DOI":"10.1109/TMI.2019.2959609","CorpusId":209202133,"PubMed":"31841402"},"title":"UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation"},{"paperId":"07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b","externalIds":{"MAG":"3111681398","DBLP":"journals/corr/abs-1912-04977","ArXiv":"1912.04977","DOI":"10.1561/2200000083","CorpusId":209202606},"title":"Advances and Open Problems in Federated Learning"},{"paperId":"0170bb0b524df2c81b5adc3062c6001a2eb34c96","externalIds":{"MAG":"2994536315","DBLP":"journals/corr/abs-1912-01991","ArXiv":"1912.01991","DOI":"10.1109/CVPR42600.2020.00674","CorpusId":208617491},"title":"Self-Supervised Learning of Pretext-Invariant Representations"},{"paperId":"7efcb1c3beba74abf5e68b54998a078afae02d80","externalIds":{"DBLP":"conf/icmla/SunZWCL19","ArXiv":"1912.11947","MAG":"2997798135","DOI":"10.1109/ICMLA.2019.00148","CorpusId":209500735},"title":"Colorectal Polyp Segmentation by U-Net with Dilation Convolution"},{"paperId":"349461d60b4d3d34dc97147e4b9ec2b9bd611be8","externalIds":{"MAG":"2988299447","ArXiv":"1911.07069","DBLP":"conf/mmm/JhaSRHLJJ20","DOI":"10.1007/978-3-030-37734-2_37","CorpusId":208138155},"title":"Kvasir-SEG: A Segmented Polyp Dataset"},{"paperId":"80f4c7c360d1150ba58c3bacf5c35718ebdd0c10","externalIds":{"ArXiv":"1911.07067","DBLP":"conf/ism/JhaSRJLHJ19","MAG":"2983365766","DOI":"10.1109/ISM46123.2019.00049","CorpusId":208138160},"title":"ResUNet++: An Advanced Architecture for Medical Image Segmentation"},{"paperId":"b96f80d5673749bb3c6b9d06510a83cea9bfa211","externalIds":{"MAG":"2980633303","DOI":"10.1002/mp.13865","CorpusId":204702336,"PubMed":"31610020"},"title":"Automated polyp segmentation for colonoscopy images：a method based on convolutional neural networks and ensemble learning."},{"paperId":"8cd4364347f647f2d2165953988c8895524dd8cc","externalIds":{"MAG":"2979515228","DBLP":"conf/miccai/FangCYT19","DOI":"10.1007/978-3-030-32239-7_34","CorpusId":204027843},"title":"Selective Feature Aggregation Network with Area-Boundary Constraints for Polyp Segmentation"},{"paperId":"0c55b3a00349e8e8c38ae3f7f82405342df03b2a","externalIds":{"DBLP":"conf/iccv/ChaoKRHL19","MAG":"2972283920","ArXiv":"1909.00948","DOI":"10.1109/ICCV.2019.00365","CorpusId":202541132},"title":"HarDNet: A Low Memory Traffic Network"},{"paperId":"bdc536b861687263a64d09ec4602d1033d7350f4","externalIds":{"DBLP":"conf/embc/PoomeshwaranSRJ19","MAG":"2980278535","DOI":"10.1109/EMBC.2019.8857958","CorpusId":204230275,"PubMed":"31947496"},"title":"Polyp Segmentation using Generative Adversarial Network"},{"paperId":"7c1d1cc11dcf2963cdcc9093444065e6731a6f35","externalIds":{"DBLP":"conf/embc/BagheriMTNKSS19","MAG":"2979524736","DOI":"10.1109/EMBC.2019.8856793","CorpusId":204232135,"PubMed":"31947388"},"title":"Deep Neural Network based Polyp Segmentation in Colonoscopy Images using a Combination of Color Spaces"},{"paperId":"12f754cf6c65232d1774033764818d483df850b7","externalIds":{"DBLP":"conf/cbms/ThomazFR19","MAG":"2964485128","DOI":"10.1109/CBMS.2019.00047","CorpusId":199490420},"title":"Training Data Enhancements for Robust Polyp Segmentation in Colonoscopy Images"},{"paperId":"e54fe27ed18d513e3e9171661bd9b6e1c982b7d5","externalIds":{"MAG":"3002563897","ArXiv":"2001.06810","DBLP":"journals/corr/abs-2001-06810","DOI":"10.1109/CVPR.2019.00374","CorpusId":198352766},"title":"See More, Know More: Unsupervised Video Object Segmentation With Co-Attention Siamese Networks"},{"paperId":"4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9","externalIds":{"DBLP":"conf/icml/TanL19","MAG":"2946948417","ArXiv":"1905.11946","CorpusId":167217261},"title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"},{"paperId":"02d8a8e69ac535dd1ff8c8a19e83abeecaab684d","externalIds":{"MAG":"2963649926","DBLP":"journals/corr/abs-1907-09180","ArXiv":"1907.09180","DOI":"10.1109/ISMICT.2019.8743694","CorpusId":195698011},"title":"Polyp Detection and Segmentation using Mask R-CNN: Does a Deeper Feature Extractor CNN Always Perform Better?"},{"paperId":"2a69ddbafb23c63e5e22401664bea229daaeb7d6","externalIds":{"MAG":"2971023209","ArXiv":"1904.01169","DBLP":"journals/pami/GaoCZZYT21","DOI":"10.1109/TPAMI.2019.2938758","CorpusId":91184391,"PubMed":"31484108"},"title":"Res2Net: A New Multi-Scale Backbone Architecture"},{"paperId":"2d7ed7142eb15e54661b65916e0b0fa4b25b2eda","externalIds":{"DBLP":"journals/corr/abs-1902-04099","MAG":"2979600871","ArXiv":"1902.04099","DOI":"10.1109/EMBC.2019.8857339","CorpusId":60441278,"PubMed":"31947500"},"title":"Psi-Net: Shape and boundary aware joint multi-task deep network for medical image segmentation"},{"paperId":"3ef03001691a875ba5d11bdd2886bc962d94033e","externalIds":{"DBLP":"journals/pami/KouwL21","MAG":"2979509742","ArXiv":"1901.05335","DOI":"10.1109/TPAMI.2019.2945942","CorpusId":198898096,"PubMed":"31603771"},"title":"A Review of Domain Adaptation without Target Labels"},{"paperId":"438ee09fc40b0bbf0330a6756256cdbc256e149e","externalIds":{"MAG":"2899986319","DBLP":"conf/aike/NguyenL18","DOI":"10.1109/AIKE.2018.00048","CorpusId":53284160},"title":"Colorectal Segmentation Using Multiple Encoder-Decoder Network in Colonoscopy Images"},{"paperId":"ccccebda59d357c7f0a5d90fcaa04c085582883a","externalIds":{"DBLP":"journals/cbm/Sanchez-Gonzalez18","MAG":"2840687963","DOI":"10.1016/j.compbiomed.2018.07.002","CorpusId":51678844,"PubMed":"30015012"},"title":"Automatized colon polyp segmentation via contour region analysis"},{"paperId":"a6876ea89e677a7cc42dd43f27165ff6fd414de5","externalIds":{"DBLP":"journals/corr/abs-1807-10165","MAG":"2952339589","ArXiv":"1807.10165","DOI":"10.1007/978-3-030-00889-5_1","CorpusId":50786304,"PubMed":"32613207"},"title":"UNet++: A Nested U-Net Architecture for Medical Image Segmentation"},{"paperId":"e4a04f7be7c98d1662de76cdc66a1e36fe701f70","externalIds":{"DBLP":"journals/corr/abs-1807-10584","MAG":"2883484411","DOI":"10.1016/j.media.2019.101619","CorpusId":260545942,"PubMed":"31810005"},"title":"Uncertainty and Interpretability in Convolutional Neural Networks for Semantic Segmentation of Colorectal Polyps"},{"paperId":"9a15661ab810a742095f33180c481bc7a1d37308","externalIds":{"DBLP":"journals/titb/YuanLM18","MAG":"2739977037","DOI":"10.1109/JBHI.2017.2734329","CorpusId":13366788,"PubMed":"28783650"},"title":"Automatic Polyp Detection via a Novel Unified Bottom-Up and Top-Down Saliency Approach"},{"paperId":"d1e5942d8cb764e58f4c38a0c254ca56782a98c3","externalIds":{"MAG":"2804610335","DBLP":"conf/ijcai/FanGCRCB18","ArXiv":"1805.10421","DOI":"10.24963/ijcai.2018/97","CorpusId":44072899},"title":"Enhanced-alignment Measure for Binary Foreground Map Evaluation"},{"paperId":"9406246f6972c03e5bfaac4df4676648dc4ac935","externalIds":{"MAG":"2804047627","DBLP":"journals/tmi/BernardLZCYHCLC18","DOI":"10.1109/TMI.2018.2837502","CorpusId":51610194,"PubMed":"29994302"},"title":"Deep Learning Techniques for Automatic MRI Cardiac Multi-Structures Segmentation and Diagnosis: Is the Problem Solved?"},{"paperId":"16a48e361906b75dd84a3acf99ec1f46b675e994","externalIds":{"ArXiv":"1807.10584","DBLP":"conf/mlsp/WickstromKJ18","MAG":"2890068671","DOI":"10.1109/MLSP.2018.8516998","CorpusId":51864659},"title":"UNCERTAINTY MODELING AND INTERPRETABILITY IN CONVOLUTIONAL NEURAL NETWORKS FOR POLYP SEGMENTATION"},{"paperId":"ffd2d678f2da5a9312501dba42dea2926ef9565d","externalIds":{"MAG":"2784171276","DBLP":"conf/mmm/WichakamPUV18","DOI":"10.1007/978-3-319-73603-7_32","CorpusId":45006964},"title":"Real-Time Polyps Segmentation for Colonoscopy Video Frames Using Compressed Fully Convolutional Network"},{"paperId":"d0b7d8d43ee4593e7eeef6f36e731f90cacdefda","externalIds":{"MAG":"2962927567","DBLP":"conf/embc/AkbariMNSKSN18","ArXiv":"1802.00368","DOI":"10.1109/EMBC.2018.8512197","CorpusId":53092209,"PubMed":"30440343"},"title":"Polyp Segmentation in Colonoscopy Images Using Fully Convolutional Network"},{"paperId":"f06ff5f719eb9cd939dde8fc9b199b17adcbc75f","externalIds":{"MAG":"2774320778","DBLP":"journals/corr/abs-1711-10684","ArXiv":"1711.10684","DOI":"10.1109/LGRS.2018.2802944","CorpusId":206437632},"title":"Road Extraction by Deep Residual U-Net"},{"paperId":"a6f835ca6e12245a835ab6074bc6ec2c3c60b85a","externalIds":{"MAG":"2964006983","DBLP":"journals/tec/SuVS19","ArXiv":"1710.08864","DOI":"10.1109/TEVC.2019.2890858","CorpusId":2698863},"title":"One Pixel Attack for Fooling Deep Neural Networks"},{"paperId":"dc7629d45a27c18505b7564044b9fa29ad687bac","externalIds":{"MAG":"2963200328","DBLP":"journals/corr/abs-1710-07390","ArXiv":"1710.07390","DOI":"10.1109/SPMB.2017.8257027","CorpusId":3875041},"title":"Superpixel based segmentation and classification of polyps in wireless capsule endoscopy"},{"paperId":"3f9f16ddad5e7c383405021f0111ed5de685e1ce","externalIds":{"MAG":"2793703004","DBLP":"conf/bmei/LiYCHCXZZZW17","DOI":"10.1109/CISP-BMEI.2017.8301980","CorpusId":3704217},"title":"Colorectal polyp segmentation using a fully convolutional neural network"},{"paperId":"fb37561499573109fc2cebb6a7b08f44917267dd","externalIds":{"MAG":"2963420686","DBLP":"journals/corr/abs-1709-01507","ArXiv":"1709.01507","DOI":"10.1109/CVPR.2018.00745","CorpusId":140309863},"title":"Squeeze-and-Excitation Networks"},{"paperId":"381d56f925530bc0fcd11e7cd4c4f7bb033fe000","externalIds":{"MAG":"2740248187","ArXiv":"1708.00786","DBLP":"conf/iccv/FanCLLB17","DOI":"10.1007/s11263-021-01490-8","CorpusId":22726592},"title":"Structure-Measure: A New Way to Evaluate Foreground Maps"},{"paperId":"acbd957256f2aca9b286667e2d7e0af70104b92b","externalIds":{"MAG":"2681379703","DBLP":"conf/miua/ZhangDY17","DOI":"10.1007/978-3-319-60964-5_62","CorpusId":11875277},"title":"Automated Polyp Segmentation in Colonoscopy Frames Using Fully Convolutional Neural Network and Textons"},{"paperId":"ee4a012a4b12d11d7ab8c0e79c61e807927a163c","externalIds":{"ArXiv":"1706.05587","DBLP":"journals/corr/ChenPSA17","MAG":"2630837129","CorpusId":22655199},"title":"Rethinking Atrous Convolution for Semantic Image Segmentation"},{"paperId":"2984e527510e7e7c0eadb339a6172c05a6919b5e","externalIds":{"MAG":"3105636206","DBLP":"conf/vcip/ChaurasiaC17","ArXiv":"1707.03718","DOI":"10.1109/VCIP.2017.8305148","CorpusId":3666466},"title":"LinkNet: Exploiting encoder representations for efficient semantic segmentation"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"1a0912bb76777469295bb2c059faee907e7f3258","externalIds":{"ArXiv":"1703.06870","CorpusId":54465873},"title":"Mask R-CNN"},{"paperId":"05413ea5c16302f286dabe0d0cacf404dba3ecbf","externalIds":{"MAG":"2593488799","DBLP":"conf/micad/BrandaoMCCBMDKA17","DOI":"10.1117/12.2254361","CorpusId":40686885},"title":"Fully convolutional neural networks for polyp segmentation in colonoscopy"},{"paperId":"fdf0586fee56ee8a1b2fefea2600d86140382c5b","externalIds":{"DBLP":"journals/tmi/BernalTSMCYARRB17","MAG":"2586952804","DOI":"10.1109/TMI.2017.2664042","CorpusId":25019972,"PubMed":"28182555"},"title":"Comparative Validation of Polyp Detection Methods in Video Colonoscopy: Results From the MICCAI 2015 Endoscopic Vision Challenge"},{"paperId":"2a94c84383ee3de5e6211d43d16e7de387f68878","externalIds":{"ArXiv":"1612.03144","DBLP":"conf/cvpr/LinDGHHB17","MAG":"2565639579","DOI":"10.1109/CVPR.2017.106","CorpusId":10716717},"title":"Feature Pyramid Networks for Object Detection"},{"paperId":"1031a69923b80ad01cf3fbb703d10757a80e699b","externalIds":{"DBLP":"journals/corr/ZhaoSQWJ16","ArXiv":"1612.01105","MAG":"2560023338","DOI":"10.1109/CVPR.2017.660","CorpusId":5299559},"title":"Pyramid Scene Parsing Network"},{"paperId":"8b008beb62007504aed4234980b5481edda644b0","externalIds":{"PubMedCentral":"5549472","MAG":"2560328367","ArXiv":"1612.00799","DBLP":"journals/corr/VazquezBSFLRDC16","DOI":"10.1155/2017/4037190","CorpusId":12575597,"PubMed":"29065595"},"title":"A Benchmark for Endoluminal Scene Segmentation of Colonoscopy Images"},{"paperId":"f6e0856b4a9199fa968ac00da612a9407b5cb85c","externalIds":{"DBLP":"conf/cvpr/XieGDTH17","MAG":"2953328958","ArXiv":"1611.05431","DOI":"10.1109/CVPR.2017.634","CorpusId":8485068},"title":"Aggregated Residual Transformations for Deep Neural Networks"},{"paperId":"9a99af9495bab7f56278eff4f1ba04e63e8061f6","externalIds":{"MAG":"2518605621","DBLP":"journals/jimaging/Prasath17","ArXiv":"1609.01915","DOI":"10.3390/jimaging3010001","CorpusId":1357965},"title":"Polyp Detection and Segmentation from Video Capsule Endoscopy: A Review"},{"paperId":"5694e46284460a648fe29117cbc55f6c9be3fa3c","externalIds":{"MAG":"2963446712","ArXiv":"1608.06993","DBLP":"journals/corr/HuangLW16a","DOI":"10.1109/CVPR.2017.243","CorpusId":9433631},"title":"Densely Connected Convolutional Networks"},{"paperId":"9993e93f69050c2faa2985b94040f72ac311e82b","externalIds":{"DBLP":"journals/tmi/TajbakhshGL16","MAG":"2285968993","DOI":"10.1109/TMI.2015.2487997","CorpusId":33242299,"PubMed":"26462083"},"title":"Automated Polyp Detection in Colonoscopy Videos Using Shape and Context Information"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"6e360e47e5a0fe2f929ddefb97af330da1716996","externalIds":{"DBLP":"conf/robio/Jia15","MAG":"2289212015","DOI":"10.1109/ROBIO.2015.7419005","CorpusId":11844755},"title":"Polyps auto-detection in Wireless Capsule Endoscopy images using improved method based on image segmentation"},{"paperId":"b0c065cd43aa7280e766b5dcbcc7e26abce59330","externalIds":{"MAG":"1910657905","DBLP":"journals/pami/BadrinarayananK17","ArXiv":"1511.00561","DOI":"10.1109/TPAMI.2016.2644615","CorpusId":60814714,"PubMed":"28060704"},"title":"SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation"},{"paperId":"0245171475005c171bd359fe9f461f5b6b7fb634","externalIds":{"DBLP":"journals/cmig/BernalSFGRV15","MAG":"2008359794","DOI":"10.1016/j.compmedimag.2015.02.007","CorpusId":1961788,"PubMed":"25863519"},"title":"WM-DOVA maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians"},{"paperId":"6364fdaa0a0eccd823a779fcdd489173f938e91a","externalIds":{"MAG":"1901129140","DBLP":"journals/corr/RonnebergerFB15","ArXiv":"1505.04597","DOI":"10.1007/978-3-319-24574-4_28","CorpusId":3719281},"title":"U-Net: Convolutional Networks for Biomedical Image Segmentation"},{"paperId":"6fc6803df5f9ae505cae5b2f178ade4062c768d0","externalIds":{"DBLP":"journals/corr/ShelhamerLD16","MAG":"2952632681","ArXiv":"1411.4038","DOI":"10.1109/CVPR.2015.7298965","CorpusId":1629541},"title":"Fully convolutional networks for semantic segmentation"},{"paperId":"5011f145ef876f11d7a8c6ca820d227270f34645","externalIds":{"DBLP":"conf/miccai/BernalNSV14","MAG":"7789328","DOI":"10.1007/978-3-319-13909-8_6","CorpusId":19844054},"title":"Polyp Segmentation Method in Colonoscopy Videos by Means of MSA-DOVA Energy Maps Calculation"},{"paperId":"eb42cf88027de515750f230b23b1a057dc782108","externalIds":{"MAG":"2949429431","ArXiv":"1409.1556","DBLP":"journals/corr/SimonyanZ14a","CorpusId":14124313},"title":"Very Deep Convolutional Networks for Large-Scale Image Recognition"},{"paperId":"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5","externalIds":{"MAG":"2133564696","ArXiv":"1409.0473","DBLP":"journals/corr/BahdanauCB14","CorpusId":11212020},"title":"Neural Machine Translation by Jointly Learning to Align and Translate"},{"paperId":"eaaa16fe11bf17b6df58dfbd346a5b8cbfabd596","externalIds":{"DBLP":"conf/cvpr/MargolinZT14","MAG":"1994922096","DOI":"10.1109/CVPR.2014.39","CorpusId":854969},"title":"How to Evaluate Foreground Maps"},{"paperId":"d5e0460472a2ce2494f721e05f24898470e03e5e","externalIds":{"MAG":"2021088830","DBLP":"journals/cars/SilvaHRDG14","DOI":"10.1007/s11548-013-0926-3","CorpusId":9957792,"PubMed":"24037504"},"title":"Toward embedded detection of polyps in WCE images for early diagnosis of colorectal cancer"},{"paperId":"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad","externalIds":{"ArXiv":"1312.6199","MAG":"2964153729","DBLP":"journals/corr/SzegedyZSBEGF13","CorpusId":604334},"title":"Intriguing properties of neural networks"},{"paperId":"9d32259f16ac76089c39e84063296f697a76460f","externalIds":{"MAG":"2034269173","DBLP":"journals/pr/BernalSV12","DOI":"10.1016/j.patcog.2012.03.002","CorpusId":1620711},"title":"Towards automatic polyp detection with a polyp appearance model"},{"paperId":"7abac1f397a76bc06d7508ab4108462786395c0f","externalIds":{"DBLP":"conf/cvpr/PerazziKPH12","MAG":"1982075130","DOI":"10.1109/CVPR.2012.6247743","CorpusId":9146763},"title":"Saliency filters: Contrast based filtering for salient region detection"},{"paperId":"9bee3444b10f93d029b48f221271ea4b1f7212bc","externalIds":{"DBLP":"journals/tbe/GanzYS12","MAG":"2096552575","DOI":"10.1109/TBME.2012.2195314","CorpusId":17644470,"PubMed":"22542647"},"title":"Automatic Segmentation of Polyps in Colonoscopic Narrow-Band Imaging Data"},{"paperId":"ba68d399a3f815422cb0b47c0f5d6091a71a9dab","externalIds":{"MAG":"2018001563","DBLP":"conf/icassp/HwangC10","DOI":"10.1109/ICASSP.2010.5495103","CorpusId":33731899},"title":"Polyp detection in Wireless Capsule Endoscopy videos based on image segmentation and geometric feature"},{"paperId":"2f52d46714a3fccbe9ea293763b03550ada7bd7d","externalIds":{"MAG":"2100470808","DBLP":"conf/cvpr/AchantaHES09","DOI":"10.1109/CVPR.2009.5206596","CorpusId":1334960},"title":"Frequency-tuned salient region detection"},{"paperId":"7ea4114262ef84a8afa219d5b049e5ff2ee21b01","externalIds":{"DBLP":"conf/cvpr/LuBWLSC08","MAG":"2163435437","DOI":"10.1109/CVPR.2008.4587423","CorpusId":7990808},"title":"Accurate polyp segmentation for 3D CT colongraphy using multi-staged probabilistic binary learning and compositional model"},{"paperId":"79ad463104c7b7afeab11c2046fe7c18d5108ac6","externalIds":{"DOI":"10.1080/10131750485310161","CorpusId":218497666},"title":"Pattern"},{"paperId":"8b79449c896556615aa5cde5db6f0196d0e19e3d","externalIds":{"MAG":"2106705035","DBLP":"journals/tmi/YaoMFS04","DOI":"10.1109/TMI.2004.826941","CorpusId":2373701,"PubMed":"15554123"},"title":"Colonic polyp segmentation in CT colonography-based on fuzzy clustering and deformable models"},{"paperId":"391e58b8d3549a20d01dc8122cab3f149b7d3928","externalIds":{"MAG":"2091323138","DOI":"10.1117/12.480696","CorpusId":6449999},"title":"Polyp segmentation method for CT colonography computer-aided detection"},{"paperId":"bfcb67ff2e36656032e8c0784f3a07cf1c5c9196","externalIds":{"DBLP":"conf/mmm/MauTBTNCTN23","DOI":"10.1007/978-3-031-27818-1_20","CorpusId":257986529},"title":"PEFNet: Positional Embedding Feature for Polyp Segmentation"},{"paperId":"e329238ef314d2a74fee21467f160e69bc20bbd1","externalIds":{"DBLP":"conf/miccai/LingWYCWZCD23","DOI":"10.1007/978-3-031-43990-2_54","CorpusId":263673423},"title":"Probabilistic Modeling Ensemble Vision Transformer Improves Complex Polyp Segmentation"},{"paperId":"f26e26c11dcc63bff288f3f3c9ec688bdd2ed5f1","externalIds":{"DBLP":"conf/miccai/SuSYHC23","DOI":"10.1007/978-3-031-43904-9_61","CorpusId":263673493},"title":"Revisiting Feature Propagation and Aggregation in Polyp Segmentation"},{"paperId":"6b8c7bf8fb6104f439c60058ccebdd6bf698260f","externalIds":{"CorpusId":253968583},"title":"FuzzyNet: A Fuzzy Attention Module for Polyp Segmentation"},{"paperId":"aabf8b7de9bf8d3be390e522e77ab325117849f8","externalIds":{"DBLP":"conf/miccai/ShenLJBM22","DOI":"10.1007/978-3-031-16440-8_57","CorpusId":252369320},"title":"Task-Relevant Feature Replenishment for Cross-Centre Polyp Segmentation"},{"paperId":"15f3267d3f7db06faeeb18a38dcb09a8d5c2d016","externalIds":{"DBLP":"conf/miccai/CaiWCBYLZ22","DOI":"10.1007/978-3-031-16440-8_60","CorpusId":252369742},"title":"Using Guided Self-Attention with Local Information for Polyp Segmentation"},{"paperId":"1ca21836fa8c850be1fd1410ef984fb29e74d4c1","externalIds":{"DBLP":"conf/miccai/ZhaoWTFLWL22","DOI":"10.1007/978-3-031-16440-8_44","CorpusId":252369203},"title":"Semi-supervised Spatial Temporal Attention Network for Video Polyp Segmentation"},{"paperId":"953b15944be4cd4ad817dad58101e4480f5a0544","externalIds":{"DBLP":"conf/miccai/MaCCLS21","DOI":"10.1007/978-3-030-87240-3_37","CorpusId":238207848},"title":"LDPolypVideo Benchmark: A Large-Scale Colonoscopy Video Dataset of Diverse Polyps"},{"paperId":"7a252e1bbcebd3cbabb86e97cedc5702a7747017","externalIds":{"DBLP":"conf/miccai/NguyenNDTNT21","DOI":"10.1007/978-3-030-87193-2_60","CorpusId":237621785},"title":"CCBANet: Cascading Context and Balancing Attention for Polyp Segmentation"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","externalIds":{"ArXiv":"2103.14030","DBLP":"conf/iccv/LiuL00W0LG21","DOI":"10.1109/ICCV48922.2021.00986","CorpusId":232352874},"title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"},{"paperId":"044e9463e40a74dd451a95bc18a0b806ff25eed2","externalIds":{"DBLP":"conf/miccai/ChengKSTLC21","DOI":"10.1007/978-3-030-87193-2_68","CorpusId":237621142},"title":"Learnable Oriented-Derivative Network for Polyp Segmentation"},{"paperId":"07123a70f4ce4282ae0246390471c9d3f80087bb","externalIds":{"DBLP":"conf/miccai/ShenJM21","DOI":"10.1007/978-3-030-87193-2_53","CorpusId":237621225},"title":"HRENet: A Hard Region Enhancement Network for Polyp Segmentation"},{"paperId":"6a2b55f55da7f94bc00a7b070e77008c4d1f449a","externalIds":{"CorpusId":102353561},"title":"Supplementary Material for Few Sample Knowledge Distillation for Efﬁcient Network Compression"},{"paperId":"aaa2d1c25f8fee9a27e416089a5f5254b2ede1c7","externalIds":{"MAG":"2927278850","DBLP":"conf/visapp/GuoM19","DOI":"10.5220/0007698806320641","CorpusId":132523872},"title":"GIANA Polyp Segmentation with Fully Convolutional Dilation Neural Networks"},{"paperId":"00f85ff06aecc5ac4947f7bcdb76622f6b0e6327","externalIds":{"MAG":"2593068728","DOI":"10.2316/P.2017.852-031","CorpusId":35272712},"title":"Automatic polyp detection in endoscopy videos: A survey"},{"paperId":"f5947d23080a3ea4173b18d0a31c82533232c2ee","externalIds":{"DBLP":"conf/bildmed/GrossKSWTTA09","MAG":"1576792801","DOI":"10.1007/978-3-540-93860-6_51","CorpusId":17279614},"title":"Polyp Segmentation in NBI Colonoscopy"}]}