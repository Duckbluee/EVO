{"abstract":"Adverse Childhood Experiences (ACEs) are a public health crisis. The American Academy of Pediatrics (AAP) recommends routine screening for ACEs. Current challenges in practice include a lack of validated screening tools, lack of resources to address issues found on screening, and the inability to translate population outcomes to individual patient care. Health care providers, and researchers are seeking innovative approaches and tools for ACEs screening, diagnosis, management, and continuous monitoring. Multimodal AI is an emerging concept that combines different input modalities to train AI agents to learn more accurate results by using both content and context. We present the Semantic Platform for Adverse Childhood Experiences Surveillance (SPACES), an explainable multimodal AI platform to facilitate ACEs surveillance and diagnosis of related health conditions, and subsequent interventions. We utilize a bottom-up approach to multimodal, explainable knowledge graph-based learning to derive recommendations and insights for better resource allocation and care management. SPACEs provides a novel approach to active ACEs surveillance by utilizing 360-degree views about patients and populations."}