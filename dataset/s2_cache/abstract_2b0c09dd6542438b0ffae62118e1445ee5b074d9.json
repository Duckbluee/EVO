{"abstract":"How to estimate the quality of the network output is an important issue, and currently there is no effective solution in the field of human parsing. To solve this problem, this work proposes a statistical method based on the output probability map to calculate the pixel classification quality, which is called pixel score. In addition, the Quality-Aware Module (QAM) is proposed to fuse the different quality information, the purpose of which is to estimate the quality of human parsing results. We combine QAM with a concise and effective network design to propose Quality-Aware Network (QANet) for human parsing. Benefiting from the superiority of QAM and QANet, we achieve the best performance on three multiple and one single human parsing benchmarks, including CIHP, MHP-v2, Pascal-Person-Part, ATR and LIP. Without increasing the training and inference time, QAM improves the AP<inline-formula><tex-math notation=\"LaTeX\">$^\\text{r}$</tex-math></inline-formula> criterion by more than 10 points in the multiple human parsing task. QAM can be extended to other tasks with good quality estimation, <italic>e.g</italic> instance segmentation. Specifically, QAM improves Mask R-CNN by <inline-formula><tex-math notation=\"LaTeX\">$\\scriptstyle \\sim$</tex-math></inline-formula>1% mAP on COCO and LVISv1.0 datasets. Based on the proposed QAM and QANet, our overall system wins 1st place in CVPR2021 L2ID High-resolution Human Parsing (HRHP) Challenge, and 2nd in CVPR2021 PIC Short-video Face Parsing (SFP) Challenge. Code and models are available at <uri>https://github.com/soeaver/QANet</uri>."}