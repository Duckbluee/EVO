{"references":[{"paperId":"b0563e7fb71cf5b5159422960bee3e595ed4704c","externalIds":{"DBLP":"journals/bise/KleselW25","DOI":"10.1007/s12599-025-00945-3","CorpusId":279086821},"title":"Retrieval-Augmented Generation (RAG)"},{"paperId":"47b10e2aa4b0d06271a5fe9247cf77f88854b1cc","externalIds":{"DBLP":"journals/tdsc/WuCZFHDX25","ArXiv":"2501.14008","DOI":"10.1109/TDSC.2024.3429271","CorpusId":271261766},"title":"WAFBooster: Automatic Boosting of WAF Security Against Mutated Malicious Payloads"},{"paperId":"7698ad870dc0a74001ca579fab61233cdc23e1cd","externalIds":{"ArXiv":"2501.11577","DBLP":"journals/corr/abs-2501-11577","DOI":"10.1109/TIFS.2024.3413592","CorpusId":270461470},"title":"Rethinking Membership Inference Attacks Against Transfer Learning"},{"paperId":"23621579d3054410ddd23986779d37ff3fd963bb","externalIds":{"DBLP":"journals/tgcn/WangLLFMW24","DOI":"10.1109/TGCN.2024.3374700","CorpusId":268403412},"title":"Distributed Semantic Communications for Multimodal Audio-Visual Parsing Tasks"},{"paperId":"f5d093022e7f9717842a3ffb856ca78d7be55ff3","externalIds":{"DBLP":"journals/corr/abs-2409-08538","ArXiv":"2409.08538","DOI":"10.1109/JSAC.2024.3459027","CorpusId":272653638},"title":"An Efficient Privacy-Aware Split Learning Framework for Satellite Communications"},{"paperId":"8f15f919418ed87dff9bca8cfec94fe3111a7565","externalIds":{"DBLP":"journals/corr/abs-2409-11416","ArXiv":"2409.11416","DOI":"10.48550/arXiv.2409.11416","CorpusId":272704026},"title":"The Unseen AI Disruptions for Power Grids: LLM-Induced Transients"},{"paperId":"9b59c2c6a026e974f440c75545e108e44d66c6a6","externalIds":{"DBLP":"journals/corr/abs-2408-10647","ArXiv":"2408.10647","DOI":"10.1109/TIFS.2025.3609104","CorpusId":271909446},"title":"Privacy-Preserving Universal Adversarial Defense for Black-Box Models"},{"paperId":"36f708fa17b9a096223d234565be16ad8ee83a35","externalIds":{"ArXiv":"2407.00952","DBLP":"journals/corr/abs-2407-00952","DOI":"10.48550/arXiv.2407.00952","CorpusId":270869805},"title":"SplitLoRA: A Split Parameter-Efficient Fine-Tuning Framework for Large Language Models"},{"paperId":"414bb74813c7b1c0112068bbbef840603d5fb818","externalIds":{"DBLP":"journals/tsc/XiongBLLDWYH24","ArXiv":"2407.00128","DOI":"10.1109/TSC.2024.3451185","CorpusId":270870458},"title":"When Search Engine Services Meet Large Language Models: Visions and Challenges"},{"paperId":"3efb321f1b785e7e620dbf2dd94b333290955eb1","externalIds":{"ArXiv":"2406.10856","DBLP":"journals/wcl/ZhaoCLZQYG25","DOI":"10.1109/LWC.2024.3505550","CorpusId":270560223},"title":"LEO Satellite Networks Assisted Geo-Distributed Data Processing"},{"paperId":"f57eba50dc96612ac1a1f574745619ed4c08dd18","externalIds":{"DBLP":"conf/cvpr/SongCYDGCS24","DOI":"10.1109/CVPR52733.2024.01306","CorpusId":272723198},"title":"Low-Rank Approximation for Sparse Attention in Multi-Modal LLMs"},{"paperId":"1cbb64f8d9c2246a1bc45f80d5fc9a1872b09648","externalIds":{"ArXiv":"2406.06474","DBLP":"journals/corr/abs-2406-06474","DOI":"10.48550/arXiv.2406.06474","CorpusId":270370964},"title":"Towards a Personal Health Large Language Model"},{"paperId":"812356c723c082f88fb722531beaf45e344ffa1e","externalIds":{"ArXiv":"2406.02069","DBLP":"journals/corr/abs-2406-02069","DOI":"10.48550/arXiv.2406.02069","CorpusId":270226243},"title":"PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling"},{"paperId":"bbaedc7a42a0965fd2c7fcd016d6c73593fa31cd","externalIds":{"ArXiv":"2405.15542","DBLP":"journals/corr/abs-2405-15542","DOI":"10.1109/TCCN.2025.3584228","CorpusId":270045636},"title":"SATSense: Multi-Satellite Collaborative Framework for Spectrum Sensing"},{"paperId":"6aa08ece7113d0bbf96644e3a61f5be416f4358f","externalIds":{"DBLP":"journals/tmc/PengCLYFBSLRG25","ArXiv":"2405.15705","DOI":"10.1109/TMC.2024.3509861","CorpusId":270045774},"title":"Sums: Sniffing Unknown Multiband Signals Under Low Sampling Rates"},{"paperId":"d372fb69c485472385f152bc832bf1d35e223324","externalIds":{"ArXiv":"2405.14366","DBLP":"journals/corr/abs-2405-14366","DOI":"10.48550/arXiv.2405.14366","CorpusId":269982665},"title":"MiniCache: KV Cache Compression in Depth Dimension for Large Language Models"},{"paperId":"4375abf311b0ef51644551276153efaf11426916","externalIds":{"DBLP":"journals/corr/abs-2405-11299","ArXiv":"2405.11299","DOI":"10.48550/arXiv.2405.11299","CorpusId":269922123},"title":"The CAP Principle for LLM Serving: A Survey of Long-Context Large Language Model Serving"},{"paperId":"1c66c41ff22adf66bb9b06d87d5a2ab7b8ee8de7","externalIds":{"DBLP":"journals/corr/abs-2405-10825","ArXiv":"2405.10825","DOI":"10.1109/COMST.2024.3465447","CorpusId":269899574},"title":"Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities"},{"paperId":"eb9c4a07a336e8deefe7b399c550d3af0241238e","externalIds":{"ArXiv":"2405.06211","DBLP":"conf/kdd/FanDNWLYCL24","DOI":"10.1145/3637528.3671470","CorpusId":269740933},"title":"A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"},{"paperId":"17ec07ed8826c420081d11c87a72cd797ed4e898","externalIds":{"DBLP":"conf/icdcs/QuLLCH24","ArXiv":"2405.03990","DOI":"10.1109/ICDCS60910.2024.00013","CorpusId":269614239},"title":"TrimCaching: Parameter-Sharing AI Model Caching in Wireless Edge Networks"},{"paperId":"cea758c383bb665b36fec7d6864dce6c710c7f67","externalIds":{"ArXiv":"2405.00263","DBLP":"journals/corr/abs-2405-00263","DOI":"10.48550/arXiv.2405.00263","CorpusId":269484725},"title":"Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge"},{"paperId":"e3d6dc0ccbc817330c4dc75392e0633ce46757f2","externalIds":{"ArXiv":"2404.14204","DBLP":"journals/corr/abs-2404-14204","DOI":"10.48550/arXiv.2404.14204","CorpusId":269293281},"title":"TrimCaching: Parameter-sharing Edge Caching for AI Model Downloading"},{"paperId":"97b6f4357d1e3ab40a7ee60acb5260a948e3641d","externalIds":{"ArXiv":"2404.14618","DBLP":"journals/corr/abs-2404-14618","DOI":"10.48550/arXiv.2404.14618","CorpusId":269303119},"title":"Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing"},{"paperId":"d8ab87176444f8b0747972310431c647a87de2df","externalIds":{"DBLP":"journals/tifs/QiuCDLLTJ25","ArXiv":"2404.08237","DOI":"10.1109/TIFS.2024.3520015","CorpusId":269137396},"title":"IFViT: Interpretable Fixed-Length Representation for Fingerprint Matching via Vision Transformer"},{"paperId":"afc7b94e49e80f0b68f9f676f6bb652f33dd0859","externalIds":{"DBLP":"journals/corr/abs-2404-06891","ArXiv":"2404.06891","DOI":"10.1109/TMC.2024.3449371","CorpusId":269033204},"title":"PACP: Priority-Aware Collaborative Perception for Connected and Autonomous Vehicles"},{"paperId":"3b9475f14b2c9b9b326d49a6dc69a2b191dda592","externalIds":{"DBLP":"journals/corr/abs-2404-06448","ArXiv":"2404.06448","DOI":"10.48550/arXiv.2404.06448","CorpusId":269009904},"title":"Automated Federated Pipeline for Parameter-Efficient Fine-Tuning of Large Language Models"},{"paperId":"7ef10b9b5bbce61573f647774004f95221efe665","externalIds":{"DBLP":"journals/corr/abs-2404-06345","ArXiv":"2404.06345","DOI":"10.48550/arXiv.2404.06345","CorpusId":269009845},"title":"AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning"},{"paperId":"3037efe59991db85cbb7e17f41e196f09c74ba6d","externalIds":{"DBLP":"conf/emnlp/GaoZ24","ArXiv":"2404.05182","DOI":"10.48550/arXiv.2404.05182","CorpusId":269005932},"title":"DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model"},{"paperId":"5cb268c99604ae64fc74ca5386ea66340810e883","externalIds":{"DBLP":"journals/corr/abs-2403-17400","ArXiv":"2403.17400","DOI":"10.1109/COMST.2024.3421523","CorpusId":268691815},"title":"A Survey on Resource Management in Joint Communication and Computing-Embedded SAGIN"},{"paperId":"af1a88b169ed00ab9dcdc860bc5b6b183fd7a3ab","externalIds":{"ArXiv":"2403.16460","DBLP":"journals/corr/abs-2403-16460","DOI":"10.48550/arXiv.2403.16460","CorpusId":268681472},"title":"FedAC: An Adaptive Clustered Federated Learning Framework for Heterogeneous Data"},{"paperId":"916b4926cda574dc3f9486bb9994b6f2788dd800","externalIds":{"DBLP":"journals/corr/abs-2403-14608","ArXiv":"2403.14608","DOI":"10.48550/arXiv.2403.14608","CorpusId":268553763},"title":"Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey"},{"paperId":"1bf7a9b8e0b294f0bef61ad126896cdbaf1023b6","externalIds":{"DBLP":"journals/corr/abs-2403-13101","ArXiv":"2403.13101","DOI":"10.1109/TON.2025.3577790","CorpusId":268537322},"title":"AdaptSFL: Adaptive Split Federated Learning in Resource-Constrained Edge Networks"},{"paperId":"41f0e442285cfdfe33f33e81b574671dfcb02bc2","externalIds":{"DBLP":"conf/pimrc/HuangY0H24","ArXiv":"2403.07338","DOI":"10.1109/PIMRC59610.2024.10817394","CorpusId":268363883},"title":"D2-JSCC: Digital Deep Joint Source-channel Coding for Semantic Communications"},{"paperId":"de7029e31c2342c24704c118c4e1a8bf82739be9","externalIds":{"DBLP":"journals/corr/abs-2403-05826","ArXiv":"2403.05826","DOI":"10.1109/TON.2025.3649068","CorpusId":268357481},"title":"Cached Model-as-a-Resource: Provisioning Large Language Model Agents for Edge Intelligence in Space–Air–Ground Integrated Networks"},{"paperId":"ee529552e871dbd7d2c53d9cde4b46380712cbe0","externalIds":{"DBLP":"journals/corr/abs-2403-00871","ArXiv":"2403.00871","DOI":"10.48550/arXiv.2403.00871","CorpusId":268231023},"title":"Teach LLMs to Phish: Stealing Private Information from Language Models"},{"paperId":"dbf829c977c121c3704d070d7800d29fe5914756","externalIds":{"DBLP":"journals/corr/abs-2402-16363","ArXiv":"2402.16363","DOI":"10.48550/arXiv.2402.16363","CorpusId":268032253},"title":"LLM Inference Unveiled: Survey and Roofline Model Insights"},{"paperId":"1492d13772deb74af25f0bf1c3e089c513203b09","externalIds":{"DBLP":"journals/iotj/ZhuDCZFW24","ArXiv":"2402.15903","DOI":"10.1109/JIOT.2024.3397677","CorpusId":267938169},"title":"ESFL: Efficient Split Federated Learning Over Resource-Constrained Heterogeneous Wireless Devices"},{"paperId":"6dc5c6190dfbe55c8b45b7b23800614c21e5b51c","externalIds":{"DBLP":"journals/corr/abs-2402-15627","ArXiv":"2402.15627","DOI":"10.48550/arXiv.2402.15627","CorpusId":267938564},"title":"MegaScale: Scaling Large Language Model Training to More Than 10, 000 GPUs"},{"paperId":"f7310dac21abc6ba357bcd5e75fb2e6957a97303","externalIds":{"DBLP":"conf/icml/Liu0ILTFXCSKLC24","ArXiv":"2402.14905","CorpusId":267898017},"title":"MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases"},{"paperId":"94db8a625418800c8ae7b48157a9cad1c8129051","externalIds":{"DBLP":"journals/corr/abs-2402-13116","ArXiv":"2402.13116","DOI":"10.48550/arXiv.2402.13116","CorpusId":267760021},"title":"A Survey on Knowledge Distillation of Large Language Models"},{"paperId":"4a9ce626c65f03ba9d9dc32403d2fbf91bbb192d","externalIds":{"DBLP":"conf/iccnc/DuZNKXK24","DOI":"10.1109/ICNC59896.2024.10555960","CorpusId":268742074},"title":"Reinforcement Learning with Large Language Models (LLMs) Interaction for Network Services"},{"paperId":"a1f76db91c0debcf93ae9889736bce8470902113","externalIds":{"DBLP":"journals/corr/abs-2402-06196","ArXiv":"2402.06196","DOI":"10.48550/arXiv.2402.06196","CorpusId":267617032},"title":"Large Language Models: A Survey"},{"paperId":"a3e000e0d7f64c1d094c2a8bf6f43992cbabe91b","externalIds":{"DBLP":"conf/icml/LiuYJZXBC024","ArXiv":"2402.02750","DOI":"10.13140/RG.2.2.28167.37282","CorpusId":267413049},"title":"KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache"},{"paperId":"f1a9e0830bc36c048fa4659beaa62609869895b5","externalIds":{"DBLP":"conf/icml/FuBS024","ArXiv":"2402.02057","DOI":"10.48550/arXiv.2402.02057","CorpusId":267412730},"title":"Break the Sequential Dependency of LLM Inference Using Lookahead Decoding"},{"paperId":"7a57a52e1a273799bed7c882bc12177ca89609ab","externalIds":{"ArXiv":"2402.01748","DBLP":"journals/network/XuTHMSR24","DOI":"10.1109/MNET.2024.3427313","CorpusId":267413048},"title":"Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems"},{"paperId":"be4d586ca8add316c14f24397f57f8c77e36cb9d","externalIds":{"ArXiv":"2404.16038","DBLP":"journals/corr/abs-2404-16038","DOI":"10.48550/arXiv.2404.16038","CorpusId":269362618},"title":"A Survey on Generative AI and LLM for Video Generation, Understanding, and Streaming"},{"paperId":"c81c7fb670ac0e27c9d2025d95d68f4752aed99d","externalIds":{"DBLP":"journals/corr/abs-2401-11391","ArXiv":"2401.11391","DOI":"10.1109/MNET.2024.3401159","CorpusId":267068317},"title":"Interactive AI With Retrieval-Augmented Generation for Next Generation Networking"},{"paperId":"57e7af0b69325fafb371ef5d502e39ef9c90ef7e","externalIds":{"ArXiv":"2401.10774","DBLP":"journals/corr/abs-2401-10774","DOI":"10.48550/arXiv.2401.10774","CorpusId":267061277},"title":"Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads"},{"paperId":"cf278f48c09c2747f415c0b190c09773673ea959","externalIds":{"DBLP":"journals/corr/abs-2401-09890","ArXiv":"2401.09890","DOI":"10.3390/app15020586","CorpusId":267035076},"title":"A Survey on Hardware Accelerators for Large Language Models"},{"paperId":"8ac21a1545a907fc64b54cde36bf41415608cd7d","externalIds":{"DBLP":"journals/corr/abs-2401-08092","ArXiv":"2401.08092","DOI":"10.48550/arXiv.2401.08092","CorpusId":267027735},"title":"A Survey of Resource-efficient LLM and Multimodal Foundation Models"},{"paperId":"78875987dc674fc556873df037cf114f04932e80","externalIds":{"ArXiv":"2401.07764","DBLP":"journals/corr/abs-2401-07764","DOI":"10.1109/MWC.005.2400019","CorpusId":266999418},"title":"When Large Language Model Agents Meet 6G Networks: Perception, Grounding, and Alignment"},{"paperId":"06d860a5bbb99a4eafdbbb2d5f6aa8dd5fd32cf4","externalIds":{"ArXiv":"2401.05459","DBLP":"journals/corr/abs-2401-05459","DOI":"10.48550/arXiv.2401.05459","CorpusId":266933252},"title":"Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security"},{"paperId":"96f095efc64e48ba93d0e34053aadf9e3fe24569","externalIds":{"DBLP":"journals/corr/abs-2401-04044","ArXiv":"2401.04044","DOI":"10.48550/arXiv.2401.04044","CorpusId":266843891},"title":"FFSplit: Split Feed-Forward Network For Optimizing Accuracy-Efficiency Trade-off in Language Model Inference"},{"paperId":"0d558136634156da3677d89d7ad9654342334c4d","externalIds":{"DBLP":"journals/ojcomps/ZhouCHCYZWZZ24","ArXiv":"2401.02643","DOI":"10.1109/OJCS.2024.3380828","CorpusId":266818228},"title":"Training and Serving System of Foundation Models: A Comprehensive Survey"},{"paperId":"efc5e94635a850ede9c1f8dbce65d5dc536f3bfb","externalIds":{"DBLP":"journals/ijon/LiuHHZLTZWGZPXWLZZHZQLG25","ArXiv":"2401.02038","DOI":"10.48550/arXiv.2401.02038","CorpusId":266755678},"title":"Understanding LLMs: A Comprehensive Overview from Training to Inference"},{"paperId":"4942034aa28c3f8df80d606867366072469c9b5e","externalIds":{"DBLP":"journals/corr/abs-2401-01544","ArXiv":"2401.01544","DOI":"10.1109/MWC.002.2400348","CorpusId":266741492},"title":"Collaborative Perception for Connected and Autonomous Driving: Challenges, Possible Solutions and Opportunities"},{"paperId":"6a04b7d0206552d7c657a1e673ad7274b7cd9935","externalIds":{"DBLP":"journals/network/TianZYCYJQW24","ArXiv":"2401.01666","DOI":"10.1109/MNET.2024.3420755","CorpusId":266741503},"title":"An Edge-Cloud Collaboration Framework for Generative AI Service Provision With Synergetic Big Cloud Model and Small Edge Models"},{"paperId":"001cca7910f507f7f75b8402b826c2dc07afef00","externalIds":{"DBLP":"journals/corr/abs-2401-00625","ArXiv":"2401.00625","DOI":"10.48550/arXiv.2401.00625","CorpusId":266693677},"title":"Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models"},{"paperId":"5acbf917da5be89e4eebd7e98c81d87069450a5d","externalIds":{"DBLP":"journals/corr/abs-2312-16279","ArXiv":"2312.16279","DOI":"10.1109/CVPR52733.2024.01202","CorpusId":266573298},"title":"Cloud-Device Collaborative Learning for Multimodal Large Language Models"},{"paperId":"13261129251c9e8891cff02c3aee15c4df6a5630","externalIds":{"DBLP":"journals/corr/abs-2312-15234","ArXiv":"2312.15234","DOI":"10.1145/3754448","CorpusId":266551872},"title":"Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems"},{"paperId":"457b945ad7868b674222791d699f933be6fca58e","externalIds":{"DBLP":"conf/bdcloud/YunBSS23","DOI":"10.1109/ISPA-BDCloud-SocialCom-SustainCom59178.2023.00101","CorpusId":269090652},"title":"Privacy-Preserving Federated Learning through Clustered Sampling on Fine-Tuning Distributed non-iid Large Language Models"},{"paperId":"ddacee7382548fd9976e846c92500cfa3b6741db","externalIds":{"DBLP":"conf/sosp/SongMX024","ArXiv":"2312.12456","DOI":"10.1145/3694715.3695964","CorpusId":266375171},"title":"PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU"},{"paperId":"eb68eb83e370d6d990b40686c3037ddc2eee8fc6","externalIds":{"ArXiv":"2312.10365","DBLP":"journals/corr/abs-2312-10365","DOI":"10.48550/arXiv.2312.10365","CorpusId":266348310},"title":"SPT: Fine-Tuning Transformer-based Language Models Efficiently with Sparsification"},{"paperId":"6d2ab31aa75468f5458b9d96192c3f4a28f55d73","externalIds":{"ArXiv":"2312.09245","DBLP":"journals/corr/abs-2312-09245","DOI":"10.1007/s44267-025-00095-w","CorpusId":266210476},"title":"DriveMLM: aligning multi-modal large language models with behavioral planning states for autonomous driving"},{"paperId":"1f5b4e393a1e02ab49e5ca2e6819cc28841918a2","externalIds":{"ArXiv":"2312.08901","CorpusId":266210460},"title":"Fewer is More: Boosting LLM Reasoning with Reinforced Context Pruning"},{"paperId":"2b05686607991a39aead43f371fd7ea2b08195f5","externalIds":{"DBLP":"journals/corr/abs-2312-08361","ArXiv":"2312.08361","DOI":"10.48550/arXiv.2312.08361","CorpusId":266191568},"title":"Distributed Inference and Fine-tuning of Large Language Models Over The Internet"},{"paperId":"713806165610c237f551a7b68e6b09b3ded75502","externalIds":{"ArXiv":"2312.04985","DBLP":"conf/icml/RibarCHBLO24","DOI":"10.48550/arXiv.2312.04985","CorpusId":266149707},"title":"SparQ Attention: Bandwidth-Efficient LLM Inference"},{"paperId":"89d3d19ad717cd534bdd1866d28e2da253147705","externalIds":{"DBLP":"journals/corr/abs-2312-04916","ArXiv":"2312.04916","DOI":"10.48550/arXiv.2312.04916","CorpusId":266149909},"title":"EE-LLM: Large-Scale Training and Inference of Early-Exit Large Language Models with 3D Parallelism"},{"paperId":"5851121df5ce46be5faea265c868ec0beabfce96","externalIds":{"DBLP":"journals/corr/abs-2312-03863","ArXiv":"2312.03863","DOI":"10.48550/arXiv.2312.03863","CorpusId":266044196},"title":"Efficient Large Language Models: A Survey"},{"paperId":"658fc3bd6498bb4eb87841ef99ce292fb8e35c1f","externalIds":{"DBLP":"conf/globecom/Rahman23","DOI":"10.1109/GCWkshps58843.2023.10465035","CorpusId":268612541},"title":"A Survey on Security and Privacy of Multimodal LLMs - Connected Healthcare Perspective"},{"paperId":"da60ec67e43df670bf705d05d62075943beed36e","externalIds":{"ArXiv":"2312.00333","DBLP":"journals/pieee/MaoYHZZ24","DOI":"10.1109/JPROC.2024.3437365","CorpusId":265551891},"title":"Green Edge AI: A Contemporary Survey"},{"paperId":"0d1760f435aeb1a05ae99957a5dca58aa3f37abb","externalIds":{"DBLP":"journals/corr/abs-2311-17474","ArXiv":"2311.17474","DOI":"10.1109/MNET.2024.3435752","CorpusId":265498773},"title":"Large Language Models for Networking: Applications, Enabling Techniques, and Challenges"},{"paperId":"52941cadbd340344f3e0a6f50719fe55b3de5088","externalIds":{"DBLP":"journals/corr/abs-2311-13165","ArXiv":"2311.13165","DOI":"10.1109/BigData59044.2023.10386743","CorpusId":265351653},"title":"Multimodal Large Language Models: A Survey"},{"paperId":"451539c0d0f5f5785ff58d09ca5e67a5f129f9de","externalIds":{"ArXiv":"2311.12320","DBLP":"journals/corr/abs-2311-12320","DOI":"10.1109/WACVW60836.2024.00106","CorpusId":265308931},"title":"A Survey on Multimodal Large Language Models for Autonomous Driving"},{"paperId":"aad3d2e690f6c73f04a14622ceff51464bbc560e","externalIds":{"DBLP":"conf/cvpr/0001TZC024","ArXiv":"2311.08046","DOI":"10.1109/CVPR52733.2024.01300","CorpusId":265157455},"title":"Chat-UniVi: Unified Visual Representation Empowers Large Language Models with Image and Video Understanding"},{"paperId":"f3f58877e404dc8b26b8d387b8c4e7b8ec58d567","externalIds":{"DBLP":"journals/corr/abs-2311-00447","ArXiv":"2311.00447","DOI":"10.48550/arXiv.2311.00447","CorpusId":264833344},"title":"On the Opportunities of Green Computing: A Survey"},{"paperId":"95240dda409e28acccdc5cf619ad0c036cf4292d","externalIds":{"DBLP":"conf/icml/LiuWDZY0S0TRC23","ArXiv":"2310.17157","DOI":"10.48550/arXiv.2310.17157","CorpusId":260815690},"title":"Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time"},{"paperId":"a1a0ac34cea82cf1e7b0c85bd86bb0a52614a083","externalIds":{"DBLP":"conf/mm/YangFZWL23","DOI":"10.1145/3581783.3612568","CorpusId":264492169},"title":"Modal-aware Bias Constrained Contrastive Learning for Multimodal Recommendation"},{"paperId":"67ffe6037cf058b8c5b39f59693c4c349cc1e456","externalIds":{"DBLP":"journals/corr/abs-2310-15080","ArXiv":"2310.15080","DOI":"10.48550/arXiv.2310.15080","CorpusId":264436414},"title":"Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization"},{"paperId":"980646c7dbd3689177a2fe5c27ffa116f042f4ee","externalIds":{"DBLP":"journals/corr/abs-2310-14651","ArXiv":"2310.14651","DOI":"10.48550/arXiv.2310.14651","CorpusId":264426238},"title":"$Λ$-Split: A Privacy-Preserving Split Computing Framework for Cloud-Powered Generative AI"},{"paperId":"a3d3369ac43e6a8e89bd6328755f7bd683438da9","externalIds":{"DBLP":"conf/icct/YuanCLPFZSW023","DOI":"10.1109/ICCT59356.2023.10419549","CorpusId":267646311},"title":"Graph Learning for Multi-Satellite based Spectrum Sensing"},{"paperId":"2d058447fe3fb3384c213de0399c2610ce3cb2b2","externalIds":{"DBLP":"journals/corr/abs-2310-10049","ArXiv":"2310.10049","DOI":"10.48550/arXiv.2310.10049","CorpusId":264145987},"title":"FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models"},{"paperId":"ffdc017b1d2b493feaac9efa854882fe23d50dcf","externalIds":{"ArXiv":"2310.08041","DBLP":"journals/corr/abs-2310-08041","DOI":"10.48550/arXiv.2310.08041","CorpusId":263908852},"title":"QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models"},{"paperId":"c803b2236136fe7c59ea3619bc7520d331568d32","externalIds":{"DBLP":"conf/vtc/FangHYLL23","DOI":"10.1109/VTC2023-Fall60731.2023.10333824","CorpusId":266198179},"title":"Large Language Models (LLMs) Inference Offloading and Resource Allocation in Cloud-Edge Networks: An Active Inference Approach"},{"paperId":"c7492913370b5726eaa6ced163a60de6c9d4bb7f","externalIds":{"DBLP":"journals/inffus/HeMLRLFC25","ArXiv":"2310.05694","DOI":"10.48550/arXiv.2310.05694","CorpusId":263829396},"title":"A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics"},{"paperId":"2392b6d3a5cad9e5cf349169eaeee848266adf6a","externalIds":{"ArXiv":"2310.05736","DBLP":"journals/corr/abs-2310-05736","DOI":"10.48550/arXiv.2310.05736","CorpusId":263830701},"title":"LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models"},{"paperId":"b12541867632737e826b7b01c7fbe1c4222d8655","externalIds":{"ArXiv":"2310.06201","DBLP":"journals/corr/abs-2310-06201","DOI":"10.48550/arXiv.2310.06201","CorpusId":263830231},"title":"Compressing Context to Enhance Inference Efficiency of Large Language Models"},{"paperId":"004699d8ed6d1929e484aba461391fadb1f5b0a7","externalIds":{"ArXiv":"2310.03150","DBLP":"conf/deem/WoisetschlagerE24","DOI":"10.1145/3650203.3663331","CorpusId":263671932},"title":"Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly"},{"paperId":"f99116659c7522941c2353f23bddd07251adaccc","externalIds":{"DBLP":"journals/corr/abs-2310-01329","ArXiv":"2310.01329","DOI":"10.48550/arXiv.2310.01329","CorpusId":263605677},"title":"BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models"},{"paperId":"fdc53c2c10742464087c0525f77e32604827a21d","externalIds":{"DBLP":"conf/iclr/XiaoTCHL24","ArXiv":"2309.17453","DOI":"10.48550/arXiv.2309.17453","CorpusId":263310483},"title":"Efficient Streaming Language Models with Attention Sinks"},{"paperId":"d34ca9843a08248e1be259626f02e0a892010c26","externalIds":{"DBLP":"journals/corr/abs-2309-16739","ArXiv":"2309.16739","DOI":"10.1109/MCOM.001.2400764","CorpusId":263310790},"title":"Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities"},{"paperId":"10a1df9191e88d17299ba32773f759792b558a51","externalIds":{"ArXiv":"2310.04427","DBLP":"journals/corr/abs-2310-04427","DOI":"10.3390/buildings14010220","CorpusId":263830627},"title":"Generative AI in the Construction Industry: Opportunities & Challenges"},{"paperId":"633e3fe49fe9c314f7245f77401c2e4a95e925a9","externalIds":{"DBLP":"journals/corr/abs-2309-05516","ArXiv":"2309.05516","DOI":"10.48550/arXiv.2309.05516","CorpusId":261697282},"title":"Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs"},{"paperId":"bcac614f9774488447221ebb4f16f05e3975ec1e","externalIds":{"DBLP":"conf/iclr/Jin0XCLTHCSMZOG24","ArXiv":"2309.04669","DOI":"10.48550/arXiv.2309.04669","CorpusId":263889455},"title":"Unified Language-Vision Pretraining in LLM with Dynamic Discrete Visual Tokenization"},{"paperId":"00e889fcfaf4396a20f37f681cf8b14f3e878879","externalIds":{"ArXiv":"2309.04255","DBLP":"journals/corr/abs-2309-04255","DOI":"10.48550/arXiv.2309.04255","CorpusId":261660737},"title":"LLMCad: Fast and Scalable On-device Large Language Model Inference"},{"paperId":"28e2ecb4183ebc0eec504b12dddc677f8aef8745","externalIds":{"DBLP":"journals/corr/abs-2309-01431","ArXiv":"2309.01431","DOI":"10.48550/arXiv.2309.01431","CorpusId":261530434},"title":"Benchmarking Large Language Models in Retrieval-Augmented Generation"},{"paperId":"dcf2e723ee9c3270c98ff768b139cca75d29242e","externalIds":{"DBLP":"journals/corr/abs-2309-01105","ArXiv":"2309.01105","DOI":"10.54364/AAIML.2023.1191","CorpusId":261531346},"title":"A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture"},{"paperId":"529ff7d6441d244212cf2becafd12a7e67ac56d9","externalIds":{"DBLP":"conf/kdd/KuangQLCGPXLDZ24","ArXiv":"2309.00363","DOI":"10.1145/3637528.3671573","CorpusId":261494317},"title":"FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning"},{"paperId":"191bcafadd65ac6eddd7806170068105b43a0f75","externalIds":{"DBLP":"conf/sigcomm/Ma00Y0ZL23","DOI":"10.1145/3603269.3610856","CorpusId":261431473},"title":"Poster: PipeLLM: Pipeline LLM Inference on Heterogeneous Devices with Sequence Slicing"},{"paperId":"a15ec0c63b3f31a3e3eb996deb0a0c6953618e54","externalIds":{"DBLP":"journals/bspc/YuPKKKKAX23","DOI":"10.1016/j.bspc.2023.105325","CorpusId":260675422},"title":"A practical wearable fall detection system based on tiny convolutional neural networks"},{"paperId":"b53dba04b2518ebed943daa9ab58f19af81e2012","externalIds":{"ArXiv":"2308.15367","DBLP":"journals/corr/abs-2308-15367","DOI":"10.1109/ICCV51070.2023.01755","CorpusId":261277015},"title":"Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation"},{"paperId":"eb2c2330177f765038a2b17e2ee3498965865797","externalIds":{"DBLP":"journals/corr/abs-2308-13137","ArXiv":"2308.13137","DOI":"10.48550/arXiv.2308.13137","CorpusId":261214575},"title":"OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models"},{"paperId":"eaf64cca235f3e6ddc3633c5378bc795c61c25f6","externalIds":{"DBLP":"journals/corr/abs-2308-12043","ArXiv":"2308.12043","DOI":"10.48550/arXiv.2308.12043","CorpusId":261076438},"title":"IncreLoRA: Incremental Parameter Allocation Method for Parameter-Efficient Fine-tuning"},{"paperId":"a0ab8c94158906ce6cd4dbe99e2df292d70a03f5","externalIds":{"DBLP":"conf/naacl/ZhuLSKCLSLCM24","ArXiv":"2308.11807","DOI":"10.48550/arXiv.2308.11807","CorpusId":261076291},"title":"Towards an On-device Agent for Text Rewriting"},{"paperId":"f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f","externalIds":{"ArXiv":"2308.10792","DBLP":"journals/corr/abs-2308-10792","DOI":"10.1145/3777411","CorpusId":261049152},"title":"Instruction Tuning for Large Language Models: A Survey"},{"paperId":"cfb2f6b0a5aedc4b6e4cd46f2542f10e7d612a3c","externalIds":{"ArXiv":"2308.08896","DBLP":"conf/globecom/LyuLQCHL23","DOI":"10.1109/GCWkshps58843.2023.10465123","CorpusId":261030846},"title":"Optimal Resource Allocation for U-Shaped Parallel Split Learning"},{"paperId":"338d8f3b199abcebc85f34016b0162ab3a9d5310","externalIds":{"DBLP":"journals/corr/abs-2308-07633","ArXiv":"2308.07633","DOI":"10.1162/tacl_a_00704","CorpusId":260900101},"title":"A Survey on Model Compression for Large Language Models"},{"paperId":"5ce0fa3f0882910a5dfa2697bb04c8785d914725","externalIds":{"ArXiv":"2308.06522","DBLP":"journals/corr/abs-2308-06522","DOI":"10.48550/arXiv.2308.06522","CorpusId":260887495},"title":"SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models"},{"paperId":"3bbd6540d38db023aa55ba2c636989e8190d0483","externalIds":{"DBLP":"conf/iccchina/ChenLWDW23","DOI":"10.1109/ICCC57788.2023.10233481","CorpusId":261562315},"title":"Cross-modal Semantic Communications in 6G"},{"paperId":"cc57200030fc350701a6424649e1bf26b81aef15","externalIds":{"ArXiv":"2307.15316","DBLP":"journals/corr/abs-2307-15316","DOI":"10.1109/TWC.2024.3373015","CorpusId":260316100},"title":"Efficient Multiuser AI Downloading via Reusable Knowledge Broadcasting"},{"paperId":"4d21debb0f5fec315181e0912b5105c6ce4fc67f","externalIds":{"DBLP":"journals/corr/abs-2307-14692","ArXiv":"2307.14692","DOI":"10.48550/arXiv.2307.14692","CorpusId":260203047},"title":"Backdoor Attacks for In-Context Learning with Language Models"},{"paperId":"573dad7b2fca7ce72a7f0daf681391d96379ebe3","externalIds":{"DBLP":"journals/corr/abs-2307-13896","ArXiv":"2307.13896","DOI":"10.48550/arXiv.2307.13896","CorpusId":260164619},"title":"Low-Parameter Federated Learning with Large Language Models"},{"paperId":"104b0bb1da562d53cbda87aec79ef6a2827d191a","externalIds":{"ArXiv":"2307.09288","DBLP":"journals/corr/abs-2307-09288","CorpusId":259950998},"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models"},{"paperId":"8094f5b2b124b150167175d871015b5f583b75ff","externalIds":{"ArXiv":"2307.06148","DBLP":"journals/corr/abs-2307-06148","DOI":"10.48550/arXiv.2307.06148","CorpusId":268358719},"title":"NetGPT: A Native-AI Network Architecture Beyond Provisioning Personalized Generative Services"},{"paperId":"d62c4d00b277e948956b6610ce2644e88fe1577b","externalIds":{"DBLP":"journals/cacm/Cerf23c","ArXiv":"2307.05782","DOI":"10.1007/978-981-96-6259-3","CorpusId":259837466,"PubMed":"38320147"},"title":"Large Language Models"},{"paperId":"ed2db05074b86da6fbcb01b45bd0f1693baa93c4","externalIds":{"DBLP":"conf/hotcarbon/ChienLNRSW23","DOI":"10.1145/3604930.3605705","CorpusId":260380531},"title":"Reducing the Carbon Impact of Generative AI Inference (today and in 2035)"},{"paperId":"888728745dbb769e29ed475d4f7661eebe1a71cf","externalIds":{"DBLP":"journals/tist/ChangWWWYZCYWWYZCYYX24","ArXiv":"2307.03109","DOI":"10.1145/3641289","CorpusId":259360395},"title":"A Survey on Evaluation of Large Language Models"},{"paperId":"4c55dd37ab4c41565226a3c8194166d7412b0a02","externalIds":{"ArXiv":"2307.02779","DBLP":"journals/cm/ShenSZLPLZL24","DOI":"10.1109/MCOM.001.2300550","CorpusId":259360434},"title":"Large Language Models Empowered Autonomous Edge AI for Connected Intelligence"},{"paperId":"e586a4591ba0303b769f2c07cbddaf1899cb72e4","externalIds":{"DBLP":"conf/nips/Zhang00CZC0TRBW23","ArXiv":"2306.14048","DOI":"10.48550/arXiv.2306.14048","CorpusId":259263947},"title":"H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models"},{"paperId":"7344a2d5a46b6236793f676b68f82b0deec254cb","externalIds":{"DBLP":"journals/wc/LinQCH24","ArXiv":"2306.12194","DOI":"10.1109/MWC.014.2300319","CorpusId":259212067},"title":"Split Learning in 6G Edge Networks"},{"paperId":"3b7ef6f9f27e33e6a4e3bfac90dcb01ab09718bc","externalIds":{"DBLP":"journals/corr/abs-2306-07629","ArXiv":"2306.07629","DOI":"10.48550/arXiv.2306.07629","CorpusId":259144954},"title":"SqueezeLLM: Dense-and-Sparse Quantization"},{"paperId":"51db4c39dc0bdf5c95c8bbe89bf4211b48d0b4df","externalIds":{"DBLP":"journals/corr/abs-2306-03078","ArXiv":"2306.03078","DOI":"10.48550/arXiv.2306.03078","CorpusId":259076379},"title":"SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression"},{"paperId":"5a90a8f4ec612cef6b1bb9cf4eae897385d33c2d","externalIds":{"ArXiv":"2306.17170","DBLP":"journals/corr/abs-2306-17170","DOI":"10.1109/OJCOMS.2023.3320646","CorpusId":259309258},"title":"An Overview on Generative AI at Scale With Edge–Cloud Computing"},{"paperId":"8cc6ec31e1cba2a4016e8f81b0a6edc9562314e0","externalIds":{"DBLP":"journals/twc/LanZPGH23","DOI":"10.1109/TWC.2022.3221778","CorpusId":253701674},"title":"Progressive Feature Transmission for Split Classification at the Wireless Edge"},{"paperId":"6bd3ee1ca608bc66a490f63f2fb107d79b44f3e2","externalIds":{"DBLP":"conf/acl/LiuO0CSMSKC24","ArXiv":"2305.17888","DOI":"10.48550/arXiv.2305.17888","CorpusId":258959117},"title":"LLM-QAT: Data-Free Quantization Aware Training for Large Language Models"},{"paperId":"9df4d9374ddf5b04523402d7a71b858d8fe55646","externalIds":{"ArXiv":"2305.18469","DBLP":"conf/ijcai/Zheng0LY23","DOI":"10.24963/ijcai.2023/519","CorpusId":258967576},"title":"Reducing Communication for Split Learning by Randomized Top-k Sparsification"},{"paperId":"bf9c38ed645c8a513693a579c887053b5c7c61fb","externalIds":{"DBLP":"conf/icc/NamPK23","DOI":"10.1109/ICCWorkshops57953.2023.10283579","CorpusId":264444973},"title":"Active Wireless Split Learning via Online Cloud-Local Server Delta-Knowledge Distillation"},{"paperId":"ad4b365630f1c13d74d78f0f5d8cee87ef356d41","externalIds":{"DBLP":"conf/nips/MalladiGNDL0A23","ArXiv":"2305.17333","DOI":"10.48550/arXiv.2305.17333","CorpusId":258959274},"title":"Fine-Tuning Language Models with Just Forward Passes"},{"paperId":"0ba0e73ba636b3f93d2e5e39d8f93a40bbbe555a","externalIds":{"ACL":"2023.acl-long.721","DBLP":"journals/corr/abs-2305-17530","ArXiv":"2305.17530","DOI":"10.48550/arXiv.2305.17530","CorpusId":258959382},"title":"PuMer: Pruning and Merging Tokens for Efficient Vision Language Models"},{"paperId":"d6eeb2898bd9bd34744194ef543062dda6c4531a","externalIds":{"DBLP":"conf/nips/LiuDLWXXKS23","ArXiv":"2305.17118","DOI":"10.48550/arXiv.2305.17118","CorpusId":258947558},"title":"Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time"},{"paperId":"32ac52069e562d4f900afee70bdca63f53461481","externalIds":{"ArXiv":"2305.14314","DBLP":"conf/nips/DettmersPHZ23","DOI":"10.48550/arXiv.2305.14314","CorpusId":258841328},"title":"QLoRA: Efficient Finetuning of Quantized LLMs"},{"paperId":"9048b1dd06c5c6ab563d4c9dd8524d26c5ea5c6d","externalIds":{"DBLP":"conf/globecom/XuNZKXMH23","ArXiv":"2305.12130","DOI":"10.1109/GLOBECOM54140.2023.10436771","CorpusId":258833217},"title":"Joint Foundation Model Caching and Inference of Generative AI Services for Edge Intelligence"},{"paperId":"017010b941d902a467f6d329ae5e74fd67e67912","externalIds":{"DBLP":"journals/corr/abs-2305-11627","ArXiv":"2305.11627","DOI":"10.48550/arXiv.2305.11627","CorpusId":258823276},"title":"LLM-Pruner: On the Structural Pruning of Large Language Models"},{"paperId":"ea72fb2a0d340f9d14fbcf300cd5f5fbbe1050bb","externalIds":{"DBLP":"journals/corr/abs-2305-09617","ArXiv":"2305.09617","DOI":"10.48550/arXiv.2305.09617","CorpusId":258715226},"title":"Towards Expert-Level Medical Question Answering with Large Language Models"},{"paperId":"5db3257a61d86f302767ae1f21d6fd30567f12e5","externalIds":{"DBLP":"conf/icassp/ZhangVKLZ00024","ArXiv":"2305.05644","DOI":"10.1109/ICASSP48485.2024.10447454","CorpusId":258564501},"title":"Towards Building The Federatedgpt: Federated Instruction Tuning"},{"paperId":"d50f023fe0921cabdd6d053c377cdd26c715994c","externalIds":{"DBLP":"conf/eurosys/WangCTG23","DOI":"10.1145/3552326.3587438","CorpusId":258508784},"title":"Tabi: An Efficient Multi-Level Inference System for Large Language Models"},{"paperId":"bf52c9d94fd61fae0d231a7e43d45d673584c282","externalIds":{"ArXiv":"2305.00944","DBLP":"journals/corr/abs-2305-00944","DOI":"10.48550/arXiv.2305.00944","CorpusId":258426823},"title":"Poisoning Language Models During Instruction Tuning"},{"paperId":"389ec3e8902a5dcfcde1adec735854e93f845937","externalIds":{"DBLP":"journals/corr/abs-2304-14402","ACL":"2024.eacl-long.57","ArXiv":"2304.14402","DOI":"10.48550/arXiv.2304.14402","CorpusId":258352678},"title":"LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions"},{"paperId":"f9a16392a6fc7e85909c68918f0de7072830bd66","externalIds":{"ArXiv":"2304.11397","DBLP":"journals/corr/abs-2304-11397","DOI":"10.1109/COMST.2024.3370169","CorpusId":258298136},"title":"Vehicle as a Service (VaaS): Leverage Vehicles to Build Service Networks and Capabilities for Smart Cities"},{"paperId":"9e8cb8c91a0acb6e661b58ad724aa758490f2bea","externalIds":{"ArXiv":"2304.03277","DBLP":"journals/corr/abs-2304-03277","CorpusId":257985497},"title":"Instruction Tuning with GPT-4"},{"paperId":"537a2617c3f9110f3a3537fa85edc723e4256c2b","externalIds":{"DBLP":"journals/twc/LiuDM23","DOI":"10.1109/TWC.2022.3213411","CorpusId":253309627},"title":"Wireless Distributed Learning: A New Hybrid Split and Federated Learning Approach"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"f8e77bd3d573d0daee0744443c65c40e3b5dc10f","externalIds":{"ArXiv":"2303.16129","DBLP":"journals/corr/abs-2303-16129","DOI":"10.1109/COMST.2024.3353265","CorpusId":257771737},"title":"Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services"},{"paperId":"fd746b2500cfcadf4af180ba7d8be8fedbcb8fab","externalIds":{"DBLP":"journals/tmc/LinZDCGHF24","ArXiv":"2303.15991","DOI":"10.1109/TMC.2024.3359040","CorpusId":257771867},"title":"Efficient Parallel Split Learning Over Resource-Constrained Wireless Edge Networks"},{"paperId":"b1c13971fc8dcab2af5f71010137003bb7754eea","externalIds":{"DBLP":"journals/wc/ShiZWWJL23","ArXiv":"2303.10920","DOI":"10.1109/MWC.002.2200468","CorpusId":257632063},"title":"Task-Oriented Communications for 6G: Vision, Principles, and Technologies"},{"paperId":"df79c20b2308ca945b70dcf5a8cdb96e42e0d996","externalIds":{"DOI":"10.1038/d41586-023-00816-5","CorpusId":257580633,"PubMed":"36928404"},"title":"GPT-4 is here: what scientists think"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"88134a9d204b45526c828505f7a691b2caa34aae","externalIds":{"ArXiv":"2303.05295","DBLP":"conf/emnlp/YangLMZ23","DOI":"10.48550/arXiv.2303.05295","CorpusId":257427488},"title":"Dynamic Stashing Quantization for Efficient Transformer Training"},{"paperId":"f5fc64be662419b137894bdc5687bdbe5903f709","externalIds":{"DBLP":"journals/iotj/HuangLHQZ24","ArXiv":"2302.13580","DOI":"10.1109/JIOT.2023.3293154","CorpusId":257219699},"title":"Joint Task and Data-Oriented Semantic Communications: A Deep Separate Source-Channel Coding Scheme"},{"paperId":"ad7ad310848535803edf7d922137ee408e7bd4d1","externalIds":{"DBLP":"journals/jsac/ChenMQC23","DOI":"10.1109/JSAC.2022.3227031","CorpusId":254532563},"title":"Multi-Tier Hybrid Offloading for Computation-Aware IoT Applications in Civil Aircraft-Augmented SAGIN"},{"paperId":"da075ad0ec2c88335af85602a76a33e034536896","externalIds":{"DBLP":"journals/corr/abs-2301-12900","ArXiv":"2301.12900","DOI":"10.1109/CVPR52729.2023.01544","CorpusId":256390345},"title":"DepGraph: Towards Any Structural Pruning"},{"paperId":"a4d189fb6375245c0d72cc8ad8507708473430df","externalIds":{"ArXiv":"2301.09152","DBLP":"journals/corr/abs-2301-09152","DOI":"10.48550/arXiv.2301.09152","CorpusId":256105644},"title":"Prompt Federated Learning for Weather Forecasting: Toward Foundation Models on Meteorological Data"},{"paperId":"1f22de83d912176cb8857efa1c6d65b14d6a2f5c","externalIds":{"DBLP":"journals/corr/abs-2301-04655","ArXiv":"2301.04655","DOI":"10.48550/arXiv.2301.04655","CorpusId":255749330},"title":"ChatGPT is not all you need. A State of the Art Review of large Generative AI models"},{"paperId":"909ad57ce8caa6b390a65ae09db352d27d8f3996","externalIds":{"DBLP":"journals/corr/abs-2301-00774","ArXiv":"2301.00774","DOI":"10.48550/arXiv.2301.00774","CorpusId":255372747},"title":"SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot"},{"paperId":"381c0a7662a0065caaf0387f0cf40f1ef559010a","externalIds":{"DBLP":"journals/corr/abs-2212-06378","ArXiv":"2212.06378","DOI":"10.48550/arXiv.2212.06378","CorpusId":254591721},"title":"Robust Split Federated Learning for U-shaped Medical Image Networks"},{"paperId":"e4c3dc16e971c82da57c9bba8a687f53c0d986d3","externalIds":{"DBLP":"conf/wcnc/KimDS23","ArXiv":"2212.06107","DOI":"10.1109/WCNC55385.2023.10118601","CorpusId":254564210},"title":"A Bargaining Game for Personalized, Energy Efficient Split Learning over Wireless Networks"},{"paperId":"983ceea20b2e3e28ccc2fc8da6cac92e7e4212c2","externalIds":{"DBLP":"journals/ton/ChenZDZZF22","DOI":"10.1109/TNET.2022.3179239","CorpusId":254736383},"title":"End-to-End Service Auction: A General Double Auction Mechanism for Edge Computing Services"},{"paperId":"d8e9f8c8a37cb4cd26b92ad0d942d641cd512644","externalIds":{"DBLP":"journals/corr/abs-2211-17192","ArXiv":"2211.17192","DOI":"10.48550/arXiv.2211.17192","CorpusId":254096365},"title":"Fast Inference from Transformers via Speculative Decoding"},{"paperId":"846bdc54563f9de2e8388078ea2467b81151f6d5","externalIds":{"DBLP":"journals/corr/abs-2211-15583","ArXiv":"2211.15583","DOI":"10.48550/arXiv.2211.15583","CorpusId":254043494},"title":"On the Effectiveness of Parameter-Efficient Fine-Tuning"},{"paperId":"2c994fadbb84fb960d8306ee138dbeef41a5b323","externalIds":{"ArXiv":"2211.10438","DBLP":"conf/icml/XiaoLSWDH23","DOI":"10.48550/arXiv.2211.10438","CorpusId":253708271},"title":"SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"},{"paperId":"edd3a21eca93d460a52ff5339e70119d36e16315","externalIds":{"DBLP":"conf/ccs/0003000DZ22","DOI":"10.1145/3548606.3560553","CorpusId":253371248},"title":"EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile Devices"},{"paperId":"a66b8cfb47d037d391b8cbbf17f9ee60a9693f7a","externalIds":{"DBLP":"journals/tdsc/WuHCZD22","MAG":"3203285340","DOI":"10.1109/TDSC.2021.3116552","CorpusId":244326363},"title":"Toward Robust Detection of Puppet Attacks via Characterizing Fingertip-Touch Behaviors"},{"paperId":"7da0f2501034522e3d50af7e9b8fa7ec9d7b65b6","externalIds":{"DBLP":"journals/corr/abs-2210-17323","ArXiv":"2210.17323","CorpusId":253237200},"title":"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"},{"paperId":"1dff6b1b35e2d45d4db57c8b4e4395486c3e365f","externalIds":{"ArXiv":"2210.09461","DBLP":"conf/iclr/BolyaFDZFH23","DOI":"10.48550/arXiv.2210.09461","CorpusId":252968113},"title":"Token Merging: Your ViT But Faster"},{"paperId":"9c19a9349e5c14c627b9f071a0396c892f592f00","externalIds":{"ArXiv":"2210.03555","DBLP":"journals/corr/abs-2210-03555","DOI":"10.1109/MWC.010.2200546","CorpusId":252762391},"title":"In-Situ Model Downloading to Realize Versatile Edge AI in 6G Mobile Networks"},{"paperId":"ca086f4c09cf8de705830ac2b70951737fab93ca","externalIds":{"DBLP":"journals/corr/abs-2209-01667","ArXiv":"2209.01667","DOI":"10.48550/arXiv.2209.01667","CorpusId":252089870},"title":"A Review of Sparse Expert Models in Deep Learning"},{"paperId":"2ef60a4ea4ea53056be811ff55679eb59fb4b586","externalIds":{"DBLP":"conf/nips/SchusterFG0B0TM22","ArXiv":"2207.07061","DOI":"10.48550/arXiv.2207.07061","CorpusId":250526382},"title":"Confident Adaptive Language Modeling"},{"paperId":"5b4d0887122fd0aca22101e81a144b5fd568486f","externalIds":{"DBLP":"journals/twc/ChenZDF22","DOI":"10.1109/TWC.2022.3168538","CorpusId":249550846},"title":"Federated Learning Over Multihop Wireless Networks With In-Network Aggregation"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"af64997bf7cebd1c7bf848fee99dc9c3a59c8d57","externalIds":{"ArXiv":"2202.08587","DBLP":"journals/corr/abs-2202-08587","CorpusId":246904591},"title":"Gradients without Backpropagation"},{"paperId":"625270a54be430ad6262f848babb0d106af5b183","externalIds":{"DBLP":"journals/corr/abs-2202-07800","ArXiv":"2202.07800","CorpusId":246867285},"title":"Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations"},{"paperId":"ff334200e25321b4b8f47a630ecc01ae1d62d549","externalIds":{"DBLP":"journals/corr/abs-2202-06471","ArXiv":"2202.06471","DOI":"10.1109/MWC.004.2200050","CorpusId":246822566},"title":"Semantic Communication Meets Edge Intelligence"},{"paperId":"d424ab3b2d167db305fca17227c0197dd3014baf","externalIds":{"DBLP":"journals/jsac/WangZUM22","DOI":"10.1109/jsac.2021.3118403","CorpusId":242465446},"title":"HiveMind: Towards Cellular Native Machine Learning Model Splitting"},{"paperId":"a5bc945e24ab02695cd56f0579783cfe3f87a32c","externalIds":{"PubMedCentral":"8872156","DOI":"10.3390/healthcare10020293","CorpusId":246537005,"PubMed":"35206907"},"title":"Communication Requirements in 5G-Enabled Healthcare Applications: Review and Considerations"},{"paperId":"f5a3dbc0518df5ca1b6333ae93244dde7f793736","externalIds":{"DBLP":"conf/aaai/GuanLL0LG22","ArXiv":"2112.08560","DOI":"10.1609/aaai.v36i10.21316","CorpusId":245219235},"title":"Block-Skim: Efficient Question Answering for Transformer"},{"paperId":"795945ea94086f09e8b25f3b5997ef44fe5931d2","externalIds":{"DBLP":"journals/pieee/XuLLSTJCH21","DOI":"10.1109/jproc.2021.3119950","CorpusId":240433758},"title":"Edge Intelligence: Empowering Intelligence to the Edge of Network"},{"paperId":"f3a332ff1b73acda482e5d83696b2c701f487819","externalIds":{"DBLP":"journals/corr/abs-2110-07602","ArXiv":"2110.07602","CorpusId":238857040},"title":"P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"},{"paperId":"1dfc02d2e98d6b0dcc41c1c8b209b4fdde54fde7","externalIds":{"DBLP":"journals/wc/Rong21","DOI":"10.1109/mwc.2021.9615100","CorpusId":244145133},"title":"6G: The Next Horizon: From Connected People and Things to Connected Intelligence"},{"paperId":"c264d5c4d03c46f7f219cb1581203aaf805832d5","externalIds":{"DOI":"10.1109/UBMK52708.2021.9558906","CorpusId":238750671},"title":"Improving Text Classification with Transformer"},{"paperId":"e48b8a20a86ece87bdacfa23f182e6694f105464","externalIds":{"DBLP":"journals/corr/abs-2107-08628","ArXiv":"2107.08628","DOI":"10.1109/ICUFN49451.2021.9528601","CorpusId":236087386},"title":"Secure Aerial Surveillance using Split Learning"},{"paperId":"d79e8947f481c8ad5703611964a9f6c9bddce551","externalIds":{"DBLP":"conf/icdcs/ChenXWLLCZ21","DOI":"10.1109/ICDCS51616.2021.00010","CorpusId":234101214},"title":"Communication-Efficient Federated Learning with Adaptive Parameter Freezing"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"4fffa5245d3972077c83614c2a08a47cb578631e","externalIds":{"ArXiv":"2106.07447","DBLP":"journals/corr/abs-2106-07447","DOI":"10.1109/taslp.2021.3122291","CorpusId":235421619},"title":"HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units"},{"paperId":"9c053552dfa6184f7dc56d620bcb1e8f22c729a3","externalIds":{"DBLP":"conf/acl/LiSSYQH20","ArXiv":"2105.13878","ACL":"2021.acl-long.16","DOI":"10.18653/v1/2021.acl-long.16","CorpusId":235248193},"title":"Accelerating BERT Inference for Sequence Labeling via Early-Exit"},{"paperId":"976ae262c8e88c61462f673383da3649f935cebc","externalIds":{"DBLP":"journals/corr/abs-2104-15094","ArXiv":"2104.15094","DOI":"10.1109/ICCCN52240.2021.9522156","CorpusId":233476205},"title":"QoS-Aware Placement of Deep Learning Services on the Edge with Multiple Service Implementations"},{"paperId":"7a16d9b4e04300d034502dc7dd58428714594e2c","externalIds":{"DBLP":"journals/corr/abs-2104-10350","ArXiv":"2104.10350","CorpusId":233324338},"title":"Carbon Emissions and Large Neural Network Training"},{"paperId":"ffdbd7f0b03b85747b001b4734d5ee31b5229aa4","externalIds":{"DBLP":"journals/corr/abs-2104-08691","ArXiv":"2104.08691","ACL":"2021.emnlp-main.243","DOI":"10.18653/v1/2021.emnlp-main.243","CorpusId":233296808},"title":"The Power of Scale for Parameter-Efficient Prompt Tuning"},{"paperId":"72dd63d67588a42fc817bbb8d655b397f67425df","externalIds":{"DBLP":"journals/corr/abs-2104-07857","ArXiv":"2104.07857","DOI":"10.1145/3458817.3476205","CorpusId":233289729},"title":"ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep learning"},{"paperId":"774591fdd988eaaff3917e7c5171d044b0843e63","externalIds":{"ArXiv":"2104.04473","DBLP":"conf/sc/NarayananSCLPKV21","DOI":"10.1145/3458817.3476209","CorpusId":236635565},"title":"Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM"},{"paperId":"44930df2a3186edb58c4d6f6e5ed828c5d6a0089","externalIds":{"DBLP":"journals/corr/abs-2103-16775","ArXiv":"2103.16775","DOI":"10.1007/s10462-022-10148-x","CorpusId":232428181},"title":"Attention, please! A survey of neural attention models in deep learning"},{"paperId":"f799a81f9319a0adb29139f45de8608481e214f4","externalIds":{"DBLP":"journals/twc/LiuZSL23","ArXiv":"2103.14272","DOI":"10.1109/TWC.2022.3190512","CorpusId":250935497},"title":"Hierarchical Federated Learning With Quantization: Convergence Analysis and System Design"},{"paperId":"f7db2e2b181df60be90fd602b1aa306e4ca8b342","externalIds":{"DBLP":"journals/corr/abs-2103-06561","ArXiv":"2103.06561","CorpusId":232185258},"title":"WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training"},{"paperId":"44732fe24025c2f17777028bb49bb4a09c31af2a","externalIds":{"ArXiv":"2103.04505","DBLP":"journals/corr/abs-2103-04505","DOI":"10.1145/3527155","CorpusId":232146855},"title":"Split Computing and Early Exiting for Deep Learning Applications: Survey and Research Challenges"},{"paperId":"17858a252b041b4d7af8e87b876392f198a3e273","externalIds":{"DBLP":"journals/jsac/ShaoMZ22","ArXiv":"2102.04170","DOI":"10.1109/jsac.2021.3126087","CorpusId":231846709},"title":"Learning Task-Oriented Communication for Edge Inference: An Information Bottleneck Approach"},{"paperId":"12b71736392209b4292471b7da0aed71ba2aa545","externalIds":{"DBLP":"conf/usenix/0015RARYZ0H21","MAG":"3121562065","ArXiv":"2101.06840","CorpusId":231632857},"title":"ZeRO-Offload: Democratizing Billion-Scale Model Training"},{"paperId":"fdacf2a732f55befdc410ea927091cad3b791f13","externalIds":{"DBLP":"journals/jmlr/FedusZS22","ArXiv":"2101.03961","CorpusId":231573431},"title":"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"},{"paperId":"ad7ddcc14984caae308c397f1a589aae75d4ab71","externalIds":{"ArXiv":"2012.12877","DBLP":"journals/corr/abs-2012-12877","CorpusId":229363322},"title":"Training data-efficient image transformers & distillation through attention"},{"paperId":"c8d22fd8e8e094d624a484d770a60873baaba5f4","externalIds":{"DBLP":"journals/nle/Dale21","MAG":"3112103703","DOI":"10.1017/S1351324920000601","CorpusId":229170661},"title":"GPT-3: What’s it good for?"},{"paperId":"d22e4cc3a501c17881b9478621f29760e429e76e","externalIds":{"MAG":"3113057009","ACL":"2021.acl-long.378","DBLP":"journals/corr/abs-2012-07463","ArXiv":"2012.07463","DOI":"10.18653/v1/2021.acl-long.378","CorpusId":229152766},"title":"Parameter-Efficient Transfer Learning with Diff Pruning"},{"paperId":"dc6582842f08a4b85a0a0a000f6c6dd21aa4919a","externalIds":{"MAG":"3038214419","DBLP":"journals/iotj/WuHCDX20","DOI":"10.1109/JIOT.2020.3006870","CorpusId":226663212},"title":"CaIAuth: Context-Aware Implicit Authentication When the Screen Is Awake"},{"paperId":"f53fc9130c4bf6f253d5f0482ebfe15db111b551","externalIds":{"DBLP":"journals/corr/abs-2011-14818","MAG":"3107794213","ArXiv":"2011.14818","DOI":"10.1007/978-3-030-70604-3_4","CorpusId":227227939},"title":"Advancements of federated learning towards privacy preservation: from federated learning to split learning"},{"paperId":"f0b9e129e76a374dd401fda91214e72d6858bdc4","externalIds":{"DBLP":"journals/corr/abs-2011-05708","ArXiv":"2011.05708","MAG":"3105912911","DOI":"10.1109/TWC.2021.3081991","CorpusId":226300051},"title":"Optimizing AI Service Placement and Resource Allocation in Mobile Edge Intelligence Systems"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"MAG":"3094502228","ArXiv":"2010.11929","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"74276a37bfa50f90dfae37f767b2b67784bd402a","externalIds":{"ArXiv":"2010.11934","DBLP":"conf/naacl/XueCRKASBR21","MAG":"3169483174","ACL":"2021.naacl-main.41","DOI":"10.18653/V1/2021.NAACL-MAIN.41","CorpusId":225040574},"title":"mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"},{"paperId":"1882f194cb43828852cc052887671e55a80f945a","externalIds":{"MAG":"3040573126","DBLP":"conf/iclr/LepikhinLXCFHKS21","ArXiv":"2006.16668","CorpusId":220265858},"title":"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"962dc29fdc3fbdc5930a10aba114050b82fe5a3e","externalIds":{"MAG":"3096609285","DBLP":"conf/eccv/CarionMSUKZ20","ArXiv":"2005.12872","DOI":"10.1007/978-3-030-58452-8_13","CorpusId":218889832},"title":"End-to-End Object Detection with Transformers"},{"paperId":"659bf9ce7175e1ec266ff54359e2bd76e0b7ff31","externalIds":{"DBLP":"conf/nips/LewisPPPKGKLYR020","MAG":"3027879771","ArXiv":"2005.11401","CorpusId":218869575},"title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"},{"paperId":"7758df27ac7c553046026830ba87e2408d225411","externalIds":{"DBLP":"journals/corr/abs-2005-09868","MAG":"3027918449","ArXiv":"2005.09868","DOI":"10.1109/LCOMM.2020.2996605","CorpusId":218719551},"title":"Data-Importance Aware Radio Resource Allocation: Wireless Communication Helps Machine Learning"},{"paperId":"afbb3550da652f4eabaf88e171c68c46ac14a98b","externalIds":{"MAG":"3034212969","ACL":"2020.acl-main.504","ArXiv":"2005.02534","DBLP":"conf/acl/SoldainiM20","DOI":"10.18653/v1/2020.acl-main.504","CorpusId":218517099},"title":"The Cascade Transformer: an Application for Efficient Answer Sentence Selection"},{"paperId":"c9060df13d2e7f06b277a2893590aebb653c5995","externalIds":{"DBLP":"journals/corr/abs-2004-13336","MAG":"3021234081","ArXiv":"2004.13336","CorpusId":216562234},"title":"Automatic Cross-Replica Sharding of Weight Update in Data-Parallel Training"},{"paperId":"90a1491ac32e732c93773354e4e665794ed4d490","externalIds":{"MAG":"3035038672","DBLP":"journals/corr/abs-2004-12993","ArXiv":"2004.12993","ACL":"2020.acl-main.204","DOI":"10.18653/v1/2020.acl-main.204","CorpusId":216552850},"title":"DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference"},{"paperId":"0294bd2e6638c9a3619d4baaa63202a3c511dccc","externalIds":{"DBLP":"journals/corr/abs-2004-12088","ArXiv":"2004.12088","MAG":"3018102029","DOI":"10.1609/aaai.v36i8.20825","CorpusId":216553597},"title":"SplitFed: When Federated Learning Meets Split Learning"},{"paperId":"94f94e8892261d0377159379ca5a166ceae19a14","externalIds":{"DBLP":"conf/icml/GoyalCRCSV20","MAG":"3034742519","CorpusId":219792793},"title":"PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"},{"paperId":"a9fd5511b42206a27748f373e0fdb7eb76a23055","externalIds":{"DBLP":"journals/corr/abs-2001-07966","ArXiv":"2001.07966","MAG":"3001555892","CorpusId":210859480},"title":"ImageBERT: Cross-modal Pre-training with Large-scale Weak-supervised Image-Text Data"},{"paperId":"ccc3b85a9ce511b3a6263e7eac516aa1875eb64e","externalIds":{"DBLP":"journals/tccn/ZhongGV20","MAG":"3002844053","DOI":"10.1109/TCCN.2020.2968326","CorpusId":212646302},"title":"Deep Reinforcement Learning-Based Edge Caching in Wireless Networks"},{"paperId":"03bce1b255a6cb57c7c9a544c87e34c8f926a255","externalIds":{"MAG":"2902426498","DBLP":"journals/tmc/DingGLF19","DOI":"10.1109/TMC.2018.2883952","CorpusId":70128254},"title":"Beef Up the Edge: Spectrum-Aware Placement of Edge Computing Services for the Internet of Things"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"cb4f814bc755ee7d4083a529cc1c84c2965547b4","externalIds":{"DBLP":"journals/tccn/LiuZZH21","MAG":"3033843856","ArXiv":"1910.02214","DOI":"10.1109/TCCN.2020.2999606","CorpusId":203837065},"title":"Data-Importance Aware User Scheduling for Communication-Efficient Edge Machine Learning"},{"paperId":"00c957711b12468cb38424caccdf5291bb354033","externalIds":{"MAG":"3025935268","DBLP":"conf/sc/RajbhandariRRH20","ArXiv":"1910.02054","DOI":"10.1109/SC41405.2020.00024","CorpusId":269617042},"title":"ZeRO: Memory optimizations Toward Training Trillion Parameter Models"},{"paperId":"7a064df1aeada7e69e5173f7d4c8606f4470365b","externalIds":{"MAG":"2996428491","DBLP":"journals/corr/abs-1909-11942","ArXiv":"1909.11942","CorpusId":202888986},"title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"},{"paperId":"8323c591e119eb09b28b29fd6c7bc76bd889df7a","externalIds":{"MAG":"2973727699","ArXiv":"1909.08053","DBLP":"journals/corr/abs-1909-08053","CorpusId":202660670},"title":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"},{"paperId":"40fb2468c3a77c68fe703a6e614f4ad25bd4e3dd","externalIds":{"MAG":"3014943181","DBLP":"journals/corr/abs-1909-00560","ArXiv":"1909.00560","DOI":"10.1109/JIOT.2020.2984887","CorpusId":202541084},"title":"Edge Intelligence: The Confluence of Edge Computing and Artificial Intelligence"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"e0c6abdbdecf04ffac65c440da77fb9d66bb474c","externalIds":{"MAG":"2950813464","DBLP":"journals/corr/abs-1906-08237","ArXiv":"1906.08237","CorpusId":195069387},"title":"XLNet: Generalized Autoregressive Pretraining for Language Understanding"},{"paperId":"ec4dbc71e55abb8123b33e4eac343135fa729a6c","externalIds":{"MAG":"2948261778","ArXiv":"1906.01864","DBLP":"journals/corr/abs-1906-01864","DOI":"10.1109/ICDCS.2019.00182","CorpusId":174799395},"title":"OpenEI: An Open Framework for Edge Intelligence"},{"paperId":"928cd808aba140ec298508df87c5579811ff2f41","externalIds":{"DBLP":"journals/pieee/ZhouCLZLZ19","MAG":"2950865323","ArXiv":"1905.10083","DOI":"10.1109/JPROC.2019.2918951","CorpusId":165163986},"title":"Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing"},{"paperId":"afb1acd9cb0caa50b9b9170e3cd63fa4a6f65478","externalIds":{"DBLP":"conf/icc/Liu0SL20","MAG":"2982312326","ArXiv":"1905.06641","DOI":"10.1109/icc40277.2020.9148862","CorpusId":204978458},"title":"Client-Edge-Cloud Hierarchical Federated Learning"},{"paperId":"cd93c479b0bf433a006335912fafb3823a293e65","externalIds":{"MAG":"2962326827","DBLP":"conf/icc/Wu0CD19","DOI":"10.1109/ICC.2019.8761435","CorpusId":198168802},"title":"ICAuth: Implicit and Continuous Authentication When the Screen Is Awake"},{"paperId":"69455376f5ad52cac5b72d5e8c6cf03fb466b55c","externalIds":{"ArXiv":"1904.04745","MAG":"2980088508","DBLP":"conf/cvpr/YeR0W19","DOI":"10.1109/CVPR.2019.01075","CorpusId":104292134},"title":"Cross-Modal Self-Attention Network for Referring Image Segmentation"},{"paperId":"a8427ce5aee6d62800c725588e89940ed4910e0d","externalIds":{"DBLP":"journals/corr/abs-1904-02874","MAG":"2941531368","ArXiv":"1904.02874","DOI":"10.1145/3465055","CorpusId":102350916},"title":"An Attentive Survey of Attention Models"},{"paperId":"a82bebb9c51b7b0a57ac0026f47344b948acc9e0","externalIds":{"DBLP":"conf/infocom/HuBWL19","MAG":"2920031528","DOI":"10.1109/INFOCOM.2019.8737614","CorpusId":86836398},"title":"Dynamic Adaptive DNN Surgery for Inference Acceleration on the Edge"},{"paperId":"ff605ade239aa90caea65ef3f2447c8736a794b7","externalIds":{"MAG":"2920095265","DBLP":"conf/infocom/TranBZMH19","DOI":"10.1109/INFOCOM.2019.8737464","CorpusId":86439367},"title":"Federated Learning over Wireless Networks: Optimization Model Design and Analysis"},{"paperId":"29ddc1f43f28af7c846515e32cc167bc66886d0c","externalIds":{"DBLP":"journals/corr/abs-1902-00751","ArXiv":"1902.00751","MAG":"2964303773","CorpusId":59599816},"title":"Parameter-Efficient Transfer Learning for NLP"},{"paperId":"3558dc0a0139d6a3dd48458d207c497db027ab1b","externalIds":{"DBLP":"journals/comsur/WangJZRCH20","MAG":"2999146029","DOI":"10.1109/COMST.2020.2965856","CorpusId":210877142},"title":"Thirty Years of Machine Learning: The Road to Pareto-Optimal Wireless Networks"},{"paperId":"bbabd8a25260bf2413befcd756077efa81b1c618","externalIds":{"MAG":"2903470619","DBLP":"journals/corr/abs-1812-00564","ArXiv":"1812.00564","CorpusId":54439509},"title":"Split learning for health: Distributed deep learning without sharing raw patient data"},{"paperId":"d79a26226393f687ddbc375e32055b40b8ad8d38","externalIds":{"MAG":"2991040477","DBLP":"conf/nips/HuangCBFCCLNLWC19","CorpusId":53670168},"title":"GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism"},{"paperId":"5a445b322e87b5de04a06e665a65935b528cd180","externalIds":{"MAG":"2963209930","ArXiv":"1810.06060","DBLP":"journals/corr/abs-1810-06060","DOI":"10.1016/J.JNCA.2018.05.003","CorpusId":49675958},"title":"Distributed learning of deep neural network over multiple agents"},{"paperId":"bf8fe437f779f2098f9af82b534aa51dc9edb06f","externalIds":{"ACL":"W18-6301","ArXiv":"1806.00187","MAG":"2806311723","DBLP":"journals/corr/abs-1806-00187","DOI":"10.18653/v1/W18-6301","CorpusId":44131019},"title":"Scaling Neural Machine Translation"},{"paperId":"9a7228ce42d5cc0f2dfb676155ec0cf570f83f9b","externalIds":{"DBLP":"journals/tii/LiOD18","MAG":"2805454539","DOI":"10.1109/TII.2018.2842821","CorpusId":52931090},"title":"Deep Learning for Smart Industry: Efficient Manufacture Inspection System With Fog Computing"},{"paperId":"1ee6f6c17300e2090a17f2a4d364ea52652d35db","externalIds":{"MAG":"2761695036","DBLP":"journals/cm/Seetharam18","DOI":"10.1109/MCOM.2017.1700184","CorpusId":3386550},"title":"On Caching and Routing in Information-Centric Networks"},{"paperId":"267d7e2b1398ae3508fcee19027c0d98e272519c","externalIds":{"MAG":"2678047256","DBLP":"journals/computer/Ananthanarayanan17","DOI":"10.1109/MC.2017.3641638","CorpusId":206449115},"title":"Real-Time Video Analytics: The Killer App for Edge Computing"},{"paperId":"531a7f2c659787165df4fd5b4580590b953448e4","externalIds":{"MAG":"2963912046","ACL":"W17-5525","DBLP":"conf/sigdial/NovikovaDR17","ArXiv":"1706.09254","DOI":"10.18653/v1/W17-5525","CorpusId":19662556},"title":"The E2E Dataset: New Challenges For End-to-End Generation"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"c70e96e4e779a327f48193a91ff970bff6c71715","externalIds":{"DBLP":"conf/icdcs/CaoXAS17","MAG":"2735723457","DOI":"10.1109/ICDCS.2017.325","CorpusId":4766044},"title":"EdgeOS_H: A Home Operating System for Internet of Everything"},{"paperId":"773d5ddc414424a8948446ddaa5275b944f50891","externalIds":{"ArXiv":"1705.07565","DBLP":"journals/corr/DongCP17","MAG":"2618305643","CorpusId":5750817},"title":"Learning to Prune Deep Neural Networks via Layer-wise Optimal Brain Surgeon"},{"paperId":"b7118f8a54124b8ee1b381fe1df042b272d59cb0","externalIds":{"DBLP":"conf/isit/TandonS16","MAG":"2508764403","DOI":"10.1109/ISIT.2016.7541655","CorpusId":10715659},"title":"Cloud-aided wireless networks with edge caching: Fundamental latency trade-offs in fog Radio Access Networks"},{"paperId":"1518039b5001f1836565215eb047526b3ac7f462","externalIds":{"DBLP":"conf/acl/SennrichHB16a","ACL":"P16-1162","MAG":"1816313093","ArXiv":"1508.07909","DOI":"10.18653/v1/P16-1162","CorpusId":1114678},"title":"Neural Machine Translation of Rare Words with Subword Units"},{"paperId":"0c908739fbff75f03469d13d4a1a07de3414ee19","externalIds":{"ArXiv":"1503.02531","MAG":"1821462560","DBLP":"journals/corr/HintonVD15","CorpusId":7200347},"title":"Distilling the Knowledge in a Neural Network"},{"paperId":"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0","externalIds":{"MAG":"1895577753","DBLP":"journals/corr/VinyalsTBE14","ArXiv":"1411.4555","DOI":"10.1109/CVPR.2015.7298935","CorpusId":1169492},"title":"Show and tell: A neural image caption generator"},{"paperId":"6fde110e1c92f4e78db3aed1164da402b4a078b5","externalIds":{"MAG":"2017336596","DBLP":"conf/icc/GuWHSZ14","DOI":"10.1109/ICC.2014.6883723","CorpusId":5791707},"title":"Distributed cache replacement for caching-enable base stations in cellular networks"},{"paperId":"5604ab4a2750395327f78af6f6f0c5a035cf7933","externalIds":{"MAG":"2122642161","DBLP":"journals/comsur/XylomenosVSFTVKP14","DOI":"10.1109/SURV.2013.070813.00063","CorpusId":6645760},"title":"A Survey of Information-Centric Networking Research"},{"paperId":"5d6e79bd98a57fcfcdc3d9658b28f619fa95aad9","externalIds":{"MAG":"2088223436","ArXiv":"1405.6286","DBLP":"conf/isit/PoularakisT13","DOI":"10.1109/ISIT.2013.6620380","CorpusId":15347590},"title":"Exploiting user mobility for wireless content delivery"},{"paperId":"ed6262b569c0a62c51d941228c54f34e563af022","externalIds":{"DBLP":"conf/icassp/SchusterN12","MAG":"2121879602","DOI":"10.1109/ICASSP.2012.6289079","CorpusId":22320655},"title":"Japanese and Korean voice search"},{"paperId":"5cdcb356ab6c533fd2fbc9df8b136ce17ee7035d","externalIds":{"MAG":"2003117117","PubMedCentral":"2952804","DOI":"10.1155/2010/628086","CorpusId":8098762,"PubMed":"20976301"},"title":"Analysis of QoS Requirements for e-Health Services and Mapping to Evolved Packet System QoS Classes"},{"paperId":"6b42da07552dd40974f793f8da1ca6521f1e49e8","externalIds":{"DBLP":"journals/pervasive/SatyanarayananBCD09","MAG":"2135099885","DOI":"10.1109/MPRV.2009.82","CorpusId":261081944},"title":"The Case for VM-Based Cloudlets in Mobile Computing"},{"paperId":"2e9d221c206e9503ceb452302d68d10e293f2a10","externalIds":{"DBLP":"journals/neco/HochreiterS97","MAG":"2064675550","DOI":"10.1162/neco.1997.9.8.1735","CorpusId":1915014,"PubMed":"9377276"},"title":"Long Short-Term Memory"},{"paperId":"20b844e395355b40fa5940c61362ec40e56027aa","externalIds":{"DOI":"10.1016/S0140-6736(95)92525-2","CorpusId":2878979,"PubMed":"7491032"},"title":"Neural networks"},{"paperId":"1aa9c0045f1fe8c79cce03c7c14ef4b4643a21f8","externalIds":{"MAG":"46679369","CorpusId":59804030},"title":"A new algorithm for data compression"},{"paperId":"d9e43027a16d01ad9409703eb2237f1832c24014","externalIds":{"DBLP":"journals/corr/abs-2401-14351","DOI":"10.48550/arXiv.2401.14351","CorpusId":267211790},"title":"ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models"},{"paperId":"db8dfec91786786dc6361f67886d6b0879a76aa4","externalIds":{"DBLP":"conf/coling/ZhangGZFDH24","ACL":"2024.lrec-main.890","CorpusId":269804469},"title":"LA-UCL: LLM-Augmented Unsupervised Contrastive Learning Framework for Few-Shot Text Classification"},{"paperId":"44c417c96fbe7cf3bf280f1a53e08aa810a863a8","externalIds":{"DBLP":"journals/corr/abs-2404-09134","DOI":"10.48550/arXiv.2404.09134","CorpusId":282403211},"title":"Interactive Generative AI Agents for Satellite Networks through a Mixture of Experts Transmission"},{"paperId":"2b7c9fd2a94deaee3e7e56dc57bab0bd39d3683c","externalIds":{"DBLP":"journals/corr/abs-2306-00978","DOI":"10.48550/arXiv.2306.00978","CorpusId":271271084},"title":"AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration"},{"paperId":"dd6edb5c809c5e7302013ef0cafe4682eb41e831","externalIds":{"DBLP":"journals/tifs/YangCHBWD23","DOI":"10.1109/TIFS.2023.3287072","CorpusId":259476131},"title":"Efficient Privacy-Preserving Inference Outsourcing for Convolutional Neural Networks"},{"paperId":"350eabddafd8c22a34375b838db97f90109a7967","externalIds":{"DBLP":"journals/corr/abs-2311-01483","DOI":"10.48550/arXiv.2311.01483","CorpusId":271461446},"title":"FedSN: A General Federated Learning Framework over LEO Satellite Networks"},{"paperId":"7e7d7799ffb0ad44169dbeab2326a150830db1c3","externalIds":{"DBLP":"journals/corr/abs-2306-13840","DOI":"10.48550/arXiv.2306.13840","CorpusId":259252412},"title":"Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data"},{"paperId":"dc7b27b0a1d891e16f80dd9b8eec0aa8baf95b36","externalIds":{"DBLP":"journals/corr/abs-2308-14352","DOI":"10.48550/arXiv.2308.14352","CorpusId":283081399},"title":"EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models"},{"paperId":"971e8f37e3f9ffe90c68c91fbeb590f05a3ba4d0","externalIds":{"DBLP":"journals/corr/abs-2311-11094","DOI":"10.48550/arXiv.2311.11094","CorpusId":282404139},"title":"User-Centric Interactive AI for Distributed Diffusion Model-based AI-Generated Content"},{"paperId":"e166c97709a8c5eddc03ec0391f45e30701521c4","externalIds":{"DBLP":"journals/corr/abs-2212-10025","DOI":"10.48550/arXiv.2212.10025","CorpusId":260566902},"title":"When Federated Learning Meets Pre-trained Language Models' Parameter-Efficient Tuning Methods"},{"paperId":"53d8b356551a2361020a948f64454a6d599af69f","externalIds":{"DBLP":"conf/acl/LiL20","ACL":"2021.acl-long.353","ArXiv":"2101.00190","DOI":"10.18653/v1/2021.acl-long.353","CorpusId":230433941},"title":"Prefix-Tuning: Optimizing Continuous Prompts for Generation"},{"paperId":"fc6ae6b382a218f774f3eb778d03b3b56a245630","externalIds":{"DBLP":"conf/uss/Wu000D20","MAG":"3019478474","CorpusId":219022694},"title":"Liveness is Not Enough: Enhancing Fingerprint Authentication with Behavioral Biometrics to Defeat Puppet Attacks"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":"4f8d648c52edf74e41b0996128aa536e13cc7e82","externalIds":{"DBLP":"journals/ijsc/HaoZM16","DOI":"10.1142/S1793351X16500045","CorpusId":1779661},"title":"Deep Learning"}]}