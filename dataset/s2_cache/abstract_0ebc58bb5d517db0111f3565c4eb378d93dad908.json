{"abstract":"When video is recorded in a studio, sound is clear of external noises and unrelated sounds. However, most video is not shot at studios. Voice of people shot in family events is mixed with music and with other voices. Video conferences from home or office are often disturbed by other people, ringing phones, or barking dogs. TV reporting from city streets is mixed with traffic noise, sound of winds, etc. We propose to use visual information of face and mouth movements as seen in the video to enhance the voice of a speaker, and in particular eliminate sounds that do not relate to the face movements. The method is based on spectral information of speech as predicted by a video-to-speech system. Without visual information, the task of isolating a specific human voice while filtering out other voices or background noise is known as the cocktail party problem. This problem is solvable when N voices are recorded by N microphones. We address the challenging single microphone case, and show that visual information of the speaker can help solve this problem."}