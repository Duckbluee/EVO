{"references":[{"paperId":"3abced3a5a9702e1709a4bc7a7a78a5aed54f255","externalIds":{"DBLP":"conf/aaai/0004ZWZZ025","ArXiv":"2412.08038","DOI":"10.48550/arXiv.2412.08038","CorpusId":274638136},"title":"Bootstrapping Heterogeneous Graph Representation Learning via Large Language Models: A Generalized Approach"},{"paperId":"e0ba74fa1af77e59e588b0f6e601ab9236f22cd5","externalIds":{"DBLP":"conf/nips/NiuP0L24","ArXiv":"2410.10341","DOI":"10.48550/arXiv.2410.10341","CorpusId":273345569},"title":"Replay-and-Forget-Free Graph Class-Incremental Learning: A Task Profiling and Prompting Approach"},{"paperId":"286e5c6063ec7a490a6b8493b7d86817dcd620f3","externalIds":{"DBLP":"journals/corr/abs-2409-19667","ArXiv":"2409.19667","DOI":"10.48550/arXiv.2409.19667","CorpusId":272986925},"title":"Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models"},{"paperId":"3ba86f9723c7f1185c05a38231b4a2d3765e6a3d","externalIds":{"DBLP":"journals/corr/abs-2408-14512","ArXiv":"2408.14512","DOI":"10.48550/arXiv.2408.14512","CorpusId":271963116},"title":"LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with LLM Token Embeddings"},{"paperId":"abe7c1092bca538c509d3c06e4eceb924b445404","externalIds":{"DBLP":"journals/corr/abs-2408-12594","ArXiv":"2408.12594","DOI":"10.1145/3690624.3709219","CorpusId":271924424},"title":"Non-Homophilic Graph Pre-Training and Prompt Learning"},{"paperId":"cefee18a6e90e747b94dc25e71993cd0bcdbecbe","externalIds":{"ArXiv":"2408.08685","DBLP":"journals/corr/abs-2408-08685","DOI":"10.1145/3690624.3709256","CorpusId":271892090},"title":"Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?"},{"paperId":"02487e9dfefdcb667be4dc160780321555662a2e","externalIds":{"ArXiv":"2406.10310","DBLP":"conf/nips/LiGZLLH00Z24","DOI":"10.48550/arXiv.2406.10310","CorpusId":270560327},"title":"TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs"},{"paperId":"ca9f5b3bf0f54ad97513e6175b30497873670fed","externalIds":{"ArXiv":"2405.21060","DBLP":"conf/icml/DaoG24","CorpusId":270199762},"title":"Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality"},{"paperId":"31183ae2c92e66df10f2fabbb38339e637d578a7","externalIds":{"DBLP":"conf/nips/LeiHRW24","ArXiv":"2405.16405","DOI":"10.48550/arXiv.2405.16405","CorpusId":270062846},"title":"Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level"},{"paperId":"95887f9a63b369e436c570487bce1148285cd290","externalIds":{"DBLP":"conf/www/WangLDLW24","DOI":"10.1145/3589334.3645571","CorpusId":269707414},"title":"Exploring Neural Scaling Law and Data Pruning Methods For Node Classification on Large-scale Graphs"},{"paperId":"557f69ec4861c60c609a1e491195bf657cd7a4a1","externalIds":{"ArXiv":"2403.19063","DBLP":"conf/sigir/YangLYLWPY24","DOI":"10.1145/3626772.3657715","CorpusId":268733217},"title":"Instruction-based Hypergraph Pretraining"},{"paperId":"feca496290013a250adb2c72ecd20c8d5fd30f24","externalIds":{"DBLP":"conf/emnlp/XiaK024","ArXiv":"2403.01121","DOI":"10.48550/arXiv.2403.01121","CorpusId":268230376},"title":"OpenGraph: Towards Open Graph Foundation Models"},{"paperId":"356842f9c2e1c0abd4424d82d933e28a749c9b20","externalIds":{"DBLP":"journals/corr/abs-2402-16029","ArXiv":"2402.16029","DOI":"10.48550/arXiv.2402.16029","CorpusId":267938586},"title":"GraphWiz: An Instruction-Following Language Model for Graph Problems"},{"paperId":"7ef730e97d3fffd7603fc008431b4c35e06fea8f","externalIds":{"DBLP":"conf/kdd/TangY0SXY024","ArXiv":"2402.16024","DOI":"10.1145/3637528.3671987","CorpusId":267938438},"title":"HiGPT: Heterogeneous Graph Language Model"},{"paperId":"38f4f27bfdc6cdc4c72d714a097541f1e6ca98f2","externalIds":{"DBLP":"journals/corr/abs-2402-13556","ArXiv":"2402.13556","DOI":"10.1145/3589334.3645620","CorpusId":267770299},"title":"Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective"},{"paperId":"62081710ffd320cffb9ea9c4b3e03a31e68b120a","externalIds":{"DBLP":"journals/corr/abs-2402-12984","ArXiv":"2402.12984","DOI":"10.1145/3589334.3645627","CorpusId":267759791},"title":"Can GNN be Good Adapter for LLMs?"},{"paperId":"71d1ac7b09f833d343a966f712c6c64c1120d8e6","externalIds":{"DBLP":"journals/corr/abs-2402-12161","ArXiv":"2402.12161","DOI":"10.1145/3589334.3645703","CorpusId":267751269},"title":"Endowing Pre-trained Graph Models with Provable Fairness"},{"paperId":"0caf98b5f5ff8e9476d55027473e15fca54292ff","externalIds":{"DBLP":"conf/kdd/ZhaoCS0L24","ArXiv":"2402.09834","DOI":"10.1145/3637528.3671913","CorpusId":267682263},"title":"All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining"},{"paperId":"f59089c0b0140eb5254777088b1a4b772af2f207","externalIds":{"DBLP":"journals/corr/abs-2402-10359","ArXiv":"2402.10359","DOI":"10.1145/3589335.3651476","CorpusId":267740248},"title":"Can we Soft Prompt LLMs for Graph Learning Tasks?"},{"paperId":"d299a6b26e9ee23d0337a1d1a896fc1c847f5a46","externalIds":{"DBLP":"conf/acl/WangWH00M24","ArXiv":"2402.08785","DOI":"10.48550/arXiv.2402.08785","CorpusId":267657659},"title":"InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment"},{"paperId":"a41d4a3b005c8ec4f821e6ee96672d930ca9596c","externalIds":{"DBLP":"journals/corr/abs-2402-07630","ArXiv":"2402.07630","DOI":"10.48550/arXiv.2402.07630","CorpusId":267626823},"title":"G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering"},{"paperId":"b5c0c18ec3b6199f0f7a6d6b4756d9c0b2788492","externalIds":{"ArXiv":"2402.07309","DBLP":"conf/emnlp/BazagaLM24","DOI":"10.48550/arXiv.2402.07309","CorpusId":267626887},"title":"HyperBERT: Mixing Hypergraph-Aware Layers with Language Models for Node Classification on Text-Attributed Hypergraphs"},{"paperId":"b90ea57bf10f7ed1d50dd051604d68fb892c5633","externalIds":{"DBLP":"journals/corr/abs-2402-07197","ArXiv":"2402.07197","DOI":"10.1145/3589334.3645682","CorpusId":267627926},"title":"GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks"},{"paperId":"13f81979372850d9ab9d386c35bb00b4cc0e35f1","externalIds":{"DBLP":"conf/icml/MaoCT000S0T24","ArXiv":"2402.02216","CorpusId":267412744},"title":"Position: Graph Foundation Models Are Already Here"},{"paperId":"50047a529e997210353d94ddec5ee12037c6dab5","externalIds":{"DBLP":"conf/ijcai/ZhuWST24","ArXiv":"2401.15569","DOI":"10.48550/arXiv.2401.15569","CorpusId":267312085},"title":"Efficient Tuning and Inference for Large Language Models on Textual Graphs"},{"paperId":"2d0623c2d05be3ecc88cf0852aa769c89d0aaa68","externalIds":{"DBLP":"conf/aaai/SunHWW0Y24","ArXiv":"2401.01232","DOI":"10.48550/arXiv.2401.01232","CorpusId":266725451},"title":"Motif-aware Riemannian Graph Neural Network with Generative-Contrastive Learning"},{"paperId":"e9273e5c14343c0b34010bbf2e2aada57d5f6bcf","externalIds":{"DBLP":"journals/corr/abs-2312-14670","ArXiv":"2312.14670","DOI":"10.48550/arXiv.2312.14670","CorpusId":266521610},"title":"Zero-shot Causal Graph Extrapolation from Text via LLMs"},{"paperId":"5714916191ead5a581c6bb0258bb380e005f5d24","externalIds":{"ArXiv":"2312.13583","DBLP":"journals/corr/abs-2312-13583","DOI":"10.48550/arXiv.2312.13583","CorpusId":266435537},"title":"Fine-tuning Graph Neural Networks by Preserving Graph Generative Patterns"},{"paperId":"0e9063c34165868df384f1d602afc1fea9857a1e","externalIds":{"DBLP":"conf/aaai/Yu0L024","ArXiv":"2312.01878","DOI":"10.48550/arXiv.2312.01878","CorpusId":265609471},"title":"HGPROMPT: Bridging Homogeneous and Heterogeneous Graphs for Few-shot Prompt Learning"},{"paperId":"d2ecb191cb037c96d4c2ad0a47a49ba82b701285","externalIds":{"DBLP":"conf/nips/TanZL0023","CorpusId":265216566,"PubMed":"39130614"},"title":"WalkLM: A Uniform Language Model Fine-tuning Framework for Attributed Graph Embedding"},{"paperId":"92266bd67b15fe46aebb790a33ea5b1f66aa98d8","externalIds":{"ArXiv":"2312.03731","DBLP":"conf/www/YuZ0024","DOI":"10.1145/3589334.3645423","CorpusId":266052614},"title":"MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs"},{"paperId":"ba0d462c8094272c0205b8243c11f23b9995a253","externalIds":{"DBLP":"journals/tkde/YuLFLCZ24","ArXiv":"2311.15317","DOI":"10.1109/TKDE.2024.3419109","CorpusId":265456748},"title":"Generalized Graph Prompt: Toward a Unification of Pre-Training and Downstream Tasks on Graphs"},{"paperId":"7ec393a898521e4e9a3f510be424861f5a518109","externalIds":{"DBLP":"journals/corr/abs-2311-14324","ArXiv":"2311.14324","DOI":"10.48550/arXiv.2311.14324","CorpusId":265445904},"title":"Large Language Models as Topological Structure Enhancers for Text-Attributed Graphs"},{"paperId":"4defd1fd653b9558c2749c75208056c6ad979542","externalIds":{"DBLP":"journals/corr/abs-2311-04245","ArXiv":"2311.04245","DOI":"10.48550/arXiv.2311.04245","CorpusId":265050736},"title":"GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks"},{"paperId":"5aa3b1009955ce2c8f896e0d5e94e06155ef1e43","externalIds":{"ArXiv":"2311.00423","DBLP":"journals/corr/abs-2311-00423","DOI":"10.1145/3616855.3635853","CorpusId":264832979},"title":"LLMRec: Large Language Models with Graph Augmentation for Recommendation"},{"paperId":"4829b73a47be18f73e9e8d90f3c23c8f84d0fccb","externalIds":{"ArXiv":"2310.15950","DBLP":"conf/www/RenWXSCWY024","DOI":"10.1145/3589334.3645458","CorpusId":264439548},"title":"Representation Learning with Large Language Models for Recommendation"},{"paperId":"e391d266b0d43475567f59efeaeabc884a48abd0","externalIds":{"ArXiv":"2310.13590","DBLP":"conf/emnlp/Shi0ZL023","DOI":"10.48550/arXiv.2310.13590","CorpusId":264406019},"title":"ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction"},{"paperId":"45872b94798c3125abfb185b7926689c5e767763","externalIds":{"DBLP":"conf/sigir/Tang00SSCY024","ArXiv":"2310.13023","DOI":"10.1145/3626772.3657775","CorpusId":264405943},"title":"GraphGPT: Graph Instruction Tuning for Large Language Models"},{"paperId":"25738c43c0c4788d803981eaf5d397691aba0958","externalIds":{"ArXiv":"2310.12798","DBLP":"journals/corr/abs-2310-12798","DOI":"10.48550/arXiv.2310.12798","CorpusId":264306303},"title":"MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter"},{"paperId":"c4fa9c1e53e7818ad11c9e656869c3f35b6b2c69","externalIds":{"DBLP":"journals/corr/abs-2310-12580","ArXiv":"2310.12580","DOI":"10.48550/arXiv.2310.12580","CorpusId":264305676},"title":"Pretraining Language Models with Text-Attributed Heterogeneous Graphs"},{"paperId":"cfa6abd1af69cc6bce3a549a7886c47906dfdf4a","externalIds":{"DBLP":"conf/www/YanCWYDS24","ArXiv":"2310.11730","DOI":"10.1145/3589334.3645693","CorpusId":264289256},"title":"Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation"},{"paperId":"d5f4ecbb3fc2220eed7c62ea308e4f6cba2240b5","externalIds":{"DBLP":"journals/corr/abs-2310-07298","ArXiv":"2310.07298","DOI":"10.48550/arXiv.2310.07298","CorpusId":263834989},"title":"Beyond Memorization: Violating Privacy Via Inference with Large Language Models"},{"paperId":"22cda0fa3849c8cdaca499746c5a3126dc5c1ea5","externalIds":{"DBLP":"conf/www/ZhuWSZJT24","ArXiv":"2310.07365","DOI":"10.1145/3589334.3645439","CorpusId":263834643},"title":"GraphControl: Adding Conditional Control to Universal Graph Pre-trained Models for Graph Domain Transfer Learning"},{"paperId":"6f217d984f36499d88ab8a3d89572171552e6f3f","externalIds":{"ArXiv":"2310.07641","DBLP":"journals/corr/abs-2310-07641","DOI":"10.48550/arXiv.2310.07641","CorpusId":263834884},"title":"Evaluating Large Language Models at Evaluating Instruction Following"},{"paperId":"4d1bcfb754dcd14fd312356021d9e332d3d3b18f","externalIds":{"DBLP":"journals/corr/abs-2310-04668","ArXiv":"2310.04668","DOI":"10.48550/arXiv.2310.04668","CorpusId":263829256},"title":"Label-free Node Classification on Graphs with Large Language Models (LLMS)"},{"paperId":"3784fd84b61d482b52f7ef72aac66bcb886b892b","externalIds":{"DBLP":"conf/iclr/Yu0Y24","ArXiv":"2310.03965","DOI":"10.48550/arXiv.2310.03965","CorpusId":263831197},"title":"Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models"},{"paperId":"ab22d54dd13876d25c6c8f46c40fb9ac41c61ec5","externalIds":{"DBLP":"journals/corr/abs-2310-00149","ArXiv":"2310.00149","DOI":"10.48550/arXiv.2310.00149","CorpusId":265871676},"title":"One for All: Towards Training One Graph Model for All Classification Tasks"},{"paperId":"1081b62f3eea92c87eb024ce80cb9e5d16113057","externalIds":{"DBLP":"conf/sigir/Zhu0IKF24","ArXiv":"2309.13885","DOI":"10.1145/3626772.3657978","CorpusId":260853042},"title":"TouchUp-G: Improving Feature Representation through Graph-Centric Finetuning"},{"paperId":"d00735241af700d21762d2f3ca00d920241a15a4","externalIds":{"DBLP":"journals/corr/abs-2309-01219","ArXiv":"2309.01219","DOI":"10.1162/coli.a.16","CorpusId":261530162},"title":"Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models"},{"paperId":"b4646815d5107489e7660d71e83c6584a926d280","externalIds":{"ArXiv":"2308.14522","CorpusId":261244034},"title":"Graph Meets LLMs: Towards Large Graph Models"},{"paperId":"229a37db06386459cce7b58c72fac5c97521de5d","externalIds":{"DBLP":"conf/log/ZouZLZ23","ArXiv":"2308.11978","DOI":"10.48550/arXiv.2308.11978","CorpusId":261076376},"title":"Will More Expressive Graph Neural Networks do Better on Generative Tasks?"},{"paperId":"927fc7652e033c9eb17296df087e3e6491112bb0","externalIds":{"DBLP":"journals/corr/abs-2308-11224","ArXiv":"2308.11224","DOI":"10.48550/arXiv.2308.11224","CorpusId":261064686},"title":"Evaluating Large Language Models on Graphs: Performance Insights and Comparative Analysis"},{"paperId":"306d298e2c0606f93cd01cc8cbab0852d8e8fd12","externalIds":{"DBLP":"conf/cikm/WenFLGH23","ArXiv":"2308.10028","DOI":"10.1145/3583780.3615505","CorpusId":261049251},"title":"Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks"},{"paperId":"8d65b5940a4dbed8c18e02ca35e3a9d7a14ea76b","externalIds":{"ArXiv":"2308.07134","DBLP":"conf/eacl/YeZWXZ24","ACL":"2024.findings-eacl.132","DOI":"10.18653/v1/2024.findings-eacl.132","CorpusId":260887732},"title":"Language is All a Graph Needs"},{"paperId":"2e3dcf5a5d58ac210d0d87e9f918540a8373211a","externalIds":{"DBLP":"journals/corr/abs-2308-06911","ArXiv":"2308.06911","DOI":"10.1016/j.compbiomed.2024.108073","CorpusId":260887406,"PubMed":"38359660"},"title":"GIT-Mol: A Multi-modal Large Language Model for Molecular Science with Graph, Image, and Text"},{"paperId":"d25f8c388677d287d00ca67d44ef02da2b45f2d9","externalIds":{"DBLP":"journals/corr/abs-2308-06374","ArXiv":"2308.06374","DOI":"10.48550/arXiv.2308.06374","CorpusId":260887174},"title":"Large Language Models and Knowledge Graphs: Opportunities and Challenges"},{"paperId":"da0576c2a92daa9cc5b737647d51377e15f6c527","externalIds":{"DBLP":"conf/kdd/Guo0CLSD23","DOI":"10.1145/3580305.3599244","CorpusId":260499765},"title":"A Data-centric Framework to Endow Graph Neural Networks with Out-Of-Distribution Detection Ability"},{"paperId":"84b77180228051040286423cec82b62c323a8fda","externalIds":{"ArXiv":"2307.11019","DBLP":"journals/corr/abs-2307-11019","DOI":"10.48550/arXiv.2307.11019","CorpusId":259991467},"title":"Investigating the Factual Knowledge Boundary of Large Language Models with Retrieval Augmentation"},{"paperId":"83c48aa341850af478247e3b34ba1ee1db9f1236","externalIds":{"ArXiv":"2307.10802","DBLP":"journals/corr/abs-2307-10802","DOI":"10.48550/arXiv.2307.10802","CorpusId":259991096},"title":"Meta-Transformer: A Unified Framework for Multimodal Learning"},{"paperId":"105669ec59a58fb2d4dd3021a984af33c227c5ab","externalIds":{"DBLP":"journals/sigkdd/ChenMLJWWWYFLT23","ArXiv":"2307.03393","DOI":"10.1145/3655103.3655110","CorpusId":259375824},"title":"Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs"},{"paperId":"a35f1315e91513ff0bec0c488fe175214fd9636c","externalIds":{"DBLP":"journals/corr/abs-2307-02046","ArXiv":"2307.02046","DOI":"10.1109/TKDE.2024.3392335","CorpusId":259342486},"title":"Recommender Systems in the Era of Large Language Models (LLMs)"},{"paperId":"80c698688bb4488beaceaab5c64f701a946cb7ae","externalIds":{"DBLP":"journals/corr/abs-2307-01504","ArXiv":"2307.01504","DOI":"10.1145/3580305.3599256","CorpusId":259341605},"title":"All in One: Multi-Task Prompting for Graph Neural Networks"},{"paperId":"87d3b93d74876383d1a3e603aa6e115ac0e96e37","externalIds":{"DBLP":"journals/corr/abs-2306-15902","ArXiv":"2306.15902","DOI":"10.1109/TKDE.2023.3290792","CorpusId":259275146},"title":"Individual and Structural Graph Information Bottlenecks for Out-of-Distribution Generalization"},{"paperId":"c63de70f5e4a9b36b5ca7f50cc8dac72e4a9254b","externalIds":{"DBLP":"journals/corr/abs-2306-14123","ArXiv":"2306.14123","DOI":"10.1145/3606017","CorpusId":259245951},"title":"Privacy and Fairness in Federated Learning: On the Perspective of Tradeoff"},{"paperId":"a6d3794c23626060781da0f1ff2bcdf7457b6c43","externalIds":{"DBLP":"conf/nips/WangCPXKZXXDSTA23","ArXiv":"2306.11698","DOI":"10.48550/arXiv.2306.11698","CorpusId":259202782},"title":"DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models"},{"paperId":"aeb95aef649c6d8d031e83960f77cd798d069a0a","externalIds":{"DBLP":"conf/icml/ZhangHXWYH23","ArXiv":"2306.10683","DOI":"10.48550/arXiv.2306.10683","CorpusId":259203453},"title":"Spatial-Temporal Graph Learning with Adversarial Contrastive Adaptation"},{"paperId":"9e8b7b0d4c628c12b6a65ab56ac5f33a35eff2e6","externalIds":{"ArXiv":"2306.08302","DBLP":"journals/corr/abs-2306-08302","DOI":"10.1109/TKDE.2024.3352100","CorpusId":259165563},"title":"Unifying Large Language Models and Knowledge Graphs: A Roadmap"},{"paperId":"3090d5ef973e34e054ed520a118b2df8b16a5702","externalIds":{"DBLP":"journals/corr/abs-2306-02592","ArXiv":"2306.02592","DOI":"10.1145/3580305.3599833","CorpusId":259257650,"PubMed":"38375450"},"title":"Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help Multiple Graph Applications"},{"paperId":"5d321194696f1f75cf9da045e6022b2f20ba5b9c","externalIds":{"DBLP":"journals/corr/abs-2306-02858","ArXiv":"2306.02858","DOI":"10.48550/arXiv.2306.02858","CorpusId":259075356},"title":"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding"},{"paperId":"e94804f8df0e5a3eff6f0a278606d60dcb767d56","externalIds":{"DBLP":"journals/corr/abs-2306-01129","ArXiv":"2306.01129","DOI":"10.48550/arXiv.2306.01129","CorpusId":259064259},"title":"White-Box Transformers via Sparse Rate Reduction"},{"paperId":"2d2b05f0969568ac3fd3c2cca5df04c4136c5416","externalIds":{"DBLP":"conf/iclr/HeB0PLH24","ArXiv":"2305.19523","CorpusId":258987322},"title":"Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning"},{"paperId":"fdb361ea83c010ed0011d179567de5a1112651ac","externalIds":{"DBLP":"journals/corr/abs-2305-19713","ArXiv":"2305.19713","ACL":"2024.tacl-1.10","DOI":"10.1162/tacl_a_00639","CorpusId":258987266},"title":"Red Teaming Language Model Detectors with Language Models"},{"paperId":"119a3ed0898499fce0ce6af6958d566d82390ba5","externalIds":{"ArXiv":"2306.13089","DBLP":"conf/nips/ZhaoLMXFDKL23","DOI":"10.1101/2023.05.30.542904","CorpusId":259077070},"title":"GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning"},{"paperId":"ce913026f693101e54d3ab9152e107034d81fce1","externalIds":{"DBLP":"journals/tmlr/LiangBLTSYZNWKN23","DOI":"10.1111/nyas.15007","CorpusId":253553585,"PubMed":"37230490"},"title":"Holistic Evaluation of Language Models"},{"paperId":"1cf13ca3244f78c3bbba49bfe19836b671ff3635","externalIds":{"ArXiv":"2305.14826","DBLP":"journals/corr/abs-2305-14826","DOI":"10.1109/ITSC57777.2023.10422572","CorpusId":258865428},"title":"Building Transportation Foundation Model via Generative Graph Transformer"},{"paperId":"2b967d82b25088566980aaaf5a7062d90b2fb14f","externalIds":{"DBLP":"journals/corr/abs-2305-15066","ArXiv":"2305.15066","CorpusId":258865990},"title":"GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking"},{"paperId":"f5c73d9e6641b018b633690102121f5605d34fb0","externalIds":{"DBLP":"conf/emnlp/YaoWT0LDC023","ArXiv":"2305.13172","DOI":"10.48550/arXiv.2305.13172","CorpusId":258833129},"title":"Editing Large Language Models: Problems, Methods, and Opportunities"},{"paperId":"02529b2666a536053a2e2940de5b28de36fd594b","externalIds":{"ArXiv":"2305.12870","DBLP":"conf/emnlp/JiangCCW23","DOI":"10.18653/v1/2023.emnlp-main.189","CorpusId":258833333},"title":"Lion: Adversarial Distillation of Proprietary Large Language Models"},{"paperId":"0088c9f4d50706c7ab71efa13bcb4b42cf2058e2","externalIds":{"DBLP":"journals/corr/abs-2305-12600","ArXiv":"2305.12600","DOI":"10.48550/arXiv.2305.12600","CorpusId":258832444},"title":"PRODIGY: Enabling In-context Learning Over Graphs"},{"paperId":"3a755f8dcc9af9304c2cbd3a00e42e66feec1d5d","externalIds":{"ArXiv":"2305.12268","DBLP":"journals/corr/abs-2305-12268","ACL":"2023.acl-long.387","DOI":"10.48550/arXiv.2305.12268","CorpusId":258832995},"title":"Patton: Language Model Pretraining on Text-Rich Networks"},{"paperId":"42a30dc5470f54ec249f25d3c31e05d7c376c8e3","externalIds":{"DBLP":"conf/nips/WangCCWZZLLZQD23","ArXiv":"2305.11175","DOI":"10.48550/arXiv.2305.11175","CorpusId":258762579},"title":"VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks"},{"paperId":"e0bc91243e4e446f6b8871b4fc40b4a413f93c73","externalIds":{"DBLP":"conf/aaai/GuiYX24","ArXiv":"2305.10329","DOI":"10.48550/arXiv.2305.10329","CorpusId":258740838},"title":"G-Adapter: Towards Structure-Aware Parameter-Efficient Transfer Learning for Graph Transformer Networks"},{"paperId":"df2beaae63e4d68ef8e762bcd4704c9f11f856d9","externalIds":{"DBLP":"journals/corr/abs-2305-10037","ArXiv":"2305.10037","DOI":"10.48550/arXiv.2305.10037","CorpusId":258740923},"title":"Can Language Models Solve Graph Problems in Natural Language?"},{"paperId":"37767c063cfb1620c51f51ae726c7e6efe05dad6","externalIds":{"DBLP":"conf/sigir/Wen023","ArXiv":"2305.03324","DOI":"10.1145/3539618.3591641","CorpusId":258547183},"title":"Augmenting Low-Resource Text Classification with Graph-Grounded Pre-training and Prompting"},{"paperId":"9febfa982ced9d4eebb4fb8082a620b2b566c976","externalIds":{"DBLP":"conf/www/YeZ0YWR23","ArXiv":"2305.03883","DOI":"10.1145/3543507.3583353","CorpusId":258333793},"title":"SINCERE: Sequential Interaction Networks representation learning on Co-Evolving RiEmannian manifolds"},{"paperId":"51484cf02592a3551f944b7c6bf94fe902c0aa66","externalIds":{"DBLP":"conf/pkdd/MavromatisIWZAMZFK23","ArXiv":"2304.10668","DOI":"10.48550/arXiv.2304.10668","CorpusId":258291779},"title":"Train Your Own GNN Teacher: Graph-Aware Distillation on Textual Graphs"},{"paperId":"cba6c4fff441a317632c6a92e4e10aba59cb0217","externalIds":{"DBLP":"conf/aaai/LiH024","ArXiv":"2304.09595","DOI":"10.1609/aaai.v38i12.29264","CorpusId":266162299},"title":"AdapterGNN: Parameter-Efficient Fine-Tuning Improves Generalization in GNNs"},{"paperId":"bb435dcd5fa7c7a7112af9adcb58f23b87ef28ac","externalIds":{"DBLP":"conf/www/HouHCLDK023","ArXiv":"2304.04779","DOI":"10.1145/3543507.3583379","CorpusId":258060208},"title":"GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner"},{"paperId":"7b97979ebc76d9709ad516ee86236f64c4950356","externalIds":{"DBLP":"journals/corr/abs-2304-02806","ArXiv":"2304.02806","DOI":"10.48550/arXiv.2304.02806","CorpusId":257985095},"title":"Graph Mixture of Experts: Learning on Large-Scale Graphs with Explicit Diversity Modeling"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"30809168fff23c852867ad359baaebfae532f0a7","externalIds":{"ArXiv":"2303.03363","DBLP":"journals/corr/abs-2303-03363","DOI":"10.48550/arXiv.2303.03363","CorpusId":257364945},"title":"Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"6155e94e5174e4c615f890c185acbe4b635dba16","externalIds":{"DBLP":"journals/corr/abs-2302-13522","ArXiv":"2302.13522","DOI":"10.1145/3580305.3599843","CorpusId":257219811},"title":"IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size of Public Graph Datasets for Deep Learning Research"},{"paperId":"1c3ddc72d39d99da8c73669155e9109c6b4e1ef4","externalIds":{"DBLP":"conf/iclr/Jin00023","ArXiv":"2302.11050","DOI":"10.48550/arXiv.2302.11050","CorpusId":257078994},"title":"Edgeformers: Graph-Empowered Transformers for Representation Learning on Textual-Edge Networks"},{"paperId":"3599a236f285af48782fc30b1341d13ec7320735","externalIds":{"ArXiv":"2302.09419","DBLP":"journals/corr/abs-2302-09419","DOI":"10.48550/arXiv.2302.09419","CorpusId":257039063},"title":"A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT"},{"paperId":"ae3d869719c15099889c02c03b922516b3b60aa0","externalIds":{"DBLP":"journals/corr/abs-2302-09210","ArXiv":"2302.09210","DOI":"10.48550/arXiv.2302.09210","CorpusId":257038384},"title":"How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation"},{"paperId":"e147cc46b7f441a68706ca53549d45e9a9843fb6","externalIds":{"DBLP":"journals/corr/abs-2302-08043","ArXiv":"2302.08043","DOI":"10.1145/3543507.3583386","CorpusId":256900867},"title":"GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks"},{"paperId":"c37d43f68f6ea15e61a03781f50f7064f7521829","externalIds":{"DBLP":"journals/tnn/TuXLZCC25","ArXiv":"2302.07524","DOI":"10.1109/TNNLS.2024.3349850","CorpusId":256868457,"PubMed":"38215316"},"title":"Revisiting Initializing Then Refining: An Incomplete and Missing Graph Imputation Network"},{"paperId":"30258c205060af5ce958dc6c9e184c9498ee48ed","externalIds":{"ArXiv":"2302.04181","DBLP":"journals/tmlr/Muller00R24","DOI":"10.48550/arXiv.2302.04181","CorpusId":256662315},"title":"Attending to Graph Transformers"},{"paperId":"3f5b31c4f7350dc88002c121aecbdc82f86eb5bb","externalIds":{"DBLP":"journals/corr/abs-2301-12597","ArXiv":"2301.12597","DOI":"10.48550/arXiv.2301.12597","CorpusId":256390509},"title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"},{"paperId":"958bb3831589246fe5b6b58cf99e3b65c58d027f","externalIds":{"DBLP":"journals/natmi/LiuNWLQLTXA23","ArXiv":"2212.10789","DOI":"10.1038/s42256-023-00759-6","CorpusId":254926709},"title":"Multi-modal molecule structureâ€“text model for text-based retrieval and editing"},{"paperId":"3fd66f10b978d44e063aa23c64cdfe98722a3812","externalIds":{"DBLP":"conf/aaai/Gong0S23","ArXiv":"2212.07035","DOI":"10.48550/arXiv.2212.07035","CorpusId":254636489},"title":"MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning"},{"paperId":"efb6899d2eeb27fbd099220146f511aeb78acfa9","externalIds":{"DBLP":"journals/corr/abs-2211-16327","ArXiv":"2211.16327","DOI":"10.48550/arXiv.2211.16327","CorpusId":254069358},"title":"On the power of foundation models"},{"paperId":"b35cf53b13065f9860faa4760279e3c164d9762c","externalIds":{"ArXiv":"2210.16484","DBLP":"conf/ijcai/Xia0DL23","DOI":"10.24963/ijcai.2023/760","CorpusId":258352439},"title":"A Systematic Survey of Chemical Pre-trained Models"},{"paperId":"8bb37e8ae7dd6fa8cab2407f63a61f697152717f","externalIds":{"ArXiv":"2210.14709","DBLP":"journals/corr/abs-2210-14709","DOI":"10.48550/arXiv.2210.14709","CorpusId":253117079},"title":"Learning on Large-scale Text-attributed Graphs via Variational Inference"},{"paperId":"85f578d2df32bdc3f42fdaa9b65a1904b680a262","externalIds":{"ArXiv":"2209.15240","DBLP":"conf/nips/FangZYWC23","CorpusId":258866085},"title":"Universal Prompt Tuning for Graph Neural Networks"},{"paperId":"1c7a4e8d9f4fcf19a5d1caa078c66ca39cb75dd2","externalIds":{"ArXiv":"2209.05481","DBLP":"journals/corr/abs-2209-05481","DOI":"10.48550/arXiv.2209.05481","CorpusId":252212175},"title":"A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language"},{"paperId":"51f98ef273a868d2db82727b339f52f19b7883f9","externalIds":{"DBLP":"journals/corr/abs-2208-09905","ArXiv":"2208.09905","DOI":"10.1145/3511808.3557393","CorpusId":251719377},"title":"MentorGNN: Deriving Curriculum for Pre-Training GNNs"},{"paperId":"e60ad3d4ed3273af6a94745689783b83f59c8b4a","externalIds":{"DBLP":"conf/kdd/SunZHWW22","DOI":"10.1145/3534678.3539249","CorpusId":251518260},"title":"GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks"},{"paperId":"5eda60d4940d4185df45c5703e103458171d465d","externalIds":{"DBLP":"journals/corr/abs-2207-02505","ArXiv":"2207.02505","DOI":"10.48550/arXiv.2207.02505","CorpusId":250311113},"title":"Pure Transformers are Powerful Graph Learners"},{"paperId":"f7a3d9bcf052f2b4ef7d59dcca4013ea11081d0f","externalIds":{"DBLP":"conf/nips/DwivediRGPWLB22","ArXiv":"2206.08164","DOI":"10.48550/arXiv.2206.08164","CorpusId":249712241},"title":"Long Range Graph Benchmark"},{"paperId":"dac3a172b504f4e33c029655e9befb3386e5f63a","externalIds":{"DBLP":"journals/corr/abs-2206-07682","ArXiv":"2206.07682","DOI":"10.48550/arXiv.2206.07682","CorpusId":249674500},"title":"Emergent Abilities of Large Language Models"},{"paperId":"277dd73bfeb5c46513ce305136b0e71fcd2a311c","externalIds":{"ArXiv":"2205.12454","DBLP":"journals/corr/abs-2205-12454","DOI":"10.48550/arXiv.2205.12454","CorpusId":249062808},"title":"Recipe for a General, Powerful, Scalable Graph Transformer"},{"paperId":"09d31d7f124a30f6a7ccbf430feee62633decc05","externalIds":{"DBLP":"journals/corr/abs-2205-11332","ArXiv":"2205.11332","DOI":"10.48550/arXiv.2205.11332","CorpusId":248987279},"title":"ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification"},{"paperId":"b161c4aaddd2983a9d4d5a240bd5ffa84b36c4e7","externalIds":{"DBLP":"journals/corr/abs-2205-10803","ArXiv":"2205.10803","DOI":"10.1145/3534678.3539321","CorpusId":248987361},"title":"GraphMAE: Self-Supervised Masked Graph Autoencoders"},{"paperId":"5445c21f471938a495ba7459fc8e3662d9a4b1eb","externalIds":{"DBLP":"conf/kdd/JinZZ023","ArXiv":"2205.10282","DOI":"10.1145/3580305.3599376","CorpusId":259076296},"title":"Heterformer: Transformer-based Deep Node Representation Learning on Heterogeneous Text-Rich Networks"},{"paperId":"246c97ebe5ebd13603be168515cd5f5a347e7e0a","externalIds":{"ArXiv":"2204.03080","DBLP":"journals/corr/abs-2204-03080","DOI":"10.48550/arXiv.2204.03080","CorpusId":248006345},"title":"Graph Neural Networks Designed for Different Graph Types: A Survey"},{"paperId":"f2b0869b17bace854d73c19b449e3f88b9fed82e","externalIds":{"DBLP":"conf/acl/LiLSDSLJJL22","ACL":"2022.findings-acl.136","ArXiv":"2203.16747","DOI":"10.48550/arXiv.2203.16747","CorpusId":247839380},"title":"How Pre-trained Language Models Capture Factual Knowledge? A Causal-Inspired Analysis"},{"paperId":"6e25c608be17fc5c7246a486f3cb27cb3d6c0378","externalIds":{"DBLP":"journals/corr/abs-2203-12949","ArXiv":"2203.12949","DOI":"10.1109/TPAMI.2022.3161804","CorpusId":247628030,"PubMed":"35324433"},"title":"Duality-Induced Regularizer for Semantic Matching Knowledge Graph Embeddings"},{"paperId":"2ef9d47cf3249e4a3e26480345b06692dab60fec","externalIds":{"DBLP":"journals/pami/LianCSLT23","ArXiv":"2203.02177","DOI":"10.1109/TPAMI.2023.3234553","CorpusId":247244956,"PubMed":"37018613"},"title":"GCNet: Graph Completion Network for Incomplete Multimodal Learning in Conversation"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"9163e0003cc7a431da4be85a957f9ac415849a7e","externalIds":{"DBLP":"journals/pami/LuCCY24","ArXiv":"2203.00387","DOI":"10.1109/TPAMI.2024.3395804","CorpusId":247187728,"PubMed":"38717889"},"title":"Motion-Aware Dynamic Graph Neural Network for Video Compressive Sensing"},{"paperId":"4f0925684db82985f9c48566065d4ead5e00a16b","externalIds":{"DBLP":"journals/corr/abs-2202-08816","ArXiv":"2202.08816","DOI":"10.1145/3485447.3511948","CorpusId":246904359},"title":"Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning"},{"paperId":"ea0e4a9778e33b7f8e7b3246d63071330950995a","externalIds":{"DBLP":"conf/icml/ChenOB22","ArXiv":"2202.03036","CorpusId":246634635},"title":"Structure-Aware Transformer for Graph Representation Learning"},{"paperId":"355ca47b5896f974f8187470318794b14cb0a3ab","externalIds":{"DOI":"10.1109/tpami.2021.3129857","CorpusId":245860497},"title":"Guest Editorial: Non-Euclidean Machine Learning"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"be8e58320203a92bfacc1a1f95f6e65f3ee4fa5c","externalIds":{"DBLP":"journals/csur/ZhangSLZS24","ArXiv":"2201.05337","DOI":"10.1145/3617680","CorpusId":245986550},"title":"A Survey of Controllable Text Generation Using Transformer-based Pre-trained Language Models"},{"paperId":"002c58077a1f1b296468b117230a1199e91f35c2","externalIds":{"ArXiv":"2201.03514","DBLP":"conf/icml/SunSQHQ22","CorpusId":245836882},"title":"Black-Box Tuning for Language-Model-as-a-Service"},{"paperId":"745e5ea4223575d460e3c7422b04d7c06ce01b3c","externalIds":{"ArXiv":"2112.05393","DBLP":"journals/corr/abs-2112-05393","DOI":"10.1609/aaai.v36i4.20333","CorpusId":245117650},"title":"A Self-supervised Mixed-curvature Graph Neural Network"},{"paperId":"4755b49e44a453666022ac47a0706802aed8ec94","externalIds":{"ArXiv":"2111.15367","DBLP":"journals/corr/abs-2111-15367","DOI":"10.6339/22-jds1047","CorpusId":244729791},"title":"A Review on Graph Neural Network Methods in Financial Applications"},{"paperId":"054f789db0e32ba2c6bda1d0029f35ea4b5bff2c","externalIds":{"ArXiv":"2111.10657","DBLP":"journals/pami/FanWSCW24","DOI":"10.1109/TPAMI.2023.3321097","CorpusId":244478202,"PubMed":"37782581"},"title":"Generalizing Graph Neural Networks on Out-of-Distribution Graphs"},{"paperId":"09f2b7eaa20c98c7668885ff5276580734100fe5","externalIds":{"DBLP":"journals/tnn/ZhuJLL23","DOI":"10.1109/TNNLS.2021.3122899","CorpusId":244131660,"PubMed":"34780333"},"title":"Cross-Domain Graph Convolutions for Adversarial Unsupervised Domain Adaptation"},{"paperId":"8436897e713c2242d6291df9a6a33c1544d4dd39","externalIds":{"DBLP":"journals/corr/abs-2111-02840","ArXiv":"2111.02840","CorpusId":242757097},"title":"Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models"},{"paperId":"259cbc1492c51d985bdafb67e48fa170471ee446","externalIds":{"DBLP":"conf/iclr/ChienCHYZMD22","ArXiv":"2111.00064","CorpusId":240354406},"title":"Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction"},{"paperId":"cb8dcaf8e5fe7256577c6bc83e11dd64d8f3ae31","externalIds":{"PubMedCentral":"9163040","ArXiv":"2110.14378","DOI":"10.1038/s41467-022-30761-2","CorpusId":249314857,"PubMed":"35655064"},"title":"Towards artificial general intelligence via a multimodal foundation model"},{"paperId":"06487c52f923b3123f9fddcc6f611bf39d593bd6","externalIds":{"DBLP":"conf/cikm/JiangL0S21","DOI":"10.1145/3459637.3482332","CorpusId":240230682},"title":"Contrastive Pre-Training of GNNs on Heterogeneous Graphs"},{"paperId":"b8f816e23ff40d6afabccca2ee4770087ef0ef57","externalIds":{"DBLP":"conf/iclr/LiuWLLGT22","ArXiv":"2110.07728","CorpusId":239009574},"title":"Pre-training Molecular Graph Representation with 3D Geometry"},{"paperId":"3b2f5884e8199544375ddcdb4fa58f44df0b1a7e","externalIds":{"DBLP":"conf/nips/WangLSY21","ArXiv":"2109.14285","CorpusId":238215193},"title":"Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration"},{"paperId":"cddf40e579a596d0110b260313adf43470617c4c","externalIds":{"DBLP":"journals/corr/abs-2109-02846","ArXiv":"2109.02846","ACL":"2021.emnlp-demo.21","DOI":"10.18653/v1/2021.emnlp-demo.21","CorpusId":237431340},"title":"Datasets: A Community Library for Natural Language Processing"},{"paperId":"76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2","externalIds":{"DBLP":"journals/corr/abs-2108-07258","ArXiv":"2108.07258","CorpusId":237091588},"title":"On the Opportunities and Risks of Foundation Models"},{"paperId":"64a5b04b2dd6c1a80ba1201b323eea10f0674ba6","externalIds":{"DBLP":"conf/kdd/JiangJFSLW21","DOI":"10.1145/3447548.3467396","CorpusId":235667327},"title":"Pre-training on Large-Scale Heterogeneous Graph"},{"paperId":"28692beece311a90f5fa1ca2ec9d0c2ce293d069","externalIds":{"DBLP":"journals/csur/LiuYFJHN23","ArXiv":"2107.13586","DOI":"10.1145/3560815","CorpusId":236493269},"title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"},{"paperId":"0f8da99b664f3e2b76b659157ccf2d9b11ec84ab","externalIds":{"MAG":"3195716092","DOI":"10.2307/j.ctv1vtz7hp","CorpusId":242758479},"title":"Attending"},{"paperId":"5863d7b35ea317c19f707376978ef1cc53e3534c","externalIds":{"DBLP":"conf/nips/KreuzerBHLT21","ArXiv":"2106.03893","CorpusId":235368041},"title":"Rethinking Graph Transformers with Spectral Attention"},{"paperId":"a1fd9d031c77b7476c3bcb26ec169977584857f7","externalIds":{"DBLP":"conf/kdd/SunXWCZ21","ArXiv":"2106.04509","DOI":"10.1145/3447548.3467186","CorpusId":236980131,"PubMed":"35571558"},"title":"MoCL: Data-driven Molecular Fingerprint via Knowledge-aware Contrastive Learning from Molecular Graph"},{"paperId":"6245d63e6e46f7ada14df99b6220e97055545e67","externalIds":{"DBLP":"journals/pami/ZhangXJWZ22","ArXiv":"2106.04054","DOI":"10.1109/TPAMI.2021.3083269","CorpusId":235202388,"PubMed":"34033532"},"title":"Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation"},{"paperId":"2d00798b8a7d979c925901e9faa5fe4360030ca2","externalIds":{"DBLP":"journals/tkde/WuLTGL23","ArXiv":"2105.07342","DOI":"10.1109/TKDE.2021.3131584","CorpusId":238215156},"title":"Self-Supervised Learning on Graphs: Contrastive, Generative, or Predictive"},{"paperId":"bf713a9595edc9f8c4d240a08f2b5b01efbf1eb2","externalIds":{"ArXiv":"2105.02605","DBLP":"conf/nips/YangLXLLASSX21","CorpusId":238227259},"title":"GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph"},{"paperId":"ffdbd7f0b03b85747b001b4734d5ee31b5229aa4","externalIds":{"DBLP":"journals/corr/abs-2104-08691","ArXiv":"2104.08691","ACL":"2021.emnlp-main.243","DOI":"10.18653/v1/2021.emnlp-main.243","CorpusId":233296808},"title":"The Power of Scale for Parameter-Efficient Prompt Tuning"},{"paperId":"7b99c51d562e33309a46601c846abbe72a65c6a4","externalIds":{"DBLP":"conf/emnlp/PothPRG21","ArXiv":"2104.08247","ACL":"2021.emnlp-main.827","DOI":"10.18653/v1/2021.emnlp-main.827","CorpusId":233289699},"title":"What to Pre-Train on? Efficient Intermediate Task Selection"},{"paperId":"38fdd7d958708e124fd2bf65771fe5151b9ff03b","externalIds":{"DBLP":"conf/www/0002LS21","ArXiv":"2103.02885","DOI":"10.1145/3442381.3450068","CorpusId":232110804},"title":"Extract the Knowledge of Graph Neural Networks and Go Beyond it: An Effective Knowledge Distillation Framework"},{"paperId":"e259ee075998eedc0b0c91c17769bf9dffeba46f","externalIds":{"DBLP":"journals/corr/abs-2103-00111","ArXiv":"2103.00111","DOI":"10.1109/TKDE.2022.3172903","CorpusId":232076112},"title":"Graph Self-Supervised Learning: A Survey"},{"paperId":"7dee0821e4b0ece2972d4cedfbe31785a05dba37","externalIds":{"DBLP":"journals/tnn/SongYXK23","ArXiv":"2102.13303","DOI":"10.1109/TNNLS.2022.3155478","CorpusId":232068677,"PubMed":"35302941"},"title":"Graph-Based Semi-Supervised Learning: A Comprehensive Review"},{"paperId":"8d68eae4068fca5ae3e9660c2a87857c89d30f73","externalIds":{"MAG":"3129850062","DBLP":"journals/corr/abs-2102-10757","ArXiv":"2102.10757","DOI":"10.1109/TPAMI.2022.3170559","CorpusId":231985905,"PubMed":"35476575"},"title":"Self-Supervised Learning of Graph Neural Networks: A Unified Review"},{"paperId":"5bf57b615bfce122792295fd7a4e89d230787ccc","externalIds":{"PubMedCentral":"9163103","ArXiv":"2102.04925","DBLP":"journals/corr/abs-2102-04925","DOI":"10.1038/s41467-022-30714-9","CorpusId":231855559,"PubMed":"35654792"},"title":"A federated graph neural network framework for privacy-preserving personalization"},{"paperId":"4dc3c61426a3332238ea0feb23f2113a96aef0d4","externalIds":{"DBLP":"conf/nips/FatemiAK21","ArXiv":"2102.05034","CorpusId":231855665},"title":"SLAPS: Self-Supervision Improves Structure Learning for Graph Neural Networks"},{"paperId":"bad3534cc797606d1fe3cb09713407783e77cac4","externalIds":{"ArXiv":"2101.11174","DBLP":"journals/eswa/JiangL22","DOI":"10.1016/j.eswa.2022.117921","CorpusId":231718752},"title":"Graph Neural Network for Traffic Forecasting: A Survey"},{"paperId":"a50f37cdd0614567ef52ffa63c70285d97630ce4","externalIds":{"MAG":"3110901318","DOI":"10.1016/j.ddtec.2020.11.009","CorpusId":230528669,"PubMed":"34895648"},"title":"A compact review of molecular property prediction with graph neural networks."},{"paperId":"0a69c8815536a657668e089e3281ff2e963d947a","externalIds":{"MAG":"3106539141","DBLP":"journals/corr/abs-2011-08843","ArXiv":"2011.08843","CorpusId":226975970},"title":"Design Space for Graph Neural Networks"},{"paperId":"9df9810cc43719290f2796aa298f386c74228150","externalIds":{"MAG":"3101369110","DBLP":"journals/bib/MuzioOB21","PubMedCentral":"7986589","DOI":"10.1093/bib/bbaa257","CorpusId":226298045,"PubMed":"33169146"},"title":"Biological network analysis with deep learning"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"MAG":"3094502228","ArXiv":"2010.11929","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"76c124786ccf4263e6403a15a8e350ac28be4e65","externalIds":{"MAG":"3102419180","ArXiv":"2010.13902","DBLP":"journals/corr/abs-2010-13902","CorpusId":225076220},"title":"Graph Contrastive Learning with Augmentations"},{"paperId":"b8b3380efb26854bae6f51ad1d2b5a045129c5a1","externalIds":{"MAG":"3102154670","DBLP":"conf/nips/LiWWL20","CorpusId":225077570},"title":"Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning"},{"paperId":"04faf433934486c41d082e8d75ccfe5dc2f69fef","externalIds":{"DBLP":"conf/kdd/HuDWCS20","MAG":"3037208489","ArXiv":"2006.15437","DOI":"10.1145/3394486.3403237","CorpusId":220250007},"title":"GPT-GNN: Generative Pre-Training of Graph Neural Networks"},{"paperId":"a9a4e8e631890a14257539948e1813b5214c60dd","externalIds":{"DBLP":"conf/nips/RongBXX0HH20","MAG":"3101620381","CorpusId":226191736},"title":"Self-Supervised Graph Transformer on Large-Scale Molecular Data"},{"paperId":"91fb815361fdbf80ff15ce4d783a41846bd99232","externalIds":{"MAG":"3099152386","DBLP":"journals/corr/abs-2006-09963","ArXiv":"2006.09963","DOI":"10.1145/3394486.3403168","CorpusId":219720871},"title":"GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training"},{"paperId":"3bfa808ce20b2736708c3fc0b9443635e3f133a7","externalIds":{"DBLP":"journals/corr/abs-2006-05205","ArXiv":"2006.05205","MAG":"3034190530","CorpusId":219558760},"title":"On the Bottleneck of Graph Neural Networks and its Practical Implications"},{"paperId":"4bf76588122827157c43a59e656dccc6b6a22e90","externalIds":{"ArXiv":"2006.04131","MAG":"3033039844","DBLP":"journals/corr/abs-2006-04131","CorpusId":219531264},"title":"Deep Graph Contrastive Representation Learning"},{"paperId":"14b65a86c82e38fce0eb3506e0d4084ad5cdb583","externalIds":{"MAG":"3033187248","DBLP":"conf/iclr/HeLGC21","ArXiv":"2006.03654","CorpusId":219531210},"title":"DeBERTa: Decoding-enhanced BERT with Disentangled Attention"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"597bd2e45427563cdf025e53a3239006aa364cfc","externalIds":{"MAG":"3021975806","ArXiv":"2005.00687","DBLP":"journals/corr/abs-2005-00687","CorpusId":218487328},"title":"Open Graph Benchmark: Datasets for Machine Learning on Graphs"},{"paperId":"4a4f84992b4ee8331f1e3189f6f9b0437214035c","externalIds":{"DBLP":"conf/www/Wang0WJWTJY20","MAG":"3012562343","DOI":"10.1145/3366423.3380186","CorpusId":215838304},"title":"Traffic Flow Prediction via Spatial Temporal Graph Neural Network"},{"paperId":"32cd7eeb7e9ca342d6b17a1e4b8422dd51402830","externalIds":{"DBLP":"journals/pami/GaoZX21","MAG":"3016459781","DOI":"10.1109/tpami.2020.2985708","CorpusId":216030709,"PubMed":"32305892"},"title":"Learning to Model Relationships for Zero-Shot Video Classification"},{"paperId":"3bcb17559ce96eb20fa79af8194f4af0380d194a","externalIds":{"DBLP":"journals/corr/abs-2003-08271","MAG":"3088409176","ArXiv":"2003.08271","DOI":"10.1007/s11431-020-1647-3","CorpusId":212747830},"title":"Pre-trained models for natural language processing: A survey"},{"paperId":"898861ab4733194be5e6fd43449d36c700f53884","externalIds":{"MAG":"3009999522","DOI":"10.1001/jama.2020.1166","CorpusId":211834795,"PubMed":"32125404"},"title":"Estimated Research and Development Investment Needed to Bring a New Medicine to Market, 2009-2018."},{"paperId":"78542c2be9bb853a4e04642f2d315cfb0c6d94b3","externalIds":{"MAG":"3000577518","DBLP":"journals/corr/abs-2001-05140","ArXiv":"2001.05140","CorpusId":210698881},"title":"Graph-Bert: Only Attention is Needed for Learning Graph Representations"},{"paperId":"a75649771901a4881b44c0ceafa469fcc6e6f968","externalIds":{"MAG":"3044438666","ArXiv":"1911.12543","DBLP":"journals/tacl/JiangXAN20","DOI":"10.1162/tacl_a_00324","CorpusId":208513249},"title":"How Can We Know What Language Models Know?"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"df68a265f6c4d1b7a6aee5b1ebf3ef20c2c4f01e","externalIds":{"DBLP":"journals/pami/LiCCZWT22","ArXiv":"1910.02212","MAG":"2978927732","DOI":"10.1109/TPAMI.2021.3053765","CorpusId":203838498,"PubMed":"33481706"},"title":"Symbiotic Graph Neural Networks for 3D Skeleton-Based Human Action Recognition and Motion Prediction"},{"paperId":"93d63ec754f29fa22572615320afe0521f7ec66d","externalIds":{"DBLP":"journals/corr/abs-1908-10084","MAG":"2970641574","ArXiv":"1908.10084","ACL":"D19-1410","DOI":"10.18653/v1/D19-1410","CorpusId":201646309},"title":"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"},{"paperId":"bc8473992cde60fa6618886dfc354f67bc041263","externalIds":{"MAG":"2964915865","DBLP":"conf/ijcai/JiangJL19","DOI":"10.24963/ijcai.2019/369","CorpusId":199466087},"title":"CensNet: Convolution with Edge-Node Switching in Graph Neural Networks"},{"paperId":"0a6a9e6d4e3efd7c69357769305b70097281655f","externalIds":{"ArXiv":"1907.10903","MAG":"2999269676","DBLP":"conf/iclr/RongHXH20","CorpusId":212859361},"title":"DropEdge: Towards Deep Graph Convolutional Networks on Node Classification"},{"paperId":"e0c6abdbdecf04ffac65c440da77fb9d66bb474c","externalIds":{"MAG":"2950813464","DBLP":"journals/corr/abs-1906-08237","ArXiv":"1906.08237","CorpusId":195069387},"title":"XLNet: Generalized Autoregressive Pretraining for Language Understanding"},{"paperId":"3c4d3ac27a23c144bb3c4f8785bffcdc71addd15","externalIds":{"MAG":"2951269871","ArXiv":"1906.06532","DBLP":"journals/corr/abs-1906-06532","DOI":"10.24963/ijcai.2019/509","CorpusId":189928183},"title":"Attributed Graph Clustering: A Deep Attentional Embedding Approach"},{"paperId":"00b7efbf14a54cced4b9f19e663b70ffbd01324b","externalIds":{"DBLP":"conf/www/WangJSWYCY19","MAG":"2911286998","ArXiv":"1903.07293","DOI":"10.1145/3308558.3313562","CorpusId":81978964},"title":"Heterogeneous Graph Attention Network"},{"paperId":"403227333329b36183004f04db72362b604adef3","externalIds":{"MAG":"2951585248","DBLP":"journals/corr/abs-1902-09229","ArXiv":"1902.09229","CorpusId":67855945},"title":"A Theoretical Analysis of Contrastive Unsupervised Representation Learning"},{"paperId":"70f7cd54b5918aed60c3d8c3a8e4aa7e8d634c41","externalIds":{"DBLP":"conf/kdd/Yang19","ArXiv":"1902.08730","MAG":"2970929262","DOI":"10.14778/3352063.3352127","CorpusId":67855424},"title":"AliGraph: A Comprehensive Graph Neural Network Platform"},{"paperId":"29ddc1f43f28af7c846515e32cc167bc66886d0c","externalIds":{"DBLP":"journals/corr/abs-1902-00751","ArXiv":"1902.00751","MAG":"2964303773","CorpusId":59599816},"title":"Parameter-Efficient Transfer Learning for NLP"},{"paperId":"658721bc13b0fa97366d38c05a96bf0a9f4bb0ac","externalIds":{"MAG":"2963854351","ArXiv":"1901.11504","DBLP":"journals/corr/abs-1901-11504","ACL":"P19-1441","DOI":"10.18653/v1/P19-1441","CorpusId":59523594},"title":"Multi-Task Deep Neural Networks for Natural Language Understanding"},{"paperId":"ea5dd6a3d8f210d05e53a7b6fa5e16f1b115f693","externalIds":{"MAG":"3152893301","DBLP":"journals/corr/abs-1812-08434","ArXiv":"1812.08434","DOI":"10.1016/J.AIOPEN.2021.01.001","CorpusId":56517517},"title":"Graph Neural Networks: A Review of Methods and Applications"},{"paperId":"62ed9bf1d83c8db1f9cbf92ea2f57ea90ef683d9","externalIds":{"MAG":"2950468517","ArXiv":"1810.00826","DBLP":"journals/corr/abs-1810-00826","CorpusId":52895589},"title":"How Powerful are Graph Neural Networks?"},{"paperId":"967a21a111757d6af7f7a25ca7ea2bdf6d505098","externalIds":{"MAG":"2963782635","DBLP":"conf/iclr/VelickovicFHLBH19","ArXiv":"1809.10341","CorpusId":52877454},"title":"Deep Graph Infomax"},{"paperId":"510d98681e5e85fb1265513728f16e2543ae1b4b","externalIds":{"MAG":"2892880750","DBLP":"journals/corr/abs-1809-09401","ArXiv":"1809.09401","DOI":"10.1609/AAAI.V33I01.33013558","CorpusId":52825543},"title":"Hypergraph Neural Networks"},{"paperId":"59d502851cd20f28af03eef1d15dc83d3a7bb300","externalIds":{"MAG":"2809343047","DBLP":"conf/kdd/LeeRK18","DOI":"10.1145/3219819.3219980","CorpusId":47001915},"title":"Graph Classification using Structural Attention"},{"paperId":"e4715a13f6364b1c81e64f247651c3d9e80b6808","externalIds":{"MAG":"2950903083","ArXiv":"1802.09691","DBLP":"conf/nips/ZhangC18","CorpusId":3573161},"title":"Link Prediction Based on Graph Neural Networks"},{"paperId":"36652428740cd30d245d55889f01a7fb04a91c93","externalIds":{"MAG":"2951648099","DBLP":"conf/aaai/LiHW18","ArXiv":"1801.07606","DOI":"10.1609/aaai.v32i1.11604","CorpusId":11118105},"title":"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning"},{"paperId":"1e077413b25c4d34945cc2707e17e46ed4fe784a","externalIds":{"ACL":"P18-1031","MAG":"2952772027","DBLP":"conf/acl/RuderH18","DOI":"10.18653/v1/P18-1031","CorpusId":40100965},"title":"Universal Language Model Fine-tuning for Text Classification"},{"paperId":"33998aff64ce51df8dee45989cdca4b6b1329ec4","externalIds":{"DBLP":"journals/corr/abs-1710-10903","ArXiv":"1710.10903","MAG":"2766453196","DOI":"10.17863/CAM.48429","CorpusId":3292002},"title":"Graph Attention Networks"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"6b7d6e6416343b2a122f8416e69059ce919026ef","externalIds":{"DBLP":"conf/nips/HamiltonYL17","MAG":"2952779545","ArXiv":"1706.02216","CorpusId":4755450},"title":"Inductive Representation Learning on Large Graphs"},{"paperId":"e24cdf73b3e7e590c2fe5ecac9ae8aa983801367","externalIds":{"MAG":"2952254971","DBLP":"journals/corr/GilmerSRVD17","ArXiv":"1704.01212","CorpusId":9665943},"title":"Neural Message Passing for Quantum Chemistry"},{"paperId":"54906484f42e871f7c47bbfe784a358b1448231f","externalIds":{"DBLP":"journals/corr/KipfW16a","ArXiv":"1611.07308","MAG":"2554952599","CorpusId":14249137},"title":"Variational Graph Auto-Encoders"},{"paperId":"36eff562f65125511b5dfab68ce7f7a943c27478","externalIds":{"ArXiv":"1609.02907","MAG":"2519887557","DBLP":"journals/corr/KipfW16","CorpusId":3144218},"title":"Semi-Supervised Classification with Graph Convolutional Networks"},{"paperId":"36ee2c8bd605afd48035d15fdc6b8c8842363376","externalIds":{"MAG":"2951167005","ArXiv":"1607.00653","DBLP":"conf/kdd/GroverL16","DOI":"10.1145/2939672.2939754","CorpusId":207238980,"PubMed":"27853626"},"title":"node2vec: Scalable Feature Learning for Networks"},{"paperId":"2218e2e1df2c3adfb70e0def2e326a39928aacfc","externalIds":{"MAG":"2963432357","DBLP":"conf/icml/TrouillonWRGB16","ArXiv":"1606.06357","CorpusId":15150247},"title":"Complex Embeddings for Simple Link Prediction"},{"paperId":"5abf1c0ff7dc9157aedd9dfa021f8d3dcc647d9b","externalIds":{"MAG":"2268918789","DBLP":"journals/corr/ShiLZSY15","ArXiv":"1511.04854","DOI":"10.1109/TKDE.2016.2598561","CorpusId":7885409},"title":"A Survey of Heterogeneous Information Network Analysis"},{"paperId":"fce14c6aa64e888456256ac6796744683165a0ff","externalIds":{"MAG":"2242161203","DBLP":"conf/ijcai/YangLZSC15","CorpusId":2452205},"title":"Network Representation Learning with Rich Text Information"},{"paperId":"fff114cbba4f3ba900f33da574283e3de7f26c83","externalIds":{"DBLP":"conf/kdd/PerozziAS14","MAG":"2154851992","ArXiv":"1403.6652","DOI":"10.1145/2623330.2623732","CorpusId":3051291},"title":"DeepWalk: online learning of social representations"},{"paperId":"f6764d853a14b0c34df1d2283e76277aead40fde","externalIds":{"MAG":"205829674","DBLP":"conf/icml/NickelTK11","CorpusId":1157792},"title":"A Three-Way Model for Collective Learning on Multi-Relational Data"},{"paperId":"79ad463104c7b7afeab11c2046fe7c18d5108ac6","externalIds":{"DOI":"10.1080/10131750485310161","CorpusId":218497666},"title":"Pattern"},{"paperId":"bc334ae52a022f39b876888ad3764bba686f1000","externalIds":{"DBLP":"conf/nips/Zhao0GSWH024","DOI":"10.52202/079017-0131","CorpusId":276117266},"title":"FUG: Feature-Universal Graph Contrastive Pre-training for Graphs with Diverse Node Features"},{"paperId":"f01281b125128435ad134230c6a41cc55808eaac","externalIds":{"DBLP":"journals/corr/abs-2309-16595","DOI":"10.48550/arXiv.2309.16595","CorpusId":263135565},"title":"Can LLMs Effectively Leverage Graph Structural Information: When and Why"},{"paperId":"0e87f4c721c2a5302e9cf7e2b3a6ceacfaceb469","externalIds":{"DBLP":"journals/corr/abs-2310-17110","DOI":"10.48550/arXiv.2310.17110","CorpusId":271710643},"title":"LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?"},{"paperId":"ec936b808e0fab9281c050ad4010cddec92c8cbe","externalIds":{"ACL":"2022.acl-short.8","DBLP":"conf/acl/LiuJFTDY022","DOI":"10.18653/v1/2022.acl-short.8","CorpusId":248780177},"title":"P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks"},{"paperId":"57651d65078818821234d13544ac1f29858dcd67","externalIds":{"ACL":"2021.emnlp-main.47","DBLP":"conf/emnlp/EdwardsZJ21","DOI":"10.18653/v1/2021.emnlp-main.47","CorpusId":243865204},"title":"Text2Mol: Cross-Modal Molecule Retrieval with Natural Language Queries"},{"paperId":"acf87283fa8ae426f1a4987b345b401bf2913f61","externalIds":{"DBLP":"conf/nips/YingCLZKHSL21","CorpusId":265104899},"title":"Do Transformers Really Perform Badly for Graph Representation?"},{"paperId":"53d8b356551a2361020a948f64454a6d599af69f","externalIds":{"DBLP":"conf/acl/LiL20","ACL":"2021.acl-long.353","ArXiv":"2101.00190","DOI":"10.18653/v1/2021.acl-long.353","CorpusId":230433941},"title":"Prefix-Tuning: Optimizing Continuous Prompts for Generation"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","externalIds":{"ArXiv":"2103.14030","DBLP":"conf/iccv/LiuL00W0LG21","DOI":"10.1109/ICCV48922.2021.00986","CorpusId":232352874},"title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"81a4fd3004df0eb05d6c1cef96ad33d5407820df","externalIds":{"DBLP":"journals/tnn/WuPCLZY21","MAG":"2907492528","ArXiv":"1901.00596","DOI":"10.1109/TNNLS.2020.2978386","CorpusId":57375753,"PubMed":"32217482"},"title":"A Comprehensive Survey on Graph Neural Networks"},{"paperId":"6d1d91a413af1212fea8791e266282019b62c37d","externalIds":{"CorpusId":49579538},"title":"THE REDUCTION OF A GRAPH TO CANONICAL FORM AND THE ALGEBRA WHICH APPEARS THEREIN"},{"paperId":"0c0a778e6fdf7e36b1750c533dcc916f86608607","externalIds":{"MAG":"2527310337","DBLP":"journals/tkde/XunJGZ17","DOI":"10.1109/TKDE.2016.2614508","CorpusId":13490401},"title":"A Survey on Context Learning"},{"paperId":"d49cb9c050e29a2a073e636a0849626e2b2501b7","externalIds":{"MAG":"2493410043","DOI":"10.4135/9781446294413.n3","CorpusId":2054602},"title":"The Development of Social Network Analysisâ€”with an Emphasis on Recent Events"},{"paperId":"69381b5efd97e7c55f51c2730caccab3d632d4d2","externalIds":{"DBLP":"journals/pami/YanXZZYL07","MAG":"2136040699","DOI":"10.1109/TPAMI.2007.12","CorpusId":2426049,"PubMed":"17108382"},"title":"Graph Embedding and Extensions: A General Framework for Dimensionality Reduction"},{"paperId":"156d0bc37cee49f70f361e89b5ca2c6c88b6e128","externalIds":{"CorpusId":269839838},"title":"Pretrained Language Models to Solve Graph Tasks in Natural Language"}]}