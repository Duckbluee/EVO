{"references":[{"paperId":"7e9e6ff51684e0cb5e56951463b4073769a19c82","externalIds":{"DBLP":"conf/isrr/JainSS13","MAG":"2467882958","DOI":"10.1007/978-3-319-28872-7_19","CorpusId":11249055},"title":"Beyond Geometric Path Planning: Learning Context-Driven Trajectory Preferences via Sub-optimal Feedback"},{"paperId":"4124441c9f41b5e2542cd9c012752a78ae6cc4ac","externalIds":{"MAG":"2100771357","ArXiv":"1510.06939","DBLP":"conf/iccv/JainGMS15","DOI":"10.1109/ICCV.2015.521","CorpusId":799873},"title":"Objects2action: Classifying and Localizing Actions without Any Video Example"},{"paperId":"55a3b288b6885cd8dcc247212de9e82e713702db","externalIds":{"ArXiv":"1509.02634","DBLP":"journals/corr/LiuLLLT15","MAG":"2111077768","DOI":"10.1109/ICCV.2015.162","CorpusId":8254931},"title":"Semantic Image Segmentation via Deep Parsing Network"},{"paperId":"99f2e94ff2efe712687ce2c3984e2eac5c90cec8","externalIds":{"DBLP":"journals/corr/LiZC15","MAG":"2524613005","ArXiv":"1508.06708","DOI":"10.1007/s11263-016-0962-x","CorpusId":285831},"title":"Maximum-Margin Structured Learning with Deep Networks for 3D Human Pose Estimation"},{"paperId":"1ec7433aeb4777e7d5c903920ae945e5429d3bc4","externalIds":{"DBLP":"conf/iccv/FragkiadakiLFM15","MAG":"2951188428","DOI":"10.1109/ICCV.2015.494","CorpusId":128024},"title":"Recurrent Network Models for Human Dynamics"},{"paperId":"96d288df7ca67dafe1642c427a4d9f4901267c8b","externalIds":{"MAG":"1909234690","DBLP":"conf/cvpr/ByeonBRL15","DOI":"10.1109/CVPR.2015.7298977","CorpusId":15134598},"title":"Scene labeling with LSTM recurrent neural networks"},{"paperId":"a72b8bbd039989db39769da836cdb287737deb92","externalIds":{"MAG":"1895989618","DBLP":"conf/cvpr/ChenZ15","DOI":"10.1109/CVPR.2015.7298856","CorpusId":6785090},"title":"Mind's eye: A recurrent visual representation for image caption generation"},{"paperId":"1839e17555160bd897b978c48b8ebd13dd21445f","externalIds":{"MAG":"1950788856","DBLP":"conf/cvpr/DuWW15","DOI":"10.1109/CVPR.2015.7298714","CorpusId":8040013},"title":"Hierarchical recurrent neural network for skeleton based action recognition"},{"paperId":"40be3888daa5c2e5af4d36ae22f690bcc8caf600","externalIds":{"DBLP":"journals/corr/KarpathyJL15","MAG":"1951216520","ArXiv":"1506.02078","CorpusId":988348},"title":"Visualizing and Understanding Recurrent Networks"},{"paperId":"7ffdbc358b63378f07311e883dddacc9faeeaf4b","externalIds":{"ArXiv":"1504.08083","CorpusId":206770307},"title":"Fast R-CNN"},{"paperId":"186336fb15a47ebdc6f0730d0cf4f56c58c5b906","externalIds":{"MAG":"1789187189","DBLP":"conf/iccv/JainKRSS15","DOI":"10.1109/ICCV.2015.364","CorpusId":6436645},"title":"Car that Knows Before You Do: Anticipating Maneuvers via Learning Temporal Driving Models"},{"paperId":"4cef5476f9da50c1a8fefdcb7114863966f61d67","externalIds":{"MAG":"1569892065","DBLP":"journals/corr/LinSRH15","ArXiv":"1504.01013","DOI":"10.1109/CVPR.2016.348","CorpusId":14554538},"title":"Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation"},{"paperId":"416a242f24246f8ee2c00f4d3d1561443dc65b59","externalIds":{"MAG":"2102492119","ArXiv":"1503.02351","DBLP":"journals/corr/SchwingU15","CorpusId":15939599},"title":"Fully Connected Deep Structured Networks"},{"paperId":"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d","externalIds":{"MAG":"2116435618","DBLP":"journals/corr/SrivastavaMS15","ArXiv":"1502.04681","CorpusId":11699847},"title":"Unsupervised Learning of Video Representations using LSTMs"},{"paperId":"ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a","externalIds":{"ArXiv":"1502.03240","MAG":"3100332847","DBLP":"journals/corr/ZhengJRVSDHT15","DOI":"10.1109/ICCV.2015.179","CorpusId":1318262},"title":"Conditional Random Fields as Recurrent Neural Networks"},{"paperId":"9665247ea3421929f9b6ad721f139f11edb1dbb8","externalIds":{"ArXiv":"1412.7753","DBLP":"journals/corr/MikolovJCMR14","MAG":"2951010554","CorpusId":14715110},"title":"Learning Longer Memory in Recurrent Neural Networks"},{"paperId":"39ad6c911f3351a3b390130a6e4265355b4d593b","externalIds":{"DBLP":"journals/corr/ChenPKMY14","MAG":"1923697677","ArXiv":"1412.7062","CorpusId":1996665},"title":"Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs"},{"paperId":"43795b7bac3d921c4e579964b54187bdbf6c6330","externalIds":{"DBLP":"journals/corr/VenugopalanXDRMS14","ACL":"N15-1173","ArXiv":"1412.4729","MAG":"2964241990","DOI":"10.3115/v1/N15-1173","CorpusId":52316421},"title":"Translating Videos to Natural Language Using Deep Recurrent Neural Networks"},{"paperId":"d25c65d261ea0e6a458be4c50c40ffe5bc508f77","externalIds":{"MAG":"1522734439","DBLP":"conf/iccv/TranBFTP15","DOI":"10.1109/ICCV.2015.510","CorpusId":1122604},"title":"Learning Spatiotemporal Features with 3D Convolutional Networks"},{"paperId":"f01fc808592ea7c473a69a6e7484040a435f36d9","externalIds":{"DBLP":"journals/pami/DonahueHRVGSD17","MAG":"2951183276","ArXiv":"1411.4389","DOI":"10.1109/CVPR.2015.7298878","CorpusId":5736847,"PubMed":"27608449"},"title":"Long-term recurrent convolutional networks for visual recognition and description"},{"paperId":"0ab19a80c92da54bd7e2e560d95aa301c8c3aa71","externalIds":{"DBLP":"conf/humanoids/PieropanEK14","MAG":"2061017280","DOI":"10.1109/HUMANOIDS.2014.7041337","CorpusId":15013413},"title":"Recognizing object affordances in terms of spatio-temporal object-object relationships"},{"paperId":"ae639e4bdd2e6a11bc44ff7f1ae53cd25462042b","externalIds":{"MAG":"2075156252","DBLP":"journals/tog/TompsonSLP14","DOI":"10.1145/2629500","CorpusId":5736984},"title":"Real-Time Continuous Pose Recovery of Human Hands Using Convolutional Networks"},{"paperId":"cea967b59209c6be22829699f05b8b1ac4dc092d","externalIds":{"MAG":"2130942839","DBLP":"conf/nips/SutskeverVL14","ArXiv":"1409.3215","CorpusId":7961699},"title":"Sequence to Sequence Learning with Neural Networks"},{"paperId":"c66758c1029a463489f26aeb3955f333b37f727a","externalIds":{"MAG":"2928160594","DBLP":"conf/icml/ChenSYU15","ArXiv":"1407.2538","CorpusId":10787826},"title":"Learning Deep Structured Models"},{"paperId":"bac377d3a051899dbe0d7249ed5d3d0b22d57310","externalIds":{"MAG":"2101032778","DBLP":"journals/pami/IonescuPOS14","DOI":"10.1109/TPAMI.2013.248","CorpusId":4244548,"PubMed":"26353306"},"title":"Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments"},{"paperId":"0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f","externalIds":{"MAG":"3111804057","DBLP":"conf/icml/GravesJ14","CorpusId":1166498},"title":"Towards End-To-End Speech Recognition with Recurrent Neural Networks"},{"paperId":"16fa635611f6f189c4eb9645dcfbc137b189ed55","externalIds":{"MAG":"2108945645","DBLP":"conf/ivs/ZhangJ014","DOI":"10.1109/IVS.2014.6856546","CorpusId":3224557},"title":"Overtaking vehicle detection using a spatio-temporal CRF"},{"paperId":"6d934149644f048e176630c9ee3daed7fbe16c72","externalIds":{"MAG":"2110364349","DBLP":"conf/iccv/SunN13","DOI":"10.1109/ICCV.2013.453","CorpusId":10453090},"title":"ACTIVE: Activity Concept Transitions in Video Event Classification"},{"paperId":"89d5b41b7fb0a122f811be270e6d5f72fc59d680","externalIds":{"MAG":"2147414309","ArXiv":"1311.5591","DBLP":"journals/corr/ZhangPRDB13","DOI":"10.1109/CVPR.2014.212","CorpusId":6943286},"title":"PANDA: Pose Aligned Networks for Deep Attribute Modeling"},{"paperId":"6471fd1cbc081fb3b7b5b14d6ab9eaaba02b5c17","externalIds":{"MAG":"1810943226","DBLP":"journals/corr/Graves13","ArXiv":"1308.0850","CorpusId":1697424},"title":"Generating Sequences With Recurrent Neural Networks"},{"paperId":"50a00d4fa9bf2e7bff37bc944ac48b403f5eb097","externalIds":{"DBLP":"journals/pami/KoppulaS16","MAG":"2293288132","DOI":"10.1109/TPAMI.2015.2430335","CorpusId":1121245,"PubMed":"26656575"},"title":"Anticipating Human Activities Using Object Affordances for Reactive Robotic Response"},{"paperId":"8f168c4fe7704ecd37895c8b9a40d2f0ae831635","externalIds":{"DBLP":"conf/icml/KoppulaS13","MAG":"2114216982","CorpusId":52865362},"title":"Learning Spatio-Temporal Structure from RGB-D Videos for Human Activity Detection and Anticipation"},{"paperId":"e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f","externalIds":{"MAG":"2146055337","DBLP":"journals/corr/abs-1210-1207","ArXiv":"1210.1207","DOI":"10.1177/0278364913478446","CorpusId":17004045},"title":"Learning human activities and object affordances from RGB-D videos"},{"paperId":"c81c20109c809cfc47565a9477c04ee005d424bf","externalIds":{"DBLP":"journals/corr/abs-1210-5644","MAG":"2952793010","ArXiv":"1210.5644","CorpusId":5574079},"title":"Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials"},{"paperId":"57aa4db02799792c138c4a9245525cf79848dd72","externalIds":{"DBLP":"conf/iccv/BrendelT11","MAG":"2137275576","DOI":"10.1109/ICCV.2011.6126316","CorpusId":8618770},"title":"Learning spatiotemporal graphs of human activities"},{"paperId":"9c0ddf74f87d154db88d79c640578c1610451eec","externalIds":{"MAG":"1423339008","DBLP":"conf/icml/SocherLNM11","CorpusId":18690358},"title":"Parsing Natural Scenes and Natural Language with Recursive Neural Networks"},{"paperId":"161a8a43b769b5930a68e07e31484d114cc32f1e","externalIds":{"MAG":"2068994826","DBLP":"conf/cvpr/Anwaar-ul-HaqGM11","DOI":"10.1109/CVPR.2011.6044588","CorpusId":10012350},"title":"Track to the future: Spatio-temporal video segmentation with long-range motion cues"},{"paperId":"6f586c709709948e0ab57d559456dcb1be7bc717","externalIds":{"DBLP":"journals/ijcv/ShiCWS11","MAG":"2014914041","DOI":"10.1007/s11263-010-0384-0","CorpusId":9054863},"title":"Human Action Segmentation and Recognition Using Discriminative Semi-Markov Models"},{"paperId":"eb9c924383aca0d137c736a41271d569a12cf518","externalIds":{"MAG":"2129999749","ArXiv":"1011.4088","DBLP":"journals/ftml/SuttonM12","DOI":"10.1561/2200000013","CorpusId":342976},"title":"An Introduction to Conditional Random Fields"},{"paperId":"20b97fd491a05b289dfd666a87c545664b25bb67","externalIds":{"DBLP":"conf/cvpr/TaylorSFH10","MAG":"2034792058","DOI":"10.1109/CVPR.2010.5540157","CorpusId":16974865},"title":"Dynamical binary latent variable models for 3D human pose tracking"},{"paperId":"5648c0b82792274944fc5428e11cec0afe260092","externalIds":{"MAG":"2170694982","DBLP":"conf/nips/McCallumSS09","CorpusId":3017946},"title":"FACTORIE: Probabilistic Programming via Imperatively Defined Factor Graphs"},{"paperId":"138c86b9283e4f26ff1583acdf4e51a5f88ccad1","externalIds":{"MAG":"2169393274","DBLP":"journals/pami/GuptaKD09","DOI":"10.1109/TPAMI.2009.83","CorpusId":5829319,"PubMed":"19696449"},"title":"Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition"},{"paperId":"f30aba767d71c1db5ea70b041d9fcc2b9b1ddad4","externalIds":{"MAG":"2031248101","DBLP":"journals/ml/JoachimsFY09","DOI":"10.1007/s10994-009-5108-8","CorpusId":14211670},"title":"Cutting-plane training of structural SVMs"},{"paperId":"36eb6fea39ce06e2807f074fa3d5e79ed0f2bcef","externalIds":{"MAG":"2803316390","CorpusId":14995779},"title":"Probabilistic Graphical Models: Principles and Techniques - Adaptive Computation and Machine Learning"},{"paperId":"8de174ab5419b9d3127695405efd079808e956e8","externalIds":{"MAG":"2296073425","DBLP":"conf/icml/BengioLCW09","DOI":"10.1145/1553374.1553380","CorpusId":873046},"title":"Curriculum learning"},{"paperId":"346fbcffe4237aa60e8bcb3d4294a8b99436f1d0","externalIds":{"DBLP":"conf/icml/TaylorH09","MAG":"2115096495","DOI":"10.1145/1553374.1553505","CorpusId":718390},"title":"Factored conditional restricted Boltzmann Machines for modeling motion style"},{"paperId":"0228810a988f6b8f06337e14f564e2fd3f6e1056","externalIds":{"MAG":"2135341757","DBLP":"conf/nips/SutskeverHT08","CorpusId":8435923},"title":"The Recurrent Temporal Restricted Boltzmann Machine"},{"paperId":"3805dbf39a9a44819d1a9d90ffa4d42b1237d3ef","externalIds":{"MAG":"1841544152","DBLP":"conf/eccv/LiN08","DOI":"10.1007/978-3-540-88693-8_30","CorpusId":5634118},"title":"Key Object Driven Multi-category Object Recognition, Localization and Tracking Using Spatio-temporal Context"},{"paperId":"3efe51b3de05884fff014d21bcae1b82af90662e","externalIds":{"DBLP":"conf/icml/UrtasunFGPDL08","MAG":"2171461439","DOI":"10.1145/1390156.1390292","CorpusId":12183624},"title":"Topologically-constrained latent variable models"},{"paperId":"860a9d55d87663ca88e74b3ca357396cd51733d0","externalIds":{"MAG":"2120419212","DBLP":"conf/cvpr/FelzenszwalbMR08","DOI":"10.1109/CVPR.2008.4587597","CorpusId":14327585},"title":"A discriminatively trained, multiscale, deformable part model"},{"paperId":"02a98118ce990942432c0147ff3c0de756b4b76a","externalIds":{"MAG":"2142194269","DBLP":"conf/cvpr/LaptevMSR08","DOI":"10.1109/CVPR.2008.4587756","CorpusId":12365014},"title":"Learning realistic human actions from movies"},{"paperId":"f33f07af0d31366e85833aabd5173895ee888abc","externalIds":{"MAG":"2124609748","DBLP":"journals/pami/WangFH08","DOI":"10.1109/TPAMI.2007.1167","CorpusId":263877441,"PubMed":"18084059"},"title":"Gaussian Process Dynamical Models for Human Motion"},{"paperId":"5e2ae724139de4d24918c3a64c69ea3201e6d382","externalIds":{"MAG":"2123277412","DBLP":"conf/atal/VailVL07","DOI":"10.1145/1329125.1329409","CorpusId":13251604},"title":"Conditional random fields for activity recognition"},{"paperId":"497a80b2813cffb17f46af50e621a71505094528","externalIds":{"DBLP":"conf/nips/TaylorHR06","MAG":"2158164339","DOI":"10.7551/mitpress/7503.003.0173","CorpusId":14962437},"title":"Modeling Human Motion Using Binary Latent Variables"},{"paperId":"40b49547451b840f959a3100a3faacfa5cb2ff55","externalIds":{"MAG":"1977970897","DBLP":"journals/ml/RichardsonD06","DOI":"10.1007/s10994-006-5833-1","CorpusId":12698795},"title":"Markov logic networks"},{"paperId":"819a2bbd4467192dbbc9e833eb4ca6653ad791aa","externalIds":{"DBLP":"conf/nips/QuattoniCD04","MAG":"2151322733","CorpusId":9389968},"title":"Conditional Random Fields for Object Recognition"},{"paperId":"9cc36397e1fef5c922d64e88211a7e08ecc64759","externalIds":{"DBLP":"journals/corr/abs-1301-0604","MAG":"2137213923","ArXiv":"1301.0604","CorpusId":2282762},"title":"Discriminative Probabilistic Models for Relational Data"},{"paperId":"d1b4a4689a0288ccf36158ba5dfef724fd5a4ea5","externalIds":{"MAG":"2137813581","DBLP":"journals/tit/KschischangFL01","DOI":"10.1109/18.910572","CorpusId":14394619},"title":"Factor graphs and the sum-product algorithm"},{"paperId":"4f0ab1dcdc9f405ca90e36a35ea335196464d387","externalIds":{"DBLP":"conf/cvpr/BottouBL97","MAG":"1902568950","DOI":"10.1109/CVPR.1997.609370","CorpusId":847249},"title":"Global training of document processing systems using graph transformer networks"},{"paperId":"3461f06617b42dadd1ce240a93ffe420513b3399","externalIds":{"MAG":"2148695089","DBLP":"conf/nips/BengioCH93","CorpusId":11550988},"title":"Globally Trained Handwritten Word Recognizer Using Spatial Representation, Convolutional Neural Networks, and Hidden Markov Models"},{"paperId":"f7084bced25ec0b230c5aa0159077dc38d6915ca","externalIds":{"MAG":"1513753641","CorpusId":58334002},"title":"MoSIFT: Recognizing Human Actions in Surveillance Videos"},{"paperId":"e25cd6819419028bfa8edc0be990570a91962b7b","externalIds":{"DBLP":"conf/isrr/DouillardFR07","MAG":"72152974","DOI":"10.1007/978-3-642-14743-2_11","CorpusId":14273543},"title":"A Spatio-Temporal Probabilistic Model for Multi-Sensor Multi-Class Object Recognition"},{"paperId":"070874b011f8eb2b18c8aa521ad0a7a932b4d9ad","externalIds":{"CorpusId":753512},"title":"Author manuscript, published in \"International Conference on Computer Vision (2013)\" Action Recognition with Improved Trajectories"}]}