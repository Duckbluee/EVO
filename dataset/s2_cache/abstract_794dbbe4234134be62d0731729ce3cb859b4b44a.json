{"abstract":"Although deep learning has achieved promising results on medical image classification, the domain shift between training and testing datasets leads to a low prediction accuracy. Domain adaptation is a effective solution. However, due to privacy issues and the lack of annotated data, itâ€™s hard for conventional domain adaptation methods to access source images and labeled target images. To tackle this issue, we propose a novel framework that only requires unlabeled target domain data. This framework has two modules, one is based on class conditional generative adversarial net for source domain generation and another is for classification m odel t raining. S pecifically, the generator can generate target-style data as the pseudo-source data using random noise and a given label to improve the classifier. The increased a ccuracy of the classifier also can guide the generator. Besides, we introduce weight regularization and clustering-based regularization to keep the training process stable and fully explore the discriminative information. We take diabetic retinopathy grade classification as our task and conduct experiments on three datasets which are EysPACS, MESSIDOR and IDRiD. The experimental results show that our method performs well on only unlabeled target data, which proves that it is a general method and can be widely used in the field of medical image classification."}