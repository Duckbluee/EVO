{"abstract":"Recommender systems play a key role in shaping modern web ecosystems. These systems alternate between (1) making recommendations, (2) collecting user responses to these recommendations, and (3) retraining the recommendation algorithm based on this feedback. During this process, the recommender influences the user behavioral data that is subsequently used to update the recommender itself, thus creating a feedback loop. Recent work has shown that feedback loops may compromise recommendation quality and homogenize user behavior, raising ethical and performance concerns around deploying recommender systems. To address these concerns, we propose the causal adjustment for feedback loops (CAFL), an algorithm that uses causal inference to break feedback loops for any loss-minimizing recommendation algorithms. The key observation is that a recommender system does not suffer from feedback loops if it reasons about causal quantities, namely the intervention distributions of recommendations on user ratings. Moreover, we can calculate these intervention distributions from observational data by adjusting for the recommender systemâ€™s predictions of user preferences. Using simulated environments, we demonstrate that CAFL improves recommendation quality when compared to prior correction methods."}