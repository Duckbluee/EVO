{"paperId":"03d1fd385dc204e4e7445c5204ed15bd5e96a99d","externalIds":{"DBLP":"journals/corr/abs-2304-11534","ArXiv":"2304.11534","DOI":"10.1007/s10462-024-10808-0","CorpusId":258298220},"title":"Graph neural networks for text classification: a survey","openAccessPdf":{"url":"https://link.springer.com/content/pdf/10.1007/s10462-024-10808-0.pdf","status":"HYBRID","license":"CCBY","disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2304.11534, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"1990752926","name":"Kunze Wang"},{"authorId":"2166956722","name":"Yihao Ding"},{"authorId":"2046142","name":"S. Han"}],"abstract":"Text Classification is the most essential and fundamental problem in Natural Language Processing. While numerous recent text classification models applied the sequential deep learning technique, graph neural network-based models can directly deal with complex structured text data and exploit global information. Many real text classification applications can be naturally cast into a graph, which captures words, documents, and corpus global features. In this survey, we bring the coverage of methods up to 2023, including corpus-level and document-level graph neural networks. We discuss each of these methods in detail, dealing with the graph construction mechanisms and the graph-based learning process. As well as the technological survey, we look at issues behind and future directions addressed in text classification using graph neural networks. We also cover datasets, evaluation metrics, and experiment design and present a summary of published performance on the publicly available benchmarks. Note that we present a comprehensive comparison between different techniques and identify the pros and cons of various evaluation metrics in this survey."}