{"abstract":": As the use of artificial intelligence technology, particularly deep learning models like the diffusion model, becomes more prevalent in the creation of art, concerns regarding the use of unauthorized work samples in their training have emerged. The lack of supervision and relevant laws has contributed to the problem. This study examines the potential infringement issues that may arise during the training of the diffusion model and explores the legality of using unauthorized samples for deep learning model training. While some scholars argue that copyright law only protects expression and not painting style, therefore, using unauthorized works in model training is not considered infringement, we propose a different viewpoint. By considering the essence of artificial intelligence from an information theory perspective, we highlight that it is still a deterministic algorithm and that data processing does not bring about an increase in information entropy without the input of additional information. Thus, the painting created by the diffusion model is essentially a mash-up of paintings in its training space, and as such, it is a copy or adaptation of the original work and should be licensed by the creator. We highlight the critical difference between human learning and AI \"learning,\" emphasizing the need for effective protection and encouragement of human artistic innovation while embracing the wave of AI."}