{"references":[{"paperId":"7c44b7fdcec2e517799f6c54f6ba42bf1a89d2e6","externalIds":{"ArXiv":"2410.07095","DBLP":"journals/corr/abs-2410-07095","DOI":"10.48550/arXiv.2410.07095","CorpusId":273233550},"title":"MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering"},{"paperId":"c4ff8bc44d88cd267baf18ac5d3a3a1fe86d08eb","externalIds":{"DBLP":"conf/iclr/KumarZASCSBIBRZ25","ArXiv":"2409.12917","DOI":"10.48550/arXiv.2409.12917","CorpusId":272753259},"title":"Training Language Models to Self-Correct via Reinforcement Learning"},{"paperId":"bdc8c92a44714b468b40ef3d77e96d966f93141b","externalIds":{"DBLP":"journals/corr/abs-2407-18219","ArXiv":"2407.18219","DOI":"10.48550/arXiv.2407.18219","CorpusId":271432135},"title":"Recursive Introspection: Teaching Language Model Agents How to Self-Improve"},{"paperId":"f2cf484329dabf3499b17d724cf476ccf92aea9c","externalIds":{"DBLP":"journals/corr/abs-2406-02378","ArXiv":"2406.02378","DOI":"10.48550/arXiv.2406.02378","CorpusId":270225983},"title":"On the Intrinsic Self-Correction Capability of LLMs: Uncertainty and Latent Concept"},{"paperId":"55a66fc5e5246511c55c2c2d1d7a060709490030","externalIds":{"ArXiv":"2405.18634","DBLP":"journals/corr/abs-2405-18634","DOI":"10.48550/arXiv.2405.18634","CorpusId":270095253},"title":"A Theoretical Understanding of Self-Correction through In-context Alignment"},{"paperId":"c946888e2f81b1db84ba4addf2a11e87f0568fe9","externalIds":{"DBLP":"journals/tacl/PanSXNWW24","ACL":"2024.tacl-1.27","DOI":"10.1162/tacl_a_00660","CorpusId":269636518},"title":"Automatically Correcting Large Language Models: Surveying the Landscape of Diverse Automated Correction Strategies"},{"paperId":"822f7a276a4ff7dae59b849f57b95d2603a40d99","externalIds":{"ArXiv":"2404.17140","DBLP":"journals/corr/abs-2404-17140","DOI":"10.48550/arXiv.2404.17140","CorpusId":269430362},"title":"Small Language Models Need Strong Verifiers to Self-Correct Reasoning"},{"paperId":"1ca3b6ff250b4f73486a89f6954edcc4ae21834e","externalIds":{"ArXiv":"2404.09129","DBLP":"conf/naacl/LiYE24","DOI":"10.48550/arXiv.2404.09129","CorpusId":269148777},"title":"When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models"},{"paperId":"abcb4bbf57100ac69a9e8d845893c8b7a8130b30","externalIds":{"DBLP":"conf/naacl/KiC24","ArXiv":"2404.07851","DOI":"10.48550/arXiv.2404.07851","CorpusId":269042921},"title":"Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations"},{"paperId":"d5e9532d12a26124f019de5f1a1d6a9a6eab3d03","externalIds":{"DBLP":"journals/corr/abs-2404-03602","ArXiv":"2404.03602","DOI":"10.48550/arXiv.2404.03602","CorpusId":268889318},"title":"Evaluating LLMs at Detecting Errors in LLM Responses"},{"paperId":"e89ee3f84f1f07229a7ba211bad3465d2c80a325","externalIds":{"ArXiv":"2402.18272","DBLP":"journals/corr/abs-2402-18272","DOI":"10.48550/arXiv.2402.18272","CorpusId":268041461},"title":"Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?"},{"paperId":"bfc7762ab90d18bdb687d93723c51e9827be254a","externalIds":{"ArXiv":"2402.12563","DBLP":"journals/corr/abs-2402-12563","DOI":"10.48550/arXiv.2402.12563","CorpusId":268032763},"title":"Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models"},{"paperId":"440d8b87e158a352efa58d2630d8626640afefe6","externalIds":{"DBLP":"journals/corr/abs-2402-10890","ArXiv":"2402.10890","DOI":"10.48550/arXiv.2402.10890","CorpusId":267740392},"title":"When is Tree Search Useful for LLM Planning? It Depends on the Discriminator"},{"paperId":"46a5ec31987a12d60ade20c6471db64c46f90106","externalIds":{"ArXiv":"2402.10963","DBLP":"conf/icml/HavrillaRNDZHR24","DOI":"10.48550/arXiv.2402.10963","CorpusId":267750213},"title":"GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements"},{"paperId":"94701d9c6cfc1aecc174ff62ccda939f790c1710","externalIds":{"DBLP":"conf/icml/Stengel-EskinPB24","ArXiv":"2401.16467","DOI":"10.48550/arXiv.2401.16467","CorpusId":267320463},"title":"ReGAL: Refactoring Programs to Discover Generalizable Abstractions"},{"paperId":"08799ed4f55cf970dcadabcfd9c26855517160a3","externalIds":{"DBLP":"journals/corr/abs-2401-07301","ArXiv":"2401.07301","DOI":"10.48550/arXiv.2401.07301","CorpusId":266999677},"title":"Small Language Model Can Self-correct"},{"paperId":"028d75496e51943f52c7b2177344a3c089c18058","externalIds":{"DBLP":"journals/corr/abs-2401-06855","ArXiv":"2401.06855","DOI":"10.48550/arXiv.2401.06855","CorpusId":266999558},"title":"Fine-grained Hallucination Detection and Editing for Language Models"},{"paperId":"3528ddcd62575aa4fbfc06141b97b80ad34e7c66","externalIds":{"DBLP":"journals/corr/abs-2312-10160","ArXiv":"2312.10160","DOI":"10.48550/arXiv.2312.10160","CorpusId":266348592},"title":"Do LVLMs Understand Charts? Analyzing and Correcting Factual Errors in Chart Captioning"},{"paperId":"5f66d1a667eec13b5d337c3fc5619bcef95092bd","externalIds":{"DBLP":"journals/corr/abs-2311-17311","ArXiv":"2311.17311","DOI":"10.48550/arXiv.2311.17311","CorpusId":265498407},"title":"Universal Self-Consistency for Large Language Model Generation"},{"paperId":"b66abfe0bb08a81f682faf70dab19a11ceb35d6e","externalIds":{"DBLP":"journals/corr/abs-2311-12391","ArXiv":"2311.12391","DOI":"10.48550/arXiv.2311.12391","CorpusId":265309179},"title":"From Wrong To Right: A Recursive Approach Towards Vision-Language Explanation"},{"paperId":"2cc5a2e8e5e739dbc22fce6eb0242bda3acd7998","externalIds":{"ArXiv":"2311.08516","DBLP":"journals/corr/abs-2311-08516","DOI":"10.48550/arXiv.2311.08516","CorpusId":265213404},"title":"LLMs cannot find reasoning errors, but can correct them!"},{"paperId":"6233b5863f9a0e8bacce47ce21bc3e81c09497bd","externalIds":{"ACL":"2024.naacl-long.52","DBLP":"conf/naacl/Hong0P0Z24","ArXiv":"2311.07954","DOI":"10.48550/arXiv.2311.07954","CorpusId":265157446},"title":"A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning"},{"paperId":"de1894742b7f2e4fe02d9ff94761d6178e0a5d3c","externalIds":{"DBLP":"conf/naacl/LeePJS24","ACL":"2024.naacl-long.23","ArXiv":"2311.07362","DOI":"10.48550/arXiv.2311.07362","CorpusId":265150082},"title":"Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision"},{"paperId":"807f336176070bd3f95b82a16f125ee99b7d2c80","externalIds":{"DBLP":"journals/chinaf/YinFZXWSSLSC24","ArXiv":"2310.16045","DOI":"10.1007/s11432-024-4251-x","CorpusId":264439367},"title":"Woodpecker: hallucination correction for multimodal large language models"},{"paperId":"2218ab2653ed2ab651a03d98056e2d6ae1d99132","externalIds":{"ACL":"2024.naacl-long.462","DBLP":"conf/naacl/SahaLCBWL24","ArXiv":"2310.15123","DOI":"10.48550/arXiv.2310.15123","CorpusId":264591429},"title":"Branch-Solve-Merge Improves Large Language Model Evaluation and Generation"},{"paperId":"161b3e82567b9a9c6911171fa55f05695bf93217","externalIds":{"DBLP":"journals/corr/abs-2310-12397","ArXiv":"2310.12397","DOI":"10.48550/arXiv.2310.12397","CorpusId":264305982},"title":"GPT-4 Doesn't Know It's Wrong: An Analysis of Iterative Prompting for Reasoning Problems"},{"paperId":"20eecb9ead20ffe49a66588a9662336eefb20a54","externalIds":{"DBLP":"journals/corr/abs-2310-12426","ArXiv":"2310.12426","DOI":"10.48550/arXiv.2310.12426","CorpusId":264306325},"title":"MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models"},{"paperId":"ddbd8fe782ac98e9c64dd98710687a962195dd9b","externalIds":{"DBLP":"conf/iclr/AsaiWWSH24","ArXiv":"2310.11511","CorpusId":264288947},"title":"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"},{"paperId":"6d4bacb69923e1e94fb4de468b939ce6db32fb51","externalIds":{"DBLP":"conf/iclr/0009CMZYSZ24","ArXiv":"2310.01798","DOI":"10.48550/arXiv.2310.01798","CorpusId":263609132},"title":"Large Language Models Cannot Self-Correct Reasoning Yet"},{"paperId":"9fcdbfdf28245010c875ce85502351fe05c04b49","externalIds":{"ArXiv":"2310.02124","DBLP":"journals/corr/abs-2310-02124","DOI":"10.48550/arXiv.2310.02124","CorpusId":263608682},"title":"Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View"},{"paperId":"93c525267e93c78309a5b28a3eb0780704125744","externalIds":{"ArXiv":"2310.00754","DBLP":"conf/iclr/ZhouCYZDFBY24","DOI":"10.48550/arXiv.2310.00754","CorpusId":263334335},"title":"Analyzing and Mitigating Object Hallucination in Large Vision-Language Models"},{"paperId":"6f75e8b61f13562237851d8119cb2f9d49e073fb","externalIds":{"DBLP":"journals/corr/abs-2309-13788","ArXiv":"2309.13788","DOI":"10.48550/arXiv.2309.13788","CorpusId":262465354},"title":"Can LLM-Generated Misinformation Be Detected?"},{"paperId":"63549bf78e4b1e7e1cec505ce65e6e8f90474f41","externalIds":{"DBLP":"journals/corr/abs-2309-13007","ArXiv":"2309.13007","DOI":"10.48550/arXiv.2309.13007","CorpusId":262217323},"title":"ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs"},{"paperId":"4b0b56be0ae9479d2bd5c2f0943db1906343c10f","externalIds":{"DBLP":"journals/corr/abs-2309-11495","ArXiv":"2309.11495","DOI":"10.48550/arXiv.2309.11495","CorpusId":262062565},"title":"Chain-of-Verification Reduces Hallucination in Large Language Models"},{"paperId":"f8a2dca1e8fe56e698984c077f7ff58d8ca867e9","externalIds":{"DBLP":"journals/corr/abs-2309-03409","ArXiv":"2309.03409","DOI":"10.48550/arXiv.2309.03409","CorpusId":261582296},"title":"Large Language Models as Optimizers"},{"paperId":"eee548fbd0b9dd954c692fbd8880e80d5f077bd7","externalIds":{"ArXiv":"2308.11764","DBLP":"journals/corr/abs-2308-11764","DOI":"10.48550/arXiv.2308.11764","CorpusId":261076218},"title":"Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models"},{"paperId":"182c7b40ff7560a5545764814338f55a2098e441","externalIds":{"ArXiv":"2308.08998","DBLP":"journals/corr/abs-2308-08998","CorpusId":261031028},"title":"Reinforced Self-Training (ReST) for Language Modeling"},{"paperId":"2cdd5c3dc42c0df40bc8839709869af3560d4bfe","externalIds":{"DBLP":"journals/corr/abs-2308-07308","ArXiv":"2308.07308","DOI":"10.48550/arXiv.2308.07308","CorpusId":260887487},"title":"LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked"},{"paperId":"ec58a564fdda29e6a9a0a7bab5eeb4c290f716d7","externalIds":{"ArXiv":"2308.07201","DBLP":"journals/corr/abs-2308-07201","DOI":"10.48550/arXiv.2308.07201","CorpusId":260887105},"title":"ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate"},{"paperId":"19443d48399d4fe89a4b0a96917c50c6fd9c5af1","externalIds":{"DBLP":"journals/corr/abs-2308-04265","ArXiv":"2308.04265","ACL":"2024.emnlp-main.41","DOI":"10.48550/arXiv.2308.04265","CorpusId":260704223},"title":"FLIRT: Feedback Loop In-context Red Teaming"},{"paperId":"1e6102c981b9464c632ef0b00dbd11dfb0564e4e","externalIds":{"DBLP":"conf/iclr/MiaoTR24","ArXiv":"2308.00436","DOI":"10.48550/arXiv.2308.00436","CorpusId":260350986},"title":"SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning"},{"paperId":"7a5b44ea10a51708e18786595c8d70b18950da11","externalIds":{"DBLP":"journals/corr/abs-2307-13528","ArXiv":"2307.13528","DOI":"10.48550/arXiv.2307.13528","CorpusId":260154834},"title":"FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios"},{"paperId":"1827dd28ef866eaeb929ddf4bcfa492880aba4c7","externalIds":{"DBLP":"journals/corr/abs-2307-03987","ArXiv":"2307.03987","DOI":"10.48550/arXiv.2307.03987","CorpusId":263699899},"title":"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation"},{"paperId":"130d18d1d455336e1a5b06c85784894bb67d87ec","externalIds":{"ArXiv":"2307.02762","DBLP":"journals/corr/abs-2307-02762","DOI":"10.48550/arXiv.2307.02762","CorpusId":259360619},"title":"PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations"},{"paperId":"1cd56940219a968a04eb61b8bc53f4cd3f9822d4","externalIds":{"DBLP":"conf/iclr/OlaussonIW0S24","ArXiv":"2306.09896","CorpusId":259187989},"title":"Is Self-Repair a Silver Bullet for Code Generation?"},{"paperId":"bf4810017b54e50354cccffd8966121c7166cb17","externalIds":{"ArXiv":"2306.03856","DBLP":"journals/corr/abs-2306-03856","ACL":"2024.eamt-1.17","DOI":"10.48550/arXiv.2306.03856","CorpusId":259088848},"title":"Iterative Translation Refinement with Large Language Models"},{"paperId":"eb36681fc4c5dfce4f3e05540fc92b007de278ca","externalIds":{"ArXiv":"2306.02907","DBLP":"journals/corr/abs-2306-02907","DOI":"10.48550/arXiv.2306.02907","CorpusId":259076266},"title":"SelfEvolve: A Code Evolution Framework via Large Language Models"},{"paperId":"be8db99310602d66bba64bcf41a572c45816fbfc","externalIds":{"ArXiv":"2305.20050","DBLP":"conf/iclr/LightmanKBEBLLS24","DOI":"10.48550/arXiv.2305.20050","CorpusId":258987659},"title":"Let's Verify Step by Step"},{"paperId":"385c74957858e7d6856d48e72b5a902b4c1aa28c","externalIds":{"DBLP":"journals/corr/abs-2305-19118","ACL":"2024.emnlp-main.992","ArXiv":"2305.19118","DOI":"10.48550/arXiv.2305.19118","CorpusId":258967540},"title":"Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate"},{"paperId":"34e1a8a75bf6f35084ac6d714a136f39d02c649e","externalIds":{"ArXiv":"2306.00024","DBLP":"journals/corr/abs-2306-00024","DOI":"10.48550/arXiv.2306.00024","CorpusId":258999642},"title":"Self-Verification Improves Few-Shot Clinical Information Extraction"},{"paperId":"f542c184eec4c3252d678118a7f32cf327b6f23a","externalIds":{"DBLP":"conf/ast/TihanyiCJFC25","ArXiv":"2305.14752","DOI":"10.1109/AST66626.2025.00020","CorpusId":258865418},"title":"A New Era in Software Security: Towards Self-Healing Software via Large Language Models and Formal Verification"},{"paperId":"0476eaae29c0337c1498637ad99931e4d9d1c5df","externalIds":{"DBLP":"conf/emnlp/RaunakSWAM23","ArXiv":"2305.14878","DOI":"10.48550/arXiv.2305.14878","CorpusId":258865299},"title":"Leveraging GPT-4 for Automatic Translation Post-Editing"},{"paperId":"5dbffedcabe3fa43060ebbe2b1789500edfd871f","externalIds":{"DBLP":"conf/emnlp/HaoGMHWWH23","ArXiv":"2305.14992","DOI":"10.48550/arXiv.2305.14992","CorpusId":258865812},"title":"Reasoning with Language Model is Planning with World Model"},{"paperId":"4780d0a027c5c5a8e01d7cf697f6296880ffc945","externalIds":{"ArXiv":"2305.14325","DBLP":"journals/corr/abs-2305-14325","DOI":"10.48550/arXiv.2305.14325","CorpusId":258841118},"title":"Improving Factuality and Reasoning in Language Models through Multiagent Debate"},{"paperId":"c226a4acb42912054d498bcf771023b0ba2da001","externalIds":{"DBLP":"conf/iclr/PangWLC0Z024","ArXiv":"2305.14483","DOI":"10.48550/arXiv.2305.14483","CorpusId":258865735},"title":"Language Model Self-improvement by Reinforcement Learning Contemplation"},{"paperId":"4115a24474ef5f184f5cbae3f43aca4d3bb07bea","externalIds":{"ArXiv":"2305.14002","DBLP":"journals/corr/abs-2305-14002","DOI":"10.48550/arXiv.2305.14002","CorpusId":258841029},"title":"Improving Language Models via Plug-and-Play Retrieval Feedback"},{"paperId":"bd5deadc58ee45b5e004378ba1d54a96bc947b4a","externalIds":{"ArXiv":"2305.14251","DBLP":"conf/emnlp/MinKLLYKIZH23","DOI":"10.48550/arXiv.2305.14251","CorpusId":258841470},"title":"FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation"},{"paperId":"6825ba09383bc758f9a2feaebabe35a6cd4adc4c","externalIds":{"DBLP":"conf/icml/ZhangPMLS24","ArXiv":"2305.13534","DOI":"10.48550/arXiv.2305.13534","CorpusId":258841857},"title":"How Language Model Hallucinations Can Snowball"},{"paperId":"ed0ed87161a2beab9e1bed3e783d7487a5f1062a","externalIds":{"ArXiv":"2305.13281","DBLP":"conf/emnlp/CohenHGG23","DOI":"10.48550/arXiv.2305.13281","CorpusId":258833288},"title":"LM vs LM: Detecting Factual Errors via Cross Examination"},{"paperId":"9e9e4df2996bac794c4f04cb887df3e553bae4fd","externalIds":{"DBLP":"conf/emnlp/PanAWW23","ArXiv":"2305.12295","DOI":"10.48550/arXiv.2305.12295","CorpusId":258833332},"title":"Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning"},{"paperId":"bcdaf6c98ddbd6809cf6241aa77200d7394db163","externalIds":{"DBLP":"conf/iclr/GouSGSYDC24","ArXiv":"2305.11738","DOI":"10.48550/arXiv.2305.11738","CorpusId":258823123},"title":"CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing"},{"paperId":"2f3822eb380b5e753a6d579f31dfc3ec4c4a0820","externalIds":{"ArXiv":"2305.10601","DBLP":"journals/corr/abs-2305-10601","DOI":"10.48550/arXiv.2305.10601","CorpusId":258762525},"title":"Tree of Thoughts: Deliberate Problem Solving with Large Language Models"},{"paperId":"ebf35cef5c249d90b40043fffa41f8802c27f132","externalIds":{"DBLP":"conf/acl/AkyurekAKCWT23","ArXiv":"2305.08844","ACL":"2023.acl-long.427","DOI":"10.48550/arXiv.2305.08844","CorpusId":258685337},"title":"RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs"},{"paperId":"5471114e37448bea2457b74894b1ecb92bbcfdf6","externalIds":{"DBLP":"conf/acl/FengPLT23","ArXiv":"2305.08283","ACL":"2023.acl-long.656","DOI":"10.48550/arXiv.2305.08283","CorpusId":258686693},"title":"From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models"},{"paperId":"88884b8806262a4095036041e3567d450dba39f7","externalIds":{"DBLP":"journals/corr/abs-2305-06983","ArXiv":"2305.06983","DOI":"10.48550/arXiv.2305.06983","CorpusId":258615731},"title":"Active Retrieval Augmented Generation"},{"paperId":"2f0028060a3a3187d3cbecc3b423dbcf8c8387c3","externalIds":{"ACL":"2023.acl-long.45","ArXiv":"2305.04087","DBLP":"conf/acl/ZhangLLLJ23","DOI":"10.48550/arXiv.2305.04087","CorpusId":258557186},"title":"Self-Edit: Fault-Aware Code Editor for Code Generation"},{"paperId":"629c441076da3f8185b1cf85e8036064b714e249","externalIds":{"DBLP":"conf/acl/ZhaoLJQB23","ACL":"2023.acl-long.320","ArXiv":"2305.03268","DOI":"10.48550/arXiv.2305.03268","CorpusId":258547173},"title":"Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework"},{"paperId":"c76dd4a70361c3afd2e19d046343e2dedd16ecc3","externalIds":{"DBLP":"conf/emnlp/PryzantI0L0023","ArXiv":"2305.03495","DOI":"10.48550/arXiv.2305.03495","CorpusId":258546785},"title":"Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search"},{"paperId":"03055978e278960de9fbb5c648b1779ef9f26cd1","externalIds":{"ArXiv":"2305.01937","DBLP":"conf/acl/ChiangL23","ACL":"2023.acl-long.870","DOI":"10.48550/arXiv.2305.01937","CorpusId":258461287},"title":"Can Large Language Models Be an Alternative to Human Evaluations?"},{"paperId":"ef018d9fad6167cfddb7d6654c5422df1e953730","externalIds":{"ArXiv":"2305.00633","DBLP":"conf/nips/XieKZZKHX23","CorpusId":258426922},"title":"Self-Evaluation Guided Beam Search for Reasoning"},{"paperId":"9e3c493fb09dcd61bb05e8c5659f23327b7b6340","externalIds":{"ArXiv":"2304.05128","DBLP":"journals/corr/abs-2304-05128","DOI":"10.48550/arXiv.2304.05128","CorpusId":258059885},"title":"Teaching Large Language Models to Self-Debug"},{"paperId":"c715914c388fa64dd8686cd8755e5adfebbf2388","externalIds":{"DBLP":"journals/corr/abs-2304-01904","ArXiv":"2304.01904","ACL":"2024.eacl-long.67","DOI":"10.48550/arXiv.2304.01904","CorpusId":257921623},"title":"REFINER: Reasoning Feedback on Intermediate Representations"},{"paperId":"3aaf6a2cbad5850ad81ab5c163599cb3d523436f","externalIds":{"DBLP":"journals/corr/abs-2303-17651","ArXiv":"2303.17651","DOI":"10.48550/arXiv.2303.17651","CorpusId":257900871},"title":"Self-Refine: Iterative Refinement with Self-Feedback"},{"paperId":"9a75e23639bfcc3a51da57a3b682a984d1d8ac0b","externalIds":{"ArXiv":"2303.17491","DBLP":"conf/nips/KimBM23","DOI":"10.48550/arXiv.2303.17491","CorpusId":257834038},"title":"Language Models can Solve Computer Tasks"},{"paperId":"381ab7a640f5b46b62f7e08d1af4a8e0d3eadd55","externalIds":{"DBLP":"conf/emnlp/LiuIXWXZ23","ArXiv":"2303.16634","DOI":"10.18653/v1/2023.emnlp-main.153","CorpusId":257804696},"title":"G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment"},{"paperId":"0671fd553dd670a4e820553a974bc48040ba0819","externalIds":{"DBLP":"conf/nips/ShinnCGNY23","ArXiv":"2303.11366","CorpusId":258833055},"title":"Reflexion: language agents with verbal reinforcement learning"},{"paperId":"7c1707db9aafd209aa93db3251e7ebd593d55876","externalIds":{"DBLP":"conf/emnlp/ManakulLG23","ArXiv":"2303.08896","DOI":"10.48550/arXiv.2303.08896","CorpusId":257557820},"title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"},{"paperId":"9f8ac6ee3760ab202e492c733362e5bfc6763934","externalIds":{"DBLP":"conf/sigsoft/FirstRRB23","ArXiv":"2303.04910","DOI":"10.1145/3611643.3616243","CorpusId":257427444},"title":"Baldur: Whole-Proof Generation and Repair with Large Language Models"},{"paperId":"e5c72b92c48d68594b290c84a8904da7c8335554","externalIds":{"ArXiv":"2302.12813","DBLP":"journals/corr/abs-2302-12813","DOI":"10.48550/arXiv.2302.12813","CorpusId":257205781},"title":"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"},{"paperId":"59fe7cb560651281cfc5db6b8940da0e3ba9dea6","externalIds":{"DBLP":"journals/corr/abs-2302-08468","ArXiv":"2302.08468","DOI":"10.48550/arXiv.2302.08468","CorpusId":256900680},"title":"LEVER: Learning to Verify Language-to-Code Generation with Execution"},{"paperId":"40c318400809abf5e50aba5a5a80c8012a7715d5","externalIds":{"DBLP":"conf/naacl/FuNJ024","ArXiv":"2302.04166","ACL":"2024.naacl-long.365","DOI":"10.18653/v1/2024.naacl-long.365","CorpusId":256662188},"title":"GPTScore: Evaluate as You Desire"},{"paperId":"7715ba5e75f5256e1061c7473afe61bb0dbb9065","externalIds":{"ArXiv":"2212.09561","DBLP":"conf/emnlp/WengZX0HLSLZ23","DOI":"10.18653/v1/2023.findings-emnlp.167","CorpusId":258840837},"title":"Large Language Models are Better Reasoners with Self-Verification"},{"paperId":"3936fd3c6187f606c6e4e2e20b196dbc41cc4654","externalIds":{"DBLP":"journals/corr/abs-2212-08073","ArXiv":"2212.08073","DOI":"10.48550/arXiv.2212.08073","CorpusId":254823489},"title":"Constitutional AI: Harmlessness from AI Feedback"},{"paperId":"27961ae80ad008bd4006704b1b8fa82664137d69","externalIds":{"ArXiv":"2211.16490","DBLP":"conf/icml/ZhangYHLYF023","DOI":"10.48550/arXiv.2211.16490","CorpusId":254069951},"title":"Coder Reviewer Reranking for Code Generation"},{"paperId":"6d7b8a478801bd9d21df82d5f33ae6eced90da5e","externalIds":{"DBLP":"journals/corr/abs-2211-14275","ArXiv":"2211.14275","DOI":"10.48550/arXiv.2211.14275","CorpusId":254017497},"title":"Solving math word problems with process- and outcome-based feedback"},{"paperId":"538288d24bdad73d831dfed44b706958287ed318","externalIds":{"ArXiv":"2211.00053","DBLP":"conf/iclr/WelleckLWBSK023","DOI":"10.48550/arXiv.2211.00053","CorpusId":253244506},"title":"Generating Sequences by Learning to Self-Correct"},{"paperId":"d400a649f0f0a3de22b89a268f48aff2dcb06a09","externalIds":{"ArXiv":"2210.12217","DBLP":"journals/corr/abs-2210-12217","ACL":"2022.emnlp-main.134","DOI":"10.48550/arXiv.2210.12217","CorpusId":253097865},"title":"Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning"},{"paperId":"3fa70115248377c3d1517c9f978791a296fbc1dd","externalIds":{"DBLP":"conf/emnlp/0001GHW00023","ArXiv":"2210.11610","DOI":"10.48550/arXiv.2210.11610","CorpusId":253080328},"title":"Large Language Models Can Self-Improve"},{"paperId":"66242baf48b0f6b828e7547ac39ffaa5e1b2cb3e","externalIds":{"ArXiv":"2210.08726","DBLP":"conf/acl/GaoDPCCFZLLJG23","ACL":"2023.acl-long.910","DOI":"10.18653/v1/2023.acl-long.910","CorpusId":254247260},"title":"RARR: Researching and Revising What Language Models Say, Using Language Models"},{"paperId":"cdecefa737544971b72c5b5ef60f9eb9772fa051","externalIds":{"DBLP":"journals/corr/abs-2210-06774","ACL":"2022.emnlp-main.296","ArXiv":"2210.06774","DOI":"10.48550/arXiv.2210.06774","CorpusId":252873593},"title":"Re3: Generating Longer Stories With Recursive Reprompting and Revision"},{"paperId":"f0a0e8b6e84207f50db4d24cc4016e40601214ef","externalIds":{"ArXiv":"2208.14271","DBLP":"journals/corr/abs-2208-14271","CorpusId":251929296},"title":"Faithful Reasoning Using Large Language Models"},{"paperId":"a938ff4539b09a785a66669844f1a35f76169218","externalIds":{"DBLP":"journals/corr/abs-2208-11663","ArXiv":"2208.11663","DOI":"10.48550/arXiv.2208.11663","CorpusId":251765117},"title":"PEER: A Collaborative Language Model"},{"paperId":"876eb375cb7b365475040046df669c039ad54202","externalIds":{"DBLP":"journals/corr/abs-2207-10397","ArXiv":"2207.10397","DOI":"10.48550/arXiv.2207.10397","CorpusId":250920542},"title":"CodeT: Code Generation with Generated Tests"},{"paperId":"6d994b4f5a46cd14e8f09f1e9e49120546b15e31","externalIds":{"ArXiv":"2207.01780","DBLP":"journals/corr/abs-2207-01780","DOI":"10.48550/arXiv.2207.01780","CorpusId":250280117},"title":"CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning"},{"paperId":"8a13d58ce02734f92dcc787272afbea4bbc7f09f","externalIds":{"ArXiv":"2206.08325","DBLP":"conf/nips/RauhMUHWWDGIGIH22","DOI":"10.48550/arXiv.2206.08325","CorpusId":249712372},"title":"Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models"},{"paperId":"29acc890e521f7a6415666ab9eb3432c49b4587a","externalIds":{"DBLP":"journals/corr/abs-2206-05802","ArXiv":"2206.05802","DOI":"10.48550/arXiv.2206.05802","CorpusId":249626555},"title":"Self-critiquing models for assisting human evaluators"},{"paperId":"196cc546041cb6db167784f632037f0a1dcf4a79","externalIds":{"ACL":"2022.emnlp-main.7","ArXiv":"2205.12443","DBLP":"conf/emnlp/Yang0C22","DOI":"10.48550/arXiv.2205.12443","CorpusId":249062748},"title":"Generating Natural Language Proofs with Verifier-Guided Search"},{"paperId":"50b0c6ee2b3d53ba5af69d6c00b5d60888a9026f","externalIds":{"DBLP":"conf/emnlp/JungQWBB0C22","ArXiv":"2205.11822","ACL":"2022.emnlp-main.82","DOI":"10.48550/arXiv.2205.11822","CorpusId":249017524},"title":"Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations"},{"paperId":"47e15941c8b157873c8264e4bf50318d1ba5cd18","externalIds":{"DBLP":"journals/corr/abs-2204-11454","ACL":"2022.emnlp-main.231","ArXiv":"2204.11454","DOI":"10.48550/arXiv.2204.11454","CorpusId":248377325},"title":"Natural Language to Code Translation with Execution"},{"paperId":"23dd78e424d32f6a48660dcd67ce994b8a7db8be","externalIds":{"ArXiv":"2203.14465","CorpusId":247762790},"title":"STaR: Bootstrapping Reasoning With Reasoning"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"23c265ba884b92ecbd9d18641078d964697e4590","externalIds":{"ArXiv":"2202.04538","DBLP":"journals/corr/abs-2202-04538","CorpusId":246680398},"title":"Generating Training Data with Language Models: Towards Zero-Shot Language Understanding"},{"paperId":"e2a193a191290fa60ac39748eeb1118ff44b9129","externalIds":{"DBLP":"journals/corr/abs-2112-08634","ArXiv":"2112.08634","ACL":"2022.naacl-main.269","DOI":"10.18653/v1/2022.naacl-main.269","CorpusId":245218924},"title":"FRUIT: Faithfully Reflecting Updated Information in Text"},{"paperId":"d6045d2ccc9c09ca1671348de86d07da6bc28eea","externalIds":{"ArXiv":"2110.14168","DBLP":"journals/corr/abs-2110-14168","CorpusId":239998651},"title":"Training Verifiers to Solve Math Word Problems"},{"paperId":"4698fc4712f0212c8a3810fd67b41ee8b8896aba","externalIds":{"DBLP":"journals/corr/abs-2109-03034","ArXiv":"2109.03034","DOI":"10.18653/v1/2021.findings-emnlp.195","CorpusId":237434245},"title":"Generate & Rank: A Multi-task Framework for Math Word Problems"},{"paperId":"a989f5daa7c438d6b8433efbb1461f1b0af1aa8e","externalIds":{"DBLP":"conf/icml/YasunagaL21","ArXiv":"2106.06600","CorpusId":235421942},"title":"Break-It-Fix-It: Unsupervised Learning for Program Repair"},{"paperId":"6ca07b95e6b68798e89888d3c2f5f43938feb419","externalIds":{"DBLP":"conf/emnlp/ScialomDLPSWG21","ArXiv":"2103.12693","ACL":"2021.emnlp-main.529","DOI":"10.18653/v1/2021.emnlp-main.529","CorpusId":233219059},"title":"QuestEval: Summarization Asks for Fact-based Evaluation"},{"paperId":"ce9ca56036307217ea565644d3d3bd74b879e045","externalIds":{"DBLP":"journals/tacl/SchickUS21","ArXiv":"2103.00453","DOI":"10.1162/tacl_a_00434","CorpusId":232075876},"title":"Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP"},{"paperId":"03cb8234036dedd356901f574c1771a88e3578d8","externalIds":{"DBLP":"conf/acl/Thorne020","ArXiv":"2012.15788","ACL":"2021.acl-long.256","DOI":"10.18653/v1/2021.acl-long.256","CorpusId":235294035},"title":"Evidence-based Factual Error Correction"},{"paperId":"d030535287d17cfd215048354c928aa69ca60c62","externalIds":{"MAG":"3102645206","ACL":"2020.emnlp-main.506","DBLP":"conf/emnlp/CaoDWC20","ArXiv":"2010.08712","DOI":"10.18653/v1/2020.emnlp-main.506","CorpusId":224706057},"title":"Factual Error Correction for Abstractive Summarization Models"},{"paperId":"d47a682723f710395454687319bb55635e653105","externalIds":{"DBLP":"journals/corr/abs-2005-14050","MAG":"3032388710","ArXiv":"2005.14050","ACL":"2020.acl-main.485","DOI":"10.18653/v1/2020.acl-main.485","CorpusId":218971825},"title":"Language (Technology) is Power: A Critical Survey of “Bias” in NLP"},{"paperId":"02417d57dec9215a0b66a63e9a70571c168de54b","externalIds":{"MAG":"3027453785","ArXiv":"2005.10636","DBLP":"conf/icml/YasunagaL20","CorpusId":218763496},"title":"Graph-based, Self-Supervised Program Repair from Diagnostic Feedback"},{"paperId":"11b6d1fee0f47a8f9f892ab0d86f370c449097aa","externalIds":{"MAG":"3099766584","DBLP":"journals/corr/abs-2005-03754","ACL":"2020.acl-main.454","ArXiv":"2005.03754","DOI":"10.18653/V1/2020.ACL-MAIN.454","CorpusId":218571335},"title":"FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization"},{"paperId":"d36e39aedd802aea4be1ea303c70dc56e97dbc3c","externalIds":{"ArXiv":"2004.04228","ACL":"2020.acl-main.450","DBLP":"journals/corr/abs-2004-04228","MAG":"3034188538","DOI":"10.18653/v1/2020.acl-main.450","CorpusId":215548661},"title":"Asking and Answering Questions to Evaluate the Factual Consistency of Summaries"},{"paperId":"3d8413b64f45bb6f944e1063d83168e0eeb128b1","externalIds":{"DBLP":"conf/aaai/ShahSB20","MAG":"2998112083","ArXiv":"1909.13838","DOI":"10.1609/AAAI.V34I05.6406","CorpusId":203593563},"title":"Automatic Fact-guided Sentence Modification"},{"paperId":"558b72b9e7a1e4d6633c2836aba5896354d37d24","externalIds":{"DBLP":"conf/sigsoft/0001RJGA19","MAG":"2967096374","DOI":"10.1145/3338906.3340455","CorpusId":199501739},"title":"DeepDelta: learning to repair compilation errors"},{"paperId":"fcae82bd4a5fbe2542533cea5ccf1a795c9f64c6","externalIds":{"ACL":"N19-1333","ArXiv":"1904.05780","DBLP":"conf/naacl/LichtargeAKSPT19","MAG":"2952637312","DOI":"10.18653/v1/N19-1333","CorpusId":118680003},"title":"Corpora Generation for Grammatical Error Correction"},{"paperId":"b2e69e3a07e9137c0f9bad57940a16adfede27d2","externalIds":{"DOI":"10.4324/9780429057380-7","CorpusId":242266619},"title":"Engaging"},{"paperId":"bad5015c6183d7f74d91ea54f3580aaadc10fa9e","externalIds":{"ArXiv":"1902.06111","MAG":"2979679630","DBLP":"journals/corr/abs-1902-06111","DOI":"10.1145/3360585","CorpusId":67750638},"title":"Getafix: learning to fix bugs automatically"},{"paperId":"59cc0871534a20ac98db0663539c6675ab63566f","externalIds":{"DBLP":"journals/tse/ChenKTPPM21","ArXiv":"1901.01808","MAG":"2973195800","DOI":"10.1109/TSE.2019.2940179","CorpusId":57573711},"title":"SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair"},{"paperId":"554c9b3aa8c3b7504810270b18b942a0d22156e7","externalIds":{"DBLP":"conf/aaai/GuptaPKS17","MAG":"2605202003","DOI":"10.1609/aaai.v31i1.10742","CorpusId":29157253},"title":"DeepFix: Fixing Common C Language Errors by Deep Learning"},{"paperId":"20499f3c6fe9f84a12c9def941e2e12846a00c77","externalIds":{"DBLP":"conf/conll/NgWBHSB14","MAG":"2098297786","ACL":"W14-1701","DOI":"10.3115/v1/W14-1701","CorpusId":219306476},"title":"The CoNLL-2014 Shared Task on Grammatical Error Correction"},{"paperId":"90315d5929b1f147f565bc18e0a01d7fdfeb2e74","externalIds":{"DOI":"10.1300/J237v07n02_09","CorpusId":216112094},"title":"Canada"},{"paperId":"ba6e3b28090d935205ed0e1d398206906b5b8905","externalIds":{"DOI":"10.1177/000134559903900301","CorpusId":220057900},"title":"Linguistics"},{"paperId":"99d4f4430461a38241617df52bc05717fdb851df","externalIds":{"DBLP":"journals/corr/abs-2405-14092","DOI":"10.48550/arXiv.2405.14092","CorpusId":269983298},"title":"Large Language Models Can Self-Correct with Minimal Effort"},{"paperId":"9e3d14e4697a325fcabc6d952232a3ad7e9fa809","externalIds":{"DBLP":"journals/corr/abs-2404-04298","DOI":"10.48550/arXiv.2404.04298","CorpusId":269005582},"title":"SELF-[IN]CORRECT: LLMs Struggle with Refining Self-Generated Responses"},{"paperId":"c43a6f12b062a50617244611af180a8146e792de","externalIds":{"DBLP":"journals/tmlr/ChenSCKCBCP24","DOI":"10.48550/arXiv.2204.14146","CorpusId":248476121},"title":"Learning from Natural Language Feedback"},{"paperId":"460609e217fd59eaa34f5e11a820661f8ec8d7b6","externalIds":{"DBLP":"conf/emnlp/XuWPSFWL23","DOI":"10.48550/arXiv.2305.14282","CorpusId":258841553},"title":"INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback"},{"paperId":"68b13366ee7d0e398c2b8736cb8d42052ffbe190","externalIds":{"MAG":"2307125025","CorpusId":61801686},"title":"Empirical Methods in Natural Language Processing"}]}