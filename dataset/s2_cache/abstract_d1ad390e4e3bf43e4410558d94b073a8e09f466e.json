{"abstract":"Cross-lingual N-shot transfers are often used to solve low-resource language problems. However, the result of transfer in different languages can be inconsistent due to large fluctuations in accuracy. To reduce the inconsistency caused by the fluctuation of accuracy and improve the overall accuracy of Cross-lingual N-shot transfer, we propose the use of Multitasking Cross-lingual N-shot transfer. To the best of our knowledge, our propose Multitasking Cross-lingual N-shot transfer is the first method to combine Multitasking Learning and Cross-lingual N-shot transfer. By training with multiple languages simultaneously, the model can learn multilingual common semantic features from different languages, decreasing the fluctuations in accuracy, and also having a higher overall accuracy compared to traditional method with single high-resource language. The method presented in this paper can effectively reduce 93.2% of the accuracy fluctuations and improve the overall accuracy by 10.4% in NLI."}