{"paperId":"9761bcf49892601a3bec07d616c13c7f8bb7ac6c","externalIds":{"DBLP":"journals/corr/abs-2402-17525","ArXiv":"2402.17525","DOI":"10.1109/TPAMI.2025.3541625","CorpusId":268033671,"PubMed":"40031849"},"title":"Diffusion Model-Based Image Editing: A Survey","openAccessPdf":{"url":"http://arxiv.org/pdf/2402.17525","status":"GREEN","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2402.17525, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2249841594","name":"Yi Huang"},{"authorId":"2194958029","name":"Jiancheng Huang"},{"authorId":"2247959941","name":"Yifan Liu"},{"authorId":"2267694301","name":"Mingfu Yan"},{"authorId":"2154657214","name":"Jiaxi Lv"},{"authorId":"2267504760","name":"Jianzhuang Liu"},{"authorId":"2273646978","name":"Wei Xiong"},{"authorId":"2274091009","name":"He Zhang"},{"authorId":"2247480051","name":"Shifeng Chen"},{"authorId":"2288206453","name":"Liangliang Cao"}],"abstract":"Denoising diffusion models have emerged as a powerful tool for various image generation and editing tasks, facilitating the synthesis of visual content in an unconditional or input-conditional manner. The core idea behind them is learning to reverse the process of gradually adding noise to images, allowing them to generate high-quality samples from a complex distribution. In this survey, we provide an exhaustive overview of existing methods using diffusion models for image editing, covering both theoretical and practical aspects in the field. We delve into a thorough analysis and categorization of these works from multiple perspectives, including learning strategies, user-input conditions, and the array of specific editing tasks that can be accomplished. In addition, we pay special attention to image inpainting and outpainting, and explore both earlier traditional context-driven and current multimodal conditional methods, offering a comprehensive analysis of their methodologies. To further evaluate the performance of text-guided image editing algorithms, we propose a systematic benchmark, EditEval, featuring an innovative metric, LMM Score. Finally, we address current limitations and envision some potential directions for future research."}