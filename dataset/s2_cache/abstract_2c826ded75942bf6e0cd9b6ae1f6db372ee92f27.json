{"abstract":"The goal of continual learning (CL) is to learn a sequence of tasks\nwithout suffering from the phenomenon of catastrophic forgetting.\nPrevious work has shown that leveraging memory in the form of a replay\nbuffer can reduce performance degradation on prior tasks. We hypothesize\nthat forgetting can be further reduced when the model is encouraged to\nremember the evidence for previously made decisions. As a first\nstep towards exploring this hypothesis, we propose a simple novel\ntraining paradigm, called Remembering for the Right Reasons (RRR), that\nadditionally stores visual model explanations for each example in the\nbuffer and ensures the model has “the right reasons” for its\npredictions by encouraging its explanations to remain consistent with\nthose used to make decisions at training time. Without this constraint,\nthere is a drift in explanations and increase in forgetting as\nconventional continual learning algorithms learn new tasks. We\ndemonstrate how RRR can be easily added to any memory or\nregularization-based approach and results in reduced forgetting, and\nmore importantly, improved model explanations. We have evaluated our\napproach in the standard and few-shot settings and observed a consistent\nimprovement across various CL approaches using different architectures\nand techniques to generate model explanations and demonstrated our\napproach showing a promising connection between explainability and\ncontinual learning. Our code is available at\n\\url{https://github.com/SaynaEbrahimi/Remembering-for-the-Right-Reasons}"}