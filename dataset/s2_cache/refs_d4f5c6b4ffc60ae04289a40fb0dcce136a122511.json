{"references":[{"paperId":"bb525aab2e9e86c6ed324494c4565c05946d67ae","externalIds":{"DBLP":"journals/corr/abs-2509-02350","ArXiv":"2509.02350","DOI":"10.48550/arXiv.2509.02350","CorpusId":281079410},"title":"Implicit Reasoning in Large Language Models: A Comprehensive Survey"},{"paperId":"019cfc087c4294221cf2ba3d16f2318a419741d6","externalIds":{"DBLP":"journals/corr/abs-2507-22928","ArXiv":"2507.22928","DOI":"10.48550/arXiv.2507.22928","CorpusId":280401325},"title":"How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding"},{"paperId":"3adc9915763e550eecb0a9a200e66392b73e9fd3","externalIds":{"DBLP":"journals/corr/abs-2506-19095","ArXiv":"2506.19095","DOI":"10.48550/arXiv.2506.19095","CorpusId":280000176},"title":"Baba is LLM: Reasoning in a Game with Dynamic Rules"},{"paperId":"a6254ba16e8908796cf145d5f70cb60a53edabf3","externalIds":{"DBLP":"conf/ifaamas/KempinskiGLLBK25","DOI":"10.5555/3709347.3743629","CorpusId":280336975},"title":"Game of Thoughts: Iterative Reasoning in Game-Theoretic Domains with Large Language Models"},{"paperId":"b53ecadabdb4ab11b0e404a40610ecaa5f9a5447","externalIds":{"DBLP":"journals/jair/PlaatDSPPB25","ArXiv":"2503.23037","DOI":"10.1613/jair.1.18675","CorpusId":277451794},"title":"Agentic Large Language Models, a survey"},{"paperId":"1a462dd4acb1efd98d6804f997e082867d021c31","externalIds":{"ArXiv":"2503.12918","DBLP":"journals/corr/abs-2503-12918","DOI":"10.48550/arXiv.2503.12918","CorpusId":277065581},"title":"ThinkPatterns-21k: A Systematic Study on the Impact of Thinking Patterns in LLMs"},{"paperId":"7e0f8f026f6ccc79a16fe7d3e5a891478ed2e413","externalIds":{"DBLP":"journals/corr/abs-2502-07978","ArXiv":"2502.07978","DOI":"10.48550/arXiv.2502.07978","CorpusId":276287353},"title":"A Survey of In-Context Reinforcement Learning"},{"paperId":"ef8a8bd193b1a0a5e2c834a7a28869a2ec85bab7","externalIds":{"DBLP":"conf/emnlp/MuennighoffYSLFHZLCH25","ArXiv":"2501.19393","DOI":"10.48550/arXiv.2501.19393","CorpusId":276079693},"title":"s1: Simple test-time scaling"},{"paperId":"a99dee9602e21a71526b9681d8dba37c55b66941","externalIds":{"DBLP":"journals/corr/abs-2501-17161","ArXiv":"2501.17161","DOI":"10.48550/arXiv.2501.17161","CorpusId":275932560},"title":"SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training"},{"paperId":"668075792a7ab40457d92e09da28d35c879271c3","externalIds":{"DBLP":"journals/corr/abs-2501-12599","ArXiv":"2501.12599","DOI":"10.48550/arXiv.2501.12599","CorpusId":275789974},"title":"Kimi k1.5: Scaling Reinforcement Learning with LLMs"},{"paperId":"2eed1fad9bbf887d4395de40f20144c4fafefd7f","externalIds":{"PubMedCentral":"12443585","DBLP":"journals/nature/GuoYZSWZXZMBZY025","ArXiv":"2501.12948","DOI":"10.1038/s41586-025-09422-z","CorpusId":275789950,"PubMed":"40962978"},"title":"DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning"},{"paperId":"0a42291d9543eabe33f6c14278333484071a707c","externalIds":{"DBLP":"conf/acl/WangHDZBY025","ArXiv":"2412.16145","DOI":"10.48550/arXiv.2412.16145","CorpusId":274965107},"title":"Offline Reinforcement Learning for LLM Multi-Step Reasoning"},{"paperId":"89435c392b611b1e804c12d0176661e91ea54ea1","externalIds":{"DBLP":"journals/corr/abs-2412-11499","ArXiv":"2412.11499","DOI":"10.48550/arXiv.2412.11499","CorpusId":272330340},"title":"Embodied CoT Distillation From LLM To Off-the-shelf Agents"},{"paperId":"572a4e3e4645a14e7c70b004e624ef474d719425","externalIds":{"DBLP":"conf/icml/RuossPCLMG25","ArXiv":"2412.01441","DOI":"10.48550/arXiv.2412.01441","CorpusId":274437383},"title":"LMAct: A Benchmark for In-Context Imitation Learning with Long Multimodal Demonstrations"},{"paperId":"8ec150af9b4d2bd1c26df4a37622c16372ab8cc2","externalIds":{"ArXiv":"2412.12119","DBLP":"journals/corr/abs-2412-12119","DOI":"10.48550/arXiv.2412.12119","CorpusId":274788614},"title":"Mastering Board Games by External and Internal Planning with Language Models"},{"paperId":"1bc3afa6f78f3f1891fd34e8f07d39d1c8f7fdf8","externalIds":{"DBLP":"journals/corr/abs-2411-16489","ArXiv":"2411.16489","DOI":"10.48550/arXiv.2411.16489","CorpusId":274234336},"title":"O1 Replication Journey - Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?"},{"paperId":"6a7c29829227bfd65ae0ffec294a874bb9ea0871","externalIds":{"DBLP":"journals/corr/abs-2411-15124","ArXiv":"2411.15124","DOI":"10.48550/arXiv.2411.15124","CorpusId":274192505},"title":"TÃœLU 3: Pushing Frontiers in Open Language Model Post-Training"},{"paperId":"be8f1cdd0365a2b50ada35219592bcc7abc00009","externalIds":{"ArXiv":"2411.14215","DBLP":"journals/corr/abs-2411-14215","DOI":"10.48550/arXiv.2411.14215","CorpusId":274165438},"title":"Evaluating the Robustness of Analogical Reasoning in Large Language Models"},{"paperId":"faf5f373bd9944028664ea3e7da2d6a1fe3bf335","externalIds":{"ArXiv":"2411.13543","DBLP":"conf/iclr/PaglieriCCPWKPK25","DOI":"10.48550/arXiv.2411.13543","CorpusId":274150091},"title":"BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games"},{"paperId":"e9cfb6d77040f3db4eeb076dbe70fcc82530745b","externalIds":{"DBLP":"conf/cikm/Verberne24","DOI":"10.1145/3627673.3679059","CorpusId":273498817},"title":"Is the Search Engine of the Future a Chatbot?"},{"paperId":"794d50a7ba63e7a6800d05998708f93a12614aa4","externalIds":{"DBLP":"journals/corr/abs-2410-13639","ArXiv":"2410.13639","DOI":"10.48550/arXiv.2410.13639","CorpusId":273403589},"title":"A Comparative Study on Reasoning Patterns of OpenAI's o1 Model"},{"paperId":"df614b0587fd54bd642f03189adf91e1dc53a68c","externalIds":{"DBLP":"journals/corr/abs-2410-01280","ArXiv":"2410.01280","DOI":"10.48550/arXiv.2410.01280","CorpusId":273025577},"title":"Sparse Autoencoders Reveal Temporal Difference Learning in Large Language Models"},{"paperId":"619ea816e8ef3fbf6fbb715753bf83cc2c2df7a5","externalIds":{"ArXiv":"2407.13729","DBLP":"journals/corr/abs-2407-13729","DOI":"10.48550/arXiv.2407.13729","CorpusId":271270264},"title":"Baba Is AI: Break the Rules to Beat the Benchmark"},{"paperId":"2ac231b9cff4f5f9054d86c9b540429d4dd687f4","externalIds":{"ArXiv":"2407.02646","DBLP":"journals/corr/abs-2407-02646","DOI":"10.48550/arXiv.2407.02646","CorpusId":270924412},"title":"A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models"},{"paperId":"752f684371c9901791259dc4afd04b9754e803d1","externalIds":{"DBLP":"conf/emnlp/Zhang0FTHHT24","ArXiv":"2406.15992","DOI":"10.48550/arXiv.2406.15992","CorpusId":270702523},"title":"Can LLM Graph Reasoning Generalize beyond Pattern Memorization?"},{"paperId":"cea62bcb7b951befe148daa34b6100593c2031f0","externalIds":{"ArXiv":"2406.13094","DBLP":"journals/corr/abs-2406-13094","DOI":"10.48550/arXiv.2406.13094","CorpusId":270620065},"title":"Exploring and Benchmarking the Planning Capabilities of Large Language Models"},{"paperId":"b868d60da79e5db1d9d3e560349d996b923af805","externalIds":{"ArXiv":"2406.11698","DBLP":"journals/corr/abs-2406-11698","DOI":"10.48550/arXiv.2406.11698","CorpusId":270560836},"title":"Meta Reasoning for Large Language Models"},{"paperId":"8f9ceb5ffad8e7a066dfc9d9aaa5153b714740ee","externalIds":{"DBLP":"journals/corr/abs-2406-09246","ArXiv":"2406.09246","DOI":"10.48550/arXiv.2406.09246","CorpusId":270440391},"title":"OpenVLA: An Open-Source Vision-Language-Action Model"},{"paperId":"b00d92a2ebb024dc6c82d2cefbcd0782ce32f74c","externalIds":{"ArXiv":"2406.04271","DBLP":"conf/nips/YangYZCXZG024","DOI":"10.48550/arXiv.2406.04271","CorpusId":270285926},"title":"Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models"},{"paperId":"3fa1e1c67514b9eaf9ec8da562baef8974b4f3f9","externalIds":{"DBLP":"journals/tacl/KamoiZZHZ24a","ArXiv":"2406.01297","DOI":"10.1162/tacl_a_00713","CorpusId":270218742},"title":"When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs"},{"paperId":"8f9e7812aad3a1162424d3b094d2b425f9f701b6","externalIds":{"DBLP":"journals/corr/abs-2405-20132","ArXiv":"2405.20132","DOI":"10.1109/TEVC.2024.3497793","CorpusId":270123746},"title":"LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically Generating Metaheuristics"},{"paperId":"1b1265a7fc7debcdd0cd92fc1d9b51fc55d57fdc","externalIds":{"DBLP":"journals/corr/abs-2405-18357","ArXiv":"2405.18357","DOI":"10.48550/arXiv.2405.18357","CorpusId":270068130},"title":"Faithful Logical Reasoning via Symbolic Chain-of-Thought"},{"paperId":"79846e748a9e6324742c300453ec293661e90884","externalIds":{"DBLP":"conf/nips/DidolkarGKGVLRB24","ArXiv":"2405.12205","DOI":"10.48550/arXiv.2405.12205","CorpusId":269921384},"title":"Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving"},{"paperId":"8b750488d139f9beba0815ff8f46ebe15ebb3e58","externalIds":{"ArXiv":"2404.14082","DBLP":"journals/corr/abs-2404-14082","DOI":"10.48550/arXiv.2404.14082","CorpusId":269293418},"title":"Mechanistic Interpretability for AI Safety - A Review"},{"paperId":"d0255ce4c897bea6578955de64fc40324f991878","externalIds":{"ArXiv":"2404.01869","DBLP":"journals/corr/abs-2404-01869","DOI":"10.48550/arXiv.2404.01869","CorpusId":268857112},"title":"Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models - A Survey"},{"paperId":"d492c004b74dcbec9d5c0732d95bbd3588e30451","externalIds":{"DBLP":"journals/corr/abs-2403-15371","ArXiv":"2403.15371","DOI":"10.48550/arXiv.2403.15371","CorpusId":268667280},"title":"Can large language models explore in-context?"},{"paperId":"4a42ab34b115e5633a869343aa2b87e1286cce96","externalIds":{"MAG":"196161578","ArXiv":"2403.13705","DBLP":"journals/corr/abs-2403-13705","DOI":"10.48550/arXiv.2403.13705","CorpusId":263135798},"title":"Research Re: search & Re-search"},{"paperId":"966ba2acfe0700c2410efe15ed1b6c25340b7a95","externalIds":{"DBLP":"conf/emnlp/ShiGCFYSYRVR24","ArXiv":"2403.03031","DOI":"10.48550/arXiv.2403.03031","CorpusId":268249086},"title":"Learning to Use Tools via Cooperative and Interactive Agents"},{"paperId":"a3d2c1c932da66f48af673bcb860ba0b8fb335d1","externalIds":{"DBLP":"conf/emnlp/Paul0BF24","ArXiv":"2402.13950","DOI":"10.48550/arXiv.2402.13950","CorpusId":267770195},"title":"Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning"},{"paperId":"94db8a625418800c8ae7b48157a9cad1c8129051","externalIds":{"DBLP":"journals/corr/abs-2402-13116","ArXiv":"2402.13116","DOI":"10.48550/arXiv.2402.13116","CorpusId":267760021},"title":"A Survey on Knowledge Distillation of Large Language Models"},{"paperId":"eb6eba90a399e6a8f5810f9b1fde6db551b4a009","externalIds":{"DBLP":"journals/corr/abs-2402-11633","ArXiv":"2402.11633","DOI":"10.48550/arXiv.2402.11633","CorpusId":267750805},"title":"Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs"},{"paperId":"a1f76db91c0debcf93ae9889736bce8470902113","externalIds":{"DBLP":"journals/corr/abs-2402-06196","ArXiv":"2402.06196","DOI":"10.48550/arXiv.2402.06196","CorpusId":267617032},"title":"Large Language Models: A Survey"},{"paperId":"011d8ff0e4a2a0a13d364117a8e10d93be456455","externalIds":{"ArXiv":"2402.04678","CorpusId":267522825},"title":"FaithLM: Towards Faithful Explanations for Large Language Models"},{"paperId":"31d2ccff82e313eb5c1620c44bb8322da4a38513","externalIds":{"ArXiv":"2402.07927","DBLP":"journals/corr/abs-2402-07927","DOI":"10.48550/arXiv.2402.07927","CorpusId":267636769},"title":"A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications"},{"paperId":"35b142ea69598e6241f0011312128031df55895c","externalIds":{"ArXiv":"2402.03300","DBLP":"journals/corr/abs-2402-03300","DOI":"10.48550/arXiv.2402.03300","CorpusId":267412607},"title":"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models"},{"paperId":"c362015d426c90ec01e1ad02bf3fd66ab8fd0fd9","externalIds":{"DBLP":"journals/jair/PterneaSCOMBJ24","ArXiv":"2402.01874","DOI":"10.1613/jair.1.15960","CorpusId":267412027},"title":"The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models"},{"paperId":"b156004675ad3aa5e39a56928afc530aec191044","externalIds":{"ArXiv":"2402.01817","DBLP":"journals/corr/abs-2402-01817","DOI":"10.48550/arXiv.2402.01817","CorpusId":267413178},"title":"LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks"},{"paperId":"42445823fb0156afddc8c72eaa5ee81dded5b965","externalIds":{"ACL":"2024.eacl-srw.17","DBLP":"conf/eacl/AhnVLLZY24","ArXiv":"2402.00157","DOI":"10.48550/arXiv.2402.00157","CorpusId":267365459},"title":"Large Language Models for Mathematical Reasoning: Progresses and Challenges"},{"paperId":"40c0d1f38ab081e21cc3b1e2e5334a9b54b6ff08","externalIds":{"DBLP":"conf/acl/JinYSZHMZD24","ArXiv":"2401.04925","DOI":"10.48550/arXiv.2401.04925","CorpusId":266902900},"title":"The Impact of Reasoning Step Length on Large Language Models"},{"paperId":"3e8e63bc80176ce913c9ee8f8e9e2472adfd7109","externalIds":{"DBLP":"journals/corr/abs-2401-10910","ArXiv":"2401.10910","DOI":"10.48550/arXiv.2401.10910","CorpusId":267069482},"title":"Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior"},{"paperId":"a2e128be33b85f8f91515e205bf0237ecc0546cc","externalIds":{"ArXiv":"2401.02051","DBLP":"conf/icml/0044TY0LWL024","CorpusId":266755732},"title":"Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model"},{"paperId":"d32ba88571141ed0ebe7aeefbaa4ccaf8cda7be3","externalIds":{"PubMedCentral":"10794145","DBLP":"journals/nature/RomeraParedesBNBKDREWFKF24","DOI":"10.1038/s41586-023-06924-6","CorpusId":266223700,"PubMed":"38096900"},"title":"Mathematical discoveries from program search with large language models"},{"paperId":"1e909e2a8cdacdcdff125ebcc566f37cb869a1c8","externalIds":{"ArXiv":"2311.05232","DBLP":"journals/tois/HuangYMZFWCPFQL25","DOI":"10.1145/3703155","CorpusId":265067168},"title":"A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions"},{"paperId":"9e540662619327a3056d9e40bb58058868f6f805","externalIds":{"DBLP":"conf/cikm/LiZC23","DOI":"10.1145/3583780.3615017","CorpusId":264350121},"title":"Prompt Distillation for Efficient LLM-based Recommendation"},{"paperId":"b47e96762351b2dbf7e863ece4640df6194bcc0c","externalIds":{"DBLP":"journals/corr/abs-2310-01061","ArXiv":"2310.01061","DOI":"10.48550/arXiv.2310.01061","CorpusId":263605944},"title":"Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning"},{"paperId":"f42f61a547c5996be6aee175145b0d74e6324dff","externalIds":{"ArXiv":"2309.15402","DBLP":"conf/acl/ChuCCYH0P00L24","DOI":"10.18653/v1/2024.acl-long.65","CorpusId":263153015},"title":"Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"},{"paperId":"8eafec7014d08043517834b5a2ed26384f188873","externalIds":{"ArXiv":"2309.12288","DBLP":"journals/corr/abs-2309-12288","CorpusId":262083829},"title":"The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\""},{"paperId":"80f659d35c3a4c0b6bf9b7925cb9a68afd684337","externalIds":{"ArXiv":"2309.01664","DBLP":"journals/corr/abs-2309-01664","DOI":"10.1109/ACII59096.2023.10388177","CorpusId":261530762},"title":"Fine-grained Affective Processing Capabilities Emerging from Large Language Models"},{"paperId":"fca92fe287c44c9ec79ca1f2762b0bf2e5e8df2b","externalIds":{"ArXiv":"2308.10379","DBLP":"conf/icml/SelAK0024","DOI":"10.48550/arXiv.2308.10379","CorpusId":261049794},"title":"Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models"},{"paperId":"aade40af0d85b0b4fe15c97f6222d5c2e4d6d9b3","externalIds":{"DBLP":"conf/aaai/BestaBKGPGGLNNH24","ArXiv":"2308.09687","DOI":"10.1609/aaai.v38i16.29720","CorpusId":261030303},"title":"Graph of Thoughts: Solving Elaborate Problems with Large Language Models"},{"paperId":"896ca0a68e4d33d76a7366bcab85eb7d2605a8c4","externalIds":{"DBLP":"journals/corr/abs-2308-05342","ACL":"2024.naacl-long.106","ArXiv":"2308.05342","DOI":"10.48550/arXiv.2308.05342","CorpusId":260775822},"title":"Metacognitive Prompting Improves Understanding in Large Language Models"},{"paperId":"827afa7dd36e4afbb1a49c735bfbb2c69749756e","externalIds":{"DBLP":"journals/corr/abs-2307-13702","ArXiv":"2307.13702","DOI":"10.48550/arXiv.2307.13702","CorpusId":259953372},"title":"Measuring Faithfulness in Chain-of-Thought Reasoning"},{"paperId":"f8e99be4f9a01761fab74bade2c3c18de9fc686b","externalIds":{"DBLP":"journals/corr/abs-2307-02477","ArXiv":"2307.02477","ACL":"2024.naacl-long.102","DOI":"10.48550/arXiv.2307.02477","CorpusId":259341893},"title":"Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks"},{"paperId":"5bac7d00035bc1e246a34f9ee3152b290f97bb92","externalIds":{"DBLP":"conf/nips/0002XPCFNB23","ArXiv":"2306.14892","DOI":"10.48550/arXiv.2306.14892","CorpusId":259262142},"title":"Supervised Pretraining Can Learn In-Context Reinforcement Learning"},{"paperId":"a0a79dad89857a96f8f71b14238e5237cbfc4787","externalIds":{"ArXiv":"2306.05685","DBLP":"journals/corr/abs-2306-05685","CorpusId":259129398},"title":"Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"},{"paperId":"44f0876dec21a04533587def2add230b878a5006","externalIds":{"DOI":"10.1007/s10439-023-03272-4","CorpusId":259097639,"PubMed":"37284994"},"title":"Prompt Engineering with ChatGPT: A Guide for Academic Writers"},{"paperId":"0d1c76d45afa012ded7ab741194baf142117c495","externalIds":{"DBLP":"conf/nips/RafailovSMMEF23","ArXiv":"2305.18290","CorpusId":258959321},"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model"},{"paperId":"f197bf0fc2f228483f6af3285000d54d8d97f9eb","externalIds":{"ArXiv":"2305.16291","DBLP":"journals/tmlr/WangX0MXZFA24","DOI":"10.48550/arXiv.2305.16291","CorpusId":258887849},"title":"Voyager: An Open-Ended Embodied Agent with Large Language Models"},{"paperId":"dedfe929d182cc3537a9ed765d589b4735ce062a","externalIds":{"DBLP":"conf/nips/ValmeekamMSK23","ArXiv":"2305.15771","DOI":"10.48550/arXiv.2305.15771","CorpusId":260440590},"title":"On the Planning Abilities of Large Language Models - A Critical Investigation"},{"paperId":"9e9e4df2996bac794c4f04cb887df3e553bae4fd","externalIds":{"DBLP":"conf/emnlp/PanAWW23","ArXiv":"2305.12295","DOI":"10.48550/arXiv.2305.12295","CorpusId":258833332},"title":"Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning"},{"paperId":"2f3822eb380b5e753a6d579f31dfc3ec4c4a0820","externalIds":{"ArXiv":"2305.10601","DBLP":"journals/corr/abs-2305-10601","DOI":"10.48550/arXiv.2305.10601","CorpusId":258762525},"title":"Tree of Thoughts: Deliberate Problem Solving with Large Language Models"},{"paperId":"7dc928f41e15f65f1267bd87b0fcfcc7e715cb56","externalIds":{"DBLP":"conf/nips/TurpinMPB23","ArXiv":"2305.04388","DOI":"10.48550/arXiv.2305.04388","CorpusId":258556812},"title":"Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting"},{"paperId":"88d926cdd0f2d9ff1603b33a65c441c46a87a8b3","externalIds":{"DBLP":"journals/tai/BegusDR25","ArXiv":"2305.00948","DOI":"10.1109/TAI.2025.3575745","CorpusId":276107272},"title":"Large Linguistic Models: Investigating LLMsâ€™ Metalinguistic Abilities"},{"paperId":"ef018d9fad6167cfddb7d6654c5422df1e953730","externalIds":{"ArXiv":"2305.00633","DBLP":"conf/nips/XieKZZKHX23","CorpusId":258426922},"title":"Self-Evaluation Guided Beam Search for Reasoning"},{"paperId":"261549439aebdda72b648ecc462448fd24857ac1","externalIds":{"ArXiv":"2304.09797","DBLP":"journals/corr/abs-2304-09797","DOI":"10.48550/arXiv.2304.09797","CorpusId":258212839},"title":"Progressive-Hint Prompting Improves Reasoning in Large Language Models"},{"paperId":"9e3c493fb09dcd61bb05e8c5659f23327b7b6340","externalIds":{"ArXiv":"2304.05128","DBLP":"journals/corr/abs-2304-05128","DOI":"10.48550/arXiv.2304.05128","CorpusId":258059885},"title":"Teaching Large Language Models to Self-Debug"},{"paperId":"85cc48276c69924d3e92ddb38facb7d92be9a4a6","externalIds":{"DBLP":"journals/corr/abs-2304-03439","ArXiv":"2304.03439","DOI":"10.48550/arXiv.2304.03439","CorpusId":258041354},"title":"Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4"},{"paperId":"c715914c388fa64dd8686cd8755e5adfebbf2388","externalIds":{"DBLP":"journals/corr/abs-2304-01904","ArXiv":"2304.01904","ACL":"2024.eacl-long.67","DOI":"10.48550/arXiv.2304.01904","CorpusId":257921623},"title":"REFINER: Reasoning Feedback on Intermediate Representations"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"3aaf6a2cbad5850ad81ab5c163599cb3d523436f","externalIds":{"DBLP":"journals/corr/abs-2303-17651","ArXiv":"2303.17651","DOI":"10.48550/arXiv.2303.17651","CorpusId":257900871},"title":"Self-Refine: Iterative Refinement with Self-Feedback"},{"paperId":"5eab810cc5d90de1c52127d1a5824f0817f46c30","externalIds":{"DBLP":"journals/csur/YuZTW24","ArXiv":"2303.14725","DOI":"10.1145/3664194","CorpusId":257766470},"title":"Natural Language Reasoning, A Survey"},{"paperId":"0671fd553dd670a4e820553a974bc48040ba0819","externalIds":{"DBLP":"conf/nips/ShinnCGNY23","ArXiv":"2303.11366","CorpusId":258833055},"title":"Reflexion: language agents with verbal reinforcement learning"},{"paperId":"bfad52fc64ca0169644b6e7e0ea9a46470d51709","externalIds":{"DBLP":"conf/semweb/TanMLLHCQ23","ArXiv":"2303.07992","CorpusId":257505407},"title":"Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family"},{"paperId":"b626560f19f815808a289ef5c24a17c57320da70","externalIds":{"DBLP":"journals/corr/abs-2303-05398","ACL":"2023.acl-industry.4","ArXiv":"2303.05398","DOI":"10.48550/arXiv.2303.05398","CorpusId":257427208},"title":"MathPrompter: Mathematical Reasoning using Large Language Models"},{"paperId":"30c0cdc414f68211d5d0514df027cec22e005174","externalIds":{"DBLP":"conf/emnlp/Dong0DZMLXX0C0S24","ArXiv":"2301.00234","ACL":"2024.emnlp-main.64","DOI":"10.18653/v1/2024.emnlp-main.64","CorpusId":255372865},"title":"A Survey on In-context Learning"},{"paperId":"db4ab91d5675c37795e719e997a2827d3d83cd45","externalIds":{"ArXiv":"2212.10403","DBLP":"conf/acl/0009C23","DOI":"10.48550/arXiv.2212.10403","CorpusId":254877753},"title":"Towards Reasoning in Large Language Models: A Survey"},{"paperId":"35922cd0d6b17e45320917338e9f98cb5c1a4f6f","externalIds":{"ArXiv":"2212.10001","DBLP":"conf/acl/WangM0S0Z023","ACL":"2023.acl-long.153","DOI":"10.48550/arXiv.2212.10001","CorpusId":254877569},"title":"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters"},{"paperId":"7715ba5e75f5256e1061c7473afe61bb0dbb9065","externalIds":{"ArXiv":"2212.09561","DBLP":"conf/emnlp/WengZX0HLSLZ23","DOI":"10.18653/v1/2023.findings-emnlp.167","CorpusId":258840837},"title":"Large Language Models are Better Reasoners with Self-Verification"},{"paperId":"126a4776ff8315fd506766cb8f3c722cf746ad9e","externalIds":{"DBLP":"journals/corr/abs-2212-08410","ACL":"2023.acl-short.151","ArXiv":"2212.08410","DOI":"10.48550/arXiv.2212.08410","CorpusId":254823156},"title":"Teaching Small Language Models to Reason"},{"paperId":"6c943670dca38bfc7c8b477ae7c2d1fba1ad3691","externalIds":{"DBLP":"journals/tmlr/ChenM0C23","ArXiv":"2211.12588","CorpusId":253801709},"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"},{"paperId":"6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7","externalIds":{"ArXiv":"2211.10435","DBLP":"journals/corr/abs-2211-10435","DOI":"10.48550/arXiv.2211.10435","CorpusId":253708270},"title":"PAL: Program-aided Language Models"},{"paperId":"538288d24bdad73d831dfed44b706958287ed318","externalIds":{"ArXiv":"2211.00053","DBLP":"conf/iclr/WelleckLWBSK023","DOI":"10.48550/arXiv.2211.00053","CorpusId":253244506},"title":"Generating Sequences by Learning to Self-Correct"},{"paperId":"3fa70115248377c3d1517c9f978791a296fbc1dd","externalIds":{"DBLP":"conf/emnlp/0001GHW00023","ArXiv":"2210.11610","DOI":"10.48550/arXiv.2210.11610","CorpusId":253080328},"title":"Large Language Models Can Self-Improve"},{"paperId":"7d29a84a589aa5655e5d3fed8d725ea472816599","externalIds":{"ArXiv":"2210.06726","DBLP":"journals/corr/abs-2210-06726","DOI":"10.48550/arXiv.2210.06726","CorpusId":252873123},"title":"Explanations from Large Language Models Make Small Reasoners Better"},{"paperId":"e070ff286709db28312e08b52b05539debe88146","externalIds":{"DBLP":"conf/emnlp/PressZMSSL23","ArXiv":"2210.03350","DOI":"10.48550/arXiv.2210.03350","CorpusId":252762102},"title":"Measuring and Narrowing the Compositionality Gap in Language Models"},{"paperId":"90350aa626bed47b02d0c162462e5b0ca82be6b2","externalIds":{"DBLP":"journals/corr/abs-2210-03493","ArXiv":"2210.03493","CorpusId":252762275},"title":"Automatic Chain of Thought Prompting in Large Language Models"},{"paperId":"99832586d55f540f603637e458a292406a0ed75d","externalIds":{"DBLP":"conf/iclr/YaoZYDSN023","ArXiv":"2210.03629","CorpusId":252762395},"title":"ReAct: Synergizing Reasoning and Acting in Language Models"},{"paperId":"c88cafa3e980765a64febe369ceb7c2aa7261d2a","externalIds":{"DBLP":"journals/corr/abs-2210-00720","ArXiv":"2210.00720","DOI":"10.48550/arXiv.2210.00720","CorpusId":252683303},"title":"Complexity-Based Prompting for Multi-Step Reasoning"},{"paperId":"e7028cd7ea838ab8294ecf26d5a2c0dbb8cfa81a","externalIds":{"DBLP":"journals/corr/abs-2210-01240","ArXiv":"2210.01240","DOI":"10.48550/arXiv.2210.01240","CorpusId":252693237},"title":"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought"},{"paperId":"e86009d9f9b1cdf083a48d087552bc4153784451","externalIds":{"DBLP":"journals/corr/abs-2209-11755","ArXiv":"2209.11755","DOI":"10.48550/arXiv.2209.11755","CorpusId":252519173},"title":"Promptagator: Few-shot Dense Retrieval From 8 Examples"},{"paperId":"5581bf85386737bd3378eec68189759a05280bea","externalIds":{"ArXiv":"2209.00840","DBLP":"journals/corr/abs-2209-00840","ACL":"2024.emnlp-main.1229","DOI":"10.48550/arXiv.2209.00840","CorpusId":252070866},"title":"FOLIO: Natural Language Reasoning with First-Order Logic"},{"paperId":"f46f703a272599b8e7953c035985e20fd1b3a6c0","externalIds":{"DBLP":"journals/ijitdm/WangEPP23","DOI":"10.1142/s0219622022500547","CorpusId":251699863},"title":"Analysis of Hyper-Parameters for AlphaZero-Like Deep Reinforcement Learning"},{"paperId":"f3cf71c51b882fe3111d71c4bf104297d38197f8","externalIds":{"ArXiv":"2207.05608","DBLP":"conf/corl/HuangXXCLFZTMCS22","DOI":"10.48550/arXiv.2207.05608","CorpusId":250451569},"title":"Inner Monologue: Embodied Reasoning through Planning with Language Models"},{"paperId":"23525374cfd3af714f3ffb7a203b1ef3253333fe","externalIds":{"ArXiv":"2207.01206","DBLP":"journals/corr/abs-2207-01206","DOI":"10.48550/arXiv.2207.01206","CorpusId":250264533},"title":"WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents"},{"paperId":"32c9b3859086d15184989454eb878638659e64c6","externalIds":{"ArXiv":"2206.08853","DBLP":"conf/nips/FanWJMYZTHZA22","DOI":"10.48550/arXiv.2206.08853","CorpusId":249848263},"title":"MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge"},{"paperId":"dac3a172b504f4e33c029655e9befb3386e5f63a","externalIds":{"DBLP":"journals/corr/abs-2206-07682","ArXiv":"2206.07682","DOI":"10.48550/arXiv.2206.07682","CorpusId":249674500},"title":"Emergent Abilities of Large Language Models"},{"paperId":"bd1331b233e84bab7eba503abc60b31ac08e7881","externalIds":{"ArXiv":"2206.04615","DBLP":"journals/corr/abs-2206-04615","CorpusId":263625818},"title":"Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models"},{"paperId":"e826ac71dad8c4ce36d82fb7add43e3d306bb7e1","externalIds":{"ArXiv":"2206.02336","ACL":"2023.acl-long.291","DBLP":"conf/acl/LiLZFCLC23","DOI":"10.18653/v1/2023.acl-long.291","CorpusId":259370847},"title":"Making Language Models Better Reasoners with Step-Aware Verifier"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"5437e8adab596d7294124c0e798708e050e25321","externalIds":{"ArXiv":"2205.10625","DBLP":"conf/iclr/ZhouSHWS0SCBLC23","DOI":"10.48550/arXiv.2205.10625","CorpusId":248986239},"title":"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"},{"paperId":"b21670e8061a06ab97e7d6052c9345a326e84ff8","externalIds":{"ArXiv":"2205.05131","DBLP":"conf/iclr/Tay00GW0CBSZZHM23","CorpusId":252780443},"title":"UL2: Unifying Language Learning Paradigms"},{"paperId":"67dc33f02c8b5f24cd213b6b5fb5c74cead581aa","externalIds":{"DBLP":"journals/pami/XiaoWGLZQL23","ArXiv":"2204.09269","DOI":"10.1109/TPAMI.2023.3277122","CorpusId":248266379,"PubMed":"37200120"},"title":"A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"cb5e3f085caefd1f3d5e08637ab55d39e61234fc","externalIds":{"DBLP":"conf/corl/IchterBCFHHHIIJ22","ArXiv":"2204.01691","CorpusId":247939706},"title":"Do As I Can, Not As I Say: Grounding Language in Robotic Affordances"},{"paperId":"8342b592fe238f3d230e4959b06fd10153c45db1","externalIds":{"DBLP":"journals/corr/abs-2203-15556","ArXiv":"2203.15556","CorpusId":247778764},"title":"Training Compute-Optimal Large Language Models"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"b3848d32f7294ec708627897833c4097eb4d8778","externalIds":{"DBLP":"journals/corr/abs-2201-08239","ArXiv":"2201.08239","CorpusId":246063428},"title":"LaMDA: Language Models for Dialog Applications"},{"paperId":"68f141724814839d556a989646194be88641b143","externalIds":{"ArXiv":"2112.11446","DBLP":"journals/corr/abs-2112-11446","CorpusId":245353475},"title":"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"},{"paperId":"92173d081b15824d22a9ef070e118744ceee8052","externalIds":{"DBLP":"journals/corr/abs-2112-00114","ArXiv":"2112.00114","CorpusId":244773644},"title":"Show Your Work: Scratchpads for Intermediate Computation with Language Models"},{"paperId":"d6045d2ccc9c09ca1671348de86d07da6bc28eea","externalIds":{"ArXiv":"2110.14168","DBLP":"journals/corr/abs-2110-14168","CorpusId":239998651},"title":"Training Verifiers to Solve Math Word Problems"},{"paperId":"dfabd934d91231c536712271a8627e8eaa84ade7","externalIds":{"PubMedCentral":"8913741","DOI":"10.1038/s41467-022-28865-w","CorpusId":237550334,"PubMed":"35273146"},"title":"Improved prediction of protein-protein interactions using AlphaFold2"},{"paperId":"69ee9b3a915951cc84b74599a3a2699a66d4004f","externalIds":{"DBLP":"conf/corl/ShridharMF21","ArXiv":"2109.12098","CorpusId":237396838},"title":"CLIPort: What and Where Pathways for Robotic Manipulation"},{"paperId":"4698fc4712f0212c8a3810fd67b41ee8b8896aba","externalIds":{"DBLP":"journals/corr/abs-2109-03034","ArXiv":"2109.03034","DOI":"10.18653/v1/2021.findings-emnlp.195","CorpusId":237434245},"title":"Generate & Rank: A Multi-task Framework for Math Word Problems"},{"paperId":"28692beece311a90f5fa1ca2ec9d0c2ce293d069","externalIds":{"DBLP":"journals/csur/LiuYFJHN23","ArXiv":"2107.13586","DOI":"10.1145/3560815","CorpusId":236493269},"title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"},{"paperId":"dc32a984b651256a8ec282be52310e6bd33d9815","externalIds":{"PubMedCentral":"8371605","DOI":"10.1038/s41586-021-03819-2","CorpusId":235959867,"PubMed":"34265844"},"title":"Highly accurate protein structure prediction with AlphaFold"},{"paperId":"acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269","externalIds":{"DBLP":"journals/corr/abs-2107-03374","ArXiv":"2107.03374","CorpusId":235755472},"title":"Evaluating Large Language Models Trained on Code"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"13c4e5a6122f3fa2663f63e49537091da6532f35","externalIds":{"MAG":"3170403598","ArXiv":"2103.07191","DBLP":"conf/naacl/PatelBG21","ACL":"2021.naacl-main.168","DOI":"10.18653/V1/2021.NAACL-MAIN.168","CorpusId":232223322},"title":"Are NLP Models really able to Solve Simple Math Word Problems?"},{"paperId":"57d1e7ac339e783898f2c3b1af55737cbeee9fc5","externalIds":{"DBLP":"conf/nips/HendrycksBKABTS21","ArXiv":"2103.03874","CorpusId":232134851},"title":"Measuring Mathematical Problem Solving With the MATH Dataset"},{"paperId":"ca2f1088d3e581b2c6c75cf0ebc96506d620f64d","externalIds":{"DBLP":"conf/fat/BenderGMS21","DOI":"10.1145/3442188.3445922","CorpusId":262580630},"title":"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ"},{"paperId":"87c45a908537ffe1d2ab71a5d609bd7b4efa4fe1","externalIds":{"ACL":"2021.findings-acl.317","DBLP":"conf/acl/TafjordDC21","ArXiv":"2012.13048","DOI":"10.18653/v1/2021.findings-acl.317","CorpusId":229371222},"title":"ProofWriter: Generating Implications, Proofs, and Abductive Statements over Natural Language"},{"paperId":"3efbcfeeb0ea1051a71101d3318da4411081f0b8","externalIds":{"DBLP":"journals/corr/abs-2010-14701","ArXiv":"2010.14701","MAG":"3095645723","CorpusId":225094178},"title":"Scaling Laws for Autoregressive Generative Modeling"},{"paperId":"398a0625e8707a0b41ac58eaec51e8feb87dd7cb","externalIds":{"DBLP":"journals/corr/abs-2010-03768","MAG":"3092516542","ArXiv":"2010.03768","CorpusId":222208810},"title":"ALFWorld: Aligning Text and Embodied Environments for Interactive Learning"},{"paperId":"332c44793b70776b9b966128c52e694222b1ab73","externalIds":{"ArXiv":"2010.03522","DBLP":"journals/corr/abs-2010-03522","MAG":"3092053846","DOI":"10.1007/s10462-021-10004-4","CorpusId":222177134},"title":"A survey of deep meta-learning"},{"paperId":"f13e41d24e5d0a68ca662c1b49de398a6fb68251","externalIds":{"ArXiv":"2106.15772","DBLP":"conf/acl/MiaoLS20","MAG":"3034643750","ACL":"2020.acl-main.92","DOI":"10.18653/v1/2020.acl-main.92","CorpusId":220047831},"title":"A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers"},{"paperId":"df56748cd4f52a58973b4ac52c0bf9156c5f52f0","externalIds":{"MAG":"3033638351","DBLP":"journals/corr/abs-2006-03511","ArXiv":"2006.03511","CorpusId":219401607},"title":"Unsupervised Translation of Programming Languages"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"b9a5aa5db8836744ff2073e8368520b7a614049f","externalIds":{"MAG":"2995628494","DBLP":"conf/iclr/ChenLYZSL20","CorpusId":212814759},"title":"Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension"},{"paperId":"020bb2ba5f3923858cd6882ba5c5a44ea8041ab6","externalIds":{"MAG":"3015606043","DBLP":"journals/pami/HospedalesAMS22","ArXiv":"2004.05439","DOI":"10.1109/TPAMI.2021.3079209","CorpusId":215744839,"PubMed":"33974543"},"title":"Meta-Learning in Neural Networks: A Survey"},{"paperId":"e6c561d02500b2596a230b341a8eb8b921ca5bf2","externalIds":{"MAG":"3001279689","ArXiv":"2001.08361","DBLP":"journals/corr/abs-2001-08361","CorpusId":210861095},"title":"Scaling Laws for Neural Language Models"},{"paperId":"eef7cfe8267954adbb4675576072a1d80ca7a3a8","externalIds":{"ArXiv":"1905.13319","MAG":"2945720633","DBLP":"journals/corr/abs-1905-13319","ACL":"N19-1245","DOI":"10.18653/v1/N19-1245","CorpusId":173188048},"title":"MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms"},{"paperId":"d9f6ada77448664b71128bb19df15765336974a6","externalIds":{"MAG":"2943552823","ArXiv":"1905.00537","DBLP":"conf/nips/WangPNSMHLB19","CorpusId":143424870},"title":"SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems"},{"paperId":"f67ede490780f939103d4cc4e9c6866b83ee59b3","externalIds":{"MAG":"2952049600","ACL":"N19-1272","DBLP":"journals/corr/abs-1811-00720","ArXiv":"1811.00720","DOI":"10.18653/v1/N19-1272","CorpusId":53298878},"title":"Semantically-Aligned Equation Generation for Solving and Reasoning Math Word Problems"},{"paperId":"8e773b1840b894603c06b677a0f15ebcf0f26378","externalIds":{"DBLP":"conf/emnlp/YuZYYWLMLYRZR18","ACL":"D18-1425","ArXiv":"1809.08887","MAG":"2890431379","DOI":"10.18653/v1/D18-1425","CorpusId":52815560},"title":"Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task"},{"paperId":"305b2cf37e5dece81e95c92883d5a6e28ac93b22","externalIds":{"DBLP":"conf/emnlp/NarayanCL18","MAG":"2888482885","ArXiv":"1808.08745","ACL":"D18-1206","DOI":"10.18653/v1/D18-1206","CorpusId":215768182},"title":"Donâ€™t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization"},{"paperId":"c99179ca3784e3465fd9ed049d7f34b50d39393e","externalIds":{"MAG":"2789758093","DBLP":"journals/widm/SagiR18","DOI":"10.1002/widm.1249","CorpusId":49291826},"title":"Ensemble learning: A survey"},{"paperId":"451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c","externalIds":{"MAG":"2963310665","DBLP":"conf/emnlp/WangSMHLB18","ACL":"W18-5446","ArXiv":"1804.07461","DOI":"10.18653/v1/W18-5446","CorpusId":5034059},"title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"},{"paperId":"5b01eaef54a653ba03ddd5a978690380fbc19bfc","externalIds":{"DBLP":"journals/corr/abs-1802-06070","MAG":"2951020250","ArXiv":"1802.06070","CorpusId":3521071},"title":"Diversity is All You Need: Learning Skills without a Reward Function"},{"paperId":"59d0d7ccec2db66cad20cac5721ce54a8a058294","externalIds":{"DBLP":"journals/corr/abs-1712-05877","ArXiv":"1712.05877","MAG":"2963122961","DOI":"10.1109/CVPR.2018.00286","CorpusId":39867659},"title":"Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"},{"paperId":"c27db32efa8137cbf654902f8f728f338e55cd1c","externalIds":{"MAG":"2766447205","DBLP":"journals/nature/SilverSSAHGHBLB17","DOI":"10.1038/nature24270","CorpusId":205261034,"PubMed":"29052630"},"title":"Mastering the game of Go without human knowledge"},{"paperId":"e7fd6848cb29ca221a7e17d823e06fb566f1f135","externalIds":{"DBLP":"journals/corr/abs-1710-03740","ArXiv":"1710.03740","MAG":"2963112338","CorpusId":3297437},"title":"Mixed Precision Training"},{"paperId":"ef8ab2a0be51a0cd04c2c0f01adfae956a2a84af","externalIds":{"ArXiv":"1708.04202","DBLP":"journals/corr/abs-1708-04202","MAG":"2747592475","DOI":"10.1038/nature25978","CorpusId":205264340,"PubMed":"29595767"},"title":"Planning chemical syntheses with deep neural networks and symbolic AI"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"b123a0d46ad917b79c43c5ae981e03ed2458ed11","externalIds":{"ACL":"P17-1015","DBLP":"conf/acl/LingYDB17","ArXiv":"1705.04146","MAG":"2613312549","DOI":"10.18653/v1/P17-1015","CorpusId":12777818},"title":"Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems"},{"paperId":"c889d6f98e6d79b89c3a6adf8a921f88fa6ba518","externalIds":{"MAG":"2604763608","DBLP":"journals/corr/FinnAL17","ArXiv":"1703.03400","CorpusId":6719686},"title":"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"},{"paperId":"4c6fe6179c408e1fbb3871af13d1a8e64f766e54","externalIds":{"ACL":"D15-1202","ArXiv":"1608.01413","MAG":"2951624407","DBLP":"journals/corr/RoyR16","DOI":"10.18653/v1/D15-1202","CorpusId":560565},"title":"Solving General Arithmetic Word Problems"},{"paperId":"5ed791f810da580c78df6a052c6b9f2e258f6b0a","externalIds":{"MAG":"2952915793","ArXiv":"1606.06031","DBLP":"conf/acl/PapernoKLPBPBBF16","ACL":"P16-1144","DOI":"10.18653/v1/P16-1144","CorpusId":2381275},"title":"The LAMBADA dataset: Word prediction requiring a broad discourse context"},{"paperId":"05dd7254b632376973f3a1b4d39485da17814df5","externalIds":{"DBLP":"journals/corr/RajpurkarZLL16","MAG":"2963748441","ACL":"D16-1264","ArXiv":"1606.05250","DOI":"10.18653/v1/D16-1264","CorpusId":11816014},"title":"SQuAD: 100,000+ Questions for Machine Comprehension of Text"},{"paperId":"2bdbb07bc12b8d8c332b7a84aa05e76218c07cd9","externalIds":{"DBLP":"conf/naacl/Koncel-Kedziorski16","MAG":"2475046758","ACL":"N16-1136","DOI":"10.18653/v1/N16-1136","CorpusId":2228719},"title":"MAWPS: A Math Word Problem Repository"},{"paperId":"f3b96ef2dc1fc5e14982f1b963db8db6a54183bb","externalIds":{"ArXiv":"1511.06709","MAG":"2284660317","ACL":"P16-1009","DBLP":"journals/corr/SennrichHB15a","DOI":"10.18653/v1/P16-1009","CorpusId":15600925},"title":"Improving Neural Machine Translation Models with Monolingual Data"},{"paperId":"06a81f63fc4ccfcf02934647a7c17454b91853b0","externalIds":{"MAG":"1526441817","DBLP":"books/daglib/0045948","CorpusId":53935745},"title":"Machine Learning - The Art and Science of Algorithms that Make Sense of Data"},{"paperId":"761fb618bc7a237c7b2f0aa79a9ee942a0465e3c","externalIds":{"MAG":"1979721778","DBLP":"conf/gecco/HansenR10","DOI":"10.1145/1830761.1830768","CorpusId":2231645},"title":"Black-box optimization benchmarking of NEWUOA compared to BIPOP-CMA-ES: on the BBOB noiseless testbed"},{"paperId":"8de174ab5419b9d3127695405efd079808e956e8","externalIds":{"MAG":"2296073425","DBLP":"conf/icml/BengioLCW09","DOI":"10.1145/1553374.1553380","CorpusId":873046},"title":"Curriculum learning"},{"paperId":"12cc7892fe8e7954698ea480a3dcca2fad3b5f90","externalIds":{"MAG":"1587191403","DBLP":"reference/fai/3","DOI":"10.1016/s1574-6526(07)x0300-6","CorpusId":11808268},"title":"Handbook of Knowledge Representation"},{"paperId":"2c0f9d6e770fe1485e484201e8474efad722b9da","externalIds":{"MAG":"2163540732","DOI":"10.1007/S11409-006-6893-0","CorpusId":146690540},"title":"Metacognition and learning: conceptual and methodological considerations"},{"paperId":"d7da009f457917aa381619facfa5ffae9329a6e9","externalIds":{"DBLP":"conf/acl/PapineniRWZ02","MAG":"2101105183","ACL":"P02-1040","DOI":"10.3115/1073083.1073135","CorpusId":11080756},"title":"Bleu: a Method for Automatic Evaluation of Machine Translation"},{"paperId":"12d1d070a53d4084d88a77b8b143bad51c40c38f","externalIds":{"DBLP":"journals/corr/cs-AI-9605103","MAG":"2107726111","ArXiv":"cs/9605103","DOI":"10.1613/jair.301","CorpusId":1708582},"title":"Reinforcement Learning: A Survey"},{"paperId":"52b7bf3ba59b31f362aa07f957f1543a29a4279e","externalIds":{"MAG":"2119821739","DOI":"10.1023/A:1022627411411","CorpusId":52874011},"title":"Support-Vector Networks"},{"paperId":"5ed59f49c1bb7de06cfa2a9467d5efb535103277","externalIds":{"MAG":"2131600418","DBLP":"journals/cacm/Tesauro95","DOI":"10.1145/203330.203343","CorpusId":6023746},"title":"Temporal Difference Learning and TD-Gammon"},{"paperId":"d82829c9fd9cfba8a44efe5ba048d3332a1671fc","externalIds":{"DBLP":"reference/ml/PutermanP10","DOI":"10.1145/3731333.3731347","CorpusId":2242825,"PubMed":"24170392"},"title":"Dynamic Programming"},{"paperId":"bb879ea999c9d33a950e554e143d102c7c71fa26","externalIds":{"MAG":"2982942112","DOI":"10.1016/0167-2789(90)90086-5","CorpusId":62625340},"title":"The emergence of understanding in a computer model of concepts analogy-making"},{"paperId":"dab20ffbe49cf1e3eeb347ae5fc5ca06018f08af","externalIds":{"MAG":"1966089223","DBLP":"journals/ras/Brooks90","DOI":"10.1016/S0921-8890(05)80025-9","CorpusId":7454683},"title":"Elephants don't play chess"},{"paperId":"a91635f8d0e7fb804efd1c38d9c24ee952ba7076","externalIds":{"MAG":"2100677568","DBLP":"journals/ml/Sutton88","DOI":"10.1023/A:1022633531479","CorpusId":3349598},"title":"Learning to predict by the methods of temporal differences"},{"paperId":"c547e1f79e6039d05c5ae433a36612d7f8e4d3f5","externalIds":{"MAG":"2337392266","DBLP":"journals/ai/FikesN71","DOI":"10.1016/0004-3702(71)90010-5","CorpusId":8623866},"title":"STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving"},{"paperId":"2967159f5aad53dd6b5a2aaf8fab1ad3793a7062","externalIds":{"DBLP":"conf/iclr/WangBDZ25","CorpusId":278532809},"title":"Transformers Can Learn Temporal Difference Methods for In-Context Reinforcement Learning"},{"paperId":"b5280ed2f9b3880fa505d93fbf140b9be8572d03","externalIds":{"DBLP":"conf/iclr/XiaoZWXWHFZZS024a","CorpusId":271745931},"title":"Chain-of-Experts: When LLMs Meet Complex Operations Research Problems"},{"paperId":"d9fbf374536d625667341ed8a2616cd698ee628b","externalIds":{"DBLP":"journals/corr/abs-2405-16533","DOI":"10.48550/arXiv.2405.16533","CorpusId":277244462},"title":"Chain of Tools: Large Language Model is an Automatic Multi-tool Learner"},{"paperId":"5b2aa9b3912025db43315475c8eca164b876de4a","externalIds":{"DBLP":"journals/corr/abs-2309-15402","DOI":"10.48550/arXiv.2309.15402","CorpusId":281603643},"title":"A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future"},{"paperId":"82c6f5ffd4d2d43ae7684601f607eae26a759a5a","externalIds":{"DBLP":"conf/naacl/ZhongWTXGCW00D22","DOI":"10.18653/v1/2022.findings-naacl.177","CorpusId":250562889},"title":"Analytical Reasoning of Text"},{"paperId":"8d188daf721fde8de4877718e96f89ae9d7a1925","externalIds":{"DBLP":"conf/wmt/KocmiBBDFFGGGHKKMMNNNPP22","ACL":"2022.wmt-1.1","DOI":"10.18653/v1/2022.wmt-1.1","CorpusId":256461033},"title":"Findings of the 2022 Conference on Machine Translation (WMT22)"},{"paperId":"26b6477ef683ef55c453d65fbcbf4e51e0d77b07","externalIds":{"MAG":"3107862810","DBLP":"books/sp/Plaat20","DOI":"10.1007/978-3-030-59238-7","CorpusId":227093686},"title":"Learning to Play: Reinforcement Learning and Games"},{"paperId":"c21a4d70d83e0f6eb2a9e1c41d034842dd561e47","externalIds":{"MAG":"2952331680","ACL":"N19-1421","DBLP":"journals/corr/abs-1811-00937","ArXiv":"1811.00937","DOI":"10.18653/v1/N19-1421","CorpusId":53296520},"title":"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"0c0a778e6fdf7e36b1750c533dcc916f86608607","externalIds":{"MAG":"2527310337","DBLP":"journals/tkde/XunJGZ17","DOI":"10.1109/TKDE.2016.2614508","CorpusId":13490401},"title":"A Survey on Context Learning"},{"paperId":"4f8d648c52edf74e41b0996128aa536e13cc7e82","externalIds":{"DBLP":"journals/ijsc/HaoZM16","DOI":"10.1142/S1793351X16500045","CorpusId":1779661},"title":"Deep Learning"},{"paperId":"8e0be569ea77b8cb29bb0e8b031887630fe7a96c","externalIds":{"MAG":"2342146255","DBLP":"journals/ml/Breiman01","DOI":"10.1023/A:1010933404324","CorpusId":89141},"title":"Random Forests"},{"paperId":"f2e0164a563a6429efa9586cd65620f98ea085f2","externalIds":{"DBLP":"books/crc/99/A1999","DOI":"10.5860/choice.37-0975","CorpusId":268091948},"title":"Algorithms and Theory of Computation Handbook"},{"paperId":"e631be2638577c34fbfce510fe2a17a48d7a11e4","externalIds":{"DBLP":"books/crc/99/Korf99","DOI":"10.1201/9781420049503-c37","CorpusId":15226556},"title":"Artificial Intelligence Search Algorithms"},{"paperId":"97efafdb4a3942ab3efba53ded7413199f79c054","externalIds":{"MAG":"2121863487","DBLP":"journals/tnn/SuttonB98","DOI":"10.1109/TNN.1998.712192","CorpusId":60035920},"title":"Reinforcement Learning: An Introduction"},{"paperId":"b98ddfa5080620f00968ba439eff2e7e235ff5d5","externalIds":{"MAG":"1515891729","CorpusId":60893378},"title":"Algorithms for Sequential Decision Making"}]}