{"paperId":"41b4cd49570fc4330b600d85da1994b0532a8f95","externalIds":{"ArXiv":"2404.02062","DBLP":"journals/corr/abs-2404-02062","DOI":"10.1007/s10462-024-11078-6","CorpusId":268856658},"title":"Digital forgetting in large language models: a survey of unlearning methods","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2404.02062, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"1398451349","name":"Alberto Blanco-Justicia"},{"authorId":"1820936916","name":"N. Jebreel"},{"authorId":"2185427845","name":"Benet Manzanares-Salor"},{"authorId":"2185430066","name":"David SÃ¡nchez"},{"authorId":"2182066930","name":"Josep Domingo-Ferrer"},{"authorId":"144481186","name":"Guillem Collell"},{"authorId":"2294619683","name":"Kuan Eeik Tan"}],"abstract":"Large language models (LLMs) have become the state of the art in natural language processing. The massive adoption of generative LLMs and the capabilities they have shown have prompted public concerns regarding their impact on the labor market, privacy, the use of copyrighted work, and how these models align with human ethics and the rule of law. As a response, new regulations are being pushed, which require developers and service providers to evaluate, monitor, and forestall or at least mitigate the risks posed by their models. One mitigation strategy is digital forgetting: given a model with undesirable knowledge or behavior, the goal is to obtain a new model where the detected issues are no longer present. Digital forgetting is usually enforced via machine unlearning techniques, which modify trained machine learning models for them to behave as models trained on a subset of the original training data. In this work, we describe the motivations and desirable properties of digital forgetting when applied to LLMs, and we survey recent works on machine unlearning. Specifically, we propose a taxonomy of unlearning methods based on the reach and depth of the modifications done on the models, we discuss and compare the effectiveness of machine unlearning methods for LLMs proposed so far, and we survey their evaluation. Finally, we describe open problems of machine unlearning applied to LLMs and we put forward recommendations for developers and practitioners."}