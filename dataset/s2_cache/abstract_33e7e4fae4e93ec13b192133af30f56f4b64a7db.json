{"abstract":"In the era of noisy intermediate-scale quantum (NISQ), variational quantum circuits (VQCs) have been widely applied in various domains, demonstrating the potential advantages of quantum circuits over classical models. Similar to classic models, VQCs can be optimized by various gradient-based methods. However, the optimization may get stuck in barren plateaus initially or trapped in saddle points during training. These gradient-related issues can severely impact the trainability of VQCs. In this work, we propose a strategy that regularizes model parameters with prior knowledge of the training data and Gaussian noise diffusion. We conduct ablation studies to verify the effectiveness of our strategy across four public datasets and demonstrate that our method can improve the trainability of VQCs against the above-mentioned gradient issues."}