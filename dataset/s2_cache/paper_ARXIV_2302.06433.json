{"paperId":"f869e73e4c196f350954394f1883e357d629fff6","externalIds":{"DBLP":"journals/tai/EldeleRCWKL24a","ArXiv":"2302.06433","DOI":"10.1109/TAI.2024.3430236","CorpusId":256827807},"title":"Label-Efficient Time Series Representation Learning: A Review","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2302.06433, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2086836960","name":"Emadeldeen Eldele"},{"authorId":"122101015","name":"Mohamed Ragab"},{"authorId":"48354147","name":"Zhenghua Chen"},{"authorId":"1390606776","name":"Min Wu"},{"authorId":"145367091","name":"C. Kwoh"},{"authorId":"2108674591","name":"Xiaoli Li"}],"abstract":"Label-efficient time series representation learning, which aims to learn effective representations with limited labeled data, is crucial for deploying deep learning models in real-world applications. To address the scarcity of labeled time series data, various strategies, e.g., transfer learning, self-supervised learning, and semisupervised learning, have been developed. In this survey, we introduce a novel taxonomy for the first time, categorizing existing approaches as in-domain or cross domain based on their reliance on external data sources or not. Furthermore, we present a review of the recent advances in each strategy, conclude the limitations of current methodologies, and suggest future research directions that promise further improvements in the field."}