{"paperId":"7d4cfaf07fef7c8b877a2dd15bba60c0566425fd","externalIds":{"ArXiv":"2310.19218","CorpusId":278715248},"title":"Exploring Federated Unlearning: Review, Comparison, and Insights","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2310.19218, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2282552083","name":"Yang Zhao"},{"authorId":"2264341901","name":"Jiaxi Yang"},{"authorId":"2283519328","name":"Yiling Tao"},{"authorId":"2108631990","name":"Lixu Wang"},{"authorId":"2257359927","name":"Xiaoxiao Li"},{"authorId":"2362086753","name":"D. Niyato"},{"authorId":"2265928102","name":"H. V. Poor"}],"abstract":"The increasing demand for privacy-preserving machine learning has spurred interest in federated unlearning, which enables the selective removal of data from models trained in federated systems. However, developing federated unlearning methods presents challenges, particularly in balancing three often conflicting objectives: privacy, accuracy, and efficiency. This paper provides a comprehensive analysis of existing federated unlearning approaches, examining their algorithmic efficiency, impact on model accuracy, and effectiveness in preserving privacy. We discuss key trade-offs among these dimensions and highlight their implications for practical applications across various domains. Additionally, we propose the OpenFederatedUnlearning framework, a unified benchmark for evaluating federated unlearning methods, incorporating classic baselines and diverse performance metrics. Our findings aim to guide practitioners in navigating the complex interplay of these objectives, offering insights to achieve effective and efficient federated unlearning. Finally, we outline directions for future research to further advance the state of federated unlearning techniques."}