{"abstract":"ChatGPT has gained attention worldwide. In the medical education field, ChatGPT, or any similar large language model, provides a convenient way for students to access information and practice their skills. ChatGPT can simulate patient interactions, allowing students to practice their diagnostic and communication skills in a safe and controlled environment. ChatGPT can also answer questions and provide explanations for complex medical concepts. There have been attempts involving ChatGPT to assist researchers in writing journal articles. Due to its capabilities, ChatGPT has the potential to be abused and sparking ethical concerns. Unwise researchers can now employ ChatGPT to write academic articles. Similarly, irresponsible students, might utilize ChatGPT to cheat during exams. We investigated whether ChatGPT, in its current state, can answer Indonesian medical doctor examination problems. Among the 3 problems that we have picked, ChatGPT can only correctly answer 1 question. We also examine whether ChatGPT-generated abstracts can fool professionals and educators. We have brought 6 abstracts, 3 of which are taken from actual published papers, while the other 3 were generated by ChatGPT. We recruited 12 participants with either a medical doctor (M.D.), a doctorate (Ph.D.), or an M.D., Ph.D. degree from various institutions in Indonesia. Surprisingly, 4 of the participants couldn't guess a single abstract correctly, 6 could only identify 1 abstract accurately, one correctly guessed 2 abstracts, and one correctly identified 3 abstracts. Therefore, it is safe to say that ChatGPT, in its current state, has been able to fool professionals and educators."}