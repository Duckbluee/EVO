{"abstract":"Algorithmic data-driven decision-making systems are becoming increasingly automated and have enjoyed tremendous success in a variety of application domains. More recently, these systems are increasingly being used to render all sort of socially-sensitive decisions. Yet, these automated decisions can lead, even in the absence of an intention, to a lack of fairness in the sense that members sharing one or more sensitive attributes are being treated unequally. In this paper, we handle unfairness in both online and offline settings. We introduce an algorithm-agnostic learning mechanism for optimal and non-discriminative decision-making as appropriate. This translates to a fairness-aware learning schema which can be immediately applied to most existing algorithms and to general decision-making tasks in dynamic settings with join data distribution changes over time."}