{"paperId":"3254be6ddde457c45b352ab357690e387d22614d","externalIds":{"ArXiv":"2402.03408","DBLP":"conf/coling/WangSZLKQT25","CorpusId":267499573},"title":"A Framework for Effective Invocation Methods of Various LLM Services","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2402.03408, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2283084847","name":"Can Wang"},{"authorId":"2261388493","name":"Dianbo Sui"},{"authorId":"2141899346","name":"Bolin Zhang"},{"authorId":"2282963571","name":"Xiaoyu Liu"},{"authorId":"2283143642","name":"Jiabao Kang"},{"authorId":"2120595707","name":"Zhidong Qiao"},{"authorId":"2282568037","name":"Zhiying Tu"}],"abstract":"Large Language Models (LLMs) have shown impressive abilities in solving various natural language processing tasks and are now widely offered as services. LLM services enable users to accomplish tasks without requiring specialized knowledge, simply by paying service providers. However, numerous providers offer various LLM services with variations in pricing, latency, and performance. These factors are also affected by different invocation methods, such as the choice of context and the use of cache, which lead to unpredictable and uncontrollable service cost and quality. Consequently, utilizing various LLM services invocation methods to construct an effective (cost-saving, low-latency and high-performance) invocation strategy that best meets task demands becomes a pressing challenge. This paper provides a comprehensive overview of methods help LLM services to be invoked efficiently. Technically, we define the problem of constructing an effective LLM services invocation strategy, and based on this, propose a unified LLM service invocation framework. The framework classifies existing methods into four categories: input abstraction, semantic cache, solution design, and output enhancement, which can be used separately or jointly during the invocation life cycle. We discuss the methods in each category and compare them to provide valuable guidance for researchers. Finally, we emphasize the open challenges in this domain and shed light on future research."}