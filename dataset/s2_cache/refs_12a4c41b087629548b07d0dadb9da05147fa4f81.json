{"references":[{"paperId":"fdf16ba99ddeb9a82311b7565143cf9ccfd004a8","externalIds":{"DBLP":"journals/corr/abs-2305-18869","ArXiv":"2305.18869","DOI":"10.48550/arXiv.2305.18869","CorpusId":258967618},"title":"Dissecting Chain-of-Thought: A Study on Compositional In-Context Learning of MLPs"},{"paperId":"7e4f5589327b6b574cc950a03fd1d6236e9e6128","externalIds":{"ArXiv":"2304.13007","DBLP":"conf/emnlp/YoranWBKDB23","DOI":"10.48550/arXiv.2304.13007","CorpusId":258309779},"title":"Answering Questions by Meta-Reasoning over Multiple Chains of Thought"},{"paperId":"cc0f0cb09a73f82ed44d900f5ca710bec784acc1","externalIds":{"DBLP":"conf/nips/PourrezaR23","ArXiv":"2304.11015","DOI":"10.48550/arXiv.2304.11015","CorpusId":258291425},"title":"DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction"},{"paperId":"5c0f3b0e46e6125bf2f454bcd8565a6f3430a54c","externalIds":{"ArXiv":"2304.10464","DBLP":"conf/emnlp/GuoLWW0D24","DOI":"10.18653/v1/2024.findings-emnlp.589","CorpusId":258236649},"title":"Learning to Plan by Updating Natural Language"},{"paperId":"170c97c7215f42edfb20c2248f954879e91ef86e","externalIds":{"DBLP":"conf/nips/LuPCGCWZG23","ArXiv":"2304.09842","DOI":"10.48550/arXiv.2304.09842","CorpusId":258212542},"title":"Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models"},{"paperId":"261549439aebdda72b648ecc462448fd24857ac1","externalIds":{"ArXiv":"2304.09797","DBLP":"journals/corr/abs-2304-09797","DOI":"10.48550/arXiv.2304.09797","CorpusId":258212839},"title":"Progressive-Hint Prompting Improves Reasoning in Large Language Models"},{"paperId":"9a3edb5c6b0e8c84c94ea99a9ab647b1209f650f","externalIds":{"DBLP":"conf/nips/PrystawskiLG23","ArXiv":"2304.03843","CorpusId":258048648},"title":"Why think step-by-step? Reasoning emerges from the locality of experience"},{"paperId":"e1bd151a3f670fd0f77580702fe7a85dc78a41cb","externalIds":{"DBLP":"conf/icml/JiaTLCH024","ArXiv":"2304.00776","DOI":"10.48550/arXiv.2304.00776","CorpusId":257912725},"title":"Chain-of-Thought Predictive Control"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"63d0e5a8f195b1453006781d4d8a4eb7262652d9","externalIds":{"DBLP":"journals/corr/abs-2303-12023","ArXiv":"2303.12023","DOI":"10.48550/arXiv.2303.12023","CorpusId":257636734},"title":"Logical Reasoning over Natural Language as Knowledge Representation: A Survey"},{"paperId":"e05483a41e8002e7024d39457e55a3fe533f5835","externalIds":{"ArXiv":"2303.08119","DBLP":"conf/emnlp/ChenCZ023","DOI":"10.18653/v1/2023.findings-emnlp.745","CorpusId":258309123},"title":"How Many Demonstrations Do You Need for In-context Learning?"},{"paperId":"47c3b8dd2c8a9326249ac98900b2c3fc71f46ab1","externalIds":{"ArXiv":"2303.06689","DBLP":"journals/corr/abs-2303-06689","DOI":"10.1145/3672456","CorpusId":257495755},"title":"Self-Planning Code Generation with Large Language Models"},{"paperId":"b9d75f361b5310c6ddcddfe7858bb0416eb78de4","externalIds":{"ACL":"2023.eacl-demo.23","DBLP":"journals/corr/abs-2303-03628","ArXiv":"2303.03628","DOI":"10.48550/arXiv.2303.03628","CorpusId":257378358},"title":"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification"},{"paperId":"68b560859078171978f2c040b1522f4e7668c38e","externalIds":{"ArXiv":"2303.03012","DBLP":"conf/icse/LiW0L0WG024","DOI":"10.1145/3597503.3639091","CorpusId":257365453},"title":"On Extracting Specialized Code Abilities from Large Language Models: A Feasibility Study"},{"paperId":"b626560f19f815808a289ef5c24a17c57320da70","externalIds":{"DBLP":"journals/corr/abs-2303-05398","ACL":"2023.acl-industry.4","ArXiv":"2303.05398","DOI":"10.48550/arXiv.2303.05398","CorpusId":257427208},"title":"MathPrompter: Mathematical Reasoning using Large Language Models"},{"paperId":"1358f90705b05cdb20ebe6799b02196205e7e9f0","externalIds":{"ArXiv":"2302.12822","DBLP":"conf/emnlp/ShumDZ23","DOI":"10.48550/arXiv.2302.12822","CorpusId":257205763},"title":"Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data"},{"paperId":"df7210b2a205030583e6ee4271270548fb645b59","externalIds":{"DBLP":"journals/corr/abs-2302-09051","ArXiv":"2302.09051","DOI":"10.48550/arXiv.2302.09051","CorpusId":257019916},"title":"Complex QA and language models hybrid architectures, Survey"},{"paperId":"53d128ea815bcc0526856eb5a9c42cc977cb36a7","externalIds":{"DBLP":"journals/corr/abs-2302-04761","ArXiv":"2302.04761","DOI":"10.48550/arXiv.2302.04761","CorpusId":256697342},"title":"Toolformer: Language Models Can Teach Themselves to Use Tools"},{"paperId":"780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050","externalIds":{"DBLP":"journals/corr/abs-2302-00923","ArXiv":"2302.00923","DOI":"10.48550/arXiv.2302.00923","CorpusId":256504063},"title":"Multimodal Chain-of-Thought Reasoning in Language Models"},{"paperId":"69619a2a47faee7a29ec596db13172e2a42ff921","externalIds":{"DBLP":"journals/corr/abs-2302-00618","ArXiv":"2302.00618","DOI":"10.48550/arXiv.2302.00618","CorpusId":256459681},"title":"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models"},{"paperId":"5988806996e8d12f5d4aa911960d842cf7be0c24","externalIds":{"DBLP":"conf/sigir/YeHYLHL23","ArXiv":"2301.13808","DOI":"10.1145/3539618.3591708","CorpusId":256416408},"title":"Large Language Models are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning"},{"paperId":"b115c1e1e9e51f8ad7d47b745bc04e29a654b84d","externalIds":{"DBLP":"journals/corr/abs-2301-13379","ACL":"2023.ijcnlp-main.20","ArXiv":"2301.13379","DOI":"10.48550/arXiv.2301.13379","CorpusId":256416127},"title":"Faithful Chain-of-Thought Reasoning"},{"paperId":"fbd49b25bdab98c171af49962a41139c73dacbde","externalIds":{"DBLP":"conf/icml/FuPOSK23","ArXiv":"2301.12726","DOI":"10.48550/arXiv.2301.12726","CorpusId":256390607},"title":"Specializing Smaller Language Models towards Multi-Step Reasoning"},{"paperId":"edc9bf11c4810a77f00ccb96130ff67ee578391e","externalIds":{"DBLP":"journals/corr/abs-2301-11596","PubMedCentral":"10409727","ArXiv":"2301.11596","DOI":"10.1038/s41597-023-02433-3","CorpusId":256358591,"PubMed":"37553439"},"title":"ThoughtSource: A central hub for large language model reasoning data"},{"paperId":"c43a4a7b7ea4f4889de051321cb0073fd577f843","externalIds":{"DBLP":"conf/eacl/ZhangXYZYAC23","ACL":"2023.findings-eacl.31","ArXiv":"2301.10896","DOI":"10.48550/arXiv.2301.10896","CorpusId":256274941},"title":"Causal Reasoning of Entities and Events in Procedural Texts"},{"paperId":"a7fa71dc6856ebef79f354597128d1c68b19b6e4","externalIds":{"DBLP":"conf/icml/LiIPO23","ArXiv":"2301.07067","CorpusId":256616253},"title":"Transformers as Algorithms: Generalization and Stability in In-context Learning"},{"paperId":"30c0cdc414f68211d5d0514df027cec22e005174","externalIds":{"DBLP":"conf/emnlp/Dong0DZMLXX0C0S24","ArXiv":"2301.00234","ACL":"2024.emnlp-main.64","DOI":"10.18653/v1/2024.emnlp-main.64","CorpusId":255372865},"title":"A Survey on In-context Learning"},{"paperId":"490d8006851b1562cfd9ec1f057471f2868289d1","externalIds":{"DBLP":"journals/corr/abs-2301-00303","ArXiv":"2301.00303","DOI":"10.48550/arXiv.2301.00303","CorpusId":255372320},"title":"Rethinking with Retrieval: Faithful Large Language Model Inference"},{"paperId":"6052486bc9144dc1730c12bf35323af3792a1fd0","externalIds":{"ArXiv":"2212.13138","DBLP":"journals/corr/abs-2212-13138","PubMedCentral":"10396962","DOI":"10.1038/s41586-023-06291-2","CorpusId":255124952,"PubMed":"37438534"},"title":"Large language models encode clinical knowledge"},{"paperId":"f208ea909fa7f54fea82def9a92fd81dfc758c39","externalIds":{"ArXiv":"2212.10509","DBLP":"journals/corr/abs-2212-10509","ACL":"2023.acl-long.557","DOI":"10.48550/arXiv.2212.10509","CorpusId":254877499},"title":"Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions"},{"paperId":"35922cd0d6b17e45320917338e9f98cb5c1a4f6f","externalIds":{"ArXiv":"2212.10001","DBLP":"conf/acl/WangM0S0Z023","ACL":"2023.acl-long.153","DOI":"10.48550/arXiv.2212.10001","CorpusId":254877569},"title":"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters"},{"paperId":"a9e3e5dd7b30890553b7ae1c41f932e99192bb44","externalIds":{"ACL":"2023.acl-long.830","DBLP":"conf/acl/HoSY23","ArXiv":"2212.10071","DOI":"10.48550/arXiv.2212.10071","CorpusId":254877399},"title":"Large Language Models Are Reasoning Teachers"},{"paperId":"db4ab91d5675c37795e719e997a2827d3d83cd45","externalIds":{"ArXiv":"2212.10403","DBLP":"conf/acl/0009C23","DOI":"10.48550/arXiv.2212.10403","CorpusId":254877753},"title":"Towards Reasoning in Large Language Models: A Survey"},{"paperId":"69c85405cc1986a41f6387d869aa1648a5668d6f","externalIds":{"ArXiv":"2212.10559","CorpusId":258686544},"title":"Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers"},{"paperId":"6845bea94b2fb17d4377b3bb2bd10f73a959f9cc","externalIds":{"DBLP":"journals/corr/abs-2212-09597","ArXiv":"2212.09597","ACL":"2023.acl-long.294","DOI":"10.48550/arXiv.2212.09597","CorpusId":254854219},"title":"Reasoning with Language Model Prompting: A Survey"},{"paperId":"126a4776ff8315fd506766cb8f3c722cf746ad9e","externalIds":{"DBLP":"journals/corr/abs-2212-08410","ACL":"2023.acl-short.151","ArXiv":"2212.08410","DOI":"10.48550/arXiv.2212.08410","CorpusId":254823156},"title":"Teaching Small Language Models to Reason"},{"paperId":"95c11cc5820ba32c60d5f2671f6567b9914a4978","externalIds":{"DBLP":"journals/corr/abs-2212-08286","ACL":"2023.acl-long.60","ArXiv":"2212.08286","DOI":"10.48550/arXiv.2212.08286","CorpusId":254823245},"title":"ALERT: Adapt Language Models to Reasoning Tasks"},{"paperId":"3936fd3c6187f606c6e4e2e20b196dbc41cc4654","externalIds":{"DBLP":"journals/corr/abs-2212-08073","ArXiv":"2212.08073","DOI":"10.48550/arXiv.2212.08073","CorpusId":254823489},"title":"Constitutional AI: Harmlessness from AI Feedback"},{"paperId":"097dc73d5d422b3c09286e72d16b2561ae5fb395","externalIds":{"DBLP":"conf/acl/Ye0CSDP23","ArXiv":"2211.13892","DOI":"10.48550/arXiv.2211.13892","CorpusId":254017626},"title":"Complementary Explanations for Effective In-Context Learning"},{"paperId":"6c943670dca38bfc7c8b477ae7c2d1fba1ad3691","externalIds":{"DBLP":"journals/tmlr/ChenM0C23","ArXiv":"2211.12588","CorpusId":253801709},"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"},{"paperId":"6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7","externalIds":{"ArXiv":"2211.10435","DBLP":"journals/corr/abs-2211-10435","DOI":"10.48550/arXiv.2211.10435","CorpusId":253708270},"title":"PAL: Program-aided Language Models"},{"paperId":"4d17732d90440682b0500f4e209c6cc4fac20e0e","externalIds":{"ArXiv":"2211.09066","DBLP":"journals/corr/abs-2211-09066","DOI":"10.48550/arXiv.2211.09066","CorpusId":253553151},"title":"Teaching Algorithmic Reasoning via In-context Learning"},{"paperId":"deff814eefe597b2fe275bc3dd205ecb1cc09c4e","externalIds":{"DBLP":"journals/corr/abs-2211-01562","ArXiv":"2211.01562","DOI":"10.48550/arXiv.2211.01562","CorpusId":253265114},"title":"PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales"},{"paperId":"4610ffb1b016acaa82a2065ffd1a3adbae1ce722","externalIds":{"DBLP":"journals/corr/abs-2211-01910","ArXiv":"2211.01910","DOI":"10.48550/arXiv.2211.01910","CorpusId":253265328},"title":"Large Language Models Are Human-Level Prompt Engineers"},{"paperId":"38e1a9c5599fc7597b7c5ffd37951ba5f528094c","externalIds":{"DBLP":"journals/corr/abs-2210-13693","ArXiv":"2210.13693","DOI":"10.48550/arXiv.2210.13693","CorpusId":253107357},"title":"XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"3fa70115248377c3d1517c9f978791a296fbc1dd","externalIds":{"DBLP":"conf/emnlp/0001GHW00023","ArXiv":"2210.11610","DOI":"10.48550/arXiv.2210.11610","CorpusId":253080328},"title":"Large Language Models Can Self-Improve"},{"paperId":"663a41c866d49ce052801fbc88947d39764cad29","externalIds":{"DBLP":"conf/acl/SuzgunSSGTCCLCZ23","ArXiv":"2210.09261","DOI":"10.48550/arXiv.2210.09261","CorpusId":252917648},"title":"Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them"},{"paperId":"e66f0f822d4c4853b39b27daaafa2993005fd55e","externalIds":{"DBLP":"conf/eacl/Chen23","ACL":"2023.findings-eacl.83","ArXiv":"2210.06710","DOI":"10.48550/arXiv.2210.06710","CorpusId":252872943},"title":"Large Language Models are few(1)-shot Table Reasoners"},{"paperId":"712f21411526e8450036d7199637808590be3579","externalIds":{"DBLP":"journals/corr/abs-2210-05075","ArXiv":"2210.05075","DOI":"10.48550/arXiv.2210.05075","CorpusId":252815431},"title":"Reflection of Thought: Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems"},{"paperId":"90350aa626bed47b02d0c162462e5b0ca82be6b2","externalIds":{"DBLP":"journals/corr/abs-2210-03493","ArXiv":"2210.03493","CorpusId":252762275},"title":"Automatic Chain of Thought Prompting in Large Language Models"},{"paperId":"e070ff286709db28312e08b52b05539debe88146","externalIds":{"DBLP":"conf/emnlp/PressZMSSL23","ArXiv":"2210.03350","DOI":"10.48550/arXiv.2210.03350","CorpusId":252762102},"title":"Measuring and Narrowing the Compositionality Gap in Language Models"},{"paperId":"62f0db3a5ad5c795ec18fc7a6e7b01836809df57","externalIds":{"DBLP":"conf/iclr/ShiSF0SVCTRZ0W23","ArXiv":"2210.03057","DOI":"10.48550/arXiv.2210.03057","CorpusId":252735112},"title":"Language Models are Multilingual Chain-of-Thought Reasoners"},{"paperId":"07955e96cbd778d0ae2a68f09d073b866dd84c2a","externalIds":{"ArXiv":"2210.02406","DBLP":"conf/iclr/KhotTFF0CS23","DOI":"10.48550/arXiv.2210.02406","CorpusId":252715485},"title":"Decomposed Prompting: A Modular Approach for Solving Complex Tasks"},{"paperId":"c88cafa3e980765a64febe369ceb7c2aa7261d2a","externalIds":{"DBLP":"journals/corr/abs-2210-00720","ArXiv":"2210.00720","DOI":"10.48550/arXiv.2210.00720","CorpusId":252683303},"title":"Complexity-Based Prompting for Multi-Step Reasoning"},{"paperId":"e7028cd7ea838ab8294ecf26d5a2c0dbb8cfa81a","externalIds":{"DBLP":"journals/corr/abs-2210-01240","ArXiv":"2210.01240","DOI":"10.48550/arXiv.2210.01240","CorpusId":252693237},"title":"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought"},{"paperId":"40047a74b707743157051d38f76061ba5ff9aab4","externalIds":{"DBLP":"journals/corr/abs-2209-15003","ArXiv":"2209.15003","CorpusId":252596001},"title":"Compositional Semantic Parsing with Large Language Models"},{"paperId":"c90a99eeb57019732a6cc996bb9eaf13faedf00f","externalIds":{"ArXiv":"2209.11895","DBLP":"journals/corr/abs-2209-11895","DOI":"10.48550/arXiv.2209.11895","CorpusId":252532078},"title":"In-context Learning and Induction Heads"},{"paperId":"d3135733aa39dec20ce72aa138589dda27c8406d","externalIds":{"DBLP":"conf/nips/LuMX0CZTCK22","ArXiv":"2209.09513","DOI":"10.48550/arXiv.2209.09513","CorpusId":252383606},"title":"Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"},{"paperId":"4988b3d378b79eb8669112620baf1ff4e3e536fd","externalIds":{"ArXiv":"2209.07686","DBLP":"journals/corr/abs-2209-07686","DOI":"10.48550/arXiv.2209.07686","CorpusId":252355328},"title":"Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango"},{"paperId":"de32da8f5c6a50a6c311e9357ba16aa7d05a1bc9","externalIds":{"DBLP":"journals/corr/abs-2208-01066","ArXiv":"2208.01066","DOI":"10.48550/arXiv.2208.01066","CorpusId":251253368},"title":"What Can Transformers Learn In-Context? A Case Study of Simple Function Classes"},{"paperId":"f843233f76a5dff07bfa93a71a1cf13d8aa6a94a","externalIds":{"ArXiv":"2207.04901","DBLP":"conf/nips/AnilWALMRSGDN22","DOI":"10.48550/arXiv.2207.04901","CorpusId":250425737},"title":"Exploring Length Generalization in Large Language Models"},{"paperId":"b17cc18e4130505b939f7d527082eb6be2a7fd5b","externalIds":{"DBLP":"journals/corr/abs-2207-00747","ArXiv":"2207.00747","DOI":"10.48550/arXiv.2207.00747","CorpusId":250264890},"title":"Rationale-Augmented Ensembles in Language Models"},{"paperId":"e850d4c0dad3aee3b8b40be5e5d5e5c31354d8cc","externalIds":{"ArXiv":"2206.10498","DBLP":"conf/nips/ValmeekamMHSK23","CorpusId":249889477},"title":"PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","externalIds":{"DBLP":"journals/corr/abs-2205-11916","ArXiv":"2205.11916","CorpusId":249017743},"title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"50b0c6ee2b3d53ba5af69d6c00b5d60888a9026f","externalIds":{"DBLP":"conf/emnlp/JungQWBB0C22","ArXiv":"2205.11822","ACL":"2022.emnlp-main.82","DOI":"10.48550/arXiv.2205.11822","CorpusId":249017524},"title":"Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations"},{"paperId":"4b516216d7d150a081fd74993bddf36b6b22c118","externalIds":{"ArXiv":"2205.10816","DBLP":"conf/nips/YangSAN22","DOI":"10.48550/arXiv.2205.10816","CorpusId":248986984},"title":"Chain of Thought Imitation with Procedure Cloning"},{"paperId":"5437e8adab596d7294124c0e798708e050e25321","externalIds":{"ArXiv":"2205.10625","DBLP":"conf/iclr/ZhouSHWS0SCBLC23","DOI":"10.48550/arXiv.2205.10625","CorpusId":248986239},"title":"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"},{"paperId":"d48b29889241551e1ee6622fa78c3fa4159255dd","externalIds":{"ArXiv":"2205.09712","DBLP":"journals/corr/abs-2205-09712","CorpusId":248887351},"title":"Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning"},{"paperId":"9ffefdf1fcd780cb71450b0a7a29247c66aa87be","externalIds":{"DBLP":"conf/nips/YeD22","ArXiv":"2205.03401","CorpusId":252873674},"title":"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning"},{"paperId":"146e9e1238ff6caf18f0bd936ffcfbe1e65d2afd","externalIds":{"DBLP":"conf/nips/ChanSLWSRMH22","ArXiv":"2205.05055","DOI":"10.48550/arXiv.2205.05055","CorpusId":248665718},"title":"Data Distributional Properties Drive Emergent In-Context Learning in Transformers"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"23dd78e424d32f6a48660dcd67ce994b8a7db8be","externalIds":{"ArXiv":"2203.14465","CorpusId":247762790},"title":"STaR: Bootstrapping Reasoning With Reasoning"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","externalIds":{"DBLP":"conf/iclr/0002WSLCNCZ23","ArXiv":"2203.11171","CorpusId":247595263},"title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"3f4d11971f2c64be9125a7fe99c019588bbebf16","externalIds":{"DBLP":"conf/emnlp/Wang0S22","ArXiv":"2203.08383","ACL":"2022.emnlp-main.174","DOI":"10.18653/v1/2022.emnlp-main.174","CorpusId":253098851},"title":"Iteratively Prompt Pre-trained Language Models for Chain of Thought"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"3def68bd0f856886d34272840a7f81588f2bc082","externalIds":{"DBLP":"journals/corr/abs-2202-03629","ArXiv":"2202.03629","DOI":"10.1145/3571730","CorpusId":246652372},"title":"Survey of Hallucination in Natural Language Generation"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"002c58077a1f1b296468b117230a1199e91f35c2","externalIds":{"ArXiv":"2201.03514","DBLP":"conf/icml/SunSQHQ22","CorpusId":245836882},"title":"Black-Box Tuning for Language-Model-as-a-Service"},{"paperId":"10bd4160b44803ada6a3d2e366c44b7e2a4ffe90","externalIds":{"DBLP":"journals/corr/abs-2111-02080","ArXiv":"2111.02080","CorpusId":241035330},"title":"An Explanation of In-context Learning as Implicit Bayesian Inference"},{"paperId":"d6045d2ccc9c09ca1671348de86d07da6bc28eea","externalIds":{"ArXiv":"2110.14168","DBLP":"journals/corr/abs-2110-14168","CorpusId":239998651},"title":"Training Verifiers to Solve Math Word Problems"},{"paperId":"17dd3555fd1ccf1141cf984347fa1b3fd6b009ca","externalIds":{"ArXiv":"2110.08207","DBLP":"journals/corr/abs-2110-08207","CorpusId":239009562},"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization"},{"paperId":"ce498651107588db67adcfbb5479bdb416f4de2f","externalIds":{"ACL":"2021.findings-acl.161","DBLP":"journals/corr/abs-2106-01760","ArXiv":"2106.01760","DOI":"10.18653/v1/2021.findings-acl.161","CorpusId":235313658},"title":"Template-Based Named Entity Recognition Using BART"},{"paperId":"0adec918885dff698acf359988ed79a543157f80","externalIds":{"DBLP":"journals/corr/abs-2104-08786","ArXiv":"2104.08786","ACL":"2022.acl-long.556","DOI":"10.18653/v1/2022.acl-long.556","CorpusId":233296494},"title":"Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"},{"paperId":"59641c10ed7431a3cf841f308367dc2dc0281b74","externalIds":{"DBLP":"conf/acl-deelio/LiuSZDCC22","ArXiv":"2101.06804","ACL":"2022.deelio-1.10","DOI":"10.18653/v1/2022.deelio-1.10","CorpusId":231632658},"title":"What Makes Good In-Context Examples for GPT-3?"},{"paperId":"f30444fbb6ad806168e2564db4815cd27faa7fd9","externalIds":{"ArXiv":"2009.07118","MAG":"3085177480","DBLP":"conf/naacl/SchickS21","ACL":"2021.naacl-main.185","DOI":"10.18653/V1/2021.NAACL-MAIN.185","CorpusId":221703107},"title":"Itâ€™s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"bae1a80920b9c7bafb89c2a4bd6842448a1f4415","externalIds":{"DBLP":"journals/corr/abs-2002-03776","MAG":"3112857588","ArXiv":"2002.03776","DOI":"10.1109/SMC42975.2020.9282812","CorpusId":211069647},"title":"Towards Deep Machine Reasoning: a Prototype-based Deep Neural Network with Decision Tree Inference"},{"paperId":"653864b10564ab4712c07a3d4043a1d794b13c46","externalIds":{"DBLP":"conf/aies/SlackHJSL20","MAG":"3005086430","ArXiv":"1911.02508","DOI":"10.1145/3375627.3375830","CorpusId":211041098},"title":"Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods"},{"paperId":"cf2fcb73e2effff29ceb5a5b89bbca34d2d27c1a","externalIds":{"ACL":"2020.acl-main.432","DBLP":"journals/corr/abs-1909-07913","MAG":"2973291083","ArXiv":"1909.07913","DOI":"10.18653/v1/2020.acl-main.432","CorpusId":202583616},"title":"Learning to Deceive with Attention-Based Explanations"},{"paperId":"ef8fc5c0c8523e2cfcd3975a372b0a8705b392d2","externalIds":{"DBLP":"conf/nips/Qu019","MAG":"2951193785","ArXiv":"1906.08495","CorpusId":195218696},"title":"Probabilistic Logic Neural Networks for Reasoning"},{"paperId":"acc43abe319bca7652a91f7d4ca6187049fb82e4","externalIds":{"ArXiv":"1807.04225","DBLP":"conf/icml/SantoroHBML18","MAG":"2804180102","CorpusId":49665167},"title":"Measuring abstract reasoning in neural networks"},{"paperId":"4d05ab884a6c1645b80ce5d02b09c7e5ff499790","externalIds":{"ArXiv":"1508.05508","DBLP":"journals/corr/PengLLW15","MAG":"2133585753","CorpusId":402276},"title":"Towards Neural Network-based Reasoning"},{"paperId":"49293522fe3818769f5067e360c971bd7a82e0aa","externalIds":{"DBLP":"journals/corr/abs-2302-04813","DOI":"10.48550/arXiv.2302.04813","CorpusId":256697139},"title":"Explanation Selection Using Unlabeled Data for In-Context Learning"},{"paperId":"d1120d67b700e4dfe8b39eb1e48fbdea4e1a0c43","externalIds":{"ArXiv":"2303.17580","DBLP":"journals/corr/abs-2303-17580","DOI":"10.48550/arXiv.2303.17580","CorpusId":257833781},"title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face"},{"paperId":"760561c57f68044e2f1d089088df1da6c627b09a","externalIds":{"DBLP":"journals/corr/abs-2206-02336","DOI":"10.48550/arXiv.2206.02336","CorpusId":249395505},"title":"On the Advance of Making Language Models Better Reasoners"},{"paperId":"f02e8f1c9b5ab12ddfb1977570f9f5445a99a973","externalIds":{"DBLP":"journals/corr/abs-2212-09561","DOI":"10.48550/arXiv.2212.09561","CorpusId":254854206},"title":"Large Language Models are reasoners with Self-Verification"},{"paperId":"1e122149779c644855d1cccca5d96135db0482cb","externalIds":{"DBLP":"journals/corr/abs-2212-08635","DOI":"10.48550/arXiv.2212.08635","CorpusId":254823646},"title":"Self-Prompting Large Language Models for Open-Domain QA"},{"paperId":"be247b198a710413817cac3d8208071ea40d84fe","externalIds":{"DBLP":"journals/corr/abs-2206-05442","DOI":"10.48550/arXiv.2206.05442","CorpusId":249625585},"title":"A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams"},{"paperId":"0c0a778e6fdf7e36b1750c533dcc916f86608607","externalIds":{"MAG":"2527310337","DBLP":"journals/tkde/XunJGZ17","DOI":"10.1109/TKDE.2016.2614508","CorpusId":13490401},"title":"A Survey on Context Learning"},{"paperId":"db3224497b2ceedd39cf7f20d4875434e212979e","externalIds":{"CorpusId":15096071},"title":"Ensemble Methods: Foundations and Algorithms"}]}