{"abstract":"Text-guided image generation models can be prompted to generate images using made-up words adversarially designed to robustly evoke speciﬁc visual concepts. Two approaches for such generation are introduced: macaronic prompting , which involves designing cryptic hybrid words by concatenating subword units from diﬀerent languages; and evocative prompting , which involves designing nonce words whose broad morphological features are similar enough to that of existing words to trigger robust visual associations. The two methods can also be combined to generate images associated with more speciﬁc visual concepts. The implications of these techniques for the circumvention of existing approaches to content moderation, and particularly the generation of oﬀensive or harmful images, are discussed."}