{"references":[{"paperId":"b4e4a90601986a3fd13130aee961450328802164","externalIds":{"ArXiv":"2407.04411","DBLP":"journals/corr/abs-2407-04411","DOI":"10.48550/arXiv.2407.04411","CorpusId":271039706},"title":"Waterfall: Framework for Robust and Scalable Text Watermarking"},{"paperId":"6fed62deb232d1106d0411cecc47c43766acfa1e","externalIds":{"DBLP":"journals/corr/abs-2406-02603","ArXiv":"2406.02603","DOI":"10.48550/arXiv.2406.02603","CorpusId":270258466},"title":"Distortion-free Watermarks are not Truly Distortion-free under Watermark Key Collisions"},{"paperId":"29accab7328e0fecc7c85e96372ca9e66e91634b","externalIds":{"DBLP":"journals/corr/abs-2405-10051","ACL":"2024.emnlp-demo.7","ArXiv":"2405.10051","DOI":"10.48550/arXiv.2405.10051","CorpusId":269791444},"title":"MarkLLM: An Open-Source Toolkit for LLM Watermarking"},{"paperId":"3b1ed0508a24ef157cb4458ab95dead821b8c90a","externalIds":{"DBLP":"journals/corr/abs-2404-15639","ArXiv":"2404.15639","DOI":"10.48550/arXiv.2404.15639","CorpusId":269330308},"title":"CodeIP: A Grammar-Guided Multi-Bit Watermark for Large Language Models of Code"},{"paperId":"8745783a3786658e8cc8046fcb8685c8237352c2","externalIds":{"ArXiv":"2403.19548","DBLP":"journals/corr/abs-2403-19548","DOI":"10.48550/arXiv.2403.19548","CorpusId":268732682},"title":"WaterJudge: Quality-Detection Trade-off when Watermarking Large Language Models"},{"paperId":"507e6f43f0670195db4b224c5e8858c1317977d6","externalIds":{"DBLP":"journals/corr/abs-2403-13335","ArXiv":"2403.13335","DOI":"10.1109/IJCNN60899.2024.10651296","CorpusId":268536862},"title":"Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection"},{"paperId":"ff4ac308b02331c75c431b4bf01c0485b91761c8","externalIds":{"DBLP":"conf/acl/LuLY0K24","ArXiv":"2403.13485","DOI":"10.48550/arXiv.2403.13485","CorpusId":268536698},"title":"An Entropy-based Text Watermarking Detection Method"},{"paperId":"144399b7708c0e15b8f067f7635df173a7067905","externalIds":{"ArXiv":"2403.14719","DBLP":"conf/acl/0002C24","DOI":"10.48550/arXiv.2403.14719","CorpusId":268666965},"title":"Bypassing LLM Watermarks with Color-Aware Substitutions"},{"paperId":"c199b7ee0609a560a7607ea84add32b6f819ecf7","externalIds":{"DBLP":"journals/corr/abs-2403-04808","ArXiv":"2403.04808","DOI":"10.48550/arXiv.2403.04808","CorpusId":268296923},"title":"WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off"},{"paperId":"c7af46b35061e856aa3332ac2eec6a7ccee0cb35","externalIds":{"DBLP":"conf/icml/0001SV24","ArXiv":"2402.19361","DOI":"10.48550/arXiv.2402.19361","CorpusId":268091202},"title":"Watermark Stealing in Large Language Models"},{"paperId":"94c28609614719c68469081ed99315f54cb1fb6a","externalIds":{"DBLP":"journals/corr/abs-2402-11399","ArXiv":"2402.11399","DOI":"10.48550/arXiv.2402.11399","CorpusId":267750325},"title":"k-SemStamp: A Clustering-Based Semantic Watermark for Detection of Machine-Generated Text"},{"paperId":"92ea7d8fb89e13b3118d84d2400ae1b6aecced73","externalIds":{"ArXiv":"2312.04469","DBLP":"conf/iclr/GuLLH24","DOI":"10.48550/arXiv.2312.04469","CorpusId":266054907},"title":"On the Learnability of Watermarks for Language Models"},{"paperId":"383c598625110e0a4c60da4db10a838ef822fbcf","externalIds":{"ArXiv":"2312.02003","DBLP":"journals/corr/abs-2312-02003","DOI":"10.1016/j.hcc.2024.100211","CorpusId":265609409},"title":"A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly"},{"paperId":"8b4bdf5597be80cb83f668058609939a44a76297","externalIds":{"DBLP":"journals/corr/abs-2312-00273","ArXiv":"2312.00273","DOI":"10.1109/SaTML64287.2025.00012","CorpusId":265552122},"title":"MARKMyWORDS: Analyzing and Evaluating Language Model Watermarks"},{"paperId":"0bee079faf3dc53380db55cd5fc1ba9267c4d5e7","externalIds":{"ArXiv":"2311.09832","DBLP":"conf/acl/ChenB00LZW24","DOI":"10.18653/v1/2024.acl-long.496","CorpusId":267740518},"title":"WatME: Towards Lossless Watermarking Through Lexical Redundancy"},{"paperId":"3faa802714bfc051ada8317fdbf483742df65bd0","externalIds":{"ArXiv":"2311.08721","DBLP":"journals/corr/abs-2311-08721","DOI":"10.48550/arXiv.2311.08721","CorpusId":265213008},"title":"A Robust Semantics-based Watermark for Large Language Model against Paraphrasing"},{"paperId":"ee5e79a83b019d5a7e3ad55e6e39696aff67a5f2","externalIds":{"DBLP":"journals/aim/ChenS24","ArXiv":"2311.05656","DOI":"10.48550/arXiv.2311.05656","CorpusId":265128809},"title":"Combating Misinformation in the Age of LLMs: Opportunities and Challenges"},{"paperId":"702e727976e4f08c1ddc3a08cf76cd689dab2f63","externalIds":{"DBLP":"journals/iacr/FairozeGJMMW23","ArXiv":"2310.18491","DOI":"10.48550/arXiv.2310.18491","CorpusId":264560541},"title":"Publicly Detectable Watermarking for Language Models"},{"paperId":"8ff1dd6e15408581592f91434be870acc5f1bdd4","externalIds":{"DBLP":"conf/uss/ZhangHNK24","ArXiv":"2310.12362","DOI":"10.48550/arXiv.2310.12362","CorpusId":264305916},"title":"REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models"},{"paperId":"46eea7d651420e60f9b1393e3f5eda14cbff7a2a","externalIds":{"DBLP":"conf/iclr/PatilHB24","ArXiv":"2309.17410","DOI":"10.48550/arXiv.2309.17410","CorpusId":263311025},"title":"Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks"},{"paperId":"6f75e8b61f13562237851d8119cb2f9d49e073fb","externalIds":{"DBLP":"journals/corr/abs-2309-13788","ArXiv":"2309.13788","DOI":"10.48550/arXiv.2309.13788","CorpusId":262465354},"title":"Can LLM-Generated Misinformation Be Detected?"},{"paperId":"ab2066233ea2da540f44118d989d66db5687752a","externalIds":{"DBLP":"journals/corr/abs-2309-10544","ArXiv":"2309.10544","DOI":"10.48550/arXiv.2309.10544","CorpusId":262053852},"title":"Model Leeching: An Extraction Attack Targeting LLMs"},{"paperId":"c47cb9d407b8cfd51699881a804811cc0e5fcade","externalIds":{"DBLP":"journals/corr/abs-2308-14401","ArXiv":"2308.14401","DOI":"10.1145/3611643.3616297","CorpusId":261244028},"title":"CodeMark: Imperceptible Watermarking for Code Datasets against Neural Code Completion Models"},{"paperId":"4053dc56d31a5f0082f93e030b0dba7efc2cba01","externalIds":{"DBLP":"conf/naacl/YooAK24","ACL":"2024.naacl-long.224","ArXiv":"2308.00221","DOI":"10.18653/v1/2024.naacl-long.224","CorpusId":262940018},"title":"Advancing Beyond Identification: Multi-bit Watermark for Large Language Models"},{"paperId":"1628f98a0f3865e023c18bcde5c0b61fd35f4e5e","externalIds":{"DBLP":"journals/ijon/LiWZ23b","DOI":"10.1016/j.neucom.2023.126700","CorpusId":261013825},"title":"A novel watermarking framework for intellectual property protection of NLG APIs"},{"paperId":"0d24a88f29dd87efb90dc8b33c1f41c25f63e574","externalIds":{"DBLP":"conf/iclr/LiuPH0WKY24","ArXiv":"2307.16230","CorpusId":260333928},"title":"An Unforgeable Publicly Verifiable Watermark for Large Language Models"},{"paperId":"aeaf588d79671267cb19629ec4966744b6eccffa","externalIds":{"DBLP":"conf/iclr/WangYC0LM0024","ArXiv":"2307.15992","CorpusId":260334887},"title":"Towards Codable Watermarking for Injecting Multi-Bits Information to LLMs"},{"paperId":"ccaff61e0c1e629d91d78f82a64b3cbc8f3f7023","externalIds":{"ArXiv":"2307.15593","DBLP":"journals/corr/abs-2307-15593","DOI":"10.48550/arXiv.2307.15593","CorpusId":260315804},"title":"Robust Distortion-free Watermarks for Language Models"},{"paperId":"ca18c18ddd730e4d690431ad6c65035d0f41aed6","externalIds":{"DBLP":"conf/aaai/FuXD24","ArXiv":"2307.13808","DOI":"10.48550/arXiv.2307.13808","CorpusId":260164516},"title":"Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy"},{"paperId":"d62c4d00b277e948956b6610ce2644e88fe1577b","externalIds":{"DBLP":"journals/cacm/Cerf23c","ArXiv":"2307.05782","DOI":"10.1007/978-981-96-6259-3","CorpusId":259837466,"PubMed":"38320147"},"title":"Large Language Models"},{"paperId":"75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc","externalIds":{"DBLP":"journals/corr/abs-2306-17439","ArXiv":"2306.17439","DOI":"10.48550/arXiv.2306.17439","CorpusId":259308864},"title":"Provable Robust Watermarking for AI-Generated Text"},{"paperId":"a0a79dad89857a96f8f71b14238e5237cbfc4787","externalIds":{"ArXiv":"2306.05685","DBLP":"journals/corr/abs-2306-05685","CorpusId":259129398},"title":"Judging LLM-as-a-judge with MT-Bench and Chatbot Arena"},{"paperId":"92e20105c6043add4ffeef86e68a4ed24e886791","externalIds":{"DBLP":"journals/corr/abs-2306-00137","ArXiv":"2306.00137","DOI":"10.48550/arXiv.2306.00137","CorpusId":258999502},"title":"A Sequence-to-Sequence&Set Model for Text-to-Table Generation"},{"paperId":"3b732c83e12948fb665094181f552f32d8a37a31","externalIds":{"DBLP":"journals/corr/abs-2305-18226","ArXiv":"2305.18226","CorpusId":258960155},"title":"HowkGPT: Investigating the Detection of ChatGPT-generated University Student Homework through Context-Aware Perplexity Analysis"},{"paperId":"90213971da84c974bc7502b1112a0ee8a0a33601","externalIds":{"DBLP":"conf/acl/Lee0AHLYSK24","ArXiv":"2305.15060","DOI":"10.48550/arXiv.2305.15060","CorpusId":258865409},"title":"Who Wrote this Code? Watermarking for Code Generation"},{"paperId":"cb6cc7d28d06a0d7c0d3f0d7ee551bbc86dbc3aa","externalIds":{"DBLP":"journals/corr/abs-2305-14387","ArXiv":"2305.14387","DOI":"10.48550/arXiv.2305.14387","CorpusId":258865545},"title":"AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback"},{"paperId":"78c516bc91be667fa25115c9d5c029ec3ac210da","externalIds":{"ArXiv":"2305.13257","DBLP":"journals/corr/abs-2305-13257","DOI":"10.48550/arXiv.2305.13257","CorpusId":271213502},"title":"Watermarking Text Data on Large Language Models for Dataset Copyright Protection"},{"paperId":"d4c3e3e3c01afed15926adf81527bf46aa491c6a","externalIds":{"DBLP":"journals/corr/abs-2305-10036","ArXiv":"2305.10036","ACL":"2023.acl-long.423","DOI":"10.48550/arXiv.2305.10036","CorpusId":258741304},"title":"Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark"},{"paperId":"bd7a45fa6dce81dbbc61a5728bf54e040e206da7","externalIds":{"DBLP":"journals/corr/abs-2305-08883","ArXiv":"2305.08883","DOI":"10.48550/arXiv.2305.08883","CorpusId":258714683},"title":"Watermarking Text Generated by Black-Box Language Models"},{"paperId":"753dd1be7581e70d65b537e8f62140b8ff8793ac","externalIds":{"ACL":"2023.acl-long.117","DBLP":"conf/acl/YooAJK23","ArXiv":"2305.01904","DOI":"10.18653/v1/2023.acl-long.117","CorpusId":259129912},"title":"Robust Multi-bit Natural Language Watermarking through Invariant Features"},{"paperId":"fdb117c68332d23cb1bd57e3cc36b8c9cfbdcbf7","externalIds":{"DBLP":"conf/chi/ZhouZLPC23","DOI":"10.1145/3544548.3581318","CorpusId":257633591},"title":"Synthetic Lies: Understanding AI-Generated Misinformation and Evaluating Algorithmic and Human Solutions"},{"paperId":"dce4e4cf1cd8c42b8a400280a48283234ad7aafb","externalIds":{"DBLP":"conf/sigdial/HudecekD23","ArXiv":"2304.06556","ACL":"2023.sigdial-1.21","DOI":"10.18653/v1/2023.sigdial-1.21","CorpusId":258108409},"title":"Are Large Language Models All You Need for Task-Oriented Dialogue?"},{"paperId":"1c13af186d1e177b85ef1ec3fc7b8d33ec314cfd","externalIds":{"DBLP":"conf/nips/KrishnaSKWI23","ArXiv":"2303.13408","DOI":"10.48550/arXiv.2303.13408","CorpusId":257687440},"title":"Paraphrasing evades detectors of AI-generated text, but retrieval is an effective defense"},{"paperId":"8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c","externalIds":{"ArXiv":"2303.12712","DBLP":"journals/corr/abs-2303-12712","CorpusId":257663729},"title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4"},{"paperId":"5c4bbf816a6e4759b9efe5f37f9c66a603ef9e2f","externalIds":{"ArXiv":"2303.11470","DBLP":"journals/sigkdd/TangFL0H23","DOI":"10.1145/3606274.3606279","CorpusId":257636598},"title":"Did You Train on My Dataset? Towards Public Dataset Protection with CleanLabel Backdoor Watermarking"},{"paperId":"5ee8bb4fc80a291b2e416a2a879e7153a783d7e9","externalIds":{"ArXiv":"2303.11156","DBLP":"journals/corr/abs-2303-11156","DOI":"10.48550/arXiv.2303.11156","CorpusId":257631570},"title":"Can AI-Generated Text be Reliably Detected?"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"ae3d869719c15099889c02c03b922516b3b60aa0","externalIds":{"DBLP":"journals/corr/abs-2302-09210","ArXiv":"2302.09210","DOI":"10.48550/arXiv.2302.09210","CorpusId":257038384},"title":"How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation"},{"paperId":"59fe7cb560651281cfc5db6b8940da0e3ba9dea6","externalIds":{"DBLP":"journals/corr/abs-2302-08468","ArXiv":"2302.08468","DOI":"10.48550/arXiv.2302.08468","CorpusId":256900680},"title":"LEVER: Learning to Verify Language-to-Code Generation with Execution"},{"paperId":"c25d2a27f1abe169d7b68078071b6698f0980469","externalIds":{"DBLP":"conf/icml/ZhaoWL23","ArXiv":"2302.03162","DOI":"10.48550/arXiv.2302.03162","CorpusId":256627372},"title":"Protecting Language Generation Models via Invisible Watermarking"},{"paperId":"a4a41319d5805a29316f24ed9519f09db77d4c29","externalIds":{"ArXiv":"2301.13848","DBLP":"journals/tacl/ZhangLDLMH24a","ACL":"2024.tacl-1.3","DOI":"10.1162/tacl_a_00632","CorpusId":256416014},"title":"Benchmarking Large Language Models for News Summarization"},{"paperId":"9a7ac45eafe11ca003db3a300505f3b5c3f9009a","externalIds":{"DBLP":"journals/corr/abs-2301-11305","ArXiv":"2301.11305","DOI":"10.48550/arXiv.2301.11305","CorpusId":256274849},"title":"DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature"},{"paperId":"c7bdd6c7b786fba60ff8a6e656cc14c3f7b57b78","externalIds":{"ArXiv":"2210.03312","DBLP":"conf/emnlp/ZhaoLW22","DOI":"10.48550/arXiv.2210.03312","CorpusId":252762324},"title":"Distillation-Resistant Watermarking for Model Protection in NLP"},{"paperId":"823cacd5255f3897a8d29f29a7c7cb8f978bd928","externalIds":{"DBLP":"journals/corr/abs-2209-08773","ArXiv":"2209.08773","DOI":"10.48550/arXiv.2209.08773","CorpusId":252367820},"title":"CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks"},{"paperId":"e19b54ad4c1c8af045069e9cac350ffc2ce60e1a","externalIds":{"DBLP":"journals/corr/abs-2207-04672","ArXiv":"2207.04672","DOI":"10.48550/arXiv.2207.04672","CorpusId":250425961},"title":"No Language Left Behind: Scaling Human-Centered Machine Translation"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","externalIds":{"DBLP":"journals/corr/abs-2205-01068","ArXiv":"2205.01068","CorpusId":248496292},"title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"4054fc9e8776dc0324cfc215462d606eb75916c0","externalIds":{"DBLP":"conf/chi/Vaithilingam0G22","DOI":"10.1145/3491101.3519665","CorpusId":247255943},"title":"Expectation vs.Â Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models"},{"paperId":"40cabeaeea1c7d7688f9834b7c8081564ece6664","externalIds":{"ArXiv":"2204.07359","DBLP":"conf/aaai/0007LGKL22","ACL":"2022.in2writing-1.7","DOI":"10.48550/arXiv.2204.07359","CorpusId":248218549},"title":"Text Revision by On-the-Fly Representation Optimization"},{"paperId":"38115e80d805fb0fb8f090dc88ced4b24be07878","externalIds":{"ArXiv":"2203.13474","DBLP":"conf/iclr/NijkampPHTWZSX23","CorpusId":252668917},"title":"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"},{"paperId":"f8292d4ddf7a6dfe240eeaa9685f5d18eed9a3f6","externalIds":{"DBLP":"journals/corr/abs-2203-13224","ArXiv":"2203.13224","DOI":"10.48550/arXiv.2203.13224","CorpusId":247627671},"title":"Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion"},{"paperId":"b32a6f6ef7dd775e0f876b4713ceccebc56e651e","externalIds":{"DBLP":"journals/corr/abs-2202-13169","ArXiv":"2202.13169","DOI":"10.1145/3520312.3534862","CorpusId":247158549},"title":"A systematic evaluation of large language models of code"},{"paperId":"5d49c7401c5f2337c4cc88d243ae39ed659afe64","externalIds":{"DBLP":"journals/corr/abs-2202-03286","ACL":"2022.emnlp-main.225","ArXiv":"2202.03286","DOI":"10.18653/v1/2022.emnlp-main.225","CorpusId":246634238},"title":"Red Teaming Language Models with Language Models"},{"paperId":"b3848d32f7294ec708627897833c4097eb4d8778","externalIds":{"DBLP":"journals/corr/abs-2201-08239","ArXiv":"2201.08239","CorpusId":246063428},"title":"LaMDA: Language Models for Dialog Applications"},{"paperId":"9b79eb8d21c8a832daedbfc6d8c31bebe0da3ed5","externalIds":{"ArXiv":"2112.07873","DBLP":"conf/aaai/YangZCZMWY22","DOI":"10.1609/aaai.v36i10.21415","CorpusId":245144237},"title":"Tracing Text Provenance via Context-Aware Lexical Substitution"},{"paperId":"2569a7309142e40815cf556b6417059df9abbda8","externalIds":{"DBLP":"conf/aaai/HeXLWW22","ArXiv":"2112.02701","DOI":"10.1609/aaai.v36i10.21321","CorpusId":244909149},"title":"Protecting Intellectual Property of Language Generation APIs with Lexical Watermark"},{"paperId":"02183e69f1dfd6e9b2d0fb876153299bab4bb82b","externalIds":{"DBLP":"conf/www/Sun0SN022","ArXiv":"2110.12925","DOI":"10.1145/3485447.3512225","CorpusId":239768432},"title":"CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning"},{"paperId":"77d956cdab4508d569ae5741549b78e715fd0749","externalIds":{"DBLP":"journals/corr/abs-2109-07958","ACL":"2022.acl-long.229","ArXiv":"2109.07958","DOI":"10.18653/v1/2022.acl-long.229","CorpusId":237532606},"title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods"},{"paperId":"0bca80c452d4f2900a17acaa476c36e92df9a3af","externalIds":{"DBLP":"conf/IEEEares/MegiasKRM21","DOI":"10.1145/3465481.3470088","CorpusId":237099530},"title":"DISSIMILAR: Towards fake news detection using information hiding, signal processing and machine learning"},{"paperId":"acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269","externalIds":{"DBLP":"journals/corr/abs-2107-03374","ArXiv":"2107.03374","CorpusId":235755472},"title":"Evaluating Large Language Models Trained on Code"},{"paperId":"31e2f2835e4e59f7d8531410db28a8c59e155400","externalIds":{"MAG":"3163516254","DOI":"10.5120/IJCA2021921298","CorpusId":236359583},"title":"Review of the Literature on the Steganography Concept"},{"paperId":"78db1529bd67ef885fe550ab3ed7f965067e8928","externalIds":{"DBLP":"journals/corr/abs-2009-03015","MAG":"3083360291","ArXiv":"2009.03015","DOI":"10.1109/SP40001.2021.00083","CorpusId":221516138},"title":"Adversarial Watermarking Transformer: Towards Tracing Text Provenance with Data Hiding"},{"paperId":"63c04274fdaf2498d2afc635bc5f20688c23aca1","externalIds":{"MAG":"3043430239","DBLP":"conf/nips/LiLMJLK20","ArXiv":"2007.08557","CorpusId":220633071},"title":"Unsupervised Text Generation by Learning from Search"},{"paperId":"dc373d5e108a90a70f55285a852a32706adbeb45","externalIds":{"MAG":"2994928925","ArXiv":"2002.06823","DBLP":"conf/iclr/ZhuXWHQZLL20","CorpusId":210846009},"title":"Incorporating BERT into Neural Machine Translation"},{"paperId":"d9e1c06bcac34fa735152a42c2d903ab67435104","externalIds":{"DBLP":"journals/information/BegumU20","MAG":"3006625877","DOI":"10.3390/info11020110","CorpusId":213907789},"title":"Digital Image Watermarking Techniques: A Review"},{"paperId":"495da6f19baa09c6db3697d839e10432cdc25934","externalIds":{"MAG":"3001434439","ArXiv":"2001.08210","DBLP":"journals/corr/abs-2001-08210","DOI":"10.1162/tacl_a_00343","CorpusId":210861178},"title":"Multilingual Denoising Pre-training for Neural Machine Translation"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"93d63ec754f29fa22572615320afe0521f7ec66d","externalIds":{"DBLP":"journals/corr/abs-1908-10084","MAG":"2970641574","ArXiv":"1908.10084","ACL":"D19-1410","DOI":"10.18653/v1/D19-1410","CorpusId":201646309},"title":"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"},{"paperId":"ebf59587f8f170ff4241c42263bbfb9da5bd2135","externalIds":{"MAG":"2964040452","DBLP":"conf/acl/FanJPGWA19","ACL":"P19-1346","ArXiv":"1907.09190","DOI":"10.18653/v1/P19-1346","CorpusId":196170479},"title":"ELI5: Long Form Question Answering"},{"paperId":"1906e3a2fda12641a42739e3fb6a8f8b1accc8dd","externalIds":{"DBLP":"conf/nips/KulalPC0PAL19","MAG":"2950621612","ArXiv":"1906.04908","CorpusId":186206968},"title":"SPoC: Search-based Pseudocode to Code"},{"paperId":"2f294a7a67cfee6791ad21922ba94e2dabbebce0","externalIds":{"MAG":"2963626782","DBLP":"conf/iwcmc/IqbalKHHJ19","DOI":"10.1109/IWCMC.2019.8766644","CorpusId":198144869},"title":"A Robust Digital Watermarking Algorithm for Text Document Copyright Protection based on Feature Coding"},{"paperId":"cf4aa38ae31b43fd07abe13b4ffdb265babb7be1","externalIds":{"DBLP":"journals/corr/abs-1904-09751","MAG":"2938704169","ArXiv":"1904.09751","CorpusId":127986954},"title":"The Curious Case of Neural Text Degeneration"},{"paperId":"295065d942abca0711300b2b4c39829551060578","externalIds":{"MAG":"2936695845","ArXiv":"1904.09675","DBLP":"journals/corr/abs-1904-09675","CorpusId":127986044},"title":"BERTScore: Evaluating Text Generation with BERT"},{"paperId":"22655979df781d222eaf812b0d325fa9adf11594","externalIds":{"ACL":"D18-1259","DBLP":"journals/corr/abs-1809-09600","MAG":"2952862139","ArXiv":"1809.09600","DOI":"10.18653/v1/D18-1259","CorpusId":52822214},"title":"HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering"},{"paperId":"7191680b572ee7145f1a9d95ff11ab1ff44259f3","externalIds":{"MAG":"2798658104","DBLP":"conf/www/MaiaHFDMZB18","DOI":"10.1145/3184558.3192301","CorpusId":13866508},"title":"WWW'18 Open Challenge: Financial Opinion Mining and Question Answering"},{"paperId":"7e652d902c871dec3c851b48b7f0fcac71c2cc4c","externalIds":{"DBLP":"journals/scn/AhvanooeyLSH18","MAG":"2803028604","DOI":"10.1155/2018/5325040","CorpusId":21705679},"title":"A Comparative Analysis of Information Hiding Techniques for Copyright Protection of Text Documents"},{"paperId":"a76706d350b8c483a3aff73e61b91d15b5687335","externalIds":{"MAG":"2794557536","ArXiv":"1803.11175","DBLP":"journals/corr/abs-1803-11175","CorpusId":4494896},"title":"Universal Sentence Encoder"},{"paperId":"f010affab57b5fcf1cd6be23df79d8ec98c7289c","externalIds":{"MAG":"2612431505","ArXiv":"1705.03551","ACL":"P17-1147","DBLP":"journals/corr/JoshiCWZ17","DOI":"10.18653/v1/P17-1147","CorpusId":26501419},"title":"TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"},{"paperId":"69220b1c2bdfce552d97a3b142e8519a5d19e1a3","externalIds":{"ArXiv":"1701.04082","MAG":"3103782966","DBLP":"journals/corr/UchidaNSS17","DOI":"10.1145/3078971.3078974","CorpusId":13060737},"title":"Embedding Watermarks into Deep Neural Networks"},{"paperId":"2b7034ae14808f60304d157e1a4c296a20f7d8d2","externalIds":{"DBLP":"journals/scn/AlkawazSSAR16","MAG":"2588990876","DOI":"10.1002/sec.1738","CorpusId":39302764},"title":"Concise analysis of current text automation and watermarking approaches"},{"paperId":"29e944711a354c396fad71936f536e83025b6ce0","externalIds":{"MAG":"2547875792","DBLP":"conf/iclr/JangGP17","ArXiv":"1611.01144","CorpusId":2428314},"title":"Categorical Reparameterization with Gumbel-Softmax"},{"paperId":"a52aee41169df2788f6acad5eb750eb54bda624a","externalIds":{"DBLP":"conf/ideas/RizzoBM16","MAG":"2518688495","DOI":"10.1145/2938503.2938510","CorpusId":11689200},"title":"Content-preserving Text Watermarking through Unicode Homoglyph Substitution"},{"paperId":"85b68477a6e031d88b963833e15a4b4fc6855264","externalIds":{"MAG":"2891014615","DBLP":"conf/naacl/MostafazadehCHP16","ACL":"N16-1098","ArXiv":"1604.01696","DOI":"10.18653/v1/N16-1098","CorpusId":1726501},"title":"A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories"},{"paperId":"d1505c6123c102e53eb19dff312cb25cea840b72","externalIds":{"MAG":"2949615363","DBLP":"conf/nips/HermannKGEKSB15","ArXiv":"1506.03340","CorpusId":6203757},"title":"Teaching Machines to Read and Comprehend"},{"paperId":"ec33bd4545bd0e56d6f8b2db43dea12b32d9f313","externalIds":{"DBLP":"journals/jss/PorWC12","MAG":"2099278641","DOI":"10.1016/j.jss.2011.12.023","CorpusId":17690312},"title":"UniSpaCh: A text-based data hiding method using Unicode space characters"},{"paperId":"959fc54c28c55a9ec8bdea5b7e123d2b4a6fcbf6","externalIds":{"MAG":"2145018257","DOI":"10.1109/ISWPC.2007.342654","CorpusId":9841379},"title":"Improved Hamming Code for Error Detection and Correction"},{"paperId":"0d3ba30dd4c6a29349539e6c94ab0ffd95c22b3e","externalIds":{"MAG":"2112507198","DOI":"10.1145/1178766.1178777","CorpusId":5854860},"title":"Words are not enough: sentence level natural language watermarking"},{"paperId":"4757b911780581cf3d24fdfb2749608f370dc034","externalIds":{"DBLP":"conf/mmsec/TopkaraTA06","MAG":"2108498102","DOI":"10.1145/1161366.1161397","CorpusId":3061822},"title":"The hiding virtues of ambiguity: quantifiably resilient watermarking of natural language text through synonym substitutions"},{"paperId":"7533d30329cfdbf04ee8ee82bfef792d08015ee5","externalIds":{"MAG":"2123301721","ACL":"W05-0909","DBLP":"conf/acl/BanerjeeL05","CorpusId":7164502},"title":"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments"},{"paperId":"60b05f32c32519a809f21642ef1eb3eaf3848008","externalIds":{"MAG":"2154652894","ACL":"W04-1013","CorpusId":964287},"title":"ROUGE: A Package for Automatic Evaluation of Summaries"},{"paperId":"d7da009f457917aa381619facfa5ffae9329a6e9","externalIds":{"DBLP":"conf/acl/PapineniRWZ02","MAG":"2101105183","ACL":"P02-1040","DOI":"10.3115/1073083.1073135","CorpusId":11080756},"title":"Bleu: a Method for Automatic Evaluation of Machine Translation"},{"paperId":"9754d6793d756a7924fe1da8120780f658ce4704","externalIds":{"MAG":"2083055907","DBLP":"journals/cacm/GabrilovichG02","DOI":"10.1145/503124.503156","CorpusId":73840},"title":"The homograph attack"},{"paperId":"57e52aa90497f5325772e5f51fd35f669f9b88eb","externalIds":{"DBLP":"conf/ih/AtallahRCHKMN01","MAG":"1605292408","DOI":"10.1007/3-540-45496-9_14","CorpusId":37687669},"title":"Natural Language Watermarking: Design, Analysis, and a Proof-of-Concept Implementation"},{"paperId":"79ac99fc33c13999faf4d94367afe18d18da00ed","externalIds":{"MAG":"2117197027","DBLP":"conf/infocom/BrassilLMO94","DOI":"10.1109/INFCOM.1994.337544","CorpusId":6540783},"title":"Electronic marking and identification techniques to discourage document copying"},{"paperId":"b590a26956f3057a348f180731ece3e44b30c5a9","externalIds":{"DBLP":"conf/acl/Lu0ZDFNL25","DOI":"10.48550/arXiv.2310.00646","CorpusId":278062974},"title":"WASA: WAtermark-based Source Attribution for Large Language Model-Generated Data"},{"paperId":"289533e16e509d0ba8f499a371b4e470f3e492de","externalIds":{"ACL":"2024.naacl-long.226","DBLP":"conf/naacl/HouZHWCWSDKT24","DOI":"10.18653/v1/2024.naacl-long.226","CorpusId":263831179},"title":"SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation"},{"paperId":"636617acd35dc523cf4ba046d7e93aa956df253f","externalIds":{"DBLP":"journals/corr/abs-2403-10020","DOI":"10.48550/arXiv.2403.10020","CorpusId":276116612},"title":"Lost in Overlap: Exploring Watermark Collision in LLMs"},{"paperId":"3f358e5bedaae0eb49849dce98edb516f0731df5","externalIds":{"DBLP":"journals/corr/abs-2305-05773","DOI":"10.48550/arXiv.2305.05773","CorpusId":258588289},"title":"DeepTextMark: Deep Learning based Text Watermarking for Detection of Large Language Model Generated Text"},{"paperId":"cf046cee879e39c34dcb8057b9de06210e592536","externalIds":{"DBLP":"journals/corr/abs-2308-00221","DOI":"10.48550/arXiv.2308.00221","CorpusId":262903996},"title":"Advancing Beyond Identification: Multi-bit Watermark for Language Models"},{"paperId":"2c1060be56aa4f50ff891bbf1d6fb31ec9fdf322","externalIds":{"DBLP":"journals/jowua/MegiasKRCM22","DOI":"10.22667/JOWUA.2022.03.31.033","CorpusId":248326491},"title":"Architecture of a fake news detection system combining digital watermarking, signal processing, and machine learning"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"bc30886a5540fdbb9f4cf877b597f74b68dca52a","externalIds":{"MAG":"2790136966","DBLP":"journals/access/KamaruddinKPR18","DOI":"10.1109/ACCESS.2018.2796585","CorpusId":3783650},"title":"A Review of Text Watermarking: Theory, Methods, and Applications"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":"568de809eeab07d8c170ec45fce8a2e4fc8e1733","externalIds":{"MAG":"2011200687","DBLP":"journals/chb/Mir14","DOI":"10.1016/j.chb.2013.07.040","CorpusId":206615109},"title":"Copyright for web content using invisible text watermarking"},{"paperId":"f9865553ac941c393643d33f195a37d04617ac8f","externalIds":{"DBLP":"journals/csl/MeralSOGS09","MAG":"1975586457","DOI":"10.1016/j.csl.2008.04.001","CorpusId":1192689},"title":"Natural language watermarking via morphosyntactic alterations"},{"paperId":"0f90e44ab1c318f357647c0e3055816e8b939f72","externalIds":{"CorpusId":263887013},"title":"Publication date"},{"paperId":"d53bcbac7ea19173e95d3bd855b998fab765737d","externalIds":{"MAG":"1509982784","CorpusId":57814228},"title":"WordNet: An Electronic Lexical Database"}]}