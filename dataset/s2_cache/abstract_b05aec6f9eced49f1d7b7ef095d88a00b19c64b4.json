{"abstract":"Federated Learning (FL) is a promising approach to privacy-preserving machine learning. However, recent works reveal that gradients can leak private data. Using trusted SGX-processors for this task yields gradient-preserving but requires to prevent exploitation of any side-channel attacks. In this work, we present ShuffleFL, a gradient-preserving system using trusted SGX, which combines random group structure and intra-group gradient segment aggregation for combating any side-channel attacks. We analyze the security of our system against semi-honest adversaries. ShuffleFL effectively guarantees the participants' gradient privacy. We demonstrate the performance of ShuffleFL and show its applicability in the federated learning system."}