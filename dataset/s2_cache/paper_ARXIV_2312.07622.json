{"paperId":"5ee871537ae51e7e2e93d2a70fff5d100649a655","externalIds":{"DBLP":"journals/csur/LiuHZDLZHCJZH26","ArXiv":"2312.07622","DOI":"10.1145/3773985","CorpusId":266191124},"title":"Mathematical Language Models: A Survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2312.07622, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2274069658","name":"Wentao Liu"},{"authorId":"2274044365","name":"Hanglei Hu"},{"authorId":"145558445","name":"Jie Zhou"},{"authorId":"2274086380","name":"Yuyang Ding"},{"authorId":"2274071511","name":"Junsong Li"},{"authorId":"2274074102","name":"Jiayi Zeng"},{"authorId":"2330315159","name":"Mengliang He"},{"authorId":"2152518131","name":"Qin Chen"},{"authorId":"2274199162","name":"Bo Jiang"},{"authorId":"2273936831","name":"Aimin Zhou"},{"authorId":"2268703214","name":"Liang He"}],"abstract":"In recent years, there has been remarkable progress in leveraging Language Models (LMs), encompassing Pre-trained Language Models (PLMs) and Large-scale Language Models (LLMs), within the domain of mathematics. This article conducts a comprehensive survey of mathematical LMs, systematically categorizing pivotal research endeavors from two distinct perspectives: tasks and methodologies. The landscape reveals a large number of proposed mathematical LLMs, which are further delineated into instruction learning, tool-based methods, fundamental CoT techniques, advanced CoT methodologies, and multi-modal methods. To comprehend the benefits of mathematical LMs more thoroughly, we carry out an in-depth contrast of their characteristics and performance. In addition, our survey entails the compilation of over 60 mathematical datasets, including training datasets, benchmark datasets, and augmented datasets. Addressing the primary challenges and delineating future trajectories within the field of mathematical LMs, this survey is poised to facilitate and inspire future innovation among researchers invested in advancing this domain."}