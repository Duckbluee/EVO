{"references":[{"paperId":"e5eed0973a4256660aeb41d78dadbcba25599642","externalIds":{"DBLP":"journals/tase/LiMT24","DOI":"10.1109/TASE.2023.3244331","CorpusId":257119768},"title":"Scheduling of Continuous Annealing With a Multi-Objective Differential Evolution Algorithm Based on Deep Reinforcement Learning"},{"paperId":"5176f8e9f8670487c82cd7fd7705adfe50ed8b06","externalIds":{"DBLP":"journals/tsmc/SongOPSWXZ24","DOI":"10.1109/TSMC.2023.3345928","CorpusId":267120249},"title":"Generalized Model and Deep Reinforcement Learning-Based Evolutionary Method for Multitype Satellite Observation Scheduling"},{"paperId":"7d193e8e6718a7d0890592e5874e7c4ac307ac54","externalIds":{"DBLP":"journals/tetci/LiGWG24","DOI":"10.1109/TETCI.2023.3281876","CorpusId":259783343},"title":"Evolutionary Multitasking via Reinforcement Learning"},{"paperId":"a93006cf3ca8feffa1b62b122c3c0809b5b19fa2","externalIds":{"DBLP":"journals/tetci/LiuSZWX23","DOI":"10.1109/TETCI.2023.3251441","CorpusId":257526624},"title":"Learning to Learn Evolutionary Algorithm: A Learnable Differential Evolution"},{"paperId":"365f6c95bbf18522fb14ec4d0c6330a257b416bb","externalIds":{"DBLP":"journals/eswa/JiaYW23","DOI":"10.1016/j.eswa.2023.120837","CorpusId":259446531},"title":"Q-learning driven multi-population memetic algorithm for distributed three-stage assembly hybrid flow shop scheduling with flexible preventive maintenance"},{"paperId":"547ef56d3252f3c2f5d37d5c38f972748a16c48b","externalIds":{"DBLP":"journals/taes/SongOSPYX23","DOI":"10.1109/TAES.2023.3312626","CorpusId":261605790},"title":"Learning Adaptive Genetic Algorithm for Earth Electromagnetic Satellite Scheduling"},{"paperId":"4bf44514a79197f94adf511f3d1a2818419a129b","externalIds":{"DBLP":"journals/tits/LinGWS23","DOI":"10.1109/TITS.2023.3296387","CorpusId":260981738},"title":"Scheduling Eight-Phase Urban Traffic Light Problems via Ensemble Meta-Heuristics and Q-Learning Based Local Search"},{"paperId":"14f95f8549bdc774825510781118ef226b096f24","externalIds":{"DBLP":"journals/tase/ZhaoWW23","DOI":"10.1109/TASE.2022.3212786","CorpusId":253365022},"title":"A Reinforcement Learning Driven Artificial Bee Colony Algorithm for Distributed Heterogeneous No-Wait Flowshop Scheduling Problem With Sequence-Dependent Setup Times"},{"paperId":"e43084906673e57915f4f53216e3ad2398a47106","externalIds":{"DBLP":"journals/tetci/ZhangSWSX23","DOI":"10.1109/TETCI.2022.3221483","CorpusId":253694901},"title":"Variational Reinforcement Learning for Hyper-Parameter Tuning of Adaptive Evolutionary Algorithm"},{"paperId":"1530202078562e1254ac03cbb1b9beee2d759c6e","externalIds":{"DBLP":"journals/tetci/DuLCDP23","DOI":"10.1109/TETCI.2022.3145706","CorpusId":260003294},"title":"Knowledge-Based Reinforcement Learning and Estimation of Distribution Algorithm for Flexible Job Shop Scheduling Problem"},{"paperId":"bf07f59f284297b72fba0ffead7f42fe6746d76e","externalIds":{"DBLP":"journals/swevo/PengYDWT23","DOI":"10.1016/j.swevo.2023.101351","CorpusId":259492840},"title":"Reinforcement learning-based hybrid differential evolution for global optimization of interplanetary trajectory design"},{"paperId":"730f93d8db6a978e60bfde3e318eba98ef102c71","externalIds":{"DBLP":"journals/swevo/TatsisP23","DOI":"10.1016/j.swevo.2023.101371","CorpusId":260669529},"title":"Reinforcement learning for enhanced online gradient-based parameter adaptation in metaheuristics"},{"paperId":"1a35010db5c88813d160832955cab635b431bf0a","externalIds":{"DBLP":"journals/tetci/TianLMZTJ23","DOI":"10.1109/TETCI.2022.3146882","CorpusId":246807575},"title":"Deep Reinforcement Learning Based Adaptive Operator Selection for Evolutionary Multi-Objective Optimization"},{"paperId":"d4cb17c195f921b3c9c75d497ea1ea17109e06e1","externalIds":{"DBLP":"journals/eswa/ZhangWQHWJ23","DOI":"10.1016/j.eswa.2023.121050","CorpusId":260415489},"title":"A Q-learning-based hyper-heuristic evolutionary algorithm for the distributed flexible job-shop scheduling problem with crane transportation"},{"paperId":"c422cee7f9008eb253b5825c9cbc89d79157c6b9","externalIds":{"DBLP":"journals/asc/LiuZLJ23","DOI":"10.1016/j.asoc.2023.110680","CorpusId":260670001},"title":"NeuroCrossover: An intelligent genetic locus selection scheme for genetic algorithm using reinforcement learning"},{"paperId":"3a1bff63924d694055e295507f381a51045b6f8e","externalIds":{"DBLP":"journals/tsmc/ZhaoZ023","DOI":"10.1109/TSMC.2023.3256484","CorpusId":257846546},"title":"A Cooperative Scatter Search With Reinforcement Learning Mechanism for the Distributed Permutation Flowshop Scheduling Problem With Sequence-Dependent Setup Times"},{"paperId":"deaa7617a75e6bc2c9994ede00eff62b7de79958","externalIds":{"DBLP":"journals/asc/WangGLHS23","DOI":"10.1016/j.asoc.2023.110714","CorpusId":260855150},"title":"Problem feature based meta-heuristics with Q-learning for solving urban traffic light scheduling problems"},{"paperId":"3c2b2ef66cdedde03752c2dc094db7110de20e03","externalIds":{"DBLP":"journals/ijpr/PanzerBG24","DOI":"10.1080/00207543.2023.2233641","CorpusId":259853436},"title":"A deep reinforcement learning based hyper-heuristic for modular production control"},{"paperId":"8ab8d17df8d663763c33f7f64ceec8c5d3fb3b0c","externalIds":{"DBLP":"journals/tii/ZhaoJW23","DOI":"10.1109/TII.2022.3218645","CorpusId":253355224},"title":"A Reinforcement Learning Driven Cooperative Meta-Heuristic Algorithm for Energy-Efficient Distributed No-Wait Flow-Shop Scheduling With Sequence-Dependent Setup Time"},{"paperId":"8ae00e4857f712fa7d5ccf8f218a44f5d1a3930d","externalIds":{"DBLP":"journals/swevo/GaoGMT23","DOI":"10.1016/j.swevo.2023.101358","CorpusId":259556538},"title":"Ensemble meta-heuristics and Q-learning for solving unmanned surface vessels scheduling problems"},{"paperId":"98dd744c04e648337063a77527880528a18d924e","externalIds":{"DBLP":"journals/asc/LiLWXCG23","DOI":"10.1016/j.asoc.2023.110658","CorpusId":260326720},"title":"A Reinforcement Learning-Artificial Bee Colony algorithm for Flexible Job-shop Scheduling Problem with Lot Streaming"},{"paperId":"bd6ff3e59b605cb3a6be4a3ee37a7eabb3e1c2bc","externalIds":{"DBLP":"journals/asc/SuZXHWCX23","DOI":"10.1016/j.asoc.2023.110596","CorpusId":259648151},"title":"Evolution strategies-based optimized graph reinforcement learning for solving dynamic job shop scheduling problem"},{"paperId":"60d1b685bd332ff8da929fa0c0f5ee21f28f69b1","externalIds":{"DBLP":"journals/cor/LiXZCZ23","DOI":"10.1016/j.cor.2023.106360","CorpusId":260265431},"title":"Multi-objective energy-efficient hybrid flow shop scheduling using Q-learning and GVNS driven NSGA-II"},{"paperId":"18d02381fd00efec35a5493ebba66afecbf5ded4","externalIds":{"DBLP":"journals/tec/LiG0023","DOI":"10.1109/TEVC.2022.3175832","CorpusId":248874340},"title":"A Learning-Based Memetic Algorithm for Energy-Efficient Flexible Job-Shop Scheduling With Type-2 Fuzzy Processing Time"},{"paperId":"b5e7aa48fb80016fe266806e673f8a71dfd0ebe1","externalIds":{"DBLP":"journals/eswa/TuBAZD23","DOI":"10.1016/j.eswa.2023.120568","CorpusId":259062901},"title":"A deep reinforcement learning hyper-heuristic with feature fusion for online packing problems"},{"paperId":"aa05486731e169b440d9ea6d22feb81380cecfc5","externalIds":{"DBLP":"journals/eswa/ZhaoZXZJ23","DOI":"10.1016/j.eswa.2023.120571","CorpusId":259067536},"title":"A knowledge-driven cooperative scatter search algorithm with reinforcement learning for the distributed blocking flow shop scheduling problem"},{"paperId":"39f0966dfbea005b857a5d87f742dc5812d4c832","externalIds":{"DBLP":"journals/apin/GaoFYL23","DOI":"10.1007/s10489-023-04574-9","CorpusId":258772027},"title":"An efficient evolutionary algorithm based on deep reinforcement learning for large-scale sparse multiobjective optimization"},{"paperId":"a83b97d3744e026deffb4311e66a3230f4a98fcd","externalIds":{"DBLP":"journals/eaai/ShangML23","DOI":"10.1016/j.engappai.2023.105954","CorpusId":256751141},"title":"Green location routing problem with flexible multi-compartment for source-separated waste: A Q-learning and multi-strategy-based hyper-heuristic algorithm"},{"paperId":"23a2c5ecade0e1a5293f45ee6e8d51306f7b9aa8","externalIds":{"DBLP":"journals/tpds/ZhouRXF23","DOI":"10.1109/TPDS.2023.3243634","CorpusId":256748206},"title":"An Improved NSGA-III Algorithm Based on Deep Q-Networks for Cloud Storage Optimization of Blockchain"},{"paperId":"3fb7bf7ce376a3c5ffefeba31503e08cfe483a1c","externalIds":{"DBLP":"journals/tsmc/LiGDLZ23","DOI":"10.1109/TSMC.2022.3219380","CorpusId":253603819},"title":"An Improved Artificial Bee Colony Algorithm With Q-Learning for Solving Permutation Flow-Shop Scheduling Problems"},{"paperId":"854da4daf2c2feb74e81c2363ef1fabb300e57a5","externalIds":{"DBLP":"journals/swevo/YuGMP23","DOI":"10.1016/j.swevo.2023.101335","CorpusId":258654662},"title":"Improved meta-heuristics with Q-learning for solving distributed assembly permutation flowshop scheduling problems"},{"paperId":"37df218d8051ffaca8466a637f7f1aa65f42f558","externalIds":{"DBLP":"journals/swevo/RenGFSLL23","DOI":"10.1016/j.swevo.2023.101338","CorpusId":258900499},"title":"A novel Q-learning based variable neighborhood iterative search algorithm for solving disassembly line scheduling problems"},{"paperId":"dd759df7890db0b435b9be3a63964a8591633c22","externalIds":{"DBLP":"journals/corr/abs-2304-04022","ArXiv":"2304.04022","DOI":"10.48550/arXiv.2304.04022","CorpusId":258049315},"title":"A Reinforcement Learning-assisted Genetic Programming Algorithm for Team Formation Problem Considering Person-Job Matching"},{"paperId":"521a4041b9b62a4cd6bdb417a9360ddfa95b4a73","externalIds":{"DBLP":"journals/cor/ZhengZCH23","DOI":"10.1016/j.cor.2023.106249","CorpusId":263880989},"title":"A reinforced hybrid genetic algorithm for the traveling salesman problem"},{"paperId":"4bb9f478cb464049100abafc77b6491b6e5b731a","externalIds":{"DBLP":"journals/corr/abs-2303-04150","ArXiv":"2303.04150","DOI":"10.34133/icomputing.0025","CorpusId":257405216},"title":"Evolutionary Reinforcement Learning: A Survey"},{"paperId":"88eb6cf17a61534462757b9d1826c05da9eaf635","externalIds":{"ArXiv":"2303.02618","DBLP":"journals/corr/abs-2303-02618","DOI":"10.48550/arXiv.2303.02618","CorpusId":257365567},"title":"Ensemble Reinforcement Learning: A Survey"},{"paperId":"50e37089a827e47bde6032f3e100740e21671580","externalIds":{"DBLP":"journals/eswa/DasariS23","DOI":"10.1016/j.eswa.2023.120003","CorpusId":257900215},"title":"Two heuristic approaches for clustered traveling salesman problem with d-relaxed priority rule"},{"paperId":"3e49396323236a7d6b3105d4b8bf061fd5d7604d","externalIds":{"DBLP":"journals/mcs/YanYWCW23","DOI":"10.1016/j.matcom.2023.02.003","CorpusId":256791388},"title":"A novel reinforcement learning based tuna swarm optimization algorithm for autonomous underwater vehicle path planning"},{"paperId":"f77949d7dc6c0dfd8546bf254fe748670f75c5c1","externalIds":{"DBLP":"journals/kbs/ZhaoWW23","DOI":"10.1016/j.knosys.2023.110368","CorpusId":256710993},"title":"An inverse reinforcement learning framework with the Q-learning mechanism for the metaheuristic algorithm"},{"paperId":"834c699a5402ce4295a5cb5deb183ac7401406ab","externalIds":{"DBLP":"journals/kbs/ZhouZ23","DOI":"10.1016/j.knosys.2023.110367","CorpusId":256681764},"title":"An adaptive artificial bee colony algorithm enhanced by Deep Q-Learning for milk-run vehicle scheduling problem based on supply hub"},{"paperId":"84d4bd38a65e9eea1726878bd6973bab024022b8","externalIds":{"DBLP":"journals/swevo/00780SS023","DOI":"10.1016/j.swevo.2023.101274","CorpusId":257210541},"title":"Reinforcement learning-based particle swarm optimization with neighborhood differential mutation strategy"},{"paperId":"15873d35585a9589306521d3de716070bf5c419d","externalIds":{"DBLP":"journals/eswa/ZhaoWWXZJ23","DOI":"10.1016/j.eswa.2023.119672","CorpusId":256748234},"title":"A multi-agent reinforcement learning driven artificial bee colony algorithm with the central controller"},{"paperId":"42f5ff16c812bd97037e0f31d8992e9ab403d116","externalIds":{"DBLP":"journals/tcyb/ZhangTCL24","DOI":"10.1109/TCYB.2022.3229666","CorpusId":255736236,"PubMed":"37018615"},"title":"Reinforcement Learning-Based Multiobjective Evolutionary Algorithm for Mixed-Model Multimanned Assembly Line Balancing Under Uncertain Demand"},{"paperId":"c4dc4372ebacf84c394adcddbe1f4ac5c9ddb9e5","externalIds":{"DBLP":"journals/eor/KallestadHHS23","DOI":"10.1016/j.ejor.2023.01.017","CorpusId":256049836},"title":"A general deep reinforcement learning hyperheuristic framework for solving combinatorial optimization problems"},{"paperId":"71df90b2dad42700e926889855dea446aaa696f9","externalIds":{"DBLP":"conf/nips/00010Z022","ArXiv":"2210.08495","DOI":"10.48550/arXiv.2210.08495","CorpusId":252918760},"title":"Pareto Set Learning for Expensive Multi-Objective Optimization"},{"paperId":"a98f26128108aeff9c682a9b26136369d032b37d","externalIds":{"DBLP":"journals/tcyb/ZhaoDW23","DOI":"10.1109/TCYB.2022.3192112","CorpusId":251742422,"PubMed":"35994539"},"title":"A Hyperheuristic With Q-Learning for the Multiobjective Energy-Efficient Distributed Blocking Flow Shop Scheduling Problem"},{"paperId":"56e8863838b4dcc4790108cd1e7e680a104a7c30","externalIds":{"MAG":"2953633043","DOI":"10.21275/sr22815163219","CorpusId":40455026},"title":"Machine Learning Algorithms: A Review"},{"paperId":"3e91fd5c878b59eafea9c537f641ca045481a8f4","externalIds":{"DBLP":"journals/corr/abs-2207-08645","ArXiv":"2207.08645","DOI":"10.48550/arXiv.2207.08645","CorpusId":250626962},"title":"Active Exploration for Inverse Reinforcement Learning"},{"paperId":"8649d24685ed0a13e5ccaff0fecf5d1afca95816","externalIds":{"DBLP":"journals/corr/abs-2206-12233","ArXiv":"2206.12233","DOI":"10.1145/3520304.3533983","CorpusId":250048757},"title":"Reinforcement learning based adaptive metaheuristics"},{"paperId":"005a97dc2a524a2f66ed2e9d6fb1170c915197e8","externalIds":{"DBLP":"journals/corr/abs-2206-10464","ArXiv":"2206.10464","DOI":"10.1109/TEVC.2022.3199045","CorpusId":249890283},"title":"Hybridization of Evolutionary Algorithm and Deep Reinforcement Learning for Multiobjective Orienteering Optimization"},{"paperId":"18664ce85cda6820e6e700a72da8a111d2158360","externalIds":{"DBLP":"journals/swevo/SongWYWXC23","ArXiv":"2206.05694","DOI":"10.1016/j.swevo.2023.101236","CorpusId":255440482},"title":"RL-GA: A Reinforcement Learning-based Genetic Algorithm for Electromagnetic Detection Satellite Scheduling Problem"},{"paperId":"5dc64b147195677d196e1f3687e107bccda5ede9","externalIds":{"ArXiv":"2206.03185","DBLP":"journals/corr/abs-2206-03185","DOI":"10.48550/arXiv.2206.03185","CorpusId":249431977},"title":"A new Hyper-heuristic based on Adaptive Simulated Annealing and Reinforcement Learning for the Capacitated Electric Vehicle Routing Problem"},{"paperId":"7c2edaca0e05cf1ac88bc914ce8bfbfe362049a0","externalIds":{"DBLP":"journals/candie/ChengTZY22","DOI":"10.1016/j.cie.2022.108293","CorpusId":249321139},"title":"Scheduling flexible manufacturing cell with no-idle flow-lines and job-shop via Q-learning-based genetic algorithm"},{"paperId":"e3b80358ec0cedb5b9159837a8264ca3b9b78873","externalIds":{"DBLP":"journals/isci/QiLWJH22","DOI":"10.1016/j.ins.2022.06.056","CorpusId":249829018},"title":"QMOEA: A Q-learning-based multiobjective evolutionary algorithm for solving time-dependent green vehicle routing problems with time windows"},{"paperId":"284dc3b9df319e95cb43b9c4e6168446d50a9999","externalIds":{"DBLP":"journals/ijpr/ZhaoHWXZJ23","DOI":"10.1080/00207543.2022.2070786","CorpusId":248758796},"title":"A reinforcement learning-driven brain storm optimisation algorithm for multi-objective energy-efficient distributed assembly no-wait flow shop scheduling problem"},{"paperId":"cca0363901e0efdc85dd9d7d953a9762999b0dc4","externalIds":{"DBLP":"journals/eswa/LiGL22","DOI":"10.1016/j.eswa.2022.117380","CorpusId":248616719},"title":"A reinforcement learning based RMOEA/D for bi-objective fuzzy flexible job shop scheduling"},{"paperId":"09639041edd0f4225e07cbeea120b816b12d911e","externalIds":{"DBLP":"journals/kbs/ZhangXLZ22","DOI":"10.1016/j.knosys.2022.109075","CorpusId":249030667},"title":"Multi-objective particle swarm optimization with multi-mode collaboration based on reinforcement learning for path planning of unmanned air vehicles"},{"paperId":"cd435e0bdec50646a73e795cca6b4fa3b49c0744","externalIds":{"DBLP":"journals/eor/MamaghanMPM23","DOI":"10.1016/j.ejor.2022.03.054","CorpusId":247971553},"title":"Learning to select operators in meta-heuristics: An integration of Q-learning into the iterated greedy algorithm for the permutation flowshop scheduling problem"},{"paperId":"787972f28227240823de1cae0ef09df66bbbcc6c","externalIds":{"DBLP":"journals/cor/SunBLW22","DOI":"10.1016/j.cor.2022.105745","CorpusId":247075943},"title":"Reinforcement learning based tabu search for the minimum load coloring problem"},{"paperId":"a8f9362244f2887b2b8d5cb63152cb18fb772150","externalIds":{"DBLP":"journals/asc/WangLC22","DOI":"10.1016/j.asoc.2021.108371","CorpusId":245514976},"title":"An adaptive artificial bee colony with reinforcement learning for distributed three-stage assembly scheduling with maintenance"},{"paperId":"5ab7c6d064eb30c05830db628f3cf4b821c375bd","externalIds":{"MAG":"3157421340","DOI":"10.1016/J.EGYR.2021.01.096","CorpusId":235515991},"title":"Reinforcement learning-based differential evolution for parameters extraction of photovoltaic models"},{"paperId":"c3bf26d5a7a3fbc0335534ca37093306d05a699b","externalIds":{"DBLP":"journals/candie/KucukogluDC21","MAG":"3196485901","DOI":"10.1016/J.CIE.2021.107650","CorpusId":239640249},"title":"The electric vehicle routing problem and its variations: A literature review"},{"paperId":"5f7cd791bfb7e0d11fe7ea3c858a75813daa0245","externalIds":{"DBLP":"journals/eor/ZhangBQTJ22","DOI":"10.1016/j.ejor.2021.10.032","CorpusId":239491915},"title":"A deep reinforcement learning based hyper-heuristic for combinatorial optimisation with uncertainties"},{"paperId":"83dfb45bd196af0059f1fee70c578ef859bab969","externalIds":{"DBLP":"journals/swevo/ChengTZZ22","MAG":"3201030679","DOI":"10.1016/j.swevo.2021.100985","CorpusId":240545182},"title":"Multi-objective Q-learning-based hyper-heuristic with Bi-criteria selection for energy-aware mixed shop scheduling"},{"paperId":"b1356a3d0cf3b6472276cc2d668fed42ebe9e847","externalIds":{"DBLP":"journals/tcyb/ZhaoMW22","DOI":"10.1109/TCYB.2021.3086181","CorpusId":237254892,"PubMed":"34415843"},"title":"A Self-Learning Discrete Jaya Algorithm for Multiobjective Energy-Efficient Distributed No-Idle Flow-Shop Scheduling Problem in Heterogeneous Factory System"},{"paperId":"28766879fa497ef9b6458d117ff809a25c739e25","externalIds":{"DBLP":"conf/cec/XiaLZTWY21","DOI":"10.1109/CEC45853.2021.9504896","CorpusId":236982102},"title":"A Reinforcement-Learning-Based Evolutionary Algorithm Using Solution Space Clustering For Multimodal Optimization Problems"},{"paperId":"8bcdf89df8f80e2b5f2243dd6d283743fe6a7d6f","externalIds":{"MAG":"3159417211","DBLP":"journals/asc/HuynhDL21","DOI":"10.1016/j.asoc.2021.107464","CorpusId":235495938},"title":"Q-Learning-based parameter control in differential evolution for structural optimization"},{"paperId":"eef2a832579eac32abd0194f0cd23d60f2ef02c6","externalIds":{"DBLP":"journals/kbs/RadaidehS21","DOI":"10.1016/j.knosys.2021.106836","CorpusId":232358972},"title":"Rule-based reinforcement learning methodology to inform evolutionary algorithms for constrained optimization of engineering applications"},{"paperId":"902d70fb673a1af053e0113bb5bd09fd56682112","externalIds":{"DBLP":"journals/candie/QinZHH21","MAG":"3136908367","DOI":"10.1016/J.CIE.2021.107252","CorpusId":233713365},"title":"A novel reinforcement learning-based hyper-heuristic for heterogeneous vehicle routing problem"},{"paperId":"8bdd000b3bc2aa68ec59a59905e7e84c74904681","externalIds":{"MAG":"3132655884","DBLP":"journals/tec/SunLBX21","ArXiv":"2102.03572","DOI":"10.1109/TEVC.2021.3060811","CorpusId":231847222},"title":"Learning Adaptive Differential Evolution Algorithm From Optimization Experiences by Policy Gradient"},{"paperId":"946f82a6d2a28e361a2c1ede1e2e76aa0f2589ac","externalIds":{"DBLP":"conf/ssci/TatsisP20","DOI":"10.1109/SSCI47803.2020.9308488","CorpusId":230999324},"title":"Reinforced Online Parameter Adaptation Method for Population-based Metaheuristics"},{"paperId":"1e3a0b4ff1a56bb629d76b078550d00d0f5f472a","externalIds":{"DOI":"10.1109/CAC51589.2020.9327174","CorpusId":231737063},"title":"Driver Behavior Modeling via Inverse Reinforcement Learning Based on Particle Swarm Optimization"},{"paperId":"789f123971ff722fb8529ecb4b387a8841407f92","externalIds":{"DBLP":"journals/asc/HuangLTM20","MAG":"3083974266","DOI":"10.1016/j.asoc.2020.106693","CorpusId":225317242},"title":"A fitness landscape ruggedness multiobjective differential evolution algorithm with a reinforcement learning strategy"},{"paperId":"e01ada598d3835aec2f08e6640e9f7268427bd56","externalIds":{"DBLP":"journals/phycomm/KaurK20","MAG":"3082796870","DOI":"10.1016/j.phycom.2020.101196","CorpusId":225290660},"title":"A Reinforcement Learning based evolutionary multi-objective optimization algorithm for spectrum allocation in Cognitive Radio networks"},{"paperId":"97e4af1c188ad03d822f28dffade5f47f279c619","externalIds":{"DBLP":"journals/corr/abs-2008-12248","ArXiv":"2008.12248","MAG":"3081235889","DOI":"10.1109/AIC57670.2023.10263956","CorpusId":221341021},"title":"A Survey on Reinforcement Learning for Combinatorial Optimization"},{"paperId":"deb12d2e96f62ffea5b86e30c0931b9176d895c8","externalIds":{"DBLP":"journals/csur/Talbi21a","MAG":"3033538074","DOI":"10.1145/3459664","CorpusId":219931028},"title":"Machine Learning into Metaheuristics"},{"paperId":"8e726a71df2861f55e184cbf01dce20a6462d8c9","externalIds":{"DBLP":"journals/taes/WangSLH20","MAG":"2981381983","DOI":"10.1109/TAES.2019.2947978","CorpusId":208829504},"title":"Robust Earth Observation Satellite Scheduling With Uncertainty of Cloud Coverage"},{"paperId":"6d91acf1f62cea3bbcefcff96caef1d41af47a94","externalIds":{"MAG":"3011713911","ArXiv":"2003.06169","DBLP":"journals/corr/abs-2003-06169","DOI":"10.1109/JSYST.2020.2997050","CorpusId":212717712},"title":"Agile Earth Observation Satellite Scheduling Over 20 Years: Formulations, Methods, and Future Directions"},{"paperId":"5646b7e555fc7768db1e3e9a792b59a6553b1d7e","externalIds":{"MAG":"3009304813","DBLP":"journals/corr/abs-2003-03600","ArXiv":"2003.03600","DOI":"10.1016/j.cor.2021.105400","CorpusId":212633747},"title":"Reinforcement Learning for Combinatorial Optimization: A Survey"},{"paperId":"b0fa6699b932bf18c404f84bddc4b9fe8ab4a864","externalIds":{"MAG":"2479792287","DOI":"10.2514/2.2111","CorpusId":3114196},"title":"Particle Swarm Optimization"},{"paperId":"6a87f49c098282c1a472c80c242ee572b035cb72","externalIds":{"MAG":"2964433174","DOI":"10.1016/J.TRD.2019.07.025","CorpusId":201244001},"title":"Effects of ambient temperature on the route planning of electric freight vehicles"},{"paperId":"3e5ff92aff33e6104e7557cb40f35b44946653a1","externalIds":{"MAG":"2955147151","DBLP":"journals/swevo/LiSYSQ19","DOI":"10.1016/J.SWEVO.2019.06.010","CorpusId":198351266},"title":"Differential evolution based on reinforcement learning with fitness ranking for solving multimodal multiobjective problems"},{"paperId":"e990470bc8944d5267d3c99c80037f4f9cc3b629","externalIds":{"DBLP":"journals/swevo/WuMS19","MAG":"2892369032","DOI":"10.1016/J.SWEVO.2018.08.015","CorpusId":58952057},"title":"Ensemble strategies for population-based optimization algorithms - A survey"},{"paperId":"bdae5c2d2d8f0daab744872aa61ca05a15bd7f89","externalIds":{"MAG":"2800510013","DBLP":"journals/tits/Khadilkar19","DOI":"10.1109/TITS.2018.2829165","CorpusId":59553811},"title":"A Scalable Reinforcement Learning Algorithm for Scheduling Railway Lines"},{"paperId":"40f54e88a391214afc7a939b7b40e2375a64b5d6","externalIds":{"MAG":"2794711922","DBLP":"journals/swevo/Drugan19","DOI":"10.1016/J.SWEVO.2018.03.011","CorpusId":58952007},"title":"Reinforcement learning versus evolutionary computation: A survey on hybrid algorithms"},{"paperId":"6c87476a14c89b875664e44fa0bacbf9ee7b5cdb","externalIds":{"MAG":"2795636552","DBLP":"journals/swevo/SadhuKBD18","DOI":"10.1016/J.SWEVO.2018.03.014","CorpusId":56556497},"title":"Synergism of Firefly Algorithm and Q-Learning for Robot Arm Path Planning"},{"paperId":"4b61c25a86083c20730c9b12737ac6ac4178c364","externalIds":{"MAG":"2903218963","ArXiv":"1811.12560","DBLP":"journals/ftml/Francois-LavetH18","DOI":"10.1561/2200000071","CorpusId":54434537},"title":"An Introduction to Deep Reinforcement Learning"},{"paperId":"a39579145d3222f13e4ef19c988cdd2e5682ccc6","externalIds":{"DOI":"10.1007/3-540-29623-9_7150","CorpusId":17088312},"title":"Genetic Algorithm"},{"paperId":"7960c528ab5ac215515e255e52096549c3031eaa","externalIds":{"DBLP":"journals/isci/ChoongWL18","MAG":"2783585128","DOI":"10.1016/j.ins.2018.01.005","CorpusId":26570646},"title":"Automatic design of hyper-heuristic based on reinforcement learning"},{"paperId":"63f9e6a1d28e66c0ad9c1566b7cdd1df14ce59e0","externalIds":{"DBLP":"journals/candie/ShahrabiAM17","MAG":"2618749399","DOI":"10.1016/j.cie.2017.05.026","CorpusId":31388416},"title":"A reinforcement learning approach to parameter estimation in dynamic job shop scheduling"},{"paperId":"dce6f9d4017b1785979e7520fd0834ef8cf02f4b","externalIds":{"MAG":"2736601468","DBLP":"journals/corr/SchulmanWDRK17","ArXiv":"1707.06347","CorpusId":28695052},"title":"Proximal Policy Optimization Algorithms"},{"paperId":"5e2081625c7933ce26e2cc7dad6bb90d27955cc3","externalIds":{"DBLP":"conf/gecco/Jong17","DOI":"10.1145/3067695.3067715","CorpusId":215808417},"title":"Evolutionary computation: a unified approach"},{"paperId":"4ee802a58d32aa049d549d06be440ac947b53987","externalIds":{"DBLP":"journals/corr/SalimansHCS17","MAG":"2596367596","ArXiv":"1703.03864","CorpusId":11410889},"title":"Evolution Strategies as a Scalable Alternative to Reinforcement Learning"},{"paperId":"1ab7aa767e1779c87d822325859e47fe2986e6b2","externalIds":{"DBLP":"conf/hotnets/MaoAMK16","MAG":"2546571074","DOI":"10.1145/3005745.3005750","CorpusId":207244918},"title":"Resource Management with Deep Reinforcement Learning"},{"paperId":"aae5729e42e17439ee8fd43662979c25e0746862","externalIds":{"MAG":"2494907211","ArXiv":"1608.02971","DBLP":"conf/cec/BudhrajaO17","DOI":"10.1109/CEC.2017.7969297","CorpusId":6918480},"title":"Neuroevolution-based Inverse Reinforcement Learning"},{"paperId":"69e76e16740ed69f4dc55361a3d319ac2f1293dd","externalIds":{"MAG":"2964043796","DBLP":"journals/corr/MnihBMGLHSK16","ArXiv":"1602.01783","CorpusId":6875312},"title":"Asynchronous Methods for Deep Reinforcement Learning"},{"paperId":"4c05d7caa357148f0bbd61720bdd35f0bc05eb81","externalIds":{"DBLP":"conf/icml/WangSHHLF16","ArXiv":"1511.06581","MAG":"2951799221","CorpusId":5389801},"title":"Dueling Network Architectures for Deep Reinforcement Learning"},{"paperId":"c6170fa90d3b2efede5a2e1660cb23e1c824f2ca","externalIds":{"MAG":"2963477884","DBLP":"journals/corr/SchaulQAS15","ArXiv":"1511.05952","CorpusId":13022595},"title":"Prioritized Experience Replay"},{"paperId":"3b9732bb07dc99bde5e1f9f75251c6ea5039373e","externalIds":{"MAG":"2155968351","DBLP":"conf/aaai/HasseltGS16","ArXiv":"1509.06461","DOI":"10.1609/aaai.v30i1.10295","CorpusId":6208256},"title":"Deep Reinforcement Learning with Double Q-Learning"},{"paperId":"024006d4c2a89f7acacc6e4438d156525b60a98f","externalIds":{"MAG":"2173248099","DBLP":"journals/corr/LillicrapHPHETS15","ArXiv":"1509.02971","CorpusId":16326763},"title":"Continuous control with deep reinforcement learning"},{"paperId":"d422df8bff4e677a3077635db116679d25142bfc","externalIds":{"MAG":"1901616594","DOI":"10.1126/science.aaa8415","CorpusId":677218,"PubMed":"26185243"},"title":"Machine learning: Trends, perspectives, and prospects"},{"paperId":"062322bea7904d3c6e44cff7cb3f12b482b69085","externalIds":{"MAG":"2159308419","DBLP":"journals/tcyb/WangLYS15","DOI":"10.1109/TCYB.2014.2337117","CorpusId":2527171,"PubMed":"25099966"},"title":"MOMMOP: Multiobjective Optimization for Locating Multiple Optimal Solutions of Multimodal Optimization Problems"},{"paperId":"340f48901f72278f6bf78a04ee5b01df208cc508","externalIds":{"DBLP":"journals/nature/MnihKSRVBGRFOPB15","MAG":"2145339207","DOI":"10.1038/nature14236","CorpusId":205242740,"PubMed":"25719670"},"title":"Human-level control through deep reinforcement learning"},{"paperId":"7f46f1b3c2c3919de17b07eefa7dab889a3d1eca","externalIds":{"DBLP":"journals/tec/DebJ14","MAG":"2022485595","DOI":"10.1109/TEVC.2013.2281535","CorpusId":206682597},"title":"An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach, Part I: Solving Problems With Box Constraints"},{"paperId":"c4529a7f658c30c7ba4e19c9d31ce2235ec6a710","externalIds":{"DBLP":"conf/gecco/KarafotiasEH14","MAG":"2048256025","DOI":"10.1145/2576768.2598360","CorpusId":17407921},"title":"Generic parameter control with reinforcement learning"},{"paperId":"c316da0b64dbaf7e26462b718335fd7cc3a2b538","externalIds":{"DBLP":"conf/gecco/BuzdalovaKB14","MAG":"1987278360","DOI":"10.1145/2598394.2605681","CorpusId":14050796},"title":"Selecting evolutionary operators using reinforcement learning: initial explorations"},{"paperId":"2319a491378867c7049b3da055c5df60e1671158","externalIds":{"DBLP":"journals/corr/MnihKSGAWR13","MAG":"1757796397","ArXiv":"1312.5602","CorpusId":15238391},"title":"Playing Atari with Deep Reinforcement Learning"},{"paperId":"95b0bfd4ef9aaf38d1e740576eec8172d0e42f6e","externalIds":{"PubMedCentral":"3727332","DBLP":"journals/cor/MonaciPS13","MAG":"2037342851","DOI":"10.1016/j.cor.2013.05.005","CorpusId":7304945,"PubMed":"24187428"},"title":"Exact solution of the robust knapsack problem☆"},{"paperId":"6d11823571a7c75b9bf91e248df05939682e991c","externalIds":{"DBLP":"journals/asc/Babaei13","MAG":"1966930189","DOI":"10.1016/j.asoc.2013.02.005","CorpusId":29183999},"title":"A general approach to approximate solutions of nonlinear differential equations using particle swarm optimization"},{"paperId":"612202fd309100fe459914cc6bd876dbc0c24223","externalIds":{"DBLP":"journals/tsmc/RakshitKBGDJN13","MAG":"2067508429","DOI":"10.1109/TSMCA.2012.2226024","CorpusId":3965565},"title":"Realization of an Adaptive Memetic Algorithm Using Differential Evolution and Q-Learning: A Case Study in Multirobot Path Planning"},{"paperId":"a3d0707e0c96406825fd300131e4416fc89876e5","externalIds":{"MAG":"2050439249","DBLP":"conf/icmla/BuzdalovaB12","DOI":"10.1109/ICMLA.2012.32","CorpusId":15895667},"title":"Increasing Efficiency of Evolutionary Algorithms by Choosing between Auxiliary Fitness Functions with Reinforcement Learning"},{"paperId":"cb6b7032c86dab47c451405a1c31aac6ca43375d","externalIds":{"MAG":"1967036758","DOI":"10.1016/J.JHYDROL.2012.08.004","CorpusId":128948263},"title":"An overview of the optimization modelling applications"},{"paperId":"c4bb6b0cc85dc6bcaaf850599eb3fda9c7e10c2b","externalIds":{"DBLP":"series/isrl/38","MAG":"244247539","DOI":"10.1007/978-3-642-30504-7","CorpusId":35149012},"title":"Handbook of Optimization - From Classical to Modern Approach"},{"paperId":"df37beb5bbda42f039a059e571de253b043a221c","externalIds":{"MAG":"2008434012","DBLP":"journals/swevo/NeriC12","DOI":"10.1016/j.swevo.2011.11.003","CorpusId":42937655},"title":"Memetic algorithms and memetic computing optimization: A literature review"},{"paperId":"063568b1aed039b61a2bbeb2d60b04e7a8210a8e","externalIds":{"DBLP":"conf/gecco/Jong11","MAG":"2789910057","DOI":"10.1002/wics.5","CorpusId":19680044},"title":"Evolutionary computation"},{"paperId":"0d9155f763ad1d72e67b9ea5dbf6c84e62fcf535","externalIds":{"MAG":"2000135657","ArXiv":"1005.2908","DBLP":"journals/ijmno/YangD10","DOI":"10.1504/IJMMNO.2010.035430","CorpusId":34889796},"title":"Engineering optimisation by cuckoo search"},{"paperId":"70adc28275d30186d47cd5d758a8d0257a355010","externalIds":{"DBLP":"journals/oms/Pardalos09","MAG":"2024780670","DOI":"10.1080/10556780802583108","CorpusId":1686203},"title":"Approximate dynamic programming: solving the curses of dimensionality"},{"paperId":"b76be6707fa5858cc5378bc11f10ec6f6a97d85c","externalIds":{"MAG":"2143381319","DBLP":"journals/tec/ZhangL07","DOI":"10.1109/TEVC.2007.892759","CorpusId":7312933},"title":"MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition"},{"paperId":"d3ea470c124ae4d7bac709be1da6bd31570efc64","externalIds":{"MAG":"2084912121","DOI":"10.1038/nature02581","CorpusId":4365241,"PubMed":"15190354"},"title":"Temporal difference models describe higher-order learning in humans"},{"paperId":"26afab5607f4bfaf2fb9f786e4ed4f2d93c88e84","externalIds":{"MAG":"2138537392","DBLP":"journals/ec/HansenMK03","DOI":"10.1162/106365603321828970","CorpusId":261944074,"PubMed":"12804094"},"title":"Reducing the Time Complexity of the Derandomized Evolution Strategy with Covariance Matrix Adaptation (CMA-ES)"},{"paperId":"6eddc19efa13f7e70301908d98e85a19d6f32a02","externalIds":{"DBLP":"journals/tec/DebAPM02","MAG":"2126105956","DOI":"10.1109/4235.996017","CorpusId":9914171},"title":"A fast and elitist multiobjective genetic algorithm: NSGA-II"},{"paperId":"a20f0ce0616def7cc9a87446c228906cd5da093b","externalIds":{"DBLP":"conf/nips/SuttonMSM99","MAG":"2155027007","CorpusId":1211821},"title":"Policy Gradient Methods for Reinforcement Learning with Function Approximation"},{"paperId":"8315dff3d304baf47c025f4b33535b9d693350c1","externalIds":{"MAG":"2151554678","DBLP":"journals/tec/DolpertM97","DOI":"10.1109/4235.585893","CorpusId":5553697},"title":"No free lunch theorems for optimization"},{"paperId":"03b7e51c52084ac1db5118342a00b5fbcfc587aa","externalIds":{"MAG":"2625787351","DBLP":"journals/ml/WatkinsD92","DOI":"10.1007/BF00992698","CorpusId":208910339},"title":"Q-learning"},{"paperId":"d9b45079fb7d7b1031837197fe784756b465c011","externalIds":{"DBLP":"conf/iclr/0001WLLH024","CorpusId":270003428},"title":"Sample-Efficient Quality-Diversity by Cooperative Coevolution"},{"paperId":"b1e2998fc75e6a650721c0e4e727eb8b3b82e6f2","externalIds":{"CorpusId":255545834},"title":"LAGA: A Learning Adaptive Genetic Algorithm for Earth Electromagnetic Satellite Scheduling Problem"},{"paperId":"561f083a646114202081a77de7859084da1343fa","externalIds":{"DBLP":"conf/icic/QiuXXN23","DOI":"10.1007/978-981-99-4755-3_27","CorpusId":260840984},"title":"Q-Learning Based Particle Swarm Optimization with Multi-exemplar and Elite Learning"},{"paperId":"c96add7b90dd9c048e37f6b572fdf58ff51580ce","externalIds":{"DBLP":"conf/icic/WuQHZW23","DOI":"10.1007/978-981-99-4755-3_22","CorpusId":260841027},"title":"A Q-Learning-Based Hyper-Heuristic Evolutionary Algorithm for the Distributed Flexible Job-Shop Scheduling Problem"},{"paperId":"29fa7a1f55523e5589debed5afcd2b2b2ff3a30b","externalIds":{"DBLP":"conf/icic/ZhuHLQZ23","DOI":"10.1007/978-981-99-4755-3_17","CorpusId":260840988},"title":"Hyper-heuristic Q-Learning Algorithm for Flow-Shop Scheduling Problem with Fuzzy Processing Times"},{"paperId":"63229d7e800b62aadd1ea925ffeb64d9c526f1ec","externalIds":{"DBLP":"conf/icic/GaoSYHQ23","DOI":"10.1007/978-981-99-4755-3_25","CorpusId":265796753},"title":"Improved Particle Swarm Optimization Algorithm Combined with Reinforcement Learning for Solving Flexible Job Shop Scheduling Problem"},{"paperId":"40929ae1b1557b1a8da600b4b118bf86ab66e445","externalIds":{"DOI":"10.1007/978-981-16-8082-3_3","CorpusId":246327099},"title":"Reinforcement Learning-Based Differential Evolution for Global Optimization"},{"paperId":"f3ae22eddd2dcce298abceceabcf4f4116bcedb9","externalIds":{"DBLP":"conf/bic-ta/SongOPLH022","DOI":"10.1007/978-981-99-1549-1_7","CorpusId":259834360},"title":"A Reinforcement-Learning-Driven Bees Algorithm for Large-Scale Earth Observation Satellite Scheduling"},{"paperId":"56a6cf8269039ca1e3e55ebe9f794ec60e088e5f","externalIds":{"DBLP":"journals/isci/WangWS22","DOI":"10.1016/j.ins.2022.04.053","CorpusId":249283322},"title":"A reinforcement learning level-based particle swarm optimization algorithm for large-scale optimization"},{"paperId":"f3559b9fc51f65bbf4b8db57591ea1f2a51b5fbb","externalIds":{"MAG":"2811338889","DOI":"10.1016/J.PROCIR.2018.03.212","CorpusId":65206519},"title":"Optimization of global production scheduling with deep reinforcement learning"},{"paperId":"42eafccc012e7f871a8fc9be6d96953388e46d7a","externalIds":{"DBLP":"books/daglib/p/EibenS12","MAG":"332481212","DOI":"10.1007/978-3-642-21434-9_2","CorpusId":6870751},"title":"Evolutionary Algorithm Parameters and Methods to Tune Them"},{"paperId":"e415a2939f6ab47f64c90f26bfb16dc6b6cfccfb","externalIds":{"MAG":"2497473826","DOI":"10.1007/978-3-642-14435-6","CorpusId":64283804},"title":"Innovations in Multi-Agent Systems and Applications - 1"},{"paperId":"8851953ef486615fce803bda2e40aec97cbb5547","externalIds":{"MAG":"206679605","DOI":"10.1007/978-3-642-14435-6_7","CorpusId":17136625},"title":"Multi-agent Reinforcement Learning: An Overview"},{"paperId":"0b5b28c158b5a9ed8fa588255a1295f44dbc8fb7","externalIds":{"DOI":"10.1002/9780470640425.ch12","CorpusId":3240481},"title":"Simulated Annealing"},{"paperId":"902853b9acfb8062d0e50e02ef4735d7f9245ee6","externalIds":{"DOI":"10.1007/3-540-31306-0","CorpusId":29230178},"title":"Differential Evolution"},{"paperId":"97efafdb4a3942ab3efba53ded7413199f79c054","externalIds":{"MAG":"2121863487","DBLP":"journals/tnn/SuttonB98","DOI":"10.1109/TNN.1998.712192","CorpusId":60035920},"title":"Reinforcement Learning: An Introduction"}]}