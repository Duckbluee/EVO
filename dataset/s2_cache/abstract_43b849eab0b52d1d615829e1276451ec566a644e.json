{"abstract":"Network representation learning (RL) aims\n\nto transform the nodes in a network into low-dimensional vector spaces while\n\npreserving the inherent properties of the network. Though network RL has been intensively\n\nstudied, most existing works focus on either network structure or node\n\nattribute information. In this paper, we propose a novel framework, named ANRL,\n\nto incorporate both the network structure and node attribute information in a principled\n\nway. Specifically, we propose a neighbor enhancement autoencoder to model the\n\nnode attribute information, which reconstructs its target neighbors instead of\n\nitself. To capture the network structure, attribute-aware skip-gram model is designed\n\nbased on the attribute encoder to formulate the correlations between each node and its\n\ndirect or indirect neighbors. We conduct extensive experiments on six\n\nreal-world networks, including two social networks, two citation networks and\n\ntwo user behavior networks. The results empirically show that ANRL can achieve\n\nrelatively significant gains in node classification and link prediction tasks."}