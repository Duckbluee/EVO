{"references":[{"paperId":"2f813f7e559528e0ec89c098018b47a55642caca","externalIds":{"DBLP":"journals/corr/abs-2303-04942","ArXiv":"2303.04942","DOI":"10.1109/InteNSE59150.2023.00007","CorpusId":257427185},"title":"A Study of Variable-Role-based Feature Enrichment in Neural Models of Code"},{"paperId":"8049fe469d455f9cca4fd252002bf737986cdce5","externalIds":{"DBLP":"journals/corr/abs-2303-01739","ArXiv":"2303.01739","DOI":"10.1109/InteNSE59150.2023.00005","CorpusId":257353486},"title":"Study of Distractors in Neural Models of Code"},{"paperId":"ac9100f6e152c6560fd47305eeca83c701398be4","externalIds":{"DOI":"10.1016/j.tbench.2023.100089","CorpusId":257372140},"title":"An era of ChatGPT as a significant futuristic support tool: A study on features, abilities, and challenges"},{"paperId":"70762a912d07f4c11dbc5d02a2eb416dd21eaa5c","externalIds":{"DBLP":"journals/tse/YangXZKSHL24","ArXiv":"2301.02496","DOI":"10.1109/TSE.2024.3361661","CorpusId":255522586},"title":"Stealthy Backdoor Attack for Code Models"},{"paperId":"dae74645479f7c1fa3671066f9e24ec6c20c17ec","externalIds":{"DBLP":"journals/corr/abs-2301-02344","ArXiv":"2301.02344","DOI":"10.1109/SP54263.2024.00140","CorpusId":255522506},"title":"TrojanPuzzle: Covertly Poisoning Code-Suggestion Models"},{"paperId":"c90091ee33e3edc0734b0e1cf5d2a49c4f2dced7","externalIds":{"DBLP":"journals/corr/abs-2210-17029","ArXiv":"2210.17029","DOI":"10.48550/arXiv.2210.17029","CorpusId":253237187},"title":"Poison Attack and Defense on Deep Source Code Processing Models"},{"paperId":"f0631f7928b99ee51f8164acd04889219b2bcdbb","externalIds":{"DBLP":"conf/sigsoft/Zhang0S022","ArXiv":"2206.14390","DOI":"10.1145/3540250.3549094","CorpusId":250113729},"title":"Diet code is healthy: simplifying programs for pre-trained models of code"},{"paperId":"caa628a4671071e274fba64f810b606df67f5cfe","externalIds":{"DBLP":"journals/corr/abs-2205-14374","ArXiv":"2205.14374","DOI":"10.1145/3520312.3534869","CorpusId":249191662},"title":"Syntax-guided program reduction for understanding neural code intelligence models"},{"paperId":"9e82736043eebe3f71eb86cbef6e2ac45306ece5","externalIds":{"ACL":"2022.acl-long.107","DBLP":"conf/acl/XiaZC22","ArXiv":"2204.00408","DOI":"10.48550/arXiv.2204.00408","CorpusId":247922354},"title":"Structured Pruning Learns Compact and Accurate Models"},{"paperId":"775a9c722262c7b656876a5fef20f4577afd8981","externalIds":{"ArXiv":"2112.02043","DBLP":"journals/corr/abs-2112-02043","DOI":"10.1145/3510003.3510049","CorpusId":244909472},"title":"Multilingual training for Software Engineering"},{"paperId":"7362bf55c346ce033ae806e99b43a4cb646e367d","externalIds":{"DBLP":"journals/corr/abs-2111-05711","ArXiv":"2111.05711","DOI":"10.1145/3510457.3513081","CorpusId":243938592},"title":"Counterfactual Explanations for Models of Code"},{"paperId":"02183e69f1dfd6e9b2d0fb876153299bab4bb82b","externalIds":{"DBLP":"conf/www/Sun0SN022","ArXiv":"2110.12925","DOI":"10.1145/3485447.3512225","CorpusId":239768432},"title":"CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning"},{"paperId":"6e5eb6167d9766fbb4d14611d15cf95d7b75fb9d","externalIds":{"DBLP":"journals/cacm/PearceATDK25","ArXiv":"2108.09293","DOI":"10.1145/3610721","CorpusId":245220588},"title":"Asleep at the Keyboard? Assessing the Security of GitHub Copilotâ€™s Code Contributions"},{"paperId":"8649fbabc0b685058280cbb1f58cdaeb6e074d70","externalIds":{"DBLP":"conf/sigsoft/CitoD0M021","DOI":"10.1145/3468264.3468614","CorpusId":237205994},"title":"Explaining mispredictions of machine learning models using rule induction"},{"paperId":"69e330037afd18e5546fdcacbc9a9f7deb69bba9","externalIds":{"ArXiv":"2106.08704","DBLP":"journals/infsof/RabinHAH23","MAG":"3168117580","DOI":"10.1016/j.infsof.2022.107066","CorpusId":235446982},"title":"Memorization and Generalization in Neural Code Intelligence Models"},{"paperId":"98097b7499bffd76e89d6c28449346f383143553","externalIds":{"DBLP":"journals/corr/abs-2106-03353","ArXiv":"2106.03353","DOI":"10.1145/3468264.3468539","CorpusId":235359051},"title":"Understanding neural code intelligence through program simplification"},{"paperId":"abb90e08b106623961a2cbed107d2a7ec861b6f5","externalIds":{"DBLP":"conf/sigsoft/Harel-CanadaWGG20","MAG":"2994987245","DOI":"10.1145/3368089.3409754","CorpusId":210146632},"title":"Is neuron coverage a meaningful measure for testing deep neural networks?"},{"paperId":"be910753f93c24712942536c8dc69e320247c680","externalIds":{"MAG":"3131641316","DBLP":"journals/infsof/RabinBWYJA21","ArXiv":"2008.01566","DOI":"10.1016/j.infsof.2021.106552","CorpusId":233920647},"title":"On the generalizability of Neural Program Models with respect to semantic-preserving program transformations"},{"paperId":"69dd1b9e8391430a667214a9ca6c0bc94560deb2","externalIds":{"DBLP":"journals/corr/abs-2007-10760","MAG":"3044223678","ArXiv":"2007.10760","CorpusId":220665637},"title":"Backdoor Attacks and Countermeasures on Deep Learning: A Comprehensive Review"},{"paperId":"1ec69f1a1a9d4ff5c5bc70db0e5087157b620570","externalIds":{"DBLP":"journals/corr/abs-2007-02220","MAG":"3038680626","ArXiv":"2007.02220","CorpusId":220363858},"title":"You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion"},{"paperId":"154f54bf48264e6aa70381983212b8980001ef94","externalIds":{"MAG":"3036298391","DBLP":"conf/nips/SunSS20","ArXiv":"2006.09615","CorpusId":219720981},"title":"De-Anonymizing Text by Fingerprinting Language Generation"},{"paperId":"5af77e48f8725fff607eaf751358b71a1d4de0a2","externalIds":{"DBLP":"journals/corr/abs-2006-06841","MAG":"3035643244","ArXiv":"2006.06841","DOI":"10.1109/ICPR56361.2022.9956690","CorpusId":219636120},"title":"Backdoors in Neural Models of Source Code"},{"paperId":"6f46322243a8318a9712bedf6a218e2df85c64fb","externalIds":{"DBLP":"conf/uss/BagdasaryanS21","MAG":"3022042319","ArXiv":"2005.03823","CorpusId":218571440},"title":"Blind Backdoors in Deep Learning Models"},{"paperId":"0d360a1256ccdfca58cf98d12243df8407fd442d","externalIds":{"MAG":"3035367371","ACL":"2020.acl-main.249","DBLP":"conf/acl/KuritaMN20","ArXiv":"2004.06660","DOI":"10.18653/v1/2020.acl-main.249","CorpusId":215754328},"title":"Weight Poisoning Attacks on Pretrained Models"},{"paperId":"63aa6b35e392e26c94ae252623863b4934c0a958","externalIds":{"ArXiv":"1902.06531","MAG":"2914712270","DBLP":"journals/corr/abs-1902-06531","DOI":"10.1145/3359789.3359790","CorpusId":62841494},"title":"STRIP: a defence against trojan attacks on deep neural networks"},{"paperId":"71f212b84e8f784bb2c17bf9e2415b0b780f2e73","externalIds":{"MAG":"2950851366","DBLP":"journals/corr/abs-1811-00636","ArXiv":"1811.00636","CorpusId":53298804},"title":"Spectral Signatures in Backdoor Attacks"},{"paperId":"75be1b015c04f95507efbf8e57f59db81f07d4e2","externalIds":{"MAG":"1980276147","DOI":"10.1097/JTO.0b013e3181ec173d","CorpusId":26728886,"PubMed":"20736804"},"title":"Receiver operating characteristic curve in diagnostic test assessment."},{"paperId":"d40ee5dd758c525dfb9932d726bb4e844b7b8478","externalIds":{"DBLP":"journals/prl/Fawcett06","MAG":"2158698691","DOI":"10.1016/j.patrec.2005.10.010","CorpusId":2027090},"title":"An introduction to ROC analysis"},{"paperId":"a397c5d4fadcc0ce29123b78815987b543417ba4","externalIds":{"DBLP":"journals/tse/ZellerH02","MAG":"2170224888","DOI":"10.1109/32.988498","CorpusId":6302370},"title":"Simplifying and Isolating Failure-Inducing Input"},{"paperId":"cb123f1afd67fb8bae15dc876709c842b626c49c","externalIds":{"DBLP":"journals/corr/abs-2210-04802","DOI":"10.48550/arXiv.2210.04802","CorpusId":252780134},"title":"SimSCOOD: Systematic Analysis of Out-of-Distribution Behavior of Source Code Models"},{"paperId":"89654f548e541a8ef233be6585316ce6cc201535","externalIds":{"CorpusId":265040233},"title":"Structured Pruning Learns Compact and Accurate Models"}]}