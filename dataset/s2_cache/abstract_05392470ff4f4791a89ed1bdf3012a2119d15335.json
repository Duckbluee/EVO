{"abstract":"An image resulting from a low-resolution (LR) camera on the mobile phone has lower quality than a high-resolution(HR) camera on a DSLR. Meanwhile, the HR camera is pricing if compared with the LR camera. How to achieve a single-image quality on LR camera likewise on HR camera becomes essential research in the past years. Addressing this issue can be done by upscaling a single LR image. Recently, the super-resolution generative adversarial network (SRGAN) model is one of the state-of-the-art super-resolution(SR)models employed on single-image SR. However, implementing a deep learning model like SRGAN on a mobile device is challenging in computation power and resources. This study aims to develop a smaller and lower resources model while preserving single-image SR quality on mobile devices. To meet these objectives, we convert, quantize, and compress the SRGAN model on Snapdragon Neural Processing Engine (SNPE) as an example. We then validate the SRGAN on the DIV2K dataset on which improves the model performances. Besides, we conduct experiments on GPU, DSP environment. The experimental result confirmed that SNPE-SRGAN capable of achieves not only HR imagesâ€™ quality but also low latency by 0.06 second and smaller model by 1.7 Mb size running on DSP. Also, the SRGAN-DLC-Quantized running on GPU has a smaller size by 1.7 Mb and lower latency by 1.151 seconds compared with Non-quantized SRGAN-TensorFlow by 9.1 Mb and 1.608 seconds latency."}