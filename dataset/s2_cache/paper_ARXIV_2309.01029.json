{"paperId":"26089bdfdbca1e6eaaceca71e3116b715bec6d47","externalIds":{"DBLP":"journals/corr/abs-2309-01029","ArXiv":"2309.01029","DOI":"10.1145/3639372","CorpusId":261530292},"title":"Explainability for Large Language Models: A Survey","openAccessPdf":{"url":"https://dl.acm.org/doi/pdf/10.1145/3639372","status":"HYBRID","license":"CCBY","disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2309.01029, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2237987232","name":"Haiyan Zhao"},{"authorId":"7315244","name":"Hanjie Chen"},{"authorId":"145338224","name":"F. Yang"},{"authorId":"47717322","name":"Ninghao Liu"},{"authorId":"13689700","name":"Huiqi Deng"},{"authorId":"22561596","name":"Hengyi Cai"},{"authorId":"2237948548","name":"Shuaiqiang Wang"},{"authorId":"2136400100","name":"Dawei Yin"},{"authorId":"2237804196","name":"Mengnan Du"}],"abstract":"Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models."}