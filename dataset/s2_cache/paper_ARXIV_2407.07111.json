{"paperId":"568942c2ca574fdb89517b7d1c86f7be9026b66d","externalIds":{"ArXiv":"2407.07111","DBLP":"journals/corr/abs-2407-07111","DOI":"10.48550/arXiv.2407.07111","CorpusId":271088929},"title":"Diffusion Model-Based Video Editing: A Survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2407.07111, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2310773170","name":"Wenhao Sun"},{"authorId":"2307468312","name":"Rong-Cheng Tu"},{"authorId":"2310774600","name":"Jingyi Liao"},{"authorId":"2310610306","name":"Dacheng Tao"}],"abstract":"The rapid development of diffusion models (DMs) has significantly advanced image and video applications, making\"what you want is what you see\"a reality. Among these, video editing has gained substantial attention and seen a swift rise in research activity, necessitating a comprehensive and systematic review of the existing literature. This paper reviews diffusion model-based video editing techniques, including theoretical foundations and practical applications. We begin by overviewing the mathematical formulation and image domain's key methods. Subsequently, we categorize video editing approaches by the inherent connections of their core technologies, depicting evolutionary trajectory. This paper also dives into novel applications, including point-based editing and pose-guided human video editing. Additionally, we present a comprehensive comparison using our newly introduced V2VBench. Building on the progress achieved to date, the paper concludes with ongoing challenges and potential directions for future research."}