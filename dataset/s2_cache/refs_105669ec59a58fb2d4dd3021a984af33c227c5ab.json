{"references":[{"paperId":"7a922abcda328f9333c5a3819ade8917b98f08c9","externalIds":{"DBLP":"journals/corr/abs-2310-18152","ArXiv":"2310.18152","DOI":"10.48550/arXiv.2310.18152","CorpusId":264555213},"title":"Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs"},{"paperId":"beb3e8acd816bac1a5b7fccfd073f79048877e33","externalIds":{"DBLP":"conf/iclr/PangXMW24","ArXiv":"2310.12973","DOI":"10.48550/arXiv.2310.12973","CorpusId":264306111},"title":"Frozen Transformers in Language Models Are Effective Visual Encoder Layers"},{"paperId":"45872b94798c3125abfb185b7926689c5e767763","externalIds":{"DBLP":"conf/sigir/Tang00SSCY024","ArXiv":"2310.13023","DOI":"10.1145/3626772.3657775","CorpusId":264405943},"title":"GraphGPT: Graph Instruction Tuning for Large Language Models"},{"paperId":"062fab31d30478b57457c8b7a94d7467f5bd770c","externalIds":{"ArXiv":"2310.05845","DBLP":"journals/corr/abs-2310-05845","DOI":"10.48550/arXiv.2310.05845","CorpusId":263830019},"title":"GraphLLM: Boosting Graph Reasoning Ability of Large Language Model"},{"paperId":"4d1bcfb754dcd14fd312356021d9e332d3d3b18f","externalIds":{"DBLP":"journals/corr/abs-2310-04668","ArXiv":"2310.04668","DOI":"10.48550/arXiv.2310.04668","CorpusId":263829256},"title":"Label-free Node Classification on Graphs with Large Language Models (LLMS)"},{"paperId":"55367fbade73f96181ffcf52169d0471d4c014a2","externalIds":{"DBLP":"journals/corr/abs-2310-01089","ArXiv":"2310.01089","DOI":"10.48550/arXiv.2310.01089","CorpusId":263605738},"title":"GraphText: Graph Reasoning in Text Space"},{"paperId":"ab22d54dd13876d25c6c8f46c40fb9ac41c61ec5","externalIds":{"DBLP":"journals/corr/abs-2310-00149","ArXiv":"2310.00149","DOI":"10.48550/arXiv.2310.00149","CorpusId":265871676},"title":"One for All: Towards Training One Graph Model for All Classification Tasks"},{"paperId":"8d65b5940a4dbed8c18e02ca35e3a9d7a14ea76b","externalIds":{"ArXiv":"2308.07134","DBLP":"conf/eacl/YeZWXZ24","ACL":"2024.findings-eacl.132","DOI":"10.18653/v1/2024.findings-eacl.132","CorpusId":260887732},"title":"Language is All a Graph Needs"},{"paperId":"303b7d0a81395562e3a46578a89d6821ce564a8b","externalIds":{"ArXiv":"2308.02565","DBLP":"journals/corr/abs-2308-02565","DOI":"10.48550/arXiv.2308.02565","CorpusId":260681726},"title":"SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning"},{"paperId":"a35f1315e91513ff0bec0c488fe175214fd9636c","externalIds":{"DBLP":"journals/corr/abs-2307-02046","ArXiv":"2307.02046","DOI":"10.1109/TKDE.2024.3392335","CorpusId":259342486},"title":"Recommender Systems in the Era of Large Language Models (LLMs)"},{"paperId":"8f7297454d7f44365b9bcda5ebb9439a43daf5e6","externalIds":{"DBLP":"journals/corr/abs-2306-13063","ArXiv":"2306.13063","DOI":"10.48550/arXiv.2306.13063","CorpusId":259224389},"title":"Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"},{"paperId":"073e4f0c3a66b7557abd053301b5104cdc582636","externalIds":{"DBLP":"journals/corr/abs-2306-06615","ArXiv":"2306.06615","DOI":"10.1109/TKDE.2024.3393356","CorpusId":259137456},"title":"Empowering Molecule Discovery for Molecule-Caption Translation With Large Language Models: A ChatGPT Perspective"},{"paperId":"707142f242ee4e40489062870ca53810cb33d404","externalIds":{"DBLP":"journals/corr/abs-2306-01323","ArXiv":"2306.01323","DOI":"10.48550/arXiv.2306.01323","CorpusId":259064123},"title":"Demystifying Structural Disparity in Graph Neural Networks: Can One Size Fit All?"},{"paperId":"ad934a9344f68fcc0b9aa704102aa48c39c5b591","externalIds":{"ArXiv":"2305.19187","DBLP":"journals/corr/abs-2305-19187","DOI":"10.48550/arXiv.2305.19187","CorpusId":258967487},"title":"Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models"},{"paperId":"2b967d82b25088566980aaaf5a7062d90b2fb14f","externalIds":{"DBLP":"journals/corr/abs-2305-15066","ArXiv":"2305.15066","CorpusId":258865990},"title":"GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking"},{"paperId":"b6d6c33298b852cf63edac233deca70530d69a2a","externalIds":{"ArXiv":"2305.10403","DBLP":"journals/corr/abs-2305-10403","CorpusId":258740735},"title":"PaLM 2 Technical Report"},{"paperId":"df2beaae63e4d68ef8e762bcd4704c9f11f856d9","externalIds":{"DBLP":"journals/corr/abs-2305-10037","ArXiv":"2305.10037","DOI":"10.48550/arXiv.2305.10037","CorpusId":258740923},"title":"Can Language Models Solve Graph Problems in Natural Language?"},{"paperId":"6001dce1c8f63350263e013e0e6ff69816f0a9af","externalIds":{"ArXiv":"2305.08377","DBLP":"conf/emnlp/SunL0WGZ023","DOI":"10.18653/v1/2023.findings-emnlp.603","CorpusId":258686184},"title":"Text Classification via Large Language Models"},{"paperId":"0383e049e98c9eedbc61be728d4ef037300bbedf","externalIds":{"DBLP":"journals/corr/abs-2305-07001","ArXiv":"2305.07001","DOI":"10.1145/3708882","CorpusId":258615776},"title":"Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach"},{"paperId":"d6d3604f369bb0415cbe814e43ca3131323b03e2","externalIds":{"DBLP":"journals/pami/LiZCWPCYLL25","ArXiv":"2305.03726","DOI":"10.1109/TPAMI.2025.3571946","CorpusId":258547300,"PubMed":"40392642"},"title":"Otter: A Multi-Modal Model With In-Context Instruction Tuning"},{"paperId":"8c881130d499a21db478961d160b7d7542158c70","externalIds":{"ArXiv":"2304.13188","DBLP":"journals/corr/abs-2304-13188","DOI":"10.48550/arXiv.2304.13188","CorpusId":258331602},"title":"TABLET: Learning From Instructions For Tabular Data"},{"paperId":"ca7bd64d372e3bcb3f4633ca4a20291ff57de3c3","externalIds":{"DBLP":"journals/corr/abs-2304-10149","ArXiv":"2304.10149","DOI":"10.48550/arXiv.2304.10149","CorpusId":258236609},"title":"Is ChatGPT a Good Recommender? A Preliminary Study"},{"paperId":"0d502a1e300336ae628f5c8b99ee4d3766c8f60b","externalIds":{"DBLP":"journals/corr/abs-2304-11116","ArXiv":"2304.11116","DOI":"10.48550/arXiv.2304.11116","CorpusId":258291494},"title":"Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT"},{"paperId":"f9a7175198a2c9f3ab0134a12a7e9e5369428e42","externalIds":{"DBLP":"journals/corr/abs-2303-18223","ArXiv":"2303.18223","CorpusId":257900969},"title":"A Survey of Large Language Models"},{"paperId":"0cfdd655100055f234fd23ebecd915504b8e00e3","externalIds":{"DBLP":"journals/corr/abs-2303-14524","ArXiv":"2303.14524","CorpusId":257766541},"title":"Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System"},{"paperId":"8dbd57469bb32e6d57f23f5e765bf1c9ac8e080c","externalIds":{"ArXiv":"2303.12712","DBLP":"journals/corr/abs-2303-12712","CorpusId":257663729},"title":"Sparks of Artificial General Intelligence: Early experiments with GPT-4"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"92f19090599910af1b1c9ed2b318abc0adea0527","externalIds":{"DBLP":"journals/corr/abs-2303-07610","ArXiv":"2303.07610","DOI":"10.48550/arXiv.2303.07610","CorpusId":257504880},"title":"Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on Consistency with Human Preferences"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"5c7353fac22a8fdc43fc2f5c006b5d6902c47e75","externalIds":{"DBLP":"journals/debu/0001HH0ZWY0HGJ024","ArXiv":"2302.12095","DOI":"10.48550/arXiv.2302.12095","CorpusId":257102461},"title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective"},{"paperId":"ecd0b23e4828fca585a05eff56563852d35858d9","externalIds":{"DOI":"10.1007/s00113-023-01296-y","CorpusId":256787765,"PubMed":"36763148"},"title":"ChatGPT"},{"paperId":"53d128ea815bcc0526856eb5a9c42cc977cb36a7","externalIds":{"DBLP":"journals/corr/abs-2302-04761","ArXiv":"2302.04761","DOI":"10.48550/arXiv.2302.04761","CorpusId":256697342},"title":"Toolformer: Language Models Can Teach Themselves to Use Tools"},{"paperId":"5a3c1afe73d8bcc8288d17cb17be2baec8a98464","externalIds":{"ArXiv":"2212.03533","DBLP":"journals/corr/abs-2212-03533","CorpusId":254366618},"title":"Text Embeddings by Weakly-Supervised Contrastive Pre-training"},{"paperId":"8bb37e8ae7dd6fa8cab2407f63a61f697152717f","externalIds":{"ArXiv":"2210.14709","DBLP":"journals/corr/abs-2210-14709","DOI":"10.48550/arXiv.2210.14709","CorpusId":253117079},"title":"Learning on Large-scale Text-attributed Graphs via Variational Inference"},{"paperId":"cdbd4f9b6ab2e2fd1ddf5400d5ed2c18960635d1","externalIds":{"DBLP":"journals/corr/abs-2210-11416","ArXiv":"2210.11416","DOI":"10.48550/arXiv.2210.11416","CorpusId":253018554},"title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"ad3dfb2514cb0c899fcb9a14d229ff2a6018892f","externalIds":{"DBLP":"conf/nips/YasunagaBR0MLL22","ArXiv":"2210.09338","DOI":"10.48550/arXiv.2210.09338","CorpusId":252968266},"title":"Deep Bidirectional Language-Knowledge Graph Pretraining"},{"paperId":"88a74e972898de887ad9587d4c87c3a9f03f1dc5","externalIds":{"ACL":"2023.eacl-main.148","DBLP":"conf/eacl/MuennighoffTMR23","ArXiv":"2210.07316","DOI":"10.18653/v1/2023.eacl-main.148","CorpusId":252907685},"title":"MTEB: Massive Text Embedding Benchmark"},{"paperId":"90350aa626bed47b02d0c162462e5b0ca82be6b2","externalIds":{"DBLP":"journals/corr/abs-2210-03493","ArXiv":"2210.03493","CorpusId":252762275},"title":"Automatic Chain of Thought Prompting in Large Language Models"},{"paperId":"7c9f7eba74fd249d159b9869308d4c72a727c312","externalIds":{"ArXiv":"2209.09338","DBLP":"journals/corr/abs-2209-09338","DOI":"10.48550/arXiv.2209.09338","CorpusId":252383371},"title":"Revisiting Embeddings for Graph Neural Networks"},{"paperId":"fcad4cdc3d1c791494068007366193d28ef23483","externalIds":{"DBLP":"conf/sigir/LiLCW22","DOI":"10.1145/3477495.3531968","CorpusId":249364232},"title":"Distilling Knowledge on Text Graph for Social Media Attribute Inference"},{"paperId":"f7a3d9bcf052f2b4ef7d59dcca4013ea11081d0f","externalIds":{"DBLP":"conf/nips/DwivediRGPWLB22","ArXiv":"2206.08164","DOI":"10.48550/arXiv.2206.08164","CorpusId":249712241},"title":"Long Range Graph Benchmark"},{"paperId":"66d4efb99b1b9e98e0ae067e258089e58f0e039f","externalIds":{"DBLP":"journals/corr/abs-2206-08452","ArXiv":"2206.08452","DOI":"10.48550/arXiv.2206.08452","CorpusId":249847912},"title":"GOOD: A Graph Out-of-Distribution Benchmark"},{"paperId":"d48b29889241551e1ee6622fa78c3fa4159255dd","externalIds":{"ArXiv":"2205.09712","DBLP":"journals/corr/abs-2205-09712","CorpusId":248887351},"title":"Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning"},{"paperId":"a83cdcc0135c58fddf89fc72f1b92b7a9d1e170f","externalIds":{"ArXiv":"2203.15827","ACL":"2022.acl-long.551","DBLP":"journals/corr/abs-2203-15827","DOI":"10.48550/arXiv.2203.15827","CorpusId":247793456},"title":"LinkBERT: Pretraining Language Models with Document Links"},{"paperId":"2a3349c9f48b322400cd1d2d720fc42a42d19d5f","externalIds":{"ArXiv":"2202.07987","DBLP":"journals/pami/LiWZZ25","DOI":"10.1109/TPAMI.2025.3593897","CorpusId":246867220,"PubMed":"40742861"},"title":"Out-of-Distribution Generalization on Graphs: A Survey"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"1c97736423f5ad51f093fb044b47608533590eeb","externalIds":{"DBLP":"journals/corr/abs-2201-11349","ArXiv":"2201.11349","DOI":"10.1145/3485447.3512172","CorpusId":246294963},"title":"Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift"},{"paperId":"6d7d4fca9840504f630e9bea6acaa07322a6e889","externalIds":{"ArXiv":"2201.10005","DBLP":"journals/corr/abs-2201-10005","CorpusId":246275593},"title":"Text and Code Embeddings by Contrastive Pre-Training"},{"paperId":"6f6c8b411dfe78af7b85df9510a1e25535ce950b","externalIds":{"ArXiv":"2201.07951","DBLP":"journals/corr/abs-2201-07951","DOI":"10.1007/s10618-022-00879-4","CorpusId":246063495},"title":"Informative pseudo-labeling for graph neural networks with few labels"},{"paperId":"002c58077a1f1b296468b117230a1199e91f35c2","externalIds":{"ArXiv":"2201.03514","DBLP":"conf/icml/SunSQHQ22","CorpusId":245836882},"title":"Black-Box Tuning for Language-Model-as-a-Service"},{"paperId":"259cbc1492c51d985bdafb67e48fa170471ee446","externalIds":{"DBLP":"conf/iclr/ChienCHYZMD22","ArXiv":"2111.00064","CorpusId":240354406},"title":"Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction"},{"paperId":"ff0b2681d7b05e16c46dfb71d980cc2f605907cd","externalIds":{"DBLP":"journals/corr/abs-2109-01652","ArXiv":"2109.01652","CorpusId":237416585},"title":"Finetuned Language Models Are Zero-Shot Learners"},{"paperId":"700198bc1c52ebe86499c9647ff0f55bdad17a54","externalIds":{"DOI":"10.1017/9781108924184","CorpusId":260500147},"title":"Deep Learning on Graphs"},{"paperId":"cf30fb61a5943781144c8442563e3ef9c38df871","externalIds":{"DBLP":"conf/icml/Li0GK21","ArXiv":"2106.07476","CorpusId":235421912},"title":"Training Graph Neural Networks with 1000 Layers"},{"paperId":"a8c61aba48df8f54abd9d4616aaaa824fdc0c85b","externalIds":{"ArXiv":"2106.04714","DBLP":"conf/kdd/Dai0W21","DOI":"10.1145/3447548.3467364","CorpusId":235377152},"title":"NRGNN: Learning a Label Noise Resistant Graph Neural Network on Sparsely and Noisily Labeled Graphs"},{"paperId":"bf713a9595edc9f8c4d240a08f2b5b01efbf1eb2","externalIds":{"ArXiv":"2105.02605","DBLP":"conf/nips/YangLXLLASSX21","CorpusId":238227259},"title":"GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph"},{"paperId":"1b0896532d5f849b44f80add46a81396201cb301","externalIds":{"DBLP":"journals/pr/SunHGCLY25","ArXiv":"2104.09376","DOI":"10.1016/j.patcog.2024.111210","CorpusId":233297091},"title":"Scalable and Adaptive Graph Neural Networks with Self-Label-Enhanced training"},{"paperId":"57fbaf35321b2c4c4c0cc2b63e72bfb9c5d5d9c9","externalIds":{"DBLP":"journals/tai/00010YAWP021","ArXiv":"2105.00696","DOI":"10.1109/TAI.2021.3076021","CorpusId":233481068},"title":"Graph Learning: A Survey"},{"paperId":"06635ebccbc4c13998aea284df9b3a08f0e14821","externalIds":{"DBLP":"conf/www/ZhuCLSLPYZZZ21","ArXiv":"2101.06323","DOI":"10.1145/3442381.3449842","CorpusId":231632747},"title":"TextGNN: Improving Text Encoder via Graph Neural Network in Sponsored Search"},{"paperId":"9b1933038680b13c06b60dfe810e96a3a0ef9d37","externalIds":{"ACL":"2020.repl4nlp-1.15","DBLP":"conf/rep4nlp/MiaschiD20","MAG":"3037458976","DOI":"10.18653/v1/2020.repl4nlp-1.15","CorpusId":220273459},"title":"Contextual and Non-Contextual Word Embeddings: an in-depth Linguistic Investigation"},{"paperId":"04faf433934486c41d082e8d75ccfe5dc2f69fef","externalIds":{"DBLP":"conf/kdd/HuDWCS20","MAG":"3037208489","ArXiv":"2006.15437","DOI":"10.1145/3394486.3403237","CorpusId":220250007},"title":"GPT-GNN: Generative Pre-Training of Graph Neural Networks"},{"paperId":"21e33bd0ad95ee1f79d8b778e693fd316cbb72d4","externalIds":{"MAG":"3093814892","DBLP":"conf/nips/ZhuYZHAK20","CorpusId":225062001},"title":"Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs"},{"paperId":"14b65a86c82e38fce0eb3506e0d4084ad5cdb583","externalIds":{"MAG":"3033187248","DBLP":"conf/iclr/HeLGC21","ArXiv":"2006.03654","CorpusId":219531210},"title":"DeBERTa: Decoding-enhanced BERT with Disentangled Attention"},{"paperId":"597bd2e45427563cdf025e53a3239006aa364cfc","externalIds":{"MAG":"3021975806","ArXiv":"2005.00687","DBLP":"journals/corr/abs-2005-00687","CorpusId":218487328},"title":"Open Graph Benchmark: Datasets for Machine Learning on Graphs"},{"paperId":"3bcb17559ce96eb20fa79af8194f4af0380d194a","externalIds":{"DBLP":"journals/corr/abs-2003-08271","MAG":"3088409176","ArXiv":"2003.08271","DOI":"10.1007/s11431-020-1647-3","CorpusId":212747830},"title":"Pre-trained models for natural language processing: A survey"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"9eda533cf0badf8dbed5c8240bb828b622328183","externalIds":{"ArXiv":"1910.09796","ACL":"2020.acl-main.655","DBLP":"conf/acl/LiuXSL20","MAG":"3016482365","DOI":"10.18653/v1/2020.acl-main.655","CorpusId":215828553},"title":"Fine-grained Fact Verification with Kernel Graph Attention Network"},{"paperId":"c95383f251a62c63217586059c67f63507c3e839","externalIds":{"MAG":"2980282514","ArXiv":"1910.03771","DBLP":"journals/corr/abs-1910-03771","CorpusId":282907399},"title":"HuggingFace's Transformers: State-of-the-art Natural Language Processing"},{"paperId":"e315dde93295b6f0baff0dc39dbd319a7924a0cd","externalIds":{"DBLP":"journals/corr/abs-1910-07567","ArXiv":"1910.07567","MAG":"2981275410","CorpusId":204743739},"title":"Active Learning for Graph Neural Networks via Node Feature Propagation"},{"paperId":"06a73ad09664435f8b3cd90293f4e05a047cf375","externalIds":{"MAG":"2998385486","DBLP":"journals/corr/abs-1909-07606","ArXiv":"1909.07606","DOI":"10.1609/AAAI.V34I03.5681","CorpusId":202583325},"title":"K-BERT: Enabling Language Representation with Knowledge Graph"},{"paperId":"fd075bcdf2d7e13d23f7c249a8eded343d5bbe3b","externalIds":{"DBLP":"journals/corr/abs-1909-01315","ArXiv":"1909.01315","MAG":"2971933740","CorpusId":202539732},"title":"Deep Graph Library: Towards Efficient and Scalable Deep Learning on Graphs"},{"paperId":"9d7902e834d5d1d35179962c7a5b9d16623b0d39","externalIds":{"ArXiv":"1909.00512","MAG":"2971569798","DBLP":"journals/corr/abs-1909-00512","ACL":"D19-1006","DOI":"10.18653/v1/D19-1006","CorpusId":202120592},"title":"How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings"},{"paperId":"99fb7f7bc8fbb3fc1eea7f69ad2565ddfb68f847","externalIds":{"DOI":"10.4324/9780429287091-11","CorpusId":261398557},"title":"Key Insights"},{"paperId":"d0086b86103a620a86bc918746df0aa642e2a8a3","externalIds":{"DBLP":"journals/corr/abs-1909-01066","MAG":"2996758945","ArXiv":"1909.01066","ACL":"D19-1250","DOI":"10.18653/v1/D19-1250","CorpusId":202539551},"title":"Language Models as Knowledge Bases?"},{"paperId":"93d63ec754f29fa22572615320afe0521f7ec66d","externalIds":{"DBLP":"journals/corr/abs-1908-10084","MAG":"2970641574","ArXiv":"1908.10084","ACL":"D19-1410","DOI":"10.18653/v1/D19-1410","CorpusId":201646309},"title":"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"},{"paperId":"05c4eb154ad9512a69569c18d68bc4428ee8bb83","externalIds":{"DBLP":"conf/kdd/ChiangLSLBH19","MAG":"2963468055","ArXiv":"1905.07953","DOI":"10.1145/3292500.3330925","CorpusId":159042192},"title":"Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks"},{"paperId":"031e4e43aaffd7a479738dcea69a2d5be7957aa3","externalIds":{"DBLP":"journals/corr/abs-1904-09223","MAG":"2938830017","ArXiv":"1904.09223","CorpusId":125977708},"title":"ERNIE: Enhanced Representation through Knowledge Integration"},{"paperId":"63a513832f56addb67be81a2fa399b233f3030fc","externalIds":{"MAG":"2918342466","DBLP":"journals/corr/abs-1903-02428","ArXiv":"1903.02428","CorpusId":70349949},"title":"Fast Graph Representation Learning with PyTorch Geometric"},{"paperId":"6017e81c5ede6c38b306a3df9738aeb04baa7619","externalIds":{"MAG":"2962946486","DBLP":"conf/aaai/YaoM019","ArXiv":"1809.05679","DOI":"10.1609/aaai.v33i01.33017370","CorpusId":52284222},"title":"Graph Convolutional Networks for Text Classification"},{"paperId":"33998aff64ce51df8dee45989cdca4b6b1329ec4","externalIds":{"DBLP":"journals/corr/abs-1710-10903","ArXiv":"1710.10903","MAG":"2766453196","DOI":"10.17863/CAM.48429","CorpusId":3292002},"title":"Graph Attention Networks"},{"paperId":"6b7d6e6416343b2a122f8416e69059ce919026ef","externalIds":{"DBLP":"conf/nips/HamiltonYL17","MAG":"2952779545","ArXiv":"1706.02216","CorpusId":4755450},"title":"Inductive Representation Learning on Large Graphs"},{"paperId":"e24cdf73b3e7e590c2fe5ecac9ae8aa983801367","externalIds":{"MAG":"2952254971","DBLP":"journals/corr/GilmerSRVD17","ArXiv":"1704.01212","CorpusId":9665943},"title":"Neural Message Passing for Quantum Chemistry"},{"paperId":"36eff562f65125511b5dfab68ce7f7a943c27478","externalIds":{"ArXiv":"1609.02907","MAG":"2519887557","DBLP":"journals/corr/KipfW16","CorpusId":3144218},"title":"Semi-Supervised Classification with Graph Convolutional Networks"},{"paperId":"3d846cb01f6a975554035d2210b578ca61344b22","externalIds":{"MAG":"2315403234","ArXiv":"1603.08861","DBLP":"journals/corr/YangCS16","CorpusId":7008752},"title":"Revisiting Semi-Supervised Learning with Graph Embeddings"},{"paperId":"c5eab720b91bdf406b9490a578a8fe1e3c90e292","externalIds":{"MAG":"1724071807","DBLP":"journals/corr/RoughanT15","ArXiv":"1503.02781","CorpusId":341087},"title":"Unravelling Graph-Exchange File Formats"},{"paperId":"f6b51c8753a871dc94ff32152c00c01e94f90f09","externalIds":{"MAG":"2950577311","DBLP":"journals/corr/abs-1301-3781","ArXiv":"1301.3781","CorpusId":5959482},"title":"Efficient Estimation of Word Representations in Vector Space"},{"paperId":"43d2ed5c3c55c1100450cd74dc1031afa24d37b2","externalIds":{"MAG":"2403788960","DBLP":"journals/aim/SenNBGGE08","DOI":"10.1201/b17320-16","CorpusId":62016134},"title":"Collective Classification in Network Data"},{"paperId":"04f4085c0126ba29453a582cd1e62e05c8e15c82","externalIds":{"MAG":"2162630660","DBLP":"journals/ir/McCallumNRS00","DOI":"10.1023/A:1009953814988","CorpusId":349242},"title":"Automating the Construction of Internet Portals with Machine Learning"},{"paperId":"592462425a4d23547dd0f3c9318350e5dcceb1a6","externalIds":{"MAG":"2168190036","DBLP":"conf/dl/GilesBL98","DOI":"10.1145/276675.276685","CorpusId":514080},"title":"CiteSeer: an automatic citation indexing system"},{"paperId":"933802cd80c2249f887a433825a5eae3e66cd7e3","externalIds":{"DBLP":"conf/coling/SubediRBA24","ACL":"2024.lrec-main.611","CorpusId":269804734},"title":"Exploring the Potential of Large Language Models (LLMs) for Low-resource Languages: A Study on Named-Entity Recognition (NER) and Part-Of-Speech (POS) Tagging for Nepali Language"},{"paperId":"f01281b125128435ad134230c6a41cc55808eaac","externalIds":{"DBLP":"journals/corr/abs-2309-16595","DOI":"10.48550/arXiv.2309.16595","CorpusId":263135565},"title":"Can LLMs Effectively Leverage Graph Structural Information: When and Why"},{"paperId":"0b8265a63570d08d8d84aeacbec5495611ae3312","externalIds":{"DBLP":"journals/corr/abs-2310-01436","DOI":"10.48550/arXiv.2310.01436","CorpusId":263608402},"title":"Graph Neural Architecture Search with GPT-4"},{"paperId":"0e87f4c721c2a5302e9cf7e2b3a6ceacfaceb469","externalIds":{"DBLP":"journals/corr/abs-2310-17110","DOI":"10.48550/arXiv.2310.17110","CorpusId":271710643},"title":"LLM4DyG: Can Large Language Models Solve Problems on Dynamic Graphs?"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"0c0a778e6fdf7e36b1750c533dcc916f86608607","externalIds":{"MAG":"2527310337","DBLP":"journals/tkde/XunJGZ17","DOI":"10.1109/TKDE.2016.2614508","CorpusId":13490401},"title":"A Survey on Context Learning"},{"paperId":"b6b26564df790262abbe48fa18079d9610189b29","externalIds":{"MAG":"2527566079","CorpusId":18305366},"title":"Collective Classi!cation in Network Data"},{"paperId":"decd9bc0385612bdf936928206d83730718e737e","externalIds":{"MAG":"2882319491","DOI":"10.1007/978-94-017-6059-1_36","CorpusId":86680084},"title":"Distributional Structure"}]}