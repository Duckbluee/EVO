{"abstract":"Data augmentation has been proven effective which, by preventing overfitting, not only enhances the performance of a deep neural network but also leads to a better generalization even with limited dataset. Recently introduced regional dropout based data augmentation strategies remove (or replace) some parts of an input image with a desideratum to make the network focus on less discriminative portions of an image, which results in an improved performance. However, such approaches usually possess’ strong-edge’ problem caused by an obvious change in the pixels at the positions where the image is manipulated. It may not only impact on the local convolution operation but can also provide clues for the network to latch on to, which do not align well with the fundamental philosophy of augmentation. In order to minimize such peculiarities, we introduce Smoothmix in which blending of images is done based on soft edges and the training labels are computed accordingly. Extensive analysis performed on CIFAR-10, CIFAR- 100 and ImageNet for image classification demonstrates state-of-the-art results. Furthermore, Smoothmix significantly increases the robustness of a network against image corruption which is validated by the experiments carried out on CIFAR-100-C & ImageNet-C corruption datasets."}