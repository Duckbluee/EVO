{"references":[{"paperId":"99fc800f20fbdc7bbb70cc5dbd456959338ce7b8","externalIds":{"ArXiv":"2304.01565","DBLP":"journals/corr/abs-2304-01565","DOI":"10.13140/RG.2.2.26493.64480","CorpusId":257921356},"title":"A Survey on Graph Diffusion Models: Generative AI in Science for Molecule, Protein and Material"},{"paperId":"4de290467d903b9977e31b3d4084006789bd6ebd","externalIds":{"ArXiv":"2304.06488","DBLP":"journals/corr/abs-2304-06488","CorpusId":258108139},"title":"One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era"},{"paperId":"1b492746ee3a304a13950cad1a59861b9ee44645","externalIds":{"ArXiv":"2303.11717","DBLP":"journals/corr/abs-2303-11717","DOI":"10.48550/arXiv.2303.11717","CorpusId":257636561},"title":"A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?"},{"paperId":"35ccd924de9e8483bdcf144cbf2edf09be157b7e","externalIds":{"ArXiv":"2303.07909","DBLP":"journals/corr/abs-2303-07909","DOI":"10.48550/arXiv.2303.07909","CorpusId":257505012},"title":"Text-to-image Diffusion Models in Generative AI: A Survey"},{"paperId":"b8aac9e0a0e9afb6d41dfdf912d36de04f3a0d50","externalIds":{"DBLP":"conf/icassp/KangMH23","ArXiv":"2211.09383","DOI":"10.1109/ICASSP49357.2023.10095515","CorpusId":253581601},"title":"Grad-StyleSpeech: Any-Speaker Adaptive Text-to-Speech Synthesis with Diffusion Models"},{"paperId":"2be299b3b36195cb11dfc4f482807d84aa580581","externalIds":{"DBLP":"conf/icassp/GuoDCY23","ArXiv":"2211.09496","DOI":"10.1109/ICASSP49357.2023.10095621","CorpusId":253581264},"title":"Emodiff: Intensity Controllable Emotional Text-to-Speech with Soft-Label Guidance"},{"paperId":"98b594130d60af9163b2d2214cda262ddb988884","externalIds":{"DBLP":"journals/corr/abs-2211-04124","ArXiv":"2211.04124","DOI":"10.1109/ICASSP49357.2023.10095761","CorpusId":253397728},"title":"Unsupervised Vocal Dereverberation with Diffusion-Based Generative Models"},{"paperId":"c29d2e98fda1bf772139da11814e313836df3704","externalIds":{"DBLP":"journals/corr/abs-2211-02448","ArXiv":"2211.02448","DOI":"10.48550/arXiv.2211.02448","CorpusId":253370556},"title":"NoreSpeech: Knowledge Distillation based Conditional Diffusion Model for Noise-robust Expressive TTS"},{"paperId":"d1ddebb53da0997f88022520e81428dc72cc4fc0","externalIds":{"DBLP":"journals/corr/abs-2211-02527","ArXiv":"2211.02527","DOI":"10.1109/ICASSP49357.2023.10096064","CorpusId":253370620},"title":"Cold Diffusion for Speech Enhancement"},{"paperId":"b46a6b7068641dd90861b5c966c1e54ce43f6214","externalIds":{"DBLP":"journals/corr/abs-2210-17327","ArXiv":"2210.17327","DOI":"10.1109/ICASSP49357.2023.10095310","CorpusId":253237604},"title":"Diffusion-Based Generative Speech Source Separation"},{"paperId":"404b5431b71d4a1b0cd8cc509717e0dfc136ffb6","externalIds":{"DBLP":"journals/corr/abs-2210-15793","ArXiv":"2210.15793","DOI":"10.1109/ICASSP49357.2023.10095103","CorpusId":253224101},"title":"Conditioning and Sampling in Variational Diffusion Models for Speech Super-Resolution"},{"paperId":"53e3b4ed1ed6a4038f74b55dea9245bb9dffff87","externalIds":{"DBLP":"journals/corr/abs-2210-17287","ArXiv":"2210.17287","DOI":"10.21437/Interspeech.2023-1547","CorpusId":253237831},"title":"A Versatile Diffusion-based Generative Refiner for Speech Enhancement"},{"paperId":"0b4a66789722834b0bc05e2328d42e8a9bdeb5e8","externalIds":{"DBLP":"journals/corr/abs-2210-15228","ArXiv":"2210.15228","DOI":"10.1109/ICASSP49357.2023.10095637","CorpusId":253157756},"title":"Solving Audio Inverse Problems with a Diffusion Model"},{"paperId":"cad6acbf6c8dc6a7a6ab5f28da175f28d6df25ee","externalIds":{"DBLP":"journals/corr/abs-2210-14661","ArXiv":"2210.14661","DOI":"10.1109/ICASSP49357.2023.10096760","CorpusId":253116859},"title":"Full-Band General Audio Synthesis with Score-Based Diffusion"},{"paperId":"1620c9a484bf826fa33fd22d7bc35760a69467b8","externalIds":{"ArXiv":"2210.01029","DBLP":"journals/corr/abs-2210-01029","DOI":"10.1109/SLT54892.2023.10022496","CorpusId":252683578},"title":"Wavefit: an Iterative and Non-Autoregressive Neural Vocoder Based on Fixed-Point Iteration"},{"paperId":"2fdb7fd4192c66f40db54196e2f7ed2f1626a45d","externalIds":{"DBLP":"journals/dsp/ShiW22","DOI":"10.2139/ssrn.4164569","CorpusId":250638255},"title":"ITÔN: End-to-end audio generation with Itô stochastic differential equations"},{"paperId":"525f459f369032e2f2fa3eb1d60da34ab99191bc","externalIds":{"ArXiv":"2208.09392","DBLP":"journals/corr/abs-2208-09392","DOI":"10.48550/arXiv.2208.09392","CorpusId":251710469},"title":"Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise"},{"paperId":"a6f6fef883b0d21eb095caf80b5f61eadec873ef","externalIds":{"DBLP":"journals/corr/abs-2208-05830","ArXiv":"2208.05830","DOI":"10.1109/TASLP.2023.3285241","CorpusId":251492930},"title":"Speech Enhancement and Dereverberation With Diffusion-Based Generative Models"},{"paperId":"c036f75da24ba64a583e0b6d41c5b792347bffa6","externalIds":{"ArXiv":"2207.09983","DBLP":"journals/taslp/YangYWWWZY23","DOI":"10.1109/TASLP.2023.3268730","CorpusId":250698823},"title":"Diffsound: Discrete Diffusion Model for Text-to-Sound Generation"},{"paperId":"6fc1c18418a74b4ed46e00ee5f70e46c8ddc8460","externalIds":{"DBLP":"conf/mm/HuangZLLC022","ArXiv":"2207.06389","DOI":"10.1145/3503161.3547855","CorpusId":250492984},"title":"ProDiff: Progressive Fast Diffusion Model for High-Quality Text-to-Speech"},{"paperId":"5a5d18ca3cb00c4588af37e63f68b495928c59de","externalIds":{"DBLP":"conf/interspeech/HanL22","ArXiv":"2206.08545","DOI":"10.21437/Interspeech.2022-45","CorpusId":249848154},"title":"NU-Wave 2: A General Neural Audio Upsampling Model for Various Sampling Rates"},{"paperId":"5ac33341b4c6e0dfe30a130194ed14274c7eed6a","externalIds":{"ArXiv":"2206.03065","DBLP":"journals/corr/abs-2206-03065","DOI":"10.48550/arXiv.2206.03065","CorpusId":249431566},"title":"Universal Speech Enhancement with Score-based Diffusion"},{"paperId":"e806518c6eac26e978e10d358e717033022d514d","externalIds":{"ArXiv":"2206.02246","DBLP":"conf/interspeech/LevkovitchNW22","DOI":"10.48550/arXiv.2206.02246","CorpusId":249394915},"title":"Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models"},{"paperId":"764c9b5da16278cbbb903743b6dc110d2ad4a5e5","externalIds":{"ArXiv":"2205.15370","DBLP":"journals/corr/abs-2205-15370","DOI":"10.48550/arXiv.2205.15370","CorpusId":249209915},"title":"Guided-TTS 2: A Diffusion Model for High-quality Adaptive Text-to-Speech with Untranscribed Data"},{"paperId":"8a9e7f0663109f7f890583bd12604adfa6ebbd89","externalIds":{"ArXiv":"2205.07211","DBLP":"journals/corr/abs-2205-07211","DOI":"10.48550/arXiv.2205.07211","CorpusId":248811428},"title":"GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech Synthesis"},{"paperId":"59a1daf15ec80eb98f2a1fd29497021e6629f969","externalIds":{"DBLP":"conf/ijcai/HuangL0S00Z22","ArXiv":"2204.09934","DOI":"10.48550/arXiv.2204.09934","CorpusId":248300058},"title":"FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis"},{"paperId":"ebf62718b2e86dda0e0bfaaad5774663c66c6512","externalIds":{"DBLP":"journals/corr/abs-2203-17004","ArXiv":"2203.17004","DOI":"10.48550/arXiv.2203.17004","CorpusId":247839443},"title":"Speech Enhancement with Score-Based Generative Models in the Complex STFT Domain"},{"paperId":"3990b97b9cdb46ecb0cd2d62394865d58b223675","externalIds":{"DBLP":"journals/corr/abs-2203-16749","ArXiv":"2203.16749","DOI":"10.48550/arXiv.2203.16749","CorpusId":247839544},"title":"SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with Adaptive Noise Spectral Shaping"},{"paperId":"2f67789df52a9747a64cdcd545640efd19ff199f","externalIds":{"DBLP":"conf/iclr/Lam00022","ArXiv":"2203.13508","DOI":"10.48550/arXiv.2203.13508","CorpusId":247748837},"title":"BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis"},{"paperId":"1641774b55a471a23eb31b722ee05c2e032fec7a","externalIds":{"PubMedCentral":"10606505","DBLP":"journals/corr/abs-2203-09481","ArXiv":"2203.09481","DOI":"10.3390/e25101469","CorpusId":247519223,"PubMed":"37895590"},"title":"Diffusion Probabilistic Modeling for Video Generation"},{"paperId":"5c333f11431d1f0d04ced62b712c8d05ebac0891","externalIds":{"DBLP":"journals/corr/abs-2202-05256","ArXiv":"2202.05256","DOI":"10.1109/ICASSP43922.2022.9746901","CorpusId":246706245},"title":"Conditional Diffusion Probabilistic Model for Speech Enhancement"},{"paperId":"84f65cfb597d574ee09cb84731181cfeeeac78cd","externalIds":{"DBLP":"journals/corr/abs-2202-03751","ArXiv":"2202.03751","DOI":"10.1109/icassp43922.2022.9746690","CorpusId":246652275},"title":"Infergrad: Improving Diffusion Models for Vocoder by Considering Inference in Training"},{"paperId":"4980a95f1b4010b40168e5abddf2d72563b545e5","externalIds":{"DBLP":"journals/corr/abs-2201-12519","ArXiv":"2201.12519","DOI":"10.1109/ICASSP43922.2022.9746153","CorpusId":246430656},"title":"ItôWave: Itô Stochastic Differential Equation is all You Need for Wave Generation"},{"paperId":"098bbff093da93e7838c9faf5936ccb6562cf2a1","externalIds":{"DBLP":"journals/corr/abs-2201-11972","ArXiv":"2201.11972","CorpusId":246411236},"title":"DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising Diffusion GANs"},{"paperId":"3d3c5fcbc40aadccceda58d3d9c5cd00588ea0b7","externalIds":{"ArXiv":"2201.11793","DBLP":"journals/corr/abs-2201-11793","CorpusId":246411364},"title":"Denoising Diffusion Restoration Models"},{"paperId":"4f73a26f7c2c942d7f1b8267e1307d6f5207613b","externalIds":{"DBLP":"journals/corr/abs-2112-07804","ArXiv":"2112.07804","CorpusId":245144350},"title":"Tackling the Generative Learning Trilemma with Denoising Diffusion GANs"},{"paperId":"ea287d88039f126e33eb381c3ab1019c26f290b0","externalIds":{"DBLP":"journals/corr/abs-2110-14513","ArXiv":"2110.14513","CorpusId":239998228},"title":"Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations"},{"paperId":"0846486dab7d663bc71e1d8bb63bf5497756e79b","externalIds":{"DBLP":"journals/corr/abs-2110-13492","ArXiv":"2110.13492","DOI":"10.1109/ICASSP43922.2022.9747699","CorpusId":239885368},"title":"Tunet: A Block-Online Bandwidth Extension Model Based On Transformers And Self-Supervised Pretraining"},{"paperId":"deaa2b587f0946b5c50f83f6accd2d10ff70dce5","externalIds":{"DBLP":"journals/corr/abs-2110-08791","ArXiv":"2110.08791","DOI":"10.5244/c.35.336","CorpusId":239015904},"title":"Taming Visually Guided Sound Generation"},{"paperId":"4f0360bff75b2664d051ee9635a6c68df6147f36","externalIds":{"DBLP":"journals/corr/abs-2110-05948","ArXiv":"2110.05948","CorpusId":238634398},"title":"Denoising Diffusion Gamma Models"},{"paperId":"8aca925fe0253eb156cee794733386b5e099c362","externalIds":{"DBLP":"journals/corr/abs-2109-13731","ArXiv":"2109.13731","CorpusId":238198604},"title":"VoiceFixer: Toward General Speech Restoration With Neural Vocoder"},{"paperId":"cda3fbbac6734b603bee363b0938e9baa924aa78","externalIds":{"DBLP":"journals/corr/abs-2108-02938","ArXiv":"2108.02938","DOI":"10.1109/iccv48922.2021.01410","CorpusId":236950721},"title":"ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models"},{"paperId":"553b74de8cb7ebca42a686e2a3a2d6aae170946e","externalIds":{"ArXiv":"2107.11876","DBLP":"journals/corr/abs-2107-11876","CorpusId":236428748},"title":"A Study on Speech Enhancement Based on Diffusion Probabilistic Model"},{"paperId":"6fe50c4b326791d87a1841dd1cf5c9dba7f110a7","externalIds":{"ArXiv":"2107.09998","DBLP":"conf/mlsp/LiuIZHPW21","DOI":"10.1109/mlsp52302.2021.9596430","CorpusId":236155228},"title":"Conditional Sound Generation Using Neural Discrete Time-Frequency Representation Learning"},{"paperId":"4384ff4ac7459d3045ff660b1772c975512701d9","externalIds":{"DBLP":"journals/corr/abs-2106-15561","ArXiv":"2106.15561","CorpusId":235669930},"title":"A Survey on Neural Speech Synthesis"},{"paperId":"10ae9a3d1e0874a50820766bd414f98e095cdd8a","externalIds":{"DBLP":"conf/interspeech/ChenZZW0DC21","ArXiv":"2106.09660","DOI":"10.21437/interspeech.2021-1897","CorpusId":235458124},"title":"WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis"},{"paperId":"93667328d7f9998523f4a0b01ab6f72dea947612","externalIds":{"DBLP":"conf/ismir/RouardH21","ArXiv":"2106.07431","CorpusId":235422338},"title":"CRASH: Raw Audio Score-based Generative Modeling for Controllable High-resolution Drum Sound Synthesis"},{"paperId":"3077c2c6dade199a47b9c833401c614619e89352","externalIds":{"DBLP":"journals/corr/abs-2106-09008","ArXiv":"2106.09008","DOI":"10.1109/ICASSP39728.2021.9413999","CorpusId":235446507},"title":"A Flow-Based Neural Network for Time Domain Speech Enhancement"},{"paperId":"f364cac32b51c00a0a9729377609f5a4494009f5","externalIds":{"DBLP":"journals/corr/abs-2105-13871","ArXiv":"2105.13871","DOI":"10.1109/ASRU51503.2021.9688219","CorpusId":235248446},"title":"DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion"},{"paperId":"2e32cde6e080f990873638f2e113767a6a19c824","externalIds":{"DBLP":"journals/corr/abs-2105-06337","ArXiv":"2105.06337","CorpusId":234483016},"title":"Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech"},{"paperId":"28db8fd711ac13599c9921db08cd586235d303ba","externalIds":{"DBLP":"journals/corr/abs-2104-11347","ArXiv":"2104.11347","DOI":"10.21437/Interspeech.2021-1889","CorpusId":233387825},"title":"Restoring degraded speech via a modified diffusion model"},{"paperId":"89cc5d8b9c1579d5a5ba905cfc95c907428a7eb4","externalIds":{"DBLP":"journals/corr/abs-2104-02321","ArXiv":"2104.02321","DOI":"10.21437/Interspeech.2021-36","CorpusId":233033417},"title":"NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling"},{"paperId":"844cd260a3ca9de92fa1217c146d8cda2e0c10c0","externalIds":{"ArXiv":"2104.01409","DBLP":"journals/corr/abs-2104-01409","DOI":"10.21437/interspeech.2021-469","CorpusId":233025015},"title":"Diff-TTS: A Denoising Diffusion Model for Text-to-Speech"},{"paperId":"99e1e76d763637e4e140a8bbf0b857e425e80565","externalIds":{"DBLP":"conf/icml/MiaoLLCMWX21","MAG":"3112470437","ArXiv":"2012.03500","CorpusId":227337149},"title":"EfficientTTS: An Efficient and High-Quality Text-to-Speech Architecture"},{"paperId":"633e2fbfc0b21e959a244100937c5853afca4853","externalIds":{"DBLP":"journals/corr/abs-2011-13456","ArXiv":"2011.13456","MAG":"3110257065","CorpusId":227209335},"title":"Score-Based Generative Modeling through Stochastic Differential Equations"},{"paperId":"82e9fdf3dd75b39ac7205b109cfdb60eb28d8f34","externalIds":{"DBLP":"conf/icassp/WeissSBMK21","MAG":"3103702065","ArXiv":"2011.03568","DOI":"10.1109/ICASSP39728.2021.9413851","CorpusId":226282382},"title":"Wave-Tacotron: Spectrogram-Free End-to-End Text-to-Speech Synthesis"},{"paperId":"08046c1c7f97e06d39a4093ea0972892d256749a","externalIds":{"DBLP":"conf/icassp/PonsPCS21","MAG":"3097897727","ArXiv":"2010.14356","DOI":"10.1109/ICASSP39728.2021.9414913","CorpusId":225076033},"title":"Upsampling Artifacts in Neural Audio Synthesis"},{"paperId":"80ecebffc4b87c86311b6b19d767cab5c81f0aa3","externalIds":{"DBLP":"conf/interspeech/HouXPZC020","MAG":"3095078764","DOI":"10.21437/interspeech.2020-1994","CorpusId":226200496},"title":"Speaker and Phoneme-Aware Speech Bandwidth Extension with Residual Dual-Path Network"},{"paperId":"e98cb70e420148de2b6b52922dae631a6ee7ff74","externalIds":{"DBLP":"journals/corr/abs-2010-04301","MAG":"3091928890","ArXiv":"2010.04301","CorpusId":222272102},"title":"Non-Attentive Tacotron: Robust and Controllable Neural TTS Synthesis Including Unsupervised Duration Modeling"},{"paperId":"014576b866078524286802b1d0e18628520aa886","externalIds":{"ArXiv":"2010.02502","DBLP":"journals/corr/abs-2010-02502","MAG":"3092442149","CorpusId":222140788},"title":"Denoising Diffusion Implicit Models"},{"paperId":"34bf13e58c7226d615afead0c0f679432502940e","externalIds":{"MAG":"3087665158","DBLP":"conf/iclr/KongPHZC21","ArXiv":"2009.09761","CorpusId":221818900},"title":"DiffWave: A Versatile Diffusion Model for Audio Synthesis"},{"paperId":"685af6d2bcdff7170574643b2c5ab4fbcc36f597","externalIds":{"DBLP":"conf/iclr/ChenZZWNC21","MAG":"3082563516","ArXiv":"2009.00713","CorpusId":221447287},"title":"WaveGrad: Estimating Gradients for Waveform Generation"},{"paperId":"1948c2be5c24f1ea7ae473898c04231719ea40fd","externalIds":{"MAG":"3097945073","ArXiv":"2006.12847","DBLP":"conf/interspeech/DefossezSA20","DOI":"10.21437/interspeech.2020-2409","CorpusId":219981437},"title":"Real Time Speech Enhancement in the Waveform Domain"},{"paperId":"5c126ae3421f05768d8edd97ecd44b1364e2c99a","externalIds":{"DBLP":"conf/nips/HoJA20","MAG":"3100572490","ArXiv":"2006.11239","CorpusId":219955663},"title":"Denoising Diffusion Probabilistic Models"},{"paperId":"1156e277fa7ec195b043161d3c5c97715da17658","externalIds":{"DBLP":"conf/nips/0011E20","ArXiv":"2006.09011","MAG":"3035384201","CorpusId":219708245},"title":"Improved Techniques for Training Score-Based Generative Models"},{"paperId":"1623d6ffb6efd94d21537db2b96b91a196842aef","externalIds":{"DBLP":"journals/corr/abs-2006-04558","ArXiv":"2006.04558","MAG":"3033411150","CorpusId":219531522},"title":"FastSpeech 2: Fast and High-Quality End-to-End Text to Speech"},{"paperId":"c035cf0e1231eb196968d7255ab55827e932ec7a","externalIds":{"MAG":"3033913438","DBLP":"journals/corr/abs-2006-03575","ArXiv":"2006.03575","CorpusId":219401642},"title":"End-to-End Adversarial Text-to-Speech"},{"paperId":"7101bc1c316740d99cd87185586829291a983a1d","externalIds":{"ArXiv":"2003.13659","DBLP":"conf/eccv/PanZDLLL20","MAG":"3107096356","DOI":"10.1109/TPAMI.2021.3115428","CorpusId":214713474,"PubMed":"34559638"},"title":"Exploiting Deep Generative Prior for Versatile Image Restoration and Manipulation"},{"paperId":"7ad9b3ace5e2b9783100cd4205c94d7873723207","externalIds":{"DBLP":"journals/corr/abs-1912-07116","ArXiv":"1912.07116","MAG":"2995154278","DOI":"10.1109/cvpr42600.2020.00308","CorpusId":209377041},"title":"Image Processing Using Multi-Code GAN Prior"},{"paperId":"1cbb9b0fdf42701ac7a8ed28d012369e148f51a4","externalIds":{"DBLP":"journals/corr/abs-1910-10942","MAG":"2982264772","ArXiv":"1910.10942","DOI":"10.1109/ICASSP40776.2020.9053164","CorpusId":204852255},"title":"A Recurrent Variational Autoencoder for Speech Enhancement"},{"paperId":"28ae6fbe5ce2ab5ddf6955be1cff727e4c68cff6","externalIds":{"MAG":"2976159681","DOI":"10.3390/app9194050","CorpusId":204148442},"title":"A Review of Deep Learning Based Speech Synthesis"},{"paperId":"85381e0e89e98ea1ed8bd3dfa533d911263757df","externalIds":{"DBLP":"journals/corr/abs-1909-11646","MAG":"2996286887","ArXiv":"1909.11646","CorpusId":202749904},"title":"High Fidelity Speech Synthesis with Adversarial Networks"},{"paperId":"4be02149d31235b3077c12afdc0df9fbfa300a09","externalIds":{"MAG":"2972707556","DBLP":"conf/interspeech/LiCK19","DOI":"10.21437/interspeech.2019-3043","CorpusId":203156588},"title":"Speech Audio Super-Resolution for Speech Recognition"},{"paperId":"0f02bf7f468b0f9d0140d73e03bdd4a2f79c0b5c","externalIds":{"DBLP":"journals/corr/abs-1909-06628","MAG":"2972745527","ArXiv":"1909.06628","CorpusId":202577873},"title":"Temporal FiLM: Capturing Long-Range Sequence Dependencies with Feature-Wise Modulations"},{"paperId":"965359b3008ab50dd04e171551220ec0e7f83aba","externalIds":{"MAG":"2971034910","ArXiv":"1907.05600","DBLP":"conf/nips/SongE19","CorpusId":196470871},"title":"Generative Modeling by Estimating Gradients of the Data Distribution"},{"paperId":"6748d363ae384b8675ade6ba2e2de75d2d215368","externalIds":{"MAG":"2989576588","DBLP":"conf/nips/SanturkarITETM19","CorpusId":199511239},"title":"Image Synthesis with a Single (Robust) Classifier"},{"paperId":"054ab6f0e392c3580a364814144babf16bd2d2dd","externalIds":{"DBLP":"journals/corr/abs-1906-01083","MAG":"2948211236","ArXiv":"1906.01083","CorpusId":174798083},"title":"MelNet: A Generative Model for Audio in the Frequency Domain"},{"paperId":"f9ad5ca6e44683fc73339eed3aafe8c0e8725c09","externalIds":{"MAG":"2949558265","DBLP":"conf/icml/FuLTL19","ArXiv":"1905.04874","CorpusId":152282808},"title":"MetricGAN: Generative Adversarial Networks based Black-box Metric Scores Optimization for Speech Enhancement"},{"paperId":"961e9a7a22bb6bf6fd2f5d181b541bb2d519dbfd","externalIds":{"MAG":"2924508610","DBLP":"journals/corr/abs-1903-09027","ArXiv":"1903.09027","CorpusId":84843583},"title":"Bandwidth Extension on Raw Audio via Generative Adversarial Networks"},{"paperId":"f8bcf521f0cab6fa0a7bb87ea96a908916a8f426","externalIds":{"MAG":"2805233667","ArXiv":"1810.09137","DBLP":"journals/corr/abs-1810-09137","DOI":"10.1109/TASLP.2018.2842156","CorpusId":49417132},"title":"DNN-Based Source Enhancement to Increase Objective Sound Quality Assessment Score"},{"paperId":"9f2dd5cc190fc713f1339fca838a5537931744f8","externalIds":{"MAG":"2951418500","DBLP":"conf/aaai/Li0LZL19","DOI":"10.1609/AAAI.V33I01.33016706","CorpusId":59413863},"title":"Neural Speech Synthesis with Transformer Network"},{"paperId":"5e3a59695261f03aa3f09a8a5ac6166fb63e0a2e","externalIds":{"MAG":"2950942634","DBLP":"conf/iclr/PingPC19","ArXiv":"1807.07281","CorpusId":49882757},"title":"ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech"},{"paperId":"db3473081fd8f61a7b539e6c60a1d2718d2a6e2c","externalIds":{"DBLP":"conf/icassp/LimYXDH18","MAG":"2802034954","DOI":"10.1109/ICASSP.2018.8462049","CorpusId":52038176},"title":"Time-Frequency Networks for Audio Super-Resolution"},{"paperId":"75c00b3f040f5bc3032af1373c88ad1203458d10","externalIds":{"MAG":"2802304149","DBLP":"conf/icassp/SoniSP18","DOI":"10.1109/ICASSP.2018.8462068","CorpusId":52287199},"title":"Time-Frequency Masking-Based Speech Enhancement Using Generative Adversarial Network"},{"paperId":"1a2599e467e855f845dcbf9282f8bdbd97b85708","externalIds":{"MAG":"2964243274","DBLP":"journals/corr/abs-1712-05884","ArXiv":"1712.05884","DOI":"10.1109/ICASSP.2018.8461368","CorpusId":206742911},"title":"Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions"},{"paperId":"f6cbf83e1ce3b099d656d2346b261d5ef7f2b62e","externalIds":{"DBLP":"conf/icml/OordLBSVKDLCSCG18","MAG":"2950362437","ArXiv":"1711.10433","CorpusId":27706557},"title":"Parallel WaveNet: Fast High-Fidelity Speech Synthesis"},{"paperId":"f466157848d1a7772fb6d02cdac9a7a5e7ef982e","externalIds":{"MAG":"2963799213","DBLP":"conf/nips/OordVK17","ArXiv":"1711.00937","CorpusId":20282961},"title":"Neural Discrete Representation Learning"},{"paperId":"852120feb37d2dc136d1c6916b52b9baabfc2e11","externalIds":{"MAG":"2766812927","DBLP":"journals/corr/abs-1710-07654","ArXiv":"1710.07654","CorpusId":26100519},"title":"Deep Voice 3: 2000-Speaker Neural Text-to-Speech"},{"paperId":"0a1e664b66aae97d2f57b45d86dd7ac152e8fd92","externalIds":{"MAG":"2951983758","DBLP":"journals/taslp/FuWTLK18","ArXiv":"1709.03658","DOI":"10.1109/TASLP.2018.2821903","CorpusId":3933870},"title":"End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks"},{"paperId":"5a5bcfda3b753f8266b9ba27d34fc86b6d374a1b","externalIds":{"MAG":"2951633912","DBLP":"conf/nips/GibianskyADMPPR17","ArXiv":"1705.08947","CorpusId":21010143},"title":"Deep Voice 2: Multi-Speaker Neural Text-to-Speech"},{"paperId":"a072c2a400f62f720b68dc54a662fb1ae115bf06","externalIds":{"DBLP":"conf/interspeech/WangSSWWJYXCBLA17","MAG":"2963609956","ArXiv":"1703.10135","DOI":"10.21437/Interspeech.2017-1452","CorpusId":4689304},"title":"Tacotron: Towards End-to-End Speech Synthesis"},{"paperId":"f8d43ff00585c53f65eb04e15477113c2d2b758b","externalIds":{"MAG":"2950527469","DBLP":"journals/corr/PascualBS17","ArXiv":"1703.09452","DOI":"10.21437/Interspeech.2017-1428","CorpusId":12054873},"title":"SEGAN: Speech Enhancement Generative Adversarial Network"},{"paperId":"5ba2218b708ca64ab556e39d5997202e012717d5","externalIds":{"MAG":"2593116425","DBLP":"conf/icassp/GemmekeEFJLMPR17","DOI":"10.1109/ICASSP.2017.7952261","CorpusId":21519176},"title":"Audio Set: An ontology and human-labeled dataset for audio events"},{"paperId":"63880b57b95de8afd73036e55b9c4bccb7a528b9","externalIds":{"MAG":"2964281804","DBLP":"conf/icml/ArikCCDGKLMNRSS17","ArXiv":"1702.07825","CorpusId":5580515},"title":"Deep Voice: Real-time Neural Text-to-Speech"},{"paperId":"3b48ee3e939c75de073ea20c6b4bfe19c8e65532","externalIds":{"DBLP":"conf/iclr/KuleshovEE17","MAG":"2739619458","ArXiv":"1708.00853","CorpusId":22090507},"title":"Audio Super Resolution using Neural Networks"},{"paperId":"9203d6c076bffe87336f2ea91f5851436c02dbe6","externalIds":{"MAG":"2901997113","DBLP":"conf/iclr/SoteloMKSKCB17","CorpusId":30919574},"title":"Char2Wav: End-to-End Speech Synthesis"},{"paperId":"4c4f026f8a0fc5e9c72825dd79677a4d205e5588","externalIds":{"MAG":"2603810172","DOI":"10.1109/ICSP.2016.7877819","CorpusId":14130123},"title":"Phone-aware LSTM-RNN for voice conversion"},{"paperId":"67cc0cfd577b6792fa3da174e6c1f7ed685b12e8","externalIds":{"ArXiv":"1610.08927","MAG":"2544164552","DBLP":"journals/corr/MobinB16","CorpusId":15873519},"title":"Voice Conversion using Convolutional Neural Networks"},{"paperId":"19fb693353cca4a172cbd64f599e4bb06572b52e","externalIds":{"MAG":"2527647428","DBLP":"conf/ssw/PascualB16","DOI":"10.21437/SSW.2016-19","CorpusId":11120082},"title":"Multi-output RNN-LSTM for multiple speaker speech synthesis with α-interpolation model"},{"paperId":"df0402517a7338ae28bc54acaac400de6b456a46","externalIds":{"MAG":"2519091744","ArXiv":"1609.03499","DBLP":"journals/corr/OordDZSVGKSK16","CorpusId":6254678},"title":"WaveNet: A Generative Model for Raw Audio"},{"paperId":"7b5122e0a88d1dd4c0e5cdf20e12fd70f287fe96","externalIds":{"MAG":"2950159827","DBLP":"journals/taslp/MagronBD18","ArXiv":"1608.01953","DOI":"10.1109/TASLP.2018.2811540","CorpusId":3559678},"title":"Model-Based STFT Phase Recovery for Audio Source Separation"},{"paperId":"5a48fed28e6224855289d4a581b22f559b3da196","externalIds":{"DBLP":"conf/icassp/ZenS15","MAG":"1576227399","DOI":"10.1109/ICASSP.2015.7178816","CorpusId":1463476},"title":"Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis"},{"paperId":"e31e48562edc5dbf7ab4da7f02ae49160c526e25","externalIds":{"DBLP":"conf/icassp/SunKLM15","MAG":"1509691205","DOI":"10.1109/ICASSP.2015.7178896","CorpusId":11992303},"title":"Voice conversion using deep Bidirectional Long Short-Term Memory based Recurrent Neural Networks"},{"paperId":"2dcef55a07f8607a819c21fe84131ea269cc2e3c","externalIds":{"MAG":"2129069237","DBLP":"journals/corr/Sohl-DicksteinW15","ArXiv":"1503.03585","CorpusId":14888175},"title":"Deep Unsupervised Learning using Nonequilibrium Thermodynamics"},{"paperId":"20969e35837d93b6e4eb52d75c8713abc6069f4a","externalIds":{"MAG":"2102003408","DBLP":"conf/icassp/ZeSS13","DOI":"10.1109/ICASSP.2013.6639215","CorpusId":16664621},"title":"Statistical parametric speech synthesis using deep neural networks"},{"paperId":"490554b93ef10f5b9ba700ad9731315227301282","externalIds":{"DBLP":"journals/pieee/TokudaNTZYO13","MAG":"2111284386","DOI":"10.1109/JPROC.2013.2251852","CorpusId":33895269},"title":"Speech Synthesis Based on Hidden Markov Models"},{"paperId":"23e568fcf0192e4ff5e6bed7507ee5b9e6c43598","externalIds":{"MAG":"2294130536","DBLP":"conf/iccv/ParikhG11","DOI":"10.1109/ICCV.2011.6126281","CorpusId":2633340},"title":"Relative attributes"},{"paperId":"da477d8e3a8101df3b042aa299e5be92bb4fbcf6","externalIds":{"MAG":"2102737569","DOI":"10.1109/WOSSPA.2011.5931414","CorpusId":18115403},"title":"Speech synthesis techniques. A survey"},{"paperId":"f6c1e423159b98b147392f8c4a4a3e20ac9f37ec","externalIds":{"MAG":"2059283177","DOI":"10.1134/S1063785010070072","CorpusId":121955706},"title":"Time-frequency analysis of acoustic signals in the audio-frequency range generated during Hadfield’s steel friction"},{"paperId":"ea91ee3e9f4cf88c2d7c32e0b162e574557588c0","externalIds":{"MAG":"2164502538","DBLP":"journals/taslp/NakataniYKMJ10","DOI":"10.1109/TASL.2010.2052251","CorpusId":16593521},"title":"Speech Dereverberation Based on Variance-Normalized Delayed Linear Prediction"},{"paperId":"e5278c61bc4765f48c09add0fc2ff2f007cd9cea","externalIds":{"MAG":"2139334285","DBLP":"journals/tifs/LiuSQ09","DOI":"10.1109/TIFS.2009.2024718","CorpusId":6051454},"title":"Temporal Derivative-Based Spectrum and Mel-Cepstrum Audio Steganalysis"},{"paperId":"317d2b6e97b878e77f8aad964575bcaadddb83cf","externalIds":{"DBLP":"journals/speech/ZenTB09","MAG":"2129142580","DOI":"10.1016/j.specom.2009.04.004","CorpusId":3232238},"title":"Statistical Parametric Speech Synthesis"},{"paperId":"58b419d664c7bf093d76d5e7c81a707070d4dfb1","externalIds":{"MAG":"1689977300","DBLP":"conf/icassp/MolauPSN01","DOI":"10.1109/ICASSP.2001.940770","CorpusId":11577259},"title":"Computing Mel-frequency cepstral coefficients on the power spectrum"},{"paperId":"3d7465338dd3a93f171786e2e858faf18b47cc51","externalIds":{"DBLP":"conf/icassp/TokudaYMKK00","MAG":"2154920538","DOI":"10.1109/ICASSP.2000.861820","CorpusId":9372431},"title":"Speech parameter generation algorithms for HMM-based speech synthesis"},{"paperId":"855593c778f9f6c98a16afbd8e3097dbde09685c","externalIds":{"MAG":"2062170755","DOI":"10.1017/S1355771800003071","CorpusId":16584439},"title":"MARSYAS: a framework for audio analysis"},{"paperId":"518c3867f4272fd46fc5e8ecf1eb4f6af517c698","externalIds":{"MAG":"2049686551","DBLP":"journals/speech/KawaharaMC99","DOI":"10.1016/S0167-6393(98)00085-5","CorpusId":18151124},"title":"Restructuring speech representations using a pitch-adaptive time-frequency smoothing and an instantaneous-frequency-based F0 extraction: Possible role of a repetitive structure in sounds"},{"paperId":"0ec94f7cbfa30ba296be96f4cbcdc9c92af2aa64","externalIds":{"MAG":"2156142001","DBLP":"journals/taslp/StylianouCM98","DOI":"10.1109/89.661472","CorpusId":16280779},"title":"Continuous probabilistic transform for voice conversion"},{"paperId":"57cf18060da99d4303eacf767d0855b22191473f","externalIds":{"DBLP":"conf/interspeech/KimLO97","MAG":"1592940279","DOI":"10.21437/Eurospeech.1997-654","CorpusId":5976976},"title":"Hidden Markov model based voice conversion using dynamic characteristics of speaker"},{"paperId":"1dd0140d51e870a713340ae30734c8438b03d1a3","externalIds":{"MAG":"2150658333","DBLP":"conf/icassp/HuntB96","DOI":"10.1109/ICASSP.1996.541110","CorpusId":14621185},"title":"Unit selection in a concatenative speech synthesis system using a large speech database"},{"paperId":"214da54c3a9a1bf732f63186bf3cce83780744c2","externalIds":{"MAG":"1935012542","DBLP":"conf/icassp/TokudaKI95","DOI":"10.1109/ICASSP.1995.479684","CorpusId":7545265},"title":"Speech parameter generation from HMM using dynamic features"},{"paperId":"b219461c2ab15ce476b27b2062da3d904132c395","externalIds":{"DBLP":"conf/interspeech/TokudaKMI94","MAG":"2296704011","DOI":"10.21437/ICSLP.1994-275","CorpusId":2095460},"title":"Mel-generalized cepstral analysis - a unified approach to speech spectral estimation"},{"paperId":"589b014b2d76b253eb779fa39fcdc62ce56a252a","externalIds":{"DBLP":"conf/icassp/FukadaTKI92","MAG":"2093450784","DOI":"10.1109/ICASSP.1992.225953","CorpusId":1005918},"title":"An adaptive algorithm for mel-cepstral analysis of speech"},{"paperId":"d31898b96c994fb8d661a8094344a379712b672b","externalIds":{"DBLP":"journals/speech/MoulinesC90","MAG":"2428180336","DOI":"10.1016/0167-6393(90)90021-Z","CorpusId":15384823},"title":"Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones"},{"paperId":"f2a8695029d6ecadaf61394d3e29ae12fb992e5f","externalIds":{"MAG":"2118850452","DBLP":"conf/icassp/AbeNSK88","DOI":"10.1109/ICASSP.1988.196671","CorpusId":62203146},"title":"Voice conversion through vector quantization"},{"paperId":"5657f5888e198fecf4612ff04c4b0bdef972147c","externalIds":{"MAG":"2066452495","DOI":"10.1121/1.395275","CorpusId":14078323,"PubMed":"2958525"},"title":"Review of text-to-speech conversion for English."},{"paperId":"3a72d995c3870b52607bf790c42ae171d7cc5340","externalIds":{"DBLP":"conf/icassp/ShikanoLR86","MAG":"2110007337","DOI":"10.1109/ICASSP.1986.1168676","CorpusId":62761107},"title":"Speaker adaptation through vector quantization"},{"paperId":"082b8d576fd5cfd572ef2959f59e8506c06c9e44","externalIds":{"MAG":"1999885698","DOI":"10.1121/1.383940","CorpusId":16140885},"title":"Software for a cascade/parallel formant synthesizer"},{"paperId":"daaf96f0d16e98f56350ba2c7b0f4b105fa31b4a","externalIds":{"MAG":"1861172732","DOI":"10.1109/ICASSP.1977.1170350","CorpusId":61057770},"title":"Rule synthesis of speech from dyadic units"},{"paperId":"140576ced32df24dfcaec1333fdab94078a55a5f","externalIds":{"MAG":"1761875812","DBLP":"conf/icassp/SeeviourHJ76","DOI":"10.1109/ICASSP.1976.1169987","CorpusId":9070732},"title":"Automatic generation of control signals for a parallel formant speech synthesizer"},{"paperId":"71cc838d8a50a0d62cc9c679536f1f25b2ea6b7f","externalIds":{"DBLP":"journals/corr/abs-2209-02646","DOI":"10.48550/arXiv.2209.02646","CorpusId":252090040},"title":"A Survey on Generative Diffusion Model"},{"paperId":"250894a2b60ceeddb58ead4552fe782769e6e0b7","externalIds":{"DBLP":"journals/corr/abs-2111-11755","CorpusId":244488559},"title":"Guided-TTS: Text-to-Speech with Untranscribed Speech"},{"paperId":"d1a6890bfd0ac2b9777a7190dcd70ac2c08a76e4","externalIds":{"DBLP":"journals/corr/abs-2106-06406","CorpusId":235417212},"title":"PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Driven Adaptive Prior"},{"paperId":"5e7481a1254b02f220b3c2b61397309193de0fba","externalIds":{"MAG":"2747161606","DBLP":"conf/interspeech/QianZCYFH17","DOI":"10.21437/Interspeech.2017-1672","CorpusId":34069095},"title":"Speech Enhancement Using Bayesian Wavenet"},{"paperId":"5959f28a57c6d401e204ce8dfd8071c91eb8c586","externalIds":{"DBLP":"conf/interspeech/LiHXL15","MAG":"2399742709","DOI":"10.21437/Interspeech.2015-555","CorpusId":28615813},"title":"DNN-based speech bandwidth expansion and its application to adding high-frequency missing features for automatic speech recognition of narrowband speech"},{"paperId":"5fc6318684468678341f5e4fcc1c7317538c9ff3","externalIds":{"DBLP":"conf/ismir/YoshiiTMG13","MAG":"2403380333","CorpusId":14589908},"title":"Beyond NMF: Time-Domain Audio Source Separation without Phase Reconstruction"},{"paperId":"959a8b8e72a355fb49ac27cab33ed2f7f5e2ca6d","externalIds":{"DBLP":"conf/interspeech/VeauxR11","MAG":"2407110532","DOI":"10.21437/Interspeech.2011-692","CorpusId":3214918},"title":"Intonation Conversion from Neutral to Expressive Speech"},{"paperId":"887539061b4dec2439180eb58c2d6eae13f24548","externalIds":{"CorpusId":18418088},"title":"Blind Source Separation and Independent Component Analysis : A Review"},{"paperId":"c61926496fa04d04d937740aa31437485ed91b64","externalIds":{"MAG":"2337335398","CorpusId":57441287},"title":"Simultaneous modeling of phonetic and prosodic parameters,and characteristic conversion for HMM-based text-to-speech systems"},{"paperId":"1c424745996fd31920cadeec62a5514f3ce1a8b8","externalIds":{"MAG":"2395578248","DBLP":"conf/maveba/KawaharaEF01","CorpusId":10604954},"title":"Aperiodicity extraction and control using mixed mode excitation and group delay manipulation for a high quality speech analysis, modification and synthesis system STRAIGHT"},{"paperId":"505f9e5e4ea3711707ad0fe862401ef49215cb12","externalIds":{"MAG":"1600722501","CorpusId":8037054},"title":"Simultaneous Modeling of Spectrum, Pitch and Duration in HMM-Based Speech Synthesis"}]}