{"references":[{"paperId":"249408527106d7595d45dd761dd53c83e5a02613","externalIds":{"DBLP":"conf/iclr/WangLBF18","MAG":"2785948534","CorpusId":65051725},"title":"NerveNet: Learning Structured Policy with Graph Neural Networks"},{"paperId":"4b82cfd0229f257f44d84bedb4bead85054597cc","externalIds":{"MAG":"2964137578","DBLP":"journals/corr/abs-1804-06318","ArXiv":"1804.06318","CorpusId":3630111},"title":"Learning Awareness Models"},{"paperId":"a9a3ed69c94a3e1c08ef1f833d9199f57736238b","externalIds":{"MAG":"2781585732","ArXiv":"1801.00690","DBLP":"journals/corr/abs-1801-00690","CorpusId":6315299},"title":"DeepMind Control Suite"},{"paperId":"0af8cdb71ce9e5bf37ad2a11f05af293cfe62172","externalIds":{"MAG":"2949612618","DBLP":"conf/icra/PengAZA18","ArXiv":"1710.06537","DOI":"10.1109/ICRA.2018.8460528","CorpusId":3707478},"title":"Sim-to-Real Transfer of Robotic Control with Dynamics Randomization"},{"paperId":"cce22bf6405042a965a86557684c46a441f2a736","externalIds":{"DBLP":"journals/corr/abs-1708-02596","MAG":"2962872206","ArXiv":"1708.02596","DOI":"10.1109/ICRA.2018.8463189","CorpusId":206853161},"title":"Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning"},{"paperId":"bd1d59433e3b7ae7207c24b4cd1838acea91425c","externalIds":{"MAG":"2738675347","DBLP":"journals/corr/PascanuLVHBRRWW17","ArXiv":"1707.06170","CorpusId":20305315},"title":"Learning model-based planning from scratch"},{"paperId":"414ab203d8fc3ecfbf40d004960d3a4774830b48","externalIds":{"MAG":"2770604561","DBLP":"conf/nips/WattersZWBPT17","ArXiv":"1706.01433","CorpusId":38305207},"title":"Visual Interaction Networks: Learning a Physics Simulator from Video"},{"paperId":"007112213ece771be72cbecfd59f048209facabd","externalIds":{"MAG":"2963907629","ArXiv":"1706.01427","DBLP":"conf/nips/SantoroRBMPBL17","CorpusId":8528277},"title":"A simple neural network module for relational reasoning"},{"paperId":"099cdb087f240352a02286bf9a3e7810c7ebb02b","externalIds":{"ArXiv":"1705.02670","MAG":"2613603362","DBLP":"conf/iclr/HamrickBPVHB17","CorpusId":200884},"title":"Metacontrol for Adaptive Imagination-Based Optimization"},{"paperId":"e24cdf73b3e7e590c2fe5ecac9ae8aa983801367","externalIds":{"MAG":"2952254971","DBLP":"journals/corr/GilmerSRVD17","ArXiv":"1704.01212","CorpusId":9665943},"title":"Neural Message Passing for Quantum Chemistry"},{"paperId":"9f371ce1c7df9c325dd49b8d1b529478878a60f3","externalIds":{"DBLP":"journals/corr/EhrhardtMMV17","MAG":"2592431710","ArXiv":"1703.00247","CorpusId":15063736},"title":"Learning A Physical Long-term Predictor"},{"paperId":"15f91ae7590b88c4a533daeefa4b6fa7c0c277e5","externalIds":{"MAG":"2590960023","DBLP":"conf/iclr/RaposoSBPLB17","ArXiv":"1702.05068","CorpusId":260554498},"title":"Discovering objects and their relations from entangled scene representations"},{"paperId":"6bd1e6f70626772013a3c969c4b11d17dbb3d599","externalIds":{"MAG":"2950748517","DBLP":"journals/corr/YuLT17","ArXiv":"1702.02453","DOI":"10.15607/RSS.2017.XIII.048","CorpusId":10615022},"title":"Preparing for the Unknown: Learning a Universal Policy with Online System Identification"},{"paperId":"ae42c0cff384495683192b06bd985cdd7a54632a","externalIds":{"DBLP":"journals/corr/BattagliaPLRK16","ArXiv":"1612.00222","MAG":"2552391307","CorpusId":2200675},"title":"Interaction Networks for Learning about Objects, Relations and Physics"},{"paperId":"0e779fd59353a7f1f5b559b9d65fa4bfe367890c","externalIds":{"MAG":"3102013575","DBLP":"journals/spm/BronsteinBLSV17","ArXiv":"1611.08097","DOI":"10.1109/MSP.2017.2693418","CorpusId":15195762},"title":"Geometric Deep Learning: Going beyond Euclidean data"},{"paperId":"a1786540a4e15f0757e1b84a02f98ed436a969e0","externalIds":{"ArXiv":"1612.00341","MAG":"2559857813","DBLP":"journals/corr/ChangUTT16","CorpusId":1803861},"title":"A Compositional Object-Based Approach to Learning Physical Dynamics"},{"paperId":"9228fa3b363229780da4cb1d258942e0c13c2947","externalIds":{"ArXiv":"1610.01283","DBLP":"journals/corr/RajeswaranGLR16","MAG":"2964173023","CorpusId":1684853},"title":"EPOpt: Learning Robust Neural Network Policies Using Model Ensembles"},{"paperId":"36eff562f65125511b5dfab68ce7f7a943c27478","externalIds":{"ArXiv":"1609.02907","MAG":"2519887557","DBLP":"journals/corr/KipfW16","CorpusId":3144218},"title":"Semi-Supervised Classification with Graph Convolutional Networks"},{"paperId":"c41eb895616e453dcba1a70c9b942c5063cc656c","externalIds":{"MAG":"2468907370","ArXiv":"1606.09375","DBLP":"conf/nips/DefferrardBV16","CorpusId":3016223},"title":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"paperId":"fb3c6456708b0e143f545d77dc8ec804eb947395","externalIds":{"MAG":"2514775068","DBLP":"journals/corr/HouthooftCDSTA16","ArXiv":"1605.09674","CorpusId":17141244},"title":"Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks"},{"paperId":"7c6de5a9e02a779e24504619050c6118f4eac181","externalIds":{"MAG":"2951153836","DBLP":"journals/corr/NiepertAK16","ArXiv":"1605.05273","CorpusId":1430801},"title":"Learning Convolutional Neural Networks for Graphs"},{"paperId":"322cf9bcde458a45eaeca989a1eec92f7c6db984","externalIds":{"DBLP":"journals/corr/DaiDS16","MAG":"2299115575","ArXiv":"1603.05629","CorpusId":2708270},"title":"Discriminative Embeddings of Latent Variable Models for Structured Data"},{"paperId":"d358d41c69450b171327ebd99462b6afef687269","externalIds":{"MAG":"2290354866","ArXiv":"1603.00748","DBLP":"journals/corr/GuLSL16","CorpusId":890737},"title":"Continuous Deep Q-Learning with Model-based Acceleration"},{"paperId":"39c02227c37f0856e368d3dd5899f0867195a92e","externalIds":{"MAG":"2951054294","ArXiv":"1511.07404","DBLP":"journals/corr/FragkiadakiALM15","CorpusId":6981893},"title":"Learning Visual Predictive Models of Physics for Playing Billiards"},{"paperId":"492f57ee9ceb61fb5a47ad7aebfec1121887a175","externalIds":{"MAG":"2244807774","ArXiv":"1511.05493","DBLP":"journals/corr/LiTBZ15","CorpusId":8393918},"title":"Gated Graph Sequence Neural Networks"},{"paperId":"6640f4e4beae786f301928d82a9f8eb037aa6935","externalIds":{"DBLP":"conf/nips/HeessWSLET15","MAG":"1906772730","ArXiv":"1510.09142","CorpusId":53604},"title":"Learning Continuous Control Policies by Stochastic Value Gradients"},{"paperId":"5d1bfeed240709725c78bc72ea40e55410b373dc","externalIds":{"DBLP":"journals/corr/DuvenaudMAGHAA15","MAG":"2173027866","ArXiv":"1509.09292","CorpusId":1690180},"title":"Convolutional Networks on Graphs for Learning Molecular Fingerprints"},{"paperId":"024006d4c2a89f7acacc6e4438d156525b60a98f","externalIds":{"MAG":"2173248099","DBLP":"journals/corr/LillicrapHPHETS15","ArXiv":"1509.02971","CorpusId":16326763},"title":"Continuous control with deep reinforcement learning"},{"paperId":"e49ff72d420c8d72e62a9353e3abc053445e59bd","externalIds":{"ArXiv":"1506.05163","MAG":"637153065","DBLP":"journals/corr/HenaffBL15","CorpusId":10443309},"title":"Deep Convolutional Networks on Graph-Structured Data"},{"paperId":"d0c61536927c2f5dc2ddb74664268a3623580b9c","externalIds":{"MAG":"2121103318","DBLP":"conf/nips/LevineA14","CorpusId":2341332},"title":"Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics"},{"paperId":"6a28056e9670c4d7681045777e9e02c76f318c54","externalIds":{"DBLP":"conf/icra/TassaMT14","MAG":"1964946446","DOI":"10.1109/ICRA.2014.6907001","CorpusId":6269854},"title":"Control-limited differential dynamic programming"},{"paperId":"1eb09fecd75eb27825dce4f964b97f4f5cc399d7","externalIds":{"DBLP":"journals/corr/ChoMBB14","MAG":"2964199361","ArXiv":"1409.1259","ACL":"W14-4012","DOI":"10.3115/v1/W14-4012","CorpusId":11336213},"title":"On the Properties of Neural Machine Translation: Encoderâ€“Decoder Approaches"},{"paperId":"484ad17c926292fbe0d5211540832a8c8a8e958b","externalIds":{"MAG":"1909320841","DBLP":"conf/icml/RezendeMW14","CorpusId":16895865},"title":"Stochastic Backpropagation and Approximate Inference in Deep Generative Models"},{"paperId":"5e925a9f1e20df61d1e860a7aa71894b35a1c186","externalIds":{"MAG":"2950060523","DBLP":"journals/corr/BrunaZSL13","ArXiv":"1312.6203","CorpusId":17682909},"title":"Spectral Networks and Locally Connected Networks on Graphs"},{"paperId":"5f5dc5b9a2ba710937e2c413b37b053cd673df02","externalIds":{"DBLP":"journals/corr/KingmaW13","MAG":"2951004968","ArXiv":"1312.6114","CorpusId":216078090},"title":"Auto-Encoding Variational Bayes"},{"paperId":"29ade9f04f11dd8d434f051563f03928ed62c21b","externalIds":{"MAG":"2059100041","DOI":"10.1073/pnas.1306572110","CorpusId":1596551,"PubMed":"24145417"},"title":"Simulation as an engine of physical scene understanding"},{"paperId":"b354ee518bfc1ac0d8ac447eece9edb69e92eae1","externalIds":{"MAG":"2158782408","DBLP":"conf/iros/TodorovET12","DOI":"10.1109/IROS.2012.6386109","CorpusId":5230692},"title":"MuJoCo: A physics engine for model-based control"},{"paperId":"60b7d47758a71978e74edff6dd8dea4d9c791d7a","externalIds":{"DBLP":"conf/icml/DeisenrothR11","MAG":"2140135625","CorpusId":14273320},"title":"PILCO: A Model-Based and Data-Efficient Approach to Policy Search"},{"paperId":"5df39cc393907ea78fddf461b494b4c5b1b5a2e4","externalIds":{"MAG":"1550989509","DBLP":"journals/corr/abs-1103-5708","ArXiv":"1103.5708","DOI":"10.1007/978-3-642-22887-2_5","CorpusId":2907083},"title":"Planning to Be Surprised: Optimal Bayesian Exploration in Dynamic Environments"},{"paperId":"a1497bb0123a065a2a879c6de84dd03e16b1094d","externalIds":{"DBLP":"conf/nips/TassaES07","MAG":"2109944946","CorpusId":5324481},"title":"Receding Horizon Differential Dynamic Programming"},{"paperId":"769bfd4a4b45979cf83bb56c054ebcaaaf8b35d7","externalIds":{"MAG":"2137175628","DBLP":"conf/webi/ScarselliYGHTM05","DOI":"10.1109/WI.2005.67","CorpusId":8167952},"title":"Graph neural networks for ranking Web pages"},{"paperId":"9e0020d2cc7d8255661063ea5fb87f2000df1b21","externalIds":{"MAG":"70788614","DBLP":"conf/siggraph/GrzeszczukTH98","DOI":"10.1145/280814.280816","CorpusId":8249460},"title":"NeuroAnimator: fast neural network emulation and control of physics-based models"},{"paperId":"936a67aad36a9d9a7799237f0499d2f588d6e8ba","externalIds":{"MAG":"2117629901","DBLP":"conf/icra/AtkesonS97a","DOI":"10.1109/ROBOT.1997.606886","CorpusId":15949950},"title":"A comparison of direct and model-based reinforcement learning"},{"paperId":"9d25b53735c3078a34c3c2ed4fe1193a81ed0e82","externalIds":{"MAG":"2081817157","DBLP":"journals/nn/MiallW96","DOI":"10.1016/S0893-6080(96)00035-4","CorpusId":8214137,"PubMed":"12662535"},"title":"Forward Models for Physiological Motor Control"},{"paperId":"94db34f4b68189bfcba22beab33ee3b54f10b876","externalIds":{"MAG":"1863227302","DOI":"10.1109/IJCNN.1991.170605","CorpusId":17874844},"title":"Curious model-building control systems"},{"paperId":"ee66f87c06337fb430a90897112de06fb61f6a9f","externalIds":{"MAG":"2088823862","DOI":"10.1038/153605A0","CorpusId":4084461},"title":"The Nature of Explanation"},{"paperId":"104c4017c200f434dc7ecfbef143b5f135497abc","externalIds":{"DBLP":"journals/tnn/ScarselliGTHM09a","MAG":"2150120952","DOI":"10.1109/TNN.2008.2005141","CorpusId":206756425,"PubMed":"19129034"},"title":"Computational Capabilities of Graph Neural Networks"},{"paperId":"3efd851140aa28e95221b55fcc5659eea97b172d","externalIds":{"DBLP":"journals/tnn/ScarselliGTHM09","MAG":"2116341502","DOI":"10.1109/TNN.2008.2005605","CorpusId":206756462,"PubMed":"19068426"},"title":"The Graph Neural Network Model"},{"paperId":"1207aa55c8a2b47a25fc17c18328910daf3feb71","externalIds":{"DOI":"10.4135/9781506307633.n176","CorpusId":10185110,"PubMed":"17181705"},"title":"Core knowledge."},{"paperId":"48230ed0c3fa53ef1d43d79e1f6b113f13e83b9b","externalIds":{"MAG":"195033972","DBLP":"conf/icinco/LiT04","DOI":"10.5220/0001143902220229","CorpusId":19300},"title":"Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems"},{"paperId":"3cb699fddc1018222e58b9bddc4bb98ca94a74b2","externalIds":{"MAG":"43322953","DBLP":"journals/cogsci/Johnson-Laird80","DOI":"10.1207/s15516709cog0401_4","CorpusId":7090767},"title":"Mental Models in Cognitive Science"}]}