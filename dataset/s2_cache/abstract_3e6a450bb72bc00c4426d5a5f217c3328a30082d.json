{"abstract":"Automatic polyp segmentation from colonoscopy has a pivotal role in the early diagnosis and surgery of Colorectal Cancer(CRC). However, the diversity of polyps across different images significantly increases the difficulty of accurate polyp segmentation. Existing researches focus on learning the contextual information within an individual image but fail to exploit the co-occurrent visual patterns of polyps across images. In this paper, we argue that exploring contextual correlation from a holistic view of the whole dataset is essential and propose a Duplex Contextual Relation Network (DCRNet) to capture both within-image and cross-image contextual relations. Based on the above two types of similarity, the feature of each input region can be enhanced by its contextual region embedding within and across images. To store the characteristic region embedding from previous images during training, an episodic memory is designed and operates as a queue. We evaluate the proposed method on the EndoScene, Kvasir-SEG, and the recently released large-scale PICCOLO dataset. Experimental results show that our proposed DCRNet outperforms the state-of-the-art methods in terms of the widely-used evaluation metrics. The code is available at https://github.com/PRIS-CV/DCRNet"}