{"references":[{"paperId":"65a985c577b521068c36d55099a1e7139d592dbc","externalIds":{"DBLP":"journals/tbd/GengMLLBDR24","DOI":"10.1109/TBDATA.2023.3239116","CorpusId":256222486},"title":"Improved Gradient Inversion Attacks and Defenses in Federated Learning"},{"paperId":"2e965b5d97c2d6fb4af284307735be39283792ba","externalIds":{"ArXiv":"2301.13188","DBLP":"conf/uss/CarliniHNJSTBIW23","DOI":"10.48550/arXiv.2301.13188","CorpusId":256389993},"title":"Extracting Training Data from Diffusion Models"},{"paperId":"7a49c2c9ada7826df4cbbf2b48b43c4a78106077","externalIds":{"ArXiv":"2301.01197","DBLP":"conf/ndss/LiuL0S023","DOI":"10.48550/arXiv.2301.01197","CorpusId":255393915},"title":"Backdoor Attacks Against Dataset Distillation"},{"paperId":"f864d25e5d1588687de1267a0710a13bb25f1820","externalIds":{"ArXiv":"2211.10752","DBLP":"journals/corr/abs-2211-10752","DOI":"10.48550/arXiv.2211.10752","CorpusId":253734604},"title":"Towards Robust Dataset Learning"},{"paperId":"f8aa81482d46c61a7da9256036f277e65681d164","externalIds":{"DBLP":"journals/corr/abs-2211-04446","ArXiv":"2211.04446","DOI":"10.48550/arXiv.2211.04446","CorpusId":253397763},"title":"Private Set Generation with Discriminative Information"},{"paperId":"07bd1c24b92513c35fc83ae834f5a02f226fbba5","externalIds":{"DBLP":"journals/corr/abs-2210-16774","ArXiv":"2210.16774","DOI":"10.48550/arXiv.2210.16774","CorpusId":253237384},"title":"Dataset Distillation via Factorization"},{"paperId":"8805bba460886ce60240f47a143946c80346dbc9","externalIds":{"ArXiv":"2210.12067","DBLP":"conf/nips/LooHAR22a","DOI":"10.48550/arXiv.2210.12067","CorpusId":253080373},"title":"Efficient Dataset Distillation Using Random Feature Approximation"},{"paperId":"3d0f16515087dae04b25bdad2bb05a4a9f53c924","externalIds":{"ArXiv":"2209.14603","DBLP":"journals/corr/abs-2209-14603","DOI":"10.48550/arXiv.2209.14603","CorpusId":252595628},"title":"Dataset Distillation for Medical Dataset Sharing"},{"paperId":"db8a85e349bcd4190f394c303a6b2188dc8cd214","externalIds":{"ArXiv":"2208.10494","DBLP":"journals/corr/abs-2208-10494","DOI":"10.48550/arXiv.2208.10494","CorpusId":251741049},"title":"Dataset Condensation with Latent Space Knowledge Factorization and Sharing"},{"paperId":"66dc6277bac98622c09fd19f0d20a68471568674","externalIds":{"DBLP":"journals/corr/abs-2207-11727","ArXiv":"2207.11727","DOI":"10.48550/arXiv.2207.11727","CorpusId":251040844},"title":"Can we achieve robustness from data alone?"},{"paperId":"82f6130fef534e1cd110847f5bc1b78e19e36756","externalIds":{"DBLP":"journals/corr/abs-2207-09653","ArXiv":"2207.09653","DOI":"10.1109/CVPR52729.2023.01566","CorpusId":250698993},"title":"FedDM: Iterative Distribution Matching for Communication-Efficient Federated Learning"},{"paperId":"c3557ef800b214e8bf7b17304c509c720e03b5ae","externalIds":{"DBLP":"journals/corr/abs-2207-09639","ArXiv":"2207.09639","DOI":"10.48550/arXiv.2207.09639","CorpusId":250698926},"title":"DC-BENCH: Dataset Condensation Benchmark"},{"paperId":"5662bb5b5ed57c46f7294c7924d716b1e75f9bd5","externalIds":{"DBLP":"journals/corr/abs-2206-13697","ArXiv":"2206.13697","DOI":"10.48550/arXiv.2206.13697","CorpusId":250089388},"title":"Graph Condensation via Receptive Field Distribution Matching"},{"paperId":"200c92418ccba212e6f974665af407f06f6ccabf","externalIds":{"DBLP":"conf/kdd/JinTJLZTY22","ArXiv":"2206.07746","DOI":"10.1145/3534678.3539429","CorpusId":249712265},"title":"Condensing Graphs via One-Step Gradient Matching"},{"paperId":"b18e54ed671373a080998a8ce903c1c127a128d4","externalIds":{"ArXiv":"2206.02916","DBLP":"conf/nips/DengR22","DOI":"10.48550/arXiv.2206.02916","CorpusId":249431765},"title":"Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks"},{"paperId":"3eba23dab4c229800e14b5376046fa19b0f40cec","externalIds":{"DBLP":"journals/corr/abs-2206-00719","ArXiv":"2206.00719","DOI":"10.48550/arXiv.2206.00719","CorpusId":249282424},"title":"Dataset Distillation using Neural Feature Regression"},{"paperId":"44fe53dfa1794e29a4962b6a3a19fc738b02ddb0","externalIds":{"DBLP":"conf/icml/DongZL22","ArXiv":"2206.00240","DOI":"10.48550/arXiv.2206.00240","CorpusId":249240527},"title":"Privacy for Free: How does Dataset Condensation Help Privacy?"},{"paperId":"2d77266137673c6c5eacbb37db386da8810d4479","externalIds":{"DBLP":"conf/icml/KimKOYSJ0S22","ArXiv":"2205.14959","DOI":"10.48550/arXiv.2205.14959","CorpusId":249192018},"title":"Dataset Condensation via Efficient Synthetic-Data Parameterization"},{"paperId":"3001ffb7a5e3f92bab51baa884bbf376d0e0cf27","externalIds":{"DBLP":"journals/corr/abs-2204-07513","ArXiv":"2204.07513","DOI":"10.48550/arXiv.2204.07513","CorpusId":248218712},"title":"Synthesizing Informative Training Samples with GAN"},{"paperId":"5dafefb0755f0e105a5a1ad34d10cff4202035a1","externalIds":{"DBLP":"journals/corr/abs-2204-01273","ArXiv":"2204.01273","DOI":"10.48550/arXiv.2204.01273","CorpusId":247939255},"title":"FedSynth: Gradient Compression via Synthetic Data in Federated Learning"},{"paperId":"11154b89486fd7b41bfab5f8b0e19756c488523e","externalIds":{"DBLP":"conf/cvpr/Cazenavette00EZ22b","ArXiv":"2203.11932","DOI":"10.1109/CVPR52688.2022.01045","CorpusId":247597241},"title":"Dataset Distillation by Matching Training Trajectories"},{"paperId":"7a900a5b438bd3a361c6684c5986d4c19fa726e0","externalIds":{"DBLP":"journals/corr/abs-2110-09074","ArXiv":"2110.09074","CorpusId":239016555},"title":"Towards General Deep Leakage in Federated Learning"},{"paperId":"5f3173e24d17b92a96e82d0499b365f341edfcd2","externalIds":{"DBLP":"journals/corr/abs-2110-07580","ArXiv":"2110.07580","CorpusId":238857085},"title":"Graph Condensation for Graph Neural Networks"},{"paperId":"c03f42a6686eb5fa8b62088c4c2b5545bc60ebdc","externalIds":{"DBLP":"journals/corr/abs-2110-04181","ArXiv":"2110.04181","DOI":"10.1109/WACV56688.2023.00645","CorpusId":238531636},"title":"Dataset Condensation with Distribution Matching"},{"paperId":"39bf40fec9bb8a68198471d86bbd8b5a763d47be","externalIds":{"DBLP":"conf/nips/NguyenNXL21","ArXiv":"2107.13034","CorpusId":236469183},"title":"Dataset Distillation with Infinitely Wide Convolutional Networks"},{"paperId":"99e93357b8b3ffd309d2dbae187f61143b928abf","externalIds":{"DBLP":"conf/icml/ZhaoB21","ArXiv":"2102.08259","CorpusId":231933854},"title":"Dataset Condensation with Differentiable Siamese Augmentation"},{"paperId":"8212605d274d5e68bcedf990728f4f5c26f88168","externalIds":{"MAG":"3097629404","DBLP":"journals/corr/abs-2011-00050","ArXiv":"2011.00050","CorpusId":226226438},"title":"Dataset Meta-Learning from Kernel Ridge-Regression"},{"paperId":"08bb0b86b15d55bed854ba9f236defbf61d3d0db","externalIds":{"MAG":"3097784654","DBLP":"conf/eccv/PrabhuTD20","DOI":"10.1007/978-3-030-58536-5_31","CorpusId":221088423},"title":"GDumb: A Simple Approach that Questions Our Progress in Continual Learning"},{"paperId":"5a94bcc168330318d3020aa4d41bd73cf68ab285","externalIds":{"DBLP":"conf/iclr/ZhaoMB21","MAG":"3034486793","ArXiv":"2006.05929","CorpusId":219558792},"title":"Dataset Condensation with Gradient Matching"},{"paperId":"16a3dd5ab3e8570f6083ddf6f88aa5e916450fef","externalIds":{"DBLP":"journals/corr/abs-1912-07768","ArXiv":"1912.07768","MAG":"3034828529","CorpusId":209386415},"title":"Generative Teaching Networks: Accelerating Neural Architecture Search by Learning to Generate Synthetic Training Data"},{"paperId":"768207eac0035bfb728905ebe6a7bc1765f28e39","externalIds":{"DBLP":"conf/ijcnn/SucholutskyS21","ArXiv":"1910.02551","MAG":"2983647115","DOI":"10.1109/IJCNN52387.2021.9533769","CorpusId":207930130},"title":"Soft-Label Dataset Distillation and Text Dataset Distillation"},{"paperId":"f4327b978dec52f16b089c222c43543f8ecf4717","externalIds":{"DOI":"10.5860/choice.189890","CorpusId":240757309},"title":"arXiv"},{"paperId":"62931b3e0dce8748364e19c87ef318e22ec59c7f","externalIds":{"ArXiv":"1904.03189","MAG":"2934375473","DBLP":"conf/iccv/AbdalQW19","DOI":"10.1109/ICCV.2019.00453","CorpusId":102350964},"title":"Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?"},{"paperId":"07b1a0ed6ba8a497355ac105e9110a927e3cf913","externalIds":{"MAG":"2902287157","ArXiv":"1811.10959","DBLP":"journals/corr/abs-1811-10959","CorpusId":53763883},"title":"Dataset Distillation"},{"paperId":"058dd355ec60af11048ee49a54db599003356322","externalIds":{"MAG":"2953348396","DBLP":"conf/eccv/CastroMGSA18","ArXiv":"1807.09536","DOI":"10.1007/978-3-030-01258-8_15","CorpusId":50785377},"title":"End-to-End Incremental Learning"},{"paperId":"7a84a692327534fd227fa1e07fcb3816b633c591","externalIds":{"MAG":"2809090039","ArXiv":"1806.07572","DBLP":"conf/nips/JacotHG18","CorpusId":49321232},"title":"Neural Tangent Kernel: Convergence and Generalization in Neural Networks"},{"paperId":"da6e404d8911b0e5785019a79dc8607e0b313dc4","externalIds":{"MAG":"2797583228","ArXiv":"1804.03209","DBLP":"journals/corr/abs-1804-03209","CorpusId":4719239},"title":"Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition"},{"paperId":"c342c71cb23199f112d0bc644fcce56a7306bf94","externalIds":{"MAG":"2774918944","DBLP":"conf/iclr/SenerS18","CorpusId":3383786},"title":"Active Learning for Convolutional Neural Networks: A Core-Set Approach"},{"paperId":"30ec43601d48236f8983d7cc55bed9cc68262b57","externalIds":{"MAG":"2605801332","DBLP":"journals/corr/GravesBMMK17","ArXiv":"1704.03003","CorpusId":11137059},"title":"Automated Curriculum Learning for Neural Networks"},{"paperId":"81ea29bde0216e41420c4591bebb800142fa3269","externalIds":{"ArXiv":"1703.03365","DBLP":"conf/nips/KonyushkovaSF17","MAG":"2739068567","CorpusId":5878784},"title":"Learning Active Learning from Data"},{"paperId":"f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d","externalIds":{"ArXiv":"1610.05820","DBLP":"journals/corr/ShokriSS16","MAG":"2535690855","DOI":"10.1109/SP.2017.41","CorpusId":10488675},"title":"Membership Inference Attacks Against Machine Learning Models"},{"paperId":"71683e224ab91617950956b5005ed0439a733a71","externalIds":{"MAG":"2427497464","DBLP":"conf/nips/AndrychowiczDCH16","ArXiv":"1606.04474","CorpusId":2928017},"title":"Learning to learn by gradient descent by gradient descent"},{"paperId":"d1b9a3b11e6c9571a1553556f82b605b2b4baec3","externalIds":{"DBLP":"conf/ccs/FredriksonJR15","MAG":"2051267297","DOI":"10.1145/2810103.2813677","CorpusId":207229839},"title":"Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures"},{"paperId":"e2820bffe5b42cb7d88b7f65c12171c62ab4aae2","externalIds":{"MAG":"1868018859","DBLP":"journals/corr/MaclaurinDA15","ArXiv":"1502.03492","CorpusId":8540522},"title":"Gradient-based Hyperparameter Optimization through Reversible Learning"},{"paperId":"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5","externalIds":{"MAG":"2133564696","ArXiv":"1409.0473","DBLP":"journals/corr/BahdanauCB14","CorpusId":11212020},"title":"Neural Machine Translation by Jointly Learning to Align and Translate"},{"paperId":"193edd20cae92c6759c18ce93eeea96afd9528eb","externalIds":{"DBLP":"journals/nn/Schmidhuber15","MAG":"2076063813","ArXiv":"1404.7828","DOI":"10.1016/j.neunet.2014.09.003","CorpusId":11715509,"PubMed":"25462637"},"title":"Deep learning in neural networks: An overview"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","externalIds":{"DBLP":"conf/cvpr/DengDSLL009","MAG":"2108598243","DOI":"10.1109/CVPR.2009.5206848","CorpusId":57246310},"title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"85983d70db7bef99103c3833793f503c18445546","externalIds":{"MAG":"2610955953","DBLP":"conf/icalp/Dwork06","DOI":"10.1007/11787006_1","CorpusId":2565493},"title":"Differential Privacy"},{"paperId":"c900c66310a29bdb771270bb22440a4cf42958cb","externalIds":{"MAG":"1549656520","CorpusId":54174771},"title":"Advances in Large Margin Classifiers"},{"paperId":"5e8c8dd23f69354c56724b636a19445085ac51ac","externalIds":{"CorpusId":247223155},"title":"CAFE Learning to Condense Dataset by Aligning Features"},{"paperId":"9ab43fcb51b17c127b960149b59ee6e767e37629","externalIds":{"CorpusId":221741465},"title":"Learning to learn by gradient descent by gradient descent"},{"paperId":"092478aa9c2a30eeadcdaa60a0d3b565a9b535a6","externalIds":{"MAG":"2536977318","DOI":"10.1109/ijcnn39090.2017","CorpusId":63569499},"title":"2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)"},{"paperId":"694b3c58712deefb59502847ba1b52b192c413e5","externalIds":{"ACL":"2005.mtsummit-papers.11","MAG":"29184969","DBLP":"conf/mtsummit/Koehn05","CorpusId":38407095},"title":"Europarl: A Parallel Corpus for Statistical Machine Translation"},{"paperId":"42e5ed832d4310ce4378c44d05570439df28a393","externalIds":{"MAG":"1618905105","CorpusId":56563878},"title":"Probabilistic Outputs for Support vector Machines and Comparisons to Regularized Likelihood Methods"},{"paperId":"4d98ce60f4f8ed822503b8d13b0605f8c5d74ca7","externalIds":{"CorpusId":2877073},"title":"In Advances in Neural Information Processing Systems"}]}