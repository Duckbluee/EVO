{"abstract":"Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing artificial intelligence (AI) and shaping our society. However, the status quo cloud-based LLM deployment faces critical challenges such as long response time and privacy concerns, whereas on-device LLM deployment is hindered by the limited capabilities of end devices. To address the dilemma, this article explores the transformative potential of deploying LLMs at the 6G edge. We first introduce killer applications to exemplify the urgent need for edge LLM deployment and then, we identify the inherent limitations of on-device LLM deployment. We therefore argue that end-edge cooperation at the 6G edge is a promising solution for the dilemma. Towards this end, we elaborate on the 6G MEC architecture tailored for LLMs. Furthermore, we delve into edge training and edge inference for LLMs, with a focus on end-edge cooperation. In both aspects, we discuss a spectrum of cutting-edge techniques, including split learning/inference, parameter-efficient fine-tuning, parameter-sharing inference, and small-large language model cooperation. Finally, we investigate open problems in green and privacy-preserving edge LLM deployment. This work provides a comprehensive and forward-looking perspective and pathways for enabling LLM deployment at the network edge."}