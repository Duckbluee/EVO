{"references":[{"paperId":"2d3352e13f9d84ebad2a34ede9cb7341893b095b","externalIds":{"DBLP":"conf/icml/XuZLG0Y21","ArXiv":"2111.13293","CorpusId":235825403},"title":"KNAS: Green Neural Architecture Search"},{"paperId":"c28b7dfe341f1e13a5a98efbce7946ef795cf9b8","externalIds":{"DBLP":"journals/corr/abs-2110-07904","ArXiv":"2110.07904","ACL":"2022.acl-long.346","DOI":"10.18653/v1/2022.acl-long.346","CorpusId":239009558},"title":"SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer"},{"paperId":"f3a332ff1b73acda482e5d83696b2c701f487819","externalIds":{"DBLP":"journals/corr/abs-2110-07602","ArXiv":"2110.07602","CorpusId":238857040},"title":"P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"},{"paperId":"5b05e150ef225b8004b4be42b7325a4de51d495d","externalIds":{"DBLP":"journals/corr/abs-2109-03228","ArXiv":"2109.03228","ACL":"2021.emnlp-main.832","DOI":"10.18653/v1/2021.emnlp-main.832","CorpusId":237433629},"title":"Beyond Preserved Accuracy: Evaluating Loyalty and Robustness of BERT Compression"},{"paperId":"ff0b2681d7b05e16c46dfb71d980cc2f605907cd","externalIds":{"DBLP":"journals/corr/abs-2109-01652","ArXiv":"2109.01652","CorpusId":237416585},"title":"Finetuned Language Models Are Zero-Shot Learners"},{"paperId":"84310f76cf8909f87c6a7f2ed30ae28214cc9eab","externalIds":{"MAG":"3176017841","ACL":"2021.acl-long.231","DBLP":"conf/acl/Zhu20","DOI":"10.18653/v1/2021.acl-long.231","CorpusId":236459809},"title":"LeeBERT: Learned Early Exit for BERT with cross-level optimization"},{"paperId":"d6cbe7986a15a3d697213c8541c97dec9e65240b","externalIds":{"DBLP":"conf/acl/SchroderNP22","ACL":"2022.findings-acl.172","ArXiv":"2107.05687","DOI":"10.18653/v1/2022.findings-acl.172","CorpusId":235828923},"title":"Revisiting Uncertainty-based Query Strategies for Active Learning with Transformers"},{"paperId":"feba0c47bf12a02c3a725174bb53df78658a72a8","externalIds":{"ArXiv":"2106.07139","DBLP":"journals/aiopen/HanZDGLHQYZZHHJ21","DOI":"10.1016/j.aiopen.2021.08.002","CorpusId":235421816},"title":"Pre-Trained Models: Past, Present and Future"},{"paperId":"5f0f4a3fa3cff7ffcedabbc9ed0dad2dd71f7028","externalIds":{"ArXiv":"2106.05945","DBLP":"conf/nips/StantonIKAW21","CorpusId":235390933},"title":"Does Knowledge Distillation Really Work?"},{"paperId":"03662672662f49e6b06148e94b407b60b0bb72f3","externalIds":{"DBLP":"conf/naacl/LiaoZRSSH21","ACL":"2021.naacl-main.162","MAG":"3170113752","DOI":"10.18653/V1/2021.NAACL-MAIN.162","CorpusId":235097407},"title":"A Global Past-Future Early Exit Method for Accelerating Inference of Pre-trained Language Models"},{"paperId":"9631f5bc3e6d345db42425824f1e7d21d35efa0c","externalIds":{"MAG":"3165511581","DBLP":"journals/corr/abs-2105-13792","ArXiv":"2105.13792","CorpusId":235248158},"title":"Early Exiting with Ensemble Internal Classifiers"},{"paperId":"9c053552dfa6184f7dc56d620bcb1e8f22c729a3","externalIds":{"DBLP":"conf/acl/LiSSYQH20","ArXiv":"2105.13878","ACL":"2021.acl-long.16","DOI":"10.18653/v1/2021.acl-long.16","CorpusId":235248193},"title":"Accelerating BERT Inference for Sequence Labeling via Early-Exit"},{"paperId":"c26759e6c701201af2f62f7ee4eb68742b5bf085","externalIds":{"ArXiv":"2104.08821","DBLP":"journals/corr/abs-2104-08821","ACL":"2021.emnlp-main.552","DOI":"10.18653/v1/2021.emnlp-main.552","CorpusId":233296292},"title":"SimCSE: Simple Contrastive Learning of Sentence Embeddings"},{"paperId":"c1d0e73ec3aaf7ffdcbe41835d649d638cbc2f2d","externalIds":{"ACL":"2021.emnlp-main.406","DBLP":"journals/corr/abs-2104-08803","ArXiv":"2104.08803","DOI":"10.18653/v1/2021.emnlp-main.406","CorpusId":233296246},"title":"Consistent Accelerated Inference via Confident Adaptive Transformers"},{"paperId":"3456c1e95d8d2f985a0701232dd55171b3cbd5e0","externalIds":{"DBLP":"conf/sustainlp/TakaseK23","ArXiv":"2104.06022","ACL":"2023.sustainlp-1.5","DOI":"10.18653/v1/2023.sustainlp-1.5","CorpusId":233219888},"title":"Lessons on Parameter Sharing across Layers in Transformers"},{"paperId":"739ceacfafb1c4eaa17509351b647c773270b3ae","externalIds":{"DBLP":"journals/corr/abs-2104-02057","ArXiv":"2104.02057","MAG":"3145450063","DOI":"10.1109/ICCV48922.2021.00950","CorpusId":233024948},"title":"An Empirical Study of Training Self-Supervised Vision Transformers"},{"paperId":"093253653cd0b55970c390d77b75137c4095dc29","externalIds":{"DBLP":"journals/corr/abs-2103-13630","ArXiv":"2103.13630","DOI":"10.1201/9781003162810-13","CorpusId":232352683},"title":"A Survey of Quantization Methods for Efficient Neural Network Inference"},{"paperId":"a9fe5bd8da2d9603cf2cf6c6ea8b0f83c6d3a4f9","externalIds":{"DBLP":"journals/corr/abs-2103-08493","ArXiv":"2103.08493","MAG":"3167602185","ACL":"2021.naacl-main.208","DOI":"10.18653/V1/2021.NAACL-MAIN.208","CorpusId":232233408},"title":"How many data points is a prompt worth?"},{"paperId":"a11676f2864b2d923bb9facc9f6548c812f9e005","externalIds":{"DBLP":"journals/corr/abs-2103-00823","ArXiv":"2103.00823","CorpusId":232075617},"title":"M6: A Chinese Multimodal Pretrainer"},{"paperId":"8d84c38f5fce1bd1b4ae1d55400c8fb7fa5d19c8","externalIds":{"ArXiv":"2102.11535","DBLP":"journals/corr/abs-2102-11535","CorpusId":232013680},"title":"Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective"},{"paperId":"af9d0a18123c3bd8d8d2b1c44b03fdea5e9c3ae3","externalIds":{"ArXiv":"2102.07650","DBLP":"journals/corr/abs-2102-07650","CorpusId":231925118},"title":"Learning Student-Friendly Teacher Networks for Knowledge Distillation"},{"paperId":"837ac4ed6825502f0460caec45e12e734c85b113","externalIds":{"DBLP":"journals/corr/abs-2102-04906","ArXiv":"2102.04906","DOI":"10.1109/TPAMI.2021.3117837","CorpusId":231855426,"PubMed":"34613907"},"title":"Dynamic Neural Networks: A Survey"},{"paperId":"949c0941d4c57482318afa28f2c8eb82569fb401","externalIds":{"ArXiv":"2101.09671","MAG":"3184606595","DBLP":"journals/ijon/LiangGWSZ21","DOI":"10.1016/J.NEUCOM.2021.07.045","CorpusId":231699188},"title":"Pruning and Quantization for Deep Neural Network Acceleration: A Survey"},{"paperId":"f1edb9a58a45aa021c2561049c0370d8a2d0fb20","externalIds":{"ArXiv":"2101.09755","DBLP":"journals/corr/abs-2101-09755","CorpusId":231698881},"title":"RomeBERT: Robust Training of Multi-Exit BERT"},{"paperId":"6dc84d38f6d8d964456b127d6f45c5b4de73bb86","externalIds":{"DBLP":"journals/corr/abs-2101-08134","MAG":"3124523586","ArXiv":"2101.08134","CorpusId":231648113},"title":"Zero-Cost Proxies for Lightweight NAS"},{"paperId":"fdacf2a732f55befdc410ea927091cad3b791f13","externalIds":{"DBLP":"journals/jmlr/FedusZS22","ArXiv":"2101.03961","CorpusId":231573431},"title":"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity"},{"paperId":"124b25a74691a993673359288637716d83899a06","externalIds":{"DBLP":"conf/emnlp/ZhouGX0W21","ACL":"2021.emnlp-main.45","ArXiv":"2101.00416","DOI":"10.18653/v1/2021.emnlp-main.45","CorpusId":230437660},"title":"Improving Sequence-to-Sequence Pre-training via Sequence Span Rewriting"},{"paperId":"c375e121926db9551f224ff235018ea38bb159b7","externalIds":{"DBLP":"conf/acl/BaiZHSJJLLK20","ACL":"2021.acl-long.334","ArXiv":"2012.15701","DOI":"10.18653/v1/2021.acl-long.334","CorpusId":229923538},"title":"BinaryBERT: Pushing the Limit of BERT Quantization"},{"paperId":"3c486df457e7c40f823a53666963d14af6792e75","externalIds":{"DBLP":"journals/corr/abs-2012-15823","ArXiv":"2012.15823","DOI":"10.1109/CVPR46437.2021.00937","CorpusId":229924140},"title":"Binary Graph Neural Networks"},{"paperId":"83ed88e4f745cc9aecd1fbd479612b11beddcb86","externalIds":{"ArXiv":"2012.15466","DBLP":"journals/corr/abs-2012-15466","CorpusId":229924304},"title":"CLEAR: Contrastive Learning for Sentence Representation"},{"paperId":"d22e4cc3a501c17881b9478621f29760e429e76e","externalIds":{"MAG":"3113057009","ACL":"2021.acl-long.378","DBLP":"journals/corr/abs-2012-07463","ArXiv":"2012.07463","DOI":"10.18653/v1/2021.acl-long.378","CorpusId":229152766},"title":"Parameter-Efficient Transfer Learning with Diff Pruning"},{"paperId":"6f6f73e69ee0d9d5d7d088bb882db1851d98175a","externalIds":{"DBLP":"conf/cvpr/Chen000DLMX0021","ArXiv":"2012.00364","MAG":"3109319753","DOI":"10.1109/CVPR46437.2021.01212","CorpusId":227239228},"title":"Pre-Trained Image Processing Transformer"},{"paperId":"3af8a493cf756f9fe72623204a11e378a9cd71a5","externalIds":{"ArXiv":"2011.14203","DBLP":"conf/micro/TambeHPJYDSWR0W21","DOI":"10.1145/3466752.3480095","CorpusId":237421361},"title":"EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference"},{"paperId":"0b98f8ec299de3358c5dfc0d842529b5aee0e97c","externalIds":{"DBLP":"journals/corr/abs-2011-13635","MAG":"3108384060","ArXiv":"2011.13635","CorpusId":227210594},"title":"Progressively Stacking 2.0: A Multi-stage Layerwise Training Method for BERT Training Speedup"},{"paperId":"0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d","externalIds":{"MAG":"3107668149","DBLP":"conf/cvpr/ChenH21","ArXiv":"2011.10566","DOI":"10.1109/CVPR46437.2021.01549","CorpusId":227118869},"title":"Exploring Simple Siamese Representation Learning"},{"paperId":"74276a37bfa50f90dfae37f767b2b67784bd402a","externalIds":{"ArXiv":"2010.11934","DBLP":"conf/naacl/XueCRKASBR21","MAG":"3169483174","ACL":"2021.naacl-main.41","DOI":"10.18653/V1/2021.NAACL-MAIN.41","CorpusId":225040574},"title":"mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer"},{"paperId":"687b13c44f849d23c2496996b5da83e706094db9","externalIds":{"DBLP":"journals/corr/abs-2010-11125","MAG":"3093871477","ArXiv":"2010.11125","CorpusId":224814118},"title":"Beyond English-Centric Multilingual Machine Translation"},{"paperId":"a50d31c082521817a1e74cae584963a63163ca70","externalIds":{"ArXiv":"2010.07003","DBLP":"journals/corr/abs-2010-07003","ACL":"2021.acl-long.508","MAG":"3092746498","DOI":"10.18653/v1/2021.acl-long.508","CorpusId":222341845},"title":"Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search"},{"paperId":"d9b7620f9b9653ada1a7ce36b0d6617f5979fff2","externalIds":{"MAG":"3092747189","ArXiv":"2010.06351","DBLP":"journals/corr/abs-2010-06351","CorpusId":222310452},"title":"CAPT: Contrastive Pre-Training for Learning Denoised Sequence Representations"},{"paperId":"9fa283d4f9c2ed991383c0434ef6043bee0dc8e2","externalIds":{"DBLP":"journals/corr/abs-2010-05300","ArXiv":"2010.05300","MAG":"3101720316","CorpusId":222291744},"title":"Glance and Focus: a Dynamic Approach to Reducing Spatial Redundancy in Image Classification"},{"paperId":"226a962e9e2e01cafc3803018bb8bf511d549e9f","externalIds":{"ArXiv":"2010.03142","ACL":"2020.emnlp-main.210","MAG":"3106321930","DBLP":"conf/emnlp/LinPWQFZL20","DOI":"10.18653/v1/2020.emnlp-main.210","CorpusId":222177485},"title":"Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information"},{"paperId":"f64be662859f2c90c70d99ac94ff383391fb9e46","externalIds":{"MAG":"3092078674","DBLP":"journals/corr/abs-2010-02646","ACL":"2020.emnlp-main.78","ArXiv":"2010.02646","DOI":"10.18653/v1/2020.emnlp-main.78","CorpusId":222142224},"title":"On the Sparsity of Neural Machine Translation Models"},{"paperId":"3fbf6339273c50b04e886fa9bd4ad18c952a683d","externalIds":{"DBLP":"conf/iclr/ChoromanskiLDSG21","ArXiv":"2009.14794","MAG":"3091156754","CorpusId":222067132},"title":"Rethinking Attention with Performers"},{"paperId":"097210dc65924f8ce59523faf444e635523dc714","externalIds":{"MAG":"3098576111","DBLP":"journals/corr/abs-2009-12812","ArXiv":"2009.12812","ACL":"2020.emnlp-main.37","DOI":"10.18653/v1/2020.emnlp-main.37","CorpusId":221970445},"title":"TernaryBERT: Distillation-aware Ultra-low Bit BERT"},{"paperId":"4afc95e4247a2a50d3628a50d76fe62343caec26","externalIds":{"ArXiv":"2009.09232","DBLP":"journals/corr/abs-2009-09232","MAG":"3087314042","CorpusId":221818866},"title":"Learned Low Precision Graph Neural Networks"},{"paperId":"f30444fbb6ad806168e2564db4815cd27faa7fd9","externalIds":{"ArXiv":"2009.07118","MAG":"3085177480","DBLP":"conf/naacl/SchickS21","ACL":"2021.naacl-main.185","DOI":"10.18653/V1/2021.NAACL-MAIN.185","CorpusId":221703107},"title":"It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"},{"paperId":"9c0e855382de7e708c8eea7b4d5cf792bcd4a326","externalIds":{"DBLP":"journals/corr/abs-2008-05000","MAG":"3048770428","ArXiv":"2008.05000","CorpusId":221136343},"title":"Degree-Quant: Quantization-Aware Training for Graph Neural Networks"},{"paperId":"044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3","externalIds":{"ArXiv":"2007.14062","DBLP":"journals/corr/abs-2007-14062","MAG":"3045733172","CorpusId":220831004},"title":"Big Bird: Transformers for Longer Sequences"},{"paperId":"e71aed7a0680c8fc09733f1dcd0cd3f6bb9cb7aa","externalIds":{"MAG":"3104263050","DBLP":"conf/nips/ChenFC0ZWC20","ArXiv":"2007.12223","CorpusId":220768628},"title":"The Lottery Ticket Hypothesis for Pre-trained BERT Networks"},{"paperId":"063f8b1ecf2394ca776ac61869734de9c1953808","externalIds":{"DBLP":"journals/corr/abs-2007-07779","MAG":"3042667808","ArXiv":"2007.07779","ACL":"2020.emnlp-demos.7","DOI":"10.18653/v1/2020.emnlp-demos.7","CorpusId":220525782},"title":"AdapterHub: A Framework for Adapting Transformers"},{"paperId":"c073d59208cba1a11faf0a1fe9bf2b769c3944b0","externalIds":{"MAG":"3041756244","DBLP":"conf/ictai/FengWLYPD20","ArXiv":"2007.05100","DOI":"10.1109/ICTAI50040.2020.00198","CorpusId":220486820},"title":"SGQuant: Squeezing the Last Bit on Graph Neural Networks with Specialized Quantization"},{"paperId":"1882f194cb43828852cc052887671e55a80f945a","externalIds":{"MAG":"3040573126","DBLP":"conf/iclr/LepikhinLXCFHKS21","ArXiv":"2006.16668","CorpusId":220265858},"title":"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"},{"paperId":"235de6164e754400f82b77fb33be84fc43c79078","externalIds":{"DBLP":"conf/iclr/PlummerDFHS22","ArXiv":"2006.10598","CorpusId":247476419},"title":"Neural Parameter Allocation Search"},{"paperId":"1e1e10d75c4ebabdbfb7912ca4cc06a27ffa85af","externalIds":{"DBLP":"conf/nips/CaronMMGBJ20","MAG":"3036224891","ArXiv":"2006.09882","CorpusId":219721240},"title":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments"},{"paperId":"38f93092ece8eee9771e61c1edaf11b1293cae1b","externalIds":{"MAG":"3101821705","DBLP":"conf/nips/GrillSATRBDPGAP20","ArXiv":"2006.07733","CorpusId":219687798},"title":"Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"},{"paperId":"25c371d565b387dbf22207a954a9549557698c21","externalIds":{"DBLP":"journals/corr/abs-2006-04647","ArXiv":"2006.04647","MAG":"3033395418","CorpusId":219531078},"title":"Neural Architecture Search without Training"},{"paperId":"4abdbcf983f78cf3f5bf6e2032503f0e534f6ca8","externalIds":{"MAG":"3101163004","DBLP":"conf/nips/ZhouXGM0W20","ArXiv":"2006.04152","CorpusId":219531455},"title":"BERT Loses Patience: Fast and Robust Inference with Early Exit"},{"paperId":"32d281a1e7a0a2d4e2b3f34e0f71780c987e1374","externalIds":{"DBLP":"journals/corr/abs-2006-03659","ACL":"2021.acl-long.72","ArXiv":"2006.03659","MAG":"3033406728","DOI":"10.18653/v1/2021.acl-long.72","CorpusId":219530980},"title":"DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"9a56ab8b1aba50dc2fea3cf4b531d30891a88ba9","externalIds":{"MAG":"3027758526","ArXiv":"2005.10242","DBLP":"conf/icml/0001I20","CorpusId":218718310},"title":"Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere"},{"paperId":"66f0f35fc78bdf2af9de46093d49a428970cde2e","externalIds":{"MAG":"3099715410","DBLP":"conf/nips/Sanh0R20","ArXiv":"2005.07683","CorpusId":218665313},"title":"Movement Pruning: Adaptive Sparsity by Fine-Tuning"},{"paperId":"91ac65431b2dc46919e1673fde67671c29446812","externalIds":{"MAG":"3022969335","ACL":"2020.emnlp-main.259","ArXiv":"2005.00561","DBLP":"conf/emnlp/PrasannaRR20","DOI":"10.18653/v1/2020.emnlp-main.259","CorpusId":218487454},"title":"When BERT Plays the Lottery, All Tickets Are Winning"},{"paperId":"90a1491ac32e732c93773354e4e665794ed4d490","externalIds":{"MAG":"3035038672","DBLP":"journals/corr/abs-2004-12993","ArXiv":"2004.12993","ACL":"2020.acl-main.204","DOI":"10.18653/v1/2020.acl-main.204","CorpusId":216552850},"title":"DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference"},{"paperId":"af6ef2e9fabf493d399ef6d542b135d05b2dd02f","externalIds":{"DBLP":"journals/www/WangLZQHLL21","MAG":"3155986400","ArXiv":"2004.11147","DOI":"10.1007/s11280-021-00878-3","CorpusId":216080515},"title":"Binarized graph neural network"},{"paperId":"c5cc2340766d68ece08bb1520d357bcf8c03ad48","externalIds":{"DBLP":"conf/acl/SchwartzSSDS20","MAG":"3016791490","ArXiv":"2004.07453","ACL":"2020.acl-main.593","DOI":"10.18653/v1/2020.acl-main.593","CorpusId":215785895},"title":"The Right Tool for the Job: Matching Model and Instance Complexities"},{"paperId":"0171ad4cc87cc7db25b4ec3169e293eed9a13b39","externalIds":{"MAG":"3017022649","DBLP":"journals/corr/abs-2004-07320","ArXiv":"2004.07320","CorpusId":215814169},"title":"Training with Quantization Noise for Extreme Model Compression"},{"paperId":"5d34881ff68bd203ff790187e7e5c9e034389cfa","externalIds":{"MAG":"3014568172","DBLP":"journals/corr/abs-2004-02178","ArXiv":"2004.02178","ACL":"2020.acl-main.537","DOI":"10.18653/v1/2020.acl-main.537","CorpusId":214802887},"title":"FastBERT: a Self-distilling BERT with Adaptive Inference Time"},{"paperId":"3bcb17559ce96eb20fa79af8194f4af0380d194a","externalIds":{"DBLP":"journals/corr/abs-2003-08271","MAG":"3088409176","ArXiv":"2003.08271","DOI":"10.1007/s11431-020-1647-3","CorpusId":212747830},"title":"Pre-trained models for natural language processing: A survey"},{"paperId":"a6be0ce5af23feabe24be9cd270003f84adc49d3","externalIds":{"MAG":"3011666637","DBLP":"conf/cvpr/YangHCSDH20","ArXiv":"2003.07326","DOI":"10.1109/cvpr42600.2020.00244","CorpusId":212725240},"title":"Resolution Adaptive Networks for Efficient Inference"},{"paperId":"a48fd38cc34f8ffe9bcf043eafe11289627dd91a","externalIds":{"MAG":"3011655242","ArXiv":"2003.05689","DBLP":"journals/corr/abs-2003-05689","CorpusId":212675087},"title":"Hyper-Parameter Optimization: A Review of Algorithms and Applications"},{"paperId":"a1b8a8df281bbaec148a897927a49ea47ea31515","externalIds":{"MAG":"3009561768","DBLP":"journals/corr/abs-2003-04297","ArXiv":"2003.04297","CorpusId":212633993},"title":"Improved Baselines with Momentum Contrastive Learning"},{"paperId":"7af72a461ed7cda180e7eab878efd5f35d79bbf4","externalIds":{"DBLP":"conf/icml/ChenK0H20","MAG":"3034978746","ArXiv":"2002.05709","CorpusId":211096730},"title":"A Simple Framework for Contrastive Learning of Visual Representations"},{"paperId":"2e27f119e6fcc5477248eb0f4a6abe8d7cf4f6e7","externalIds":{"DBLP":"conf/emnlp/XuZGWZ20","MAG":"3101248447","ArXiv":"2002.02925","ACL":"2020.emnlp-main.633","DOI":"10.18653/v1/2020.emnlp-main.633","CorpusId":211066200},"title":"BERT-of-Theseus: Compressing BERT by Progressive Module Replacing"},{"paperId":"0e488f4f83303868b9fa9f807c4ad5c703fd7d61","externalIds":{"MAG":"2997224071","DBLP":"journals/corr/abs-2002-01775","ArXiv":"2002.01775","CorpusId":209319166},"title":"Feature-map-level Online Adversarial Knowledge Distillation"},{"paperId":"495da6f19baa09c6db3697d839e10432cdc25934","externalIds":{"MAG":"3001434439","ArXiv":"2001.08210","DBLP":"journals/corr/abs-2001-08210","DOI":"10.1162/tacl_a_00343","CorpusId":210861178},"title":"Multilingual Denoising Pre-training for Neural Machine Translation"},{"paperId":"055fd6a9f7293269f1b22c1470e63bd02d8d9500","externalIds":{"DBLP":"journals/corr/abs-2001-04451","MAG":"2994673210","ArXiv":"2001.04451","CorpusId":209315300},"title":"Reformer: The Efficient Transformer"},{"paperId":"25db56fc85fe15625c3375064a35e908ba6dfd2a","externalIds":{"ArXiv":"2001.04063","DBLP":"conf/emnlp/QiYGLDCZ020","ACL":"2020.findings-emnlp.217","MAG":"2999210089","DOI":"10.18653/v1/2020.findings-emnlp.217","CorpusId":210164665},"title":"ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training"},{"paperId":"029c31eee72ee0eb4d3058d48e276a2710f92325","externalIds":{"DBLP":"journals/corr/abs-2001-01536","MAG":"3096121526","ArXiv":"2001.01536","DOI":"10.1007/978-3-030-58558-7_15","CorpusId":209862398},"title":"Learning From Multiple Experts: Self-paced Knowledge Distillation for Long-tailed Classification"},{"paperId":"69599593f93023e2f91ef6673ee9860f85777d98","externalIds":{"MAG":"2998030011","DBLP":"conf/iclr/Dong020","ArXiv":"2001.00326","CorpusId":209531937},"title":"NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search"},{"paperId":"35d39c2f61277a89d09dc899fa467ade6a3789af","externalIds":{"ArXiv":"1912.00350","MAG":"2996970889","DBLP":"journals/corr/abs-1912-00350","DOI":"10.1609/AAAI.V34I04.5746","CorpusId":208526905},"title":"Online Knowledge Distillation with Diverse Peers"},{"paperId":"7cf7eac260e2f187a2fbe2321dd5478c5747a0a2","externalIds":{"ArXiv":"1912.00120","MAG":"2991340425","DBLP":"journals/corr/abs-1912-00120","CorpusId":208527060},"title":"One-Shot Pruning of Recurrent Neural Networks by Jacobian Spectrum Evaluation"},{"paperId":"40922d386116975853a743b1d810c1e0f03e886a","externalIds":{"ArXiv":"1911.07013","DBLP":"conf/nips/Xu0ZZL19","MAG":"2984542546","CorpusId":202763816},"title":"Understanding and Improving Layer Normalization"},{"paperId":"add2f205338d70e10ce5e686df4a690e2851bdfc","externalIds":{"DBLP":"conf/cvpr/He0WXG20","MAG":"2987283559","ArXiv":"1911.05722","DOI":"10.1109/cvpr42600.2020.00975","CorpusId":207930212},"title":"Momentum Contrast for Unsupervised Visual Representation Learning"},{"paperId":"354c59ebdec84c180c5288cb0088097983bf6307","externalIds":{"ACL":"D19-1367","DBLP":"conf/emnlp/JiangHXZZ19","MAG":"2970463839","DOI":"10.18653/v1/D19-1367","CorpusId":202785477},"title":"Improved Differentiable Architecture Search for Language Modeling and Named Entity Recognition"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"4585611042d2be0d997ee135e3fe219d668db9ec","externalIds":{"MAG":"2981757109","DBLP":"conf/iclr/ElbayadGGA20","ArXiv":"1910.10073","CorpusId":204824061},"title":"Depth-Adaptive Transformer"},{"paperId":"b3ea2d9c8e5ea3b87ace121f0bece71565abc187","externalIds":{"ArXiv":"1910.09700","MAG":"2981540061","DBLP":"journals/corr/abs-1910-09700","CorpusId":204823751},"title":"Quantifying the Carbon Emissions of Machine Learning"},{"paperId":"132ae47905b1a648c095da54b8533e87cf642897","externalIds":{"MAG":"3012638462","ACL":"2020.findings-emnlp.1","ArXiv":"1910.10485","DBLP":"conf/emnlp/PratoCR20","DOI":"10.18653/v1/2020.findings-emnlp.1","CorpusId":215862562},"title":"Fully Quantized Transformer for Machine Translation"},{"paperId":"4d8a4509753cc91832f80ec35795064e79630ef3","externalIds":{"MAG":"3015982254","CorpusId":216377474},"title":"Structured Pruning of a BERT-based Question Answering Model"},{"paperId":"b6b2ebcd2f1b25ca87813832a60ab056c008e31d","externalIds":{"MAG":"2979567256","DBLP":"conf/aaai/AguilarLZYFG20","ArXiv":"1910.03723","DOI":"10.1609/AAAI.V34I05.6229","CorpusId":203953149},"title":"Knowledge Distillation from Internal Representations"},{"paperId":"70fe1f854bc59092ded4bf2939a6624a80e5e4c3","externalIds":{"MAG":"2977720775","DBLP":"journals/corr/abs-1910-02054","CorpusId":203736482},"title":"ZeRO: Memory Optimization Towards Training A Trillion Parameter Models"},{"paperId":"b9b7b37d7edf4482a6f440e282c3418ab1913afa","externalIds":{"MAG":"2883111419","DBLP":"journals/pami/LuoZZXWL19","DOI":"10.1109/TPAMI.2018.2858232","CorpusId":51717116,"PubMed":"30040622"},"title":"ThiNet: Pruning CNN Filters for a Thinner Net"},{"paperId":"7a064df1aeada7e69e5173f7d4c8606f4470365b","externalIds":{"MAG":"2996428491","DBLP":"journals/corr/abs-1909-11942","ArXiv":"1909.11942","CorpusId":202888986},"title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"},{"paperId":"f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1","externalIds":{"MAG":"2996159613","DBLP":"conf/iclr/FanGJ20","ArXiv":"1909.11556","CorpusId":202750230},"title":"Reducing Transformer Depth on Demand with Structured Dropout"},{"paperId":"cfa1a6eff349cec56323a0f39ae028dbcb4841a4","externalIds":{"ArXiv":"1909.10754","DBLP":"journals/corr/abs-1909-10754","MAG":"2975451647","CorpusId":202734312},"title":"FEED: Feature-level Ensemble for Knowledge Distillation"},{"paperId":"3242bf8767179c13c7322ccfdbe18c66c1e25a99","externalIds":{"DBLP":"conf/iclr/ZelaESMBH20","ArXiv":"1909.09656","MAG":"2996012599","CorpusId":202719611},"title":"Understanding and Robustifying Differentiable Architecture Search"},{"paperId":"d47f600c2e306be7b8e85e0ab8be70704574ff0c","externalIds":{"DBLP":"journals/corr/abs-1909-09569","ArXiv":"1909.09569","MAG":"2996481211","CorpusId":202712898},"title":"Understanding Architectures Learnt by Cell-based Neural Architecture Search"},{"paperId":"48530f3d6425f2f150f07ccdd61ba951951a0a7d","externalIds":{"ACL":"D19-1165","MAG":"2970925270","DBLP":"journals/corr/abs-1909-08478","ArXiv":"1909.08478","DOI":"10.18653/v1/D19-1165","CorpusId":202660912},"title":"Simple, Scalable Adaptation for Neural Machine Translation"},{"paperId":"ae677b0441bfaea0e0c78acfa8758fff353ab715","externalIds":{"MAG":"2972176762","ArXiv":"1909.03341","DBLP":"conf/aaai/WangCG20","DOI":"10.1609/AAAI.V34I05.6451","CorpusId":202539075},"title":"Neural Machine Translation with Byte-Level Subwords"},{"paperId":"9010dac82f989210723308c547517c48e0ed650b","externalIds":{"MAG":"3100127252","DBLP":"journals/corr/abs-1909-02107","ArXiv":"1909.02107","DOI":"10.1145/3394486.3403059","CorpusId":202537711},"title":"Compositional Embeddings Using Complementary Partitions for Memory-Efficient Recommendation Systems"},{"paperId":"d0086b86103a620a86bc918746df0aa642e2a8a3","externalIds":{"DBLP":"journals/corr/abs-1909-01066","MAG":"2996758945","ArXiv":"1909.01066","ACL":"D19-1250","DOI":"10.18653/v1/D19-1250","CorpusId":202539551},"title":"Language Models as Knowledge Bases?"},{"paperId":"9a618cca0d2fc78db1be1aed70517401cb3f3859","externalIds":{"MAG":"2970900903","DBLP":"journals/corr/abs-1909-01377","ArXiv":"1909.01377","CorpusId":202539738},"title":"Deep Equilibrium Models"},{"paperId":"259377d035e5651f7d79486828a59e85c3e77938","externalIds":{"ArXiv":"1908.09982","DBLP":"journals/corr/abs-1908-09982","MAG":"2970418186","CorpusId":201646599},"title":"On the Effectiveness of Low-Rank Matrix Factorization for LSTM Model Compression"},{"paperId":"7823292e5c4b05c47af91ab6ddf671a0da709e82","externalIds":{"MAG":"2994749257","DBLP":"journals/corr/abs-1908-09791","ArXiv":"1908.09791","CorpusId":201666112},"title":"Once for All: Train One Network and Specialize it for Efficient Deployment"},{"paperId":"80cf2a6af4200ecfca1c18fc89de16148f1cd4bf","externalIds":{"DBLP":"conf/emnlp/SunCGL19","MAG":"2969515962","ACL":"D19-1441","ArXiv":"1908.09355","DOI":"10.18653/v1/D19-1441","CorpusId":201670719},"title":"Patient Knowledge Distillation for BERT Model Compression"},{"paperId":"2bc1c8bd00bbf7401afcb5460277840fd8bab029","externalIds":{"ArXiv":"1908.06066","DBLP":"journals/corr/abs-1908-06066","MAG":"2998356391","DOI":"10.1609/AAAI.V34I07.6795","CorpusId":201058752},"title":"Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training"},{"paperId":"65a9c7b0800c86a196bc14e7621ff895cc6ab287","externalIds":{"MAG":"2966715458","DBLP":"journals/corr/abs-1908-02265","ArXiv":"1908.02265","CorpusId":199453025},"title":"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"},{"paperId":"d56c1fc337fb07ec004dc846f80582c327af717c","externalIds":{"MAG":"2995923603","DBLP":"conf/iclr/0225BYWXBPS20","ArXiv":"1908.04577","CorpusId":199552081},"title":"StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding"},{"paperId":"f6390beca54411b06f3bde424fb983a451789733","externalIds":{"MAG":"2970777192","ArXiv":"1909.00015","DBLP":"journals/corr/abs-1909-00015","ACL":"D19-1223","DOI":"10.18653/v1/D19-1223","CorpusId":202538495},"title":"Adaptively Sparse Transformers"},{"paperId":"81f5810fbbab9b7203b9556f4ce3c741875407bc","externalIds":{"DBLP":"journals/corr/abs-1907-10529","ACL":"2020.tacl-1.5","MAG":"2962753370","ArXiv":"1907.10529","DOI":"10.1162/tacl_a_00300","CorpusId":198229624},"title":"SpanBERT: Improving Pre-training by Representing and Predicting Spans"},{"paperId":"9fe3cebb4454abc5d3bcfcad9c3228fbacdbdb08","externalIds":{"MAG":"2964161024","ArXiv":"1907.09682","DBLP":"journals/corr/abs-1907-09682","DOI":"10.1109/ICCV.2019.00145","CorpusId":198179476},"title":"Similarity-Preserving Knowledge Distillation"},{"paperId":"b959851238988b4683092f0bcb38d2e9c6957c1f","externalIds":{"DBLP":"conf/bmvc/LeeS19","ArXiv":"1907.02226","MAG":"2954901156","CorpusId":195847947},"title":"Graph-based Knowledge Distillation by Multi-head Attention Network"},{"paperId":"edee0c50542cf8744bf4e7d604f41b7824b8a525","externalIds":{"DBLP":"conf/icmcs/HeJDYY19","MAG":"2966048335","DOI":"10.1109/ICME.2019.00236","CorpusId":199488694},"title":"Towards Better Uncertainty Sampling: Active Learning with Multiple Views for Deep Convolutional Neural Network"},{"paperId":"62dc8ddb4907db4b889c5e93673d9b3c189d1f25","externalIds":{"DBLP":"conf/nips/MaZZDHZ019","ArXiv":"1906.09777","MAG":"2970213198","CorpusId":195345467},"title":"A Tensorized Transformer for Language Modeling"},{"paperId":"2ff41a463a374b138bb5a012e5a32bc4beefec20","externalIds":{"MAG":"2952370363","DBLP":"journals/corr/abs-1906-08101","CorpusId":195068911},"title":"Pre-Training with Whole Word Masking for Chinese BERT"},{"paperId":"e0c6abdbdecf04ffac65c440da77fb9d66bb474c","externalIds":{"MAG":"2950813464","DBLP":"journals/corr/abs-1906-08237","ArXiv":"1906.08237","CorpusId":195069387},"title":"XLNet: Generalized Autoregressive Pretraining for Language Understanding"},{"paperId":"97f4d09175705be4677d675fa27e55defac44800","externalIds":{"DBLP":"journals/corr/abs-1906-05849","ArXiv":"1906.05849","MAG":"2949517790","DOI":"10.1007/978-3-030-58621-8_45","CorpusId":189762205},"title":"Contrastive Multiview Coding"},{"paperId":"85e3010ff82c07961bc21f63b91a4981fa5123fe","externalIds":{"MAG":"2979736514","CorpusId":208121296},"title":"Neural transfer learning for natural language processing"},{"paperId":"d6a083dad7114f3a39adc65c09bfbb6cf3fee9ea","externalIds":{"ArXiv":"1906.02243","MAG":"2963809228","DBLP":"journals/corr/abs-1906-02243","ACL":"P19-1355","DOI":"10.18653/v1/P19-1355","CorpusId":174802812},"title":"Energy and Policy Considerations for Deep Learning in NLP"},{"paperId":"3366e9eb81880d172752d4397cb8e9e6de02b935","externalIds":{"DBLP":"journals/corr/abs-1906-00532","ArXiv":"1906.00532","MAG":"2947946877","CorpusId":173990430},"title":"Efficient 8-Bit Quantization of Transformer Neural Machine Language Translation Model"},{"paperId":"7e488d0ad51fba6b1cde75c439af3052e9d405f3","externalIds":{"DBLP":"conf/cvpr/WangYZF19","ArXiv":"1906.03609","MAG":"2948527124","DOI":"10.1109/CVPR.2019.00507","CorpusId":182952755},"title":"Distilling Object Detectors With Fine-Grained Feature Imitation"},{"paperId":"fe8907302f9d14233cd03cc2948a1c4e2a50bdb6","externalIds":{"MAG":"2979680761","DBLP":"conf/cvpr/DongY19","ArXiv":"1910.04465","DOI":"10.1109/CVPR.2019.00186","CorpusId":198903996},"title":"Searching for a Robust Neural Architecture in Four GPU Hours"},{"paperId":"5a3749929bf5fb8b1f98a7b2a43c3b957bcf6c88","externalIds":{"MAG":"2945667196","DBLP":"conf/icml/GongHLQWL19","CorpusId":174799716},"title":"Efficient Training of BERT by Progressively Stacking"},{"paperId":"4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9","externalIds":{"DBLP":"conf/icml/TanL19","MAG":"2946948417","ArXiv":"1905.11946","CorpusId":167217261},"title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"},{"paperId":"07a64686ce8e43ac475a8d820a8a9f1d87989583","externalIds":{"MAG":"2951528897","DBLP":"journals/corr/abs-1905-09418","ACL":"P19-1580","ArXiv":"1905.09418","DOI":"10.18653/v1/P19-1580","CorpusId":162183964},"title":"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned"},{"paperId":"3cee801d10f410f0feb1a2390776a01ba2765001","externalIds":{"DBLP":"journals/corr/abs-1905-05702","ArXiv":"1905.05702","ACL":"P19-1146","MAG":"2950858167","DOI":"10.18653/v1/P19-1146","CorpusId":153313159},"title":"Sparse Sequence-to-Sequence Models"},{"paperId":"8e22a4d2d6af1d21d29fdb875ca8b55fcfa69bf0","externalIds":{"ArXiv":"1905.03677","MAG":"2956371155","DBLP":"conf/cvpr/YooK19","DOI":"10.1109/CVPR.2019.00018","CorpusId":148571749},"title":"Learning Loss for Active Learning"},{"paperId":"1c71771c701aadfd72c5866170a9f5d71464bb88","externalIds":{"MAG":"2971274815","ArXiv":"1905.03197","DBLP":"journals/corr/abs-1905-03197","CorpusId":147704286},"title":"Unified Language Model Pre-training for Natural Language Understanding and Generation"},{"paperId":"5e19eba1e6644f7c83f607383d256deea71f87ae","externalIds":{"DBLP":"conf/iccv/HowardPALSCWCTC19","ArXiv":"1905.02244","MAG":"2944779197","DOI":"10.1109/ICCV.2019.00140","CorpusId":146808333},"title":"Searching for MobileNetV3"},{"paperId":"b03c7ff961822183bab66b2e594415e585d3fd09","externalIds":{"ArXiv":"1905.10650","MAG":"2945767825","DBLP":"conf/nips/MichelLN19","CorpusId":166227946},"title":"Are Sixteen Heads Really Better than One?"},{"paperId":"21da617a0f79aabf94272107184606cefe90ab75","externalIds":{"ArXiv":"1904.10509","DBLP":"journals/corr/abs-1904-10509","MAG":"2940744433","CorpusId":129945531},"title":"Generating Long Sequences with Sparse Transformers"},{"paperId":"b50995cb56ffb0f8a72aea996a93e149baa74836","externalIds":{"MAG":"2938998646","ArXiv":"1904.09058","DBLP":"journals/corr/abs-1904-09058","DOI":"10.1109/ICPR48806.2021.9412615","CorpusId":125950115},"title":"Feature Fusion for Online Mutual Knowledge Distillation"},{"paperId":"031e4e43aaffd7a479738dcea69a2d5be7957aa3","externalIds":{"DBLP":"journals/corr/abs-1904-09223","MAG":"2938830017","ArXiv":"1904.09223","CorpusId":125977708},"title":"ERNIE: Enhanced Representation through Knowledge Integration"},{"paperId":"7b0ed3d67375a4542133c992f4e55fd4ade0cd90","externalIds":{"ArXiv":"1904.09149","MAG":"2981819252","DBLP":"conf/iccv/JinPWLLLYH19","DOI":"10.1109/ICCV.2019.00143","CorpusId":125985701},"title":"Knowledge Distillation via Route Constrained Optimization"},{"paperId":"6dd986b2621d7f420ca80be5b71e12dece41e877","externalIds":{"MAG":"2907029635","DBLP":"conf/iclr/LiuPS19","ArXiv":"1904.05878","CorpusId":69629714},"title":"Knowledge Flow: Improve Upon Your Teachers"},{"paperId":"92ebadf9913e6800331e5f9b2699812fe77313ff","externalIds":{"DBLP":"journals/corr/abs-1904-05835","MAG":"2951513317","ArXiv":"1904.05835","DOI":"10.1109/CVPR.2019.00938","CorpusId":118649278},"title":"Variational Information Distillation for Knowledge Transfer"},{"paperId":"c4696d47e0d43a6761742e15c262a224466c4b85","externalIds":{"ArXiv":"1904.01802","MAG":"2927723982","DBLP":"conf/iccv/PengJLZWLZ019","DOI":"10.1109/ICCV.2019.00511","CorpusId":102483463},"title":"Correlation Congruence for Knowledge Distillation"},{"paperId":"f6c7b4252426607211824d5b0bac0edc8393a401","externalIds":{"MAG":"2796155151","DBLP":"journals/spic/ZhouLLCZ19","DOI":"10.1016/J.IMAGE.2018.03.017","CorpusId":58198993},"title":"Tensor rank learning in CP decomposition via convolutional neural network"},{"paperId":"17298b0b53c0b62b737f8c7c086b428f4f3b5057","externalIds":{"ACL":"N19-1313","MAG":"2962943802","DBLP":"journals/corr/abs-1903-08788","ArXiv":"1903.08788","DOI":"10.18653/v1/N19-1313","CorpusId":84843987},"title":"Selective Attention for Context-aware Neural Machine Translation"},{"paperId":"450a99659e083f5ac2f0fef9abbd9336b3470c3b","externalIds":{"DBLP":"conf/iccv/YuH19","ArXiv":"1903.05134","MAG":"2981698279","DOI":"10.1109/ICCV.2019.00189","CorpusId":76660361},"title":"Universally Slimmable Networks and Improved Training Techniques"},{"paperId":"88bd75ce3ce22ed85bf9271877aa85da7b7bb312","externalIds":{"ArXiv":"1903.00089","ACL":"N19-1388","DBLP":"conf/naacl/AharoniJF19","MAG":"2919290281","DOI":"10.18653/v1/N19-1388","CorpusId":67855815},"title":"Massively Multilingual Neural Machine Translation"},{"paperId":"bc6dfc6bda2d929fec91042dce1831fd07999b39","externalIds":{"MAG":"2997006708","ArXiv":"1902.03393","DBLP":"conf/aaai/MirzadehFLLMG20","DOI":"10.1609/AAAI.V34I04.5963","CorpusId":212908749},"title":"Improved Knowledge Distillation via Teacher Assistant"},{"paperId":"29ddc1f43f28af7c846515e32cc167bc66886d0c","externalIds":{"DBLP":"journals/corr/abs-1902-00751","ArXiv":"1902.00751","MAG":"2964303773","CorpusId":59599816},"title":"Parameter-Efficient Transfer Learning for NLP"},{"paperId":"1b24b7b4ac2427d20ab60c8451563eb8d99caf9c","externalIds":{"MAG":"2952650870","ArXiv":"1902.10461","DBLP":"journals/corr/abs-1902-10461","CorpusId":67856276},"title":"Multilingual Neural Machine Translation with Knowledge Distillation"},{"paperId":"359cdea86e4203f73de4c12356fd9139dba9a745","externalIds":{"MAG":"2963125457","DBLP":"conf/iclr/SavareseM19","ArXiv":"1902.09701","CorpusId":53408116},"title":"Learning Implicitly Recurrent CNNs Through Parameter Sharing"},{"paperId":"16c844fd4d97f3c6eb38b0d6527c87d184efedc3","externalIds":{"MAG":"2952355681","DBLP":"conf/icml/SoLL19","ArXiv":"1901.11117","CorpusId":59523610},"title":"The Evolved Transformer"},{"paperId":"66689c77f6f129db754e08ff1609229359b4a37a","externalIds":{"MAG":"2913686627","DBLP":"journals/corr/abs-1901-10008","ArXiv":"1901.10008","CorpusId":59336234},"title":"The OoO VLIW JIT Compiler for GPU Inference"},{"paperId":"96c82727dd5a80fef93007f888bb8569feb6bd85","externalIds":{"MAG":"2907121943","ArXiv":"1901.09321","DBLP":"journals/corr/abs-1901-09321","CorpusId":59317031},"title":"Fixup Initialization: Residual Learning Without Normalization"},{"paperId":"c4744a7c2bb298e4a52289a1e085c71cc3d37bc6","externalIds":{"ArXiv":"1901.02860","DBLP":"conf/acl/DaiYYCLS19","MAG":"2964110616","ACL":"P19-1285","DOI":"10.18653/v1/P19-1285","CorpusId":57759363},"title":"Transformer-XL: Attentive Language Models beyond a Fixed-Length Context"},{"paperId":"cf0a995aed9e2e1dff6d0b0d7ea526ddd84fe137","externalIds":{"MAG":"2963047948","ArXiv":"1812.11446","DBLP":"journals/corr/abs-1812-11446","CorpusId":57189514},"title":"Greedy Layerwise Learning Can Scale to ImageNet"},{"paperId":"120ffccea4787b88f78b55b9302891ff96cb4228","externalIds":{"MAG":"2952416103","DBLP":"conf/iclr/YuYXYH19","ArXiv":"1812.08928","CorpusId":56657799},"title":"Slimmable Neural Networks"},{"paperId":"45532bffbfbb5553da0b2d0844e95a1b37e59147","externalIds":{"ArXiv":"1812.03443","DBLP":"conf/cvpr/WuDZWSWTVJK19","MAG":"2904699287","DOI":"10.1109/CVPR.2019.01099","CorpusId":54461508},"title":"FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search"},{"paperId":"6da29d5ef77c9c5d1eef7ec1a09d0495e313bedc","externalIds":{"MAG":"2901489275","ArXiv":"1811.07083","DBLP":"journals/corr/abs-1811-07083","CorpusId":53712372},"title":"PydMobileNet: Improved Version of MobileNets with Pyramid Depthwise Separable Convolution"},{"paperId":"8cb3000e8959d1065532d54a07cf8fe97ef6b9c6","externalIds":{"MAG":"2950537613","ArXiv":"1811.03233","DBLP":"conf/aaai/HeoLY019a","DOI":"10.1609/AAAI.V33I01.33013779","CorpusId":53213211},"title":"Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons"},{"paperId":"06f75859afc6192f99ea708f19a641b0bb93e1ce","externalIds":{"DBLP":"journals/corr/abs-1810-10999","MAG":"2891927334","ArXiv":"1810.10999","CorpusId":53022928},"title":"Reversible Recurrent Neural Networks"},{"paperId":"5f6a87289ef0977073e49aa4460f6018de89e14c","externalIds":{"DBLP":"journals/corr/abs-1810-08854","ArXiv":"1810.08854","MAG":"2952978663","ACL":"N19-1362","DOI":"10.18653/v1/N19-1362","CorpusId":53046959},"title":"pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence Inference"},{"paperId":"a3143eaa68040d366848a9c324b29d3f56f97a5d","externalIds":{"MAG":"2951244744","DBLP":"conf/icml/KayaHD19","CorpusId":147703951},"title":"Shallow-Deep Networks: Understanding and Mitigating Network Overthinking"},{"paperId":"a2980c4ab69e017e72ca36db0ac3a0a427ff1aee","externalIds":{"DBLP":"conf/iclr/AlizadehFLG19","MAG":"2924522543","CorpusId":108364915},"title":"An Empirical study of Binary Neural Networks' Optimisation"},{"paperId":"cf440ccce4a7a8681e238b4f26d5b95109add55d","externalIds":{"MAG":"2963247446","DBLP":"conf/iclr/LeeAT19","ArXiv":"1810.02340","CorpusId":52920837},"title":"SNIP: Single-shot Network Pruning based on Connection Sensitivity"},{"paperId":"4a1004ecd34118116344633c7cdcc34493c423ee","externalIds":{"MAG":"2951569836","DBLP":"conf/iclr/LiuSZHD19","ArXiv":"1810.05270","CorpusId":52978527},"title":"Rethinking the Value of Network Pruning"},{"paperId":"f323407464c4cd492d3fc1afd7170eab08f44d9b","externalIds":{"DBLP":"journals/corr/abs-1812-00332","MAG":"2950483360","ArXiv":"1812.00332","CorpusId":54438210},"title":"ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware"},{"paperId":"e73b0250971586e7d5a2ff71254a8acc60f9715a","externalIds":{"MAG":"2888429796","ArXiv":"1808.07233","DBLP":"journals/corr/abs-1808-07233","CorpusId":52071151},"title":"Neural Architecture Optimization"},{"paperId":"990a7b4eceedb6e053e6386269481bdfc42a1094","externalIds":{"MAG":"2888296173","DBLP":"journals/tacl/ReddyCM19","ACL":"Q19-1016","ArXiv":"1808.07042","DOI":"10.1162/tacl_a_00266","CorpusId":52055325},"title":"CoQA: A Conversational Question Answering Challenge"},{"paperId":"6e5f2c7d1092d733ae85c269bf12e47755b90368","externalIds":{"DBLP":"journals/corr/abs-1808-04752","MAG":"2886014761","ArXiv":"1808.04752","CorpusId":52005096},"title":"A Survey on Methods and Theories of Quantized Neural Networks"},{"paperId":"693c97ecedb0a84539b7162c95e89fa3cd84ca73","externalIds":{"ArXiv":"1807.11626","DBLP":"conf/cvpr/TanCPVSHL19","MAG":"2886953980","DOI":"10.1109/CVPR.2019.00293","CorpusId":51891697},"title":"MnasNet: Platform-Aware Neural Architecture Search for Mobile"},{"paperId":"ea0e55bb82feceef4b8b828dc5ccdb50beff761a","externalIds":{"MAG":"2951613551","ArXiv":"1807.06819","DBLP":"conf/eccv/LeeKS18","DOI":"10.1007/978-3-030-01231-1_21","CorpusId":49869692},"title":"Self-supervised Knowledge Distillation Using Singular Value Decomposition"},{"paperId":"ac4dafdef1d2b685b7f28a11837414573d39ff4e","externalIds":{"DBLP":"conf/iclr/DehghaniGVUK19","MAG":"2866343820","ArXiv":"1807.03819","CorpusId":49667762},"title":"Universal Transformers"},{"paperId":"b227f3e4c0dc96e5ac5426b85485a70f2175a205","externalIds":{"MAG":"2842511635","DBLP":"journals/corr/abs-1807-03748","ArXiv":"1807.03748","CorpusId":49670925},"title":"Representation Learning with Contrastive Predictive Coding"},{"paperId":"2980bea598e2208b08e0996a114400415785debd","externalIds":{"DBLP":"conf/icmcs/XuSYTM18","MAG":"2903177883","DOI":"10.1109/ICMEW.2018.8551584","CorpusId":54437565},"title":"Greedy Layer-Wise Training of Long Short Term Memory Networks"},{"paperId":"89012572d4a39a948f23a664e2b9eb2d0546ac99","externalIds":{"ArXiv":"1807.02314","MAG":"2952366972","DBLP":"journals/corr/abs-1807-02314","DOI":"10.24963/ijcai.2018/589","CorpusId":49655412},"title":"Jumper: Learning When to Make Classification Decision in Reading"},{"paperId":"d8c941f049a1850191c41ee5aa6ed2333d786334","externalIds":{"DBLP":"conf/ijcai/ChenJKFY18","MAG":"2962791778","DOI":"10.24963/ijcai.2018/88","CorpusId":51608407},"title":"Sharing Residual Units Through Collective Tensor Factorization To Improve Deep Neural Networks"},{"paperId":"c1f457e31b611da727f9aef76c283a18157dfa83","externalIds":{"DBLP":"journals/corr/abs-1806-09055","MAG":"2810075754","ArXiv":"1806.09055","CorpusId":49411844},"title":"DARTS: Differentiable Architecture Search"},{"paperId":"bd8bf10edff7d2224e4eecbd63038c9e3c531590","externalIds":{"MAG":"2963689957","ArXiv":"1806.06950","DBLP":"conf/nips/ChenSLCH18","CorpusId":49317942},"title":"GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking"},{"paperId":"4d1c856275744c0284312a3a50efb6ca9dc4cd4c","externalIds":{"MAG":"2963323070","ACL":"P18-2124","ArXiv":"1806.03822","DBLP":"journals/corr/abs-1806-03822","DOI":"10.18653/v1/P18-2124","CorpusId":47018994},"title":"Know What You Don’t Know: Unanswerable Questions for SQuAD"},{"paperId":"f358437f4bb69152b34e2d7c0adac012e0e0d68c","externalIds":{"ACL":"C18-1263","DBLP":"journals/corr/abs-1806-03280","ArXiv":"1806.03280","MAG":"2953106567","CorpusId":47005349},"title":"Multilingual Neural Machine Translation with Task-Specific Attention"},{"paperId":"e81c70bc8b81797645332e5db726add973a5633a","externalIds":{"MAG":"2798820905","DBLP":"conf/cvpr/BeluchGNK18","DOI":"10.1109/CVPR.2018.00976","CorpusId":52838058},"title":"The Power of Ensembles for Active Learning in Image Classification"},{"paperId":"c864e3785a9aecf25296781c272980eaed78e51a","externalIds":{"MAG":"2949140874","DBLP":"conf/nips/LanZG18","ArXiv":"1806.04606","CorpusId":48352434},"title":"Knowledge Distillation by On-the-Fly Native Ensemble"},{"paperId":"521ebc310afd88a2672f0af5f77dd4e6ec5c994f","externalIds":{"MAG":"2807448149","DBLP":"journals/corr/abs-1806-02375","ArXiv":"1806.02375","CorpusId":46956723},"title":"Understanding Batch Normalization"},{"paperId":"cb0f3ee1e98faf92429d601cdcd76c69c1e484eb","externalIds":{"DBLP":"journals/tacl/WarstadtSB19","ArXiv":"1805.12471","MAG":"2978670439","DOI":"10.1162/tacl_a_00290","CorpusId":44072099},"title":"Neural Network Acceptability Judgments"},{"paperId":"94be567c32ae76bdaadabd4975807a94181e39b3","externalIds":{"DBLP":"journals/corr/abs-1805-11604","MAG":"2963184555","ArXiv":"1805.11604","CorpusId":53104146},"title":"How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)"},{"paperId":"451d4a16e425ecbf38c4b1cca0dcf5d9bec8255c","externalIds":{"MAG":"2963310665","DBLP":"conf/emnlp/WangSMHLB18","ACL":"W18-5446","ArXiv":"1804.07461","DOI":"10.18653/v1/W18-5446","CorpusId":5034059},"title":"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"},{"paperId":"7b29f45df975ed1e4c3864b6ab4483f11086aa76","externalIds":{"MAG":"2798081680","DBLP":"conf/naacl/QiSFPN18","ArXiv":"1804.06323","ACL":"N18-2084","DOI":"10.18653/v1/N18-2084","CorpusId":4929974},"title":"When and Why Are Pre-Trained Word Embeddings Useful for Neural Machine Translation?"},{"paperId":"a74eacdd133918f82b953fc8dcd615ddca7efdfa","externalIds":{"ArXiv":"1803.05651","MAG":"2794137799","DBLP":"journals/corr/abs-1803-05651","CorpusId":3897289},"title":"Word2Bits - Quantized Word Vectors"},{"paperId":"21937ecd9d66567184b83eca3d3e09eb4e6fbd60","externalIds":{"ArXiv":"1803.03635","MAG":"2951099858","DBLP":"conf/iclr/FrankleC19","CorpusId":53388625},"title":"The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks"},{"paperId":"d23a1cd6c73e3e43295c3585b3db147eb1c3ee91","externalIds":{"DBLP":"journals/corr/abs-1803-01719","MAG":"2953382923","ArXiv":"1803.01719","CorpusId":3710662},"title":"How to Start Training: The Effect of Initialization and Architecture"},{"paperId":"c9b61aab2ce451612b1df245af80efd480dd3468","externalIds":{"DBLP":"conf/emc2/ShengFZ00A18","MAG":"2790621718","ArXiv":"1803.08607","DOI":"10.1109/EMC2.2018.00011","CorpusId":4303893},"title":"A Quantization-Friendly Separable Convolution for MobileNets"},{"paperId":"e54a7bf9b5f610a2c19e058e005296049e180aad","externalIds":{"MAG":"2952032007","DBLP":"conf/icml/SrinivasF18","ArXiv":"1803.00443","CorpusId":3603145},"title":"Knowledge Transfer with Jacobian Matching"},{"paperId":"114c1ed1ae2e2a4b3d775c5a55d2c916f9d85972","externalIds":{"DBLP":"journals/corr/abs-1802-09841","ArXiv":"1802.09841","MAG":"2788686132","CorpusId":3550773},"title":"Adversarial Active Learning for Deep Networks: a Margin Based Approach"},{"paperId":"3febb2bed8865945e7fddc99efd791887bb7e14f","externalIds":{"DBLP":"journals/corr/abs-1802-05365","MAG":"2949856395","ArXiv":"1802.05365","ACL":"N18-1202","DOI":"10.18653/v1/N18-1202","CorpusId":3626819},"title":"Deep Contextualized Word Representations"},{"paperId":"cc59b4b1eb7d4629f753bc24f029c5cced301381","externalIds":{"MAG":"2950692601","DBLP":"journals/corr/abs-1804-03235","ArXiv":"1804.03235","CorpusId":2331610},"title":"Large scale distributed neural network training through online distillation"},{"paperId":"f6a4bf043af1a9ec7f104a7b7ab56806b241ceda","externalIds":{"MAG":"2787752464","DBLP":"conf/iclr/PolinoPA18","ArXiv":"1802.05668","CorpusId":3323727},"title":"Model compression via distillation and quantization"},{"paperId":"acdf151b8efc2c6b05662d69f27531afc557dc85","externalIds":{"DBLP":"journals/corr/abs-1802-04680","MAG":"2787513570","ArXiv":"1802.04680","CorpusId":3603886},"title":"Training and Inference with Integers in Deep Neural Networks"},{"paperId":"1717255b6aea01fe956cef998abbc3c399b5d7cf","externalIds":{"MAG":"2886851211","DBLP":"conf/eccv/HeLLWLH18","ArXiv":"1802.03494","DOI":"10.1007/978-3-030-01234-2_48","CorpusId":52048008},"title":"AMC: AutoML for Model Compression and Acceleration on Mobile Devices"},{"paperId":"fe9b8aac9fa3bfd9724db5a881a578e471e612d7","externalIds":{"ArXiv":"1802.03268","DBLP":"conf/icml/PhamGZLD18","MAG":"2953209204","CorpusId":3638969},"title":"Efficient Neural Architecture Search via Parameter Sharing"},{"paperId":"50bdda28de3dcf82a0e10f9ec13eea248b19edb5","externalIds":{"MAG":"2785430118","DBLP":"journals/corr/abs-1802-01548","ArXiv":"1802.01548","DOI":"10.1609/aaai.v33i01.33014780","CorpusId":3640974},"title":"Regularized Evolution for Image Classifier Architecture Search"},{"paperId":"9f58a7e844cd15d8aef8b2de7f246979ababe429","externalIds":{"MAG":"2963534679","DBLP":"conf/nips/KimPK18","ArXiv":"1802.04977","CorpusId":3608236},"title":"Paraphrasing Complex Network: Network Compression via Factor Transfer"},{"paperId":"0269073e07faaafa4df7b3d7ddac96e6dccf853d","externalIds":{"DBLP":"journals/corr/abs-1801-05746","MAG":"2782757030","ArXiv":"1801.05746","DOI":"10.1007/978-3-030-64340-9_15","CorpusId":1385457},"title":"TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation"},{"paperId":"ca45e17cf41cf1fd0aa7c9536f0a27bc0f4d3b33","externalIds":{"DBLP":"journals/corr/abs-1801-04380","MAG":"2783292547","ArXiv":"1801.04380","DOI":"10.1145/3178487.3178491","CorpusId":3385866},"title":"Superneurons: dynamic GPU memory management for training deep neural networks"},{"paperId":"dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4","externalIds":{"MAG":"2949261999","ArXiv":"1801.04381","DBLP":"conf/cvpr/SandlerHZZC18","DOI":"10.1109/CVPR.2018.00474","CorpusId":4555207},"title":"MobileNetV2: Inverted Residuals and Linear Bottlenecks"},{"paperId":"59d0d7ccec2db66cad20cac5721ce54a8a058294","externalIds":{"DBLP":"journals/corr/abs-1712-05877","ArXiv":"1712.05877","MAG":"2963122961","DOI":"10.1109/CVPR.2018.00286","CorpusId":39867659},"title":"Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"},{"paperId":"5f79398057bf0bbda9ff50067bc1f2950c2a2266","externalIds":{"MAG":"2963821229","DBLP":"journals/corr/abs-1712-00559","ArXiv":"1712.00559","DOI":"10.1007/978-3-030-01246-5_2","CorpusId":40430109},"title":"Progressive Neural Architecture Search"},{"paperId":"9e34a9afb4a0236de1b85b9f0bca3ba615691be8","externalIds":{"MAG":"2884751099","DBLP":"journals/ijcv/VeitB20","ArXiv":"1711.11503","DOI":"10.1007/s11263-019-01190-4","CorpusId":50780153},"title":"Convolutional Networks with Adaptive Inference Graphs"},{"paperId":"f37ea0b173dd0403a5028c12746082d31dff60bb","externalIds":{"MAG":"2951813005","DBLP":"journals/corr/abs-1711-09485","ArXiv":"1711.09485","DOI":"10.1007/978-3-030-01261-8_25","CorpusId":21110409},"title":"SkipNet: Learning Dynamic Routing in Convolutional Networks"},{"paperId":"e16cfe727e27be27115d0f842375c46e7e3f384b","externalIds":{"DBLP":"journals/corr/abs-1711-08393","MAG":"2770042371","ArXiv":"1711.08393","DOI":"10.1109/CVPR.2018.00919","CorpusId":13739860},"title":"BlockDrop: Dynamic Inference Paths in Residual Networks"},{"paperId":"56257b0804c9c2418b32337d3af0970f7b67b084","externalIds":{"MAG":"2767785892","ArXiv":"1711.02782","DBLP":"journals/corr/abs-1711-02782","CorpusId":25717514},"title":"Block-Sparse Recurrent Neural Networks"},{"paperId":"4bf6ce4a9366cdba069a45651606538f2febd8e6","externalIds":{"DBLP":"journals/corr/abs-1711-01068","MAG":"2962790997","ArXiv":"1711.01068","CorpusId":3523429},"title":"Compressing Word Embeddings via Deep Compositional Code Learning"},{"paperId":"1e4cfedd79a108d0d04cc498bb146e4dcd4b5f0a","externalIds":{"ArXiv":"1711.02085","MAG":"2963758799","DBLP":"conf/iclr/SeoMFH18","CorpusId":3140413},"title":"Neural Speed Reading via Skim-RNN"},{"paperId":"c4cca330ec7289fac16d0793da98f705f6513219","externalIds":{"MAG":"2765390540","ArXiv":"1710.09505","DBLP":"journals/corr/abs-1710-09505","CorpusId":6757659},"title":"Knowledge Projection for Deep Neural Networks"},{"paperId":"7647a06965d868a4f6451bef0818994100a142e8","externalIds":{"DBLP":"journals/corr/abs-1709-04109","MAG":"2962676330","ArXiv":"1709.04109","DOI":"10.1609/aaai.v32i1.12006","CorpusId":19232497},"title":"Empower Sequence Labeling with Task-Aware Neural Language Model"},{"paperId":"fcd30321fc03931c71afd95606698f481adf1663","externalIds":{"DBLP":"journals/csl/FiratCSYB17","MAG":"2552124255","DOI":"10.1016/j.csl.2016.10.006","CorpusId":38478980},"title":"Multi-way, multilingual neural machine translation"},{"paperId":"67250ea195589d9dad29bcbb17219d7447a23597","externalIds":{"DBLP":"conf/icip/RanganathanVCP17","MAG":"2789833952","DOI":"10.1109/ICIP.2017.8297020","CorpusId":1978135},"title":"Deep active learning for image classification"},{"paperId":"ae8d5be3caea59a21221f02ef04d49a86cb80191","externalIds":{"ArXiv":"1708.06834","DBLP":"journals/corr/abs-1708-06834","MAG":"2749590927","CorpusId":1859294},"title":"Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks"},{"paperId":"19d0bca130f4f6eabaf35f82589462dc799adbcc","externalIds":{"DBLP":"conf/premi/GrachevIS17","MAG":"3099559063","ArXiv":"1708.05963","DOI":"10.1007/978-3-319-69900-4_44","CorpusId":10128251},"title":"Neural Networks Compression for Language Modeling"},{"paperId":"3c4b6f59a4dd9b6fb589abb826d063f7872a5808","externalIds":{"MAG":"2743289088","DBLP":"conf/kdd/YouX0T17","DOI":"10.1145/3097983.3098135","CorpusId":26021416},"title":"Learning from Multiple Teacher Networks"},{"paperId":"2fd1d5d7cbbe8ec9b1efa45c4e4ce5ac1e5249f9","externalIds":{"MAG":"2951045284","DBLP":"conf/bmvc/DongLN17","ArXiv":"1708.01001","DOI":"10.5244/C.31.189","CorpusId":39143557},"title":"Learning Accurate Low-Bit Deep Neural Networks with Stochastic Quantization"},{"paperId":"c342c71cb23199f112d0bc644fcce56a7306bf94","externalIds":{"MAG":"2774918944","DBLP":"conf/iclr/SenerS18","CorpusId":3383786},"title":"Active Learning for Convolutional Neural Networks: A Core-Set Approach"},{"paperId":"a23fa96e7217ba0e9405d9e1fe3cdedd57b6e096","externalIds":{"DBLP":"journals/corr/abs-1708-00055","ACL":"S17-2001","MAG":"3104033643","ArXiv":"1708.00055","DOI":"10.18653/v1/S17-2001","CorpusId":4421747},"title":"SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation"},{"paperId":"c085682ffa152a3b85da9c72bb6b9d271db46c88","externalIds":{"ArXiv":"1707.06990","MAG":"2737788279","DBLP":"journals/corr/PleissCHLMW17","CorpusId":21370953},"title":"Memory-Efficient Implementation of DenseNets"},{"paperId":"0410659b6a311b281d10e0e44abce9b1c06be462","externalIds":{"DBLP":"conf/cvpr/YimJBK17","MAG":"2739879705","DOI":"10.1109/CVPR.2017.754","CorpusId":206596723},"title":"A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning"},{"paperId":"ee53c9480132fc0d09b1192226cb2c460462fd6d","externalIds":{"ArXiv":"1707.06168","DBLP":"journals/corr/HeZS17","MAG":"2737121650","DOI":"10.1109/ICCV.2017.155","CorpusId":20157893},"title":"Channel Pruning for Accelerating Very Deep Neural Networks"},{"paperId":"3a6d4cd0768ae8768e733280d362bdb4d25924e7","externalIds":{"DBLP":"journals/corr/GomezRUG17","MAG":"2963684275","ArXiv":"1707.04585","CorpusId":8869447},"title":"The Reversible Residual Network: Backpropagation Without Storing Activations"},{"paperId":"43ef6f1b1c0622a23bc62af5a05dd5c813eba00d","externalIds":{"MAG":"2736885633","DBLP":"conf/rep4nlp/ShenYLKA17","ArXiv":"1707.05928","ACL":"W17-2630","DOI":"10.18653/v1/W17-2630","CorpusId":3278107},"title":"Deep Active Learning for Named Entity Recognition"},{"paperId":"46c112747fb44f82d3096c07c6d8a8faeee8b3d4","externalIds":{"DBLP":"journals/jair/RuderVS19","MAG":"2769280657","ArXiv":"1706.04902","DOI":"10.1613/jair.1.11640","CorpusId":26127787},"title":"A Survey of Cross-lingual Word Embedding Models"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"ac8744e5d994a8ac48c075c587059b1cb518c6e2","externalIds":{"MAG":"2951249057","ArXiv":"1706.00885","DBLP":"journals/corr/WangLCTG17","CorpusId":6227528},"title":"IDK Cascades: Fast Deep Learning by Learning not to Overthink"},{"paperId":"f06a12928307e17b1aff2b9f4a6c11791f19b6a7","externalIds":{"ArXiv":"1706.00384","DBLP":"conf/cvpr/ZhangXHL18","MAG":"2951168573","DOI":"10.1109/CVPR.2018.00454","CorpusId":26071966},"title":"Deep Mutual Learning"},{"paperId":"ba6b48ef52e2432a0d6342381e0863fd82a8687b","externalIds":{"MAG":"2963502387","DBLP":"journals/corr/NiculaeB17","ArXiv":"1705.07704","CorpusId":20600085},"title":"A Regularized Framework for Sparse and Structured Neural Attention"},{"paperId":"81607da4b18bd7ee838afc1ab9894e3c1d836ccc","externalIds":{"DBLP":"journals/corr/Kumar17","MAG":"2611453176","ArXiv":"1704.08863","CorpusId":11589817},"title":"On weight initialization in deep neural networks"},{"paperId":"c25a67ad7e8629a9d12b9e2fc356cd73af99a060","externalIds":{"MAG":"2951061692","ArXiv":"1704.06877","DBLP":"conf/acl/YuLL17","ACL":"P17-1172","DOI":"10.18653/v1/P17-1172","CorpusId":1762731},"title":"Learning to Skim Text"},{"paperId":"5ded2b8c64491b4a67f6d39ce473d4b9347a672e","externalIds":{"DBLP":"journals/corr/WilliamsNB17","MAG":"2963846996","ArXiv":"1704.05426","ACL":"N18-1101","DOI":"10.18653/v1/N18-1101","CorpusId":3432876},"title":"A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference"},{"paperId":"3647d6d0f151dc05626449ee09cc7bce55be497e","externalIds":{"DBLP":"journals/corr/HowardZCKWWAA17","ArXiv":"1704.04861","MAG":"2612445135","CorpusId":12670695},"title":"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"},{"paperId":"1cc2f313bcb3b106af081f7031b924c9ad2662bd","externalIds":{"MAG":"2963847166","DBLP":"conf/iclr/NarangDSE17","ArXiv":"1704.05119","CorpusId":10135357},"title":"Exploring Sparsity in Recurrent Neural Networks"},{"paperId":"668db48c6a79826456341680ee1175dfc4cced71","externalIds":{"MAG":"2952913664","DBLP":"journals/corr/SeeLM17","ArXiv":"1704.04368","ACL":"P17-1099","DOI":"10.18653/v1/P17-1099","CorpusId":8314118},"title":"Get To The Point: Summarization with Pointer-Generator Networks"},{"paperId":"125ccd810f43f1cba83c6681836d000f83d1886d","externalIds":{"DBLP":"conf/iclr/HuangCLWMW18","MAG":"2950014519","CorpusId":3475998},"title":"Multi-Scale Dense Networks for Resource Efficient Image Classification"},{"paperId":"fcc12426e4143b787cd0c1d3c910bade05d8773f","externalIds":{"MAG":"2604607385","ArXiv":"1703.07115","DBLP":"journals/corr/KulkarniK17","CorpusId":10880444},"title":"Layer-wise training of deep networks using kernel similarity"},{"paperId":"1a0912bb76777469295bb2c059faee907e7f3258","externalIds":{"ArXiv":"1703.06870","CorpusId":54465873},"title":"Mask R-CNN"},{"paperId":"1342c1e1684620c019972e2679d5131f1e8a4a13","externalIds":{"DBLP":"journals/corr/TarvainenV17","ArXiv":"1703.01780","MAG":"2645998928","CorpusId":2759724},"title":"Weight-averaged consistency targets improve semi-supervised deep learning results"},{"paperId":"73d3049bdea29e312a39e01e2e90add853b05fbd","externalIds":{"ArXiv":"1702.07811","MAG":"2953187876","DBLP":"conf/icml/BolukbasiWDS17","CorpusId":6750751},"title":"Adaptive Neural Networks for Efficient Inference"},{"paperId":"6e99c98a45fb09b5a777cfb7821b0df51acac665","externalIds":{"DBLP":"journals/corr/RuderGB17","ArXiv":"1702.02052","MAG":"2586087033","CorpusId":9644084},"title":"Knowledge Adaptation: Teaching to Adapt"},{"paperId":"7944d0b061610b1c67ad15efdf192681e60d0129","externalIds":{"DBLP":"conf/cvpr/FigurnovCZZHVS17","ArXiv":"1612.02297","MAG":"2562731582","DOI":"10.1109/CVPR.2017.194","CorpusId":10569278},"title":"Spatially Adaptive Computation Time for Residual Networks"},{"paperId":"a6d7f57f683be52ccf8d24ce21e72e2b44514511","externalIds":{"ArXiv":"1612.01452","MAG":"2560696501","DBLP":"journals/corr/SimonRD16","CorpusId":2062545},"title":"ImageNet pre-trained models with batch normalization"},{"paperId":"896de8418884f4aab1ae4a60027500c9e8baffc3","externalIds":{"MAG":"2610140147","DBLP":"conf/icpr/Teerapittayanon16","ArXiv":"1709.01686","DOI":"10.1109/ICPR.2016.7900006","CorpusId":2916466},"title":"BranchyNet: Fast inference via early exiting from deep neural networks"},{"paperId":"5b5415352b9e7e11941339502adc04e9f6c9bd1c","externalIds":{"ArXiv":"1611.10176","DBLP":"journals/corr/HeWZWYZZ16","MAG":"2557257847","CorpusId":2558156},"title":"Effective Quantization Methods for Recurrent Neural Networks"},{"paperId":"2d9604cdc3ef786b50b53aaf440d451ad16e7fb9","externalIds":{"ACL":"2016.iwslt-1.6","MAG":"2555745756","DBLP":"conf/iwslt/HaNW16","ArXiv":"1611.04798","CorpusId":5234044},"title":"Toward Multilingual Neural Machine Translation with Universal Encoder and Decoder"},{"paperId":"a486e2839291111bb44fa1f07731ada123539f75","externalIds":{"MAG":"2951184134","DBLP":"journals/corr/JohnsonSLKWCTVW16","ACL":"Q17-1024","ArXiv":"1611.04558","DOI":"10.1162/tacl_a_00065","CorpusId":260464809},"title":"Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation"},{"paperId":"ade0c116120b54b57a91da51235108b75c28375a","externalIds":{"DBLP":"conf/emnlp/HashimotoXTS17","MAG":"2556468274","ArXiv":"1611.01587","ACL":"D17-1206","DOI":"10.18653/v1/D17-1206","CorpusId":2213896},"title":"A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks"},{"paperId":"f7b032a4df721d4ed2bab97f6acd33d62477b7a5","externalIds":{"MAG":"2949829435","DBLP":"journals/corr/ZagoruykoK16a","ArXiv":"1612.03928","CorpusId":829159},"title":"Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer"},{"paperId":"189e6bb7523733c4e524214b9e6ae92d4ed50dac","externalIds":{"DBLP":"journals/corr/YangSC17","MAG":"2950938254","ArXiv":"1703.06345","CorpusId":17984798},"title":"Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks"},{"paperId":"3db8730c203f88d7f08a6a99e8c02a077dc9b011","externalIds":{"DBLP":"conf/iclr/MolchanovTKAK17","MAG":"2707890836","CorpusId":17240902},"title":"Pruning Convolutional Neural Networks for Resource Efficient Inference"},{"paperId":"6d749712ef4f02a87f4e362058469a1da46c8bcc","externalIds":{"DBLP":"journals/corr/ChoiEL16","MAG":"2963935227","ArXiv":"1612.01543","CorpusId":17299045},"title":"Towards the Limit of Network Quantization"},{"paperId":"6746a18b2820f757334f75bc95428b3ea58d6603","externalIds":{"DBLP":"journals/corr/JerniteGJM16","ArXiv":"1611.06188","MAG":"2556046966","CorpusId":2514328},"title":"Variable Computation in Recurrent Neural Networks"},{"paperId":"5b6ec746d309b165f9f9def873a2375b6fb40f3d","externalIds":{"MAG":"2531409750","ArXiv":"1610.02357","DBLP":"journals/corr/Chollet16a","DOI":"10.1109/CVPR.2017.195","CorpusId":2375110},"title":"Xception: Deep Learning with Depthwise Separable Convolutions"},{"paperId":"8c8a7513cfd1e66144a1771bf4e29b7388c57bb3","externalIds":{"ACL":"D16-1104","DBLP":"journals/corr/JoshiTPBC16","MAG":"2952072734","ArXiv":"1610.00883","DOI":"10.18653/v1/D16-1104","CorpusId":5094895},"title":"Are Word Embedding-based Features Useful for Sarcasm Detection?"},{"paperId":"d2e4147eecae6f914e9e1e9aece8fdd2eaed809f","externalIds":{"ArXiv":"1609.07061","MAG":"2524428287","DBLP":"journals/corr/HubaraCSEB16","CorpusId":15817277},"title":"Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations"},{"paperId":"c636a2dd242908fe2e598a1077c0c57bfdea8633","externalIds":{"MAG":"3100621615","ArXiv":"1609.05284","DBLP":"journals/corr/ShenHGC16","DOI":"10.1145/3097983.3098177","CorpusId":6300274},"title":"ReasoNet: Learning to Stop Reading in Machine Comprehension"},{"paperId":"c2a1cb1612ba21e067a5c3ba478a8d73b796b77a","externalIds":{"MAG":"2515385951","ArXiv":"1608.08710","DBLP":"conf/iclr/0022KDSG17","CorpusId":14089312},"title":"Pruning Filters for Efficient ConvNets"},{"paperId":"7874340679ed0d90ce33b090ab875d0094a8e709","externalIds":{"MAG":"2512629640","ArXiv":"1608.06902","DBLP":"journals/corr/OttLZLB16","CorpusId":6555379},"title":"Recurrent Neural Networks With Limited Numerical Precision"},{"paperId":"63e39cdf1ad884da6bc69096bb3413b5b1100559","externalIds":{"DBLP":"journals/corr/PressW16","MAG":"2963347649","ArXiv":"1608.05859","ACL":"E17-2025","DOI":"10.18653/V1/E17-2025","CorpusId":836219},"title":"Using the Output Embedding to Improve Language Models"},{"paperId":"977bf40fe28f773b95d6802e694505beac78441d","externalIds":{"DBLP":"journals/corr/WangLF16b","MAG":"2963419583","DOI":"10.1109/ICCVW.2017.71","CorpusId":4755702},"title":"Factorized Convolutional Neural Networks"},{"paperId":"a6a0946c91209001e6d179717f6a49126c836623","externalIds":{"ArXiv":"1610.03950","MAG":"2510403588","ACL":"P16-1022","DBLP":"conf/acl/ChenMXLJ16","DOI":"10.18653/v1/P16-1022","CorpusId":14401063},"title":"Compressing Neural Language Models by Sparse Word Representations"},{"paperId":"03ad06583c9721855ccd82c3d969a01360218d86","externalIds":{"MAG":"2516255829","DBLP":"conf/acl/SogaardG16","ACL":"P16-2038","DOI":"10.18653/v1/P16-2038","CorpusId":16661147},"title":"Deep multi-task learning with low level tasks supervised at lower layers"},{"paperId":"05dd7254b632376973f3a1b4d39485da17814df5","externalIds":{"DBLP":"journals/corr/RajpurkarZLL16","MAG":"2963748441","ACL":"D16-1264","ArXiv":"1606.05250","DOI":"10.18653/v1/D16-1264","CorpusId":11816014},"title":"SQuAD: 100,000+ Questions for Machine Comprehension of Text"},{"paperId":"f61e9fd5a4878e1493f7a6b03774a61c17b7e9a4","externalIds":{"ArXiv":"1606.03401","DBLP":"conf/nips/GruslysMDLG16","MAG":"2423581336","CorpusId":12775860},"title":"Memory-Efficient Backpropagation Through Time"},{"paperId":"230579a14d54ae00073d6c3522ffcef313320be9","externalIds":{"ACL":"K16-1029","ArXiv":"1606.09274","MAG":"2963643655","DBLP":"journals/corr/SeeLM16","DOI":"10.18653/v1/K16-1029","CorpusId":2973141},"title":"Compression of Neural Machine Translation Models via Pruning"},{"paperId":"942deb7d865b7782c03176d95e3a0d56cb71009e","externalIds":{"DBLP":"journals/corr/ChenXZG16","ArXiv":"1604.06174","MAG":"2338908902","CorpusId":15865278},"title":"Training Deep Nets with Sublinear Memory Cost"},{"paperId":"bee7127aaa42ba266c939b65eec20dc66be4592c","externalIds":{"DBLP":"conf/acl/UpadhyayFDR16","MAG":"2962795068","ACL":"P16-1157","ArXiv":"1604.00425","DOI":"10.18653/v1/P16-1157","CorpusId":5357629},"title":"Cross-lingual Models of Word Embeddings: An Empirical Comparison"},{"paperId":"04cca8e341a5da42b29b0bc831cb25a0f784fa01","externalIds":{"DBLP":"journals/corr/Graves16","ArXiv":"1603.08983","MAG":"2325237720","CorpusId":8224916},"title":"Adaptive Computation Time for Recurrent Neural Networks"},{"paperId":"b649a98ce77ece8cd7638bb74ab77d22d9be77e7","externalIds":{"MAG":"2528650362","ArXiv":"1603.05279","DBLP":"journals/corr/RastegariORF16","DOI":"10.1007/978-3-319-46493-0_32","CorpusId":14925907},"title":"XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks"},{"paperId":"4d070993cb75407b285e14cb8aac0077624ef4d9","externalIds":{"DBLP":"journals/corr/Costa-JussaF16","MAG":"2950393281","ACL":"P16-2058","ArXiv":"1603.00810","DOI":"10.18653/v1/P16-2058","CorpusId":1712853},"title":"Character-based Neural Machine Translation"},{"paperId":"3d2c6941a9b4608ba52b328369a3352db2092ae0","externalIds":{"MAG":"2284050935","DBLP":"conf/nips/SalimansK16","ArXiv":"1602.07868","CorpusId":151231},"title":"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks"},{"paperId":"592d2e65489f23ebd993dbdc0c84eda9ac8aadbe","externalIds":{"ArXiv":"1602.07360","DBLP":"journals/corr/IandolaMAHDK16","MAG":"2279098554","CorpusId":14136028},"title":"SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size"},{"paperId":"b5c26ab8767d046cb6e32d959fdf726aee89bb62","externalIds":{"DBLP":"conf/aaai/SzegedyIVA17","MAG":"2952505871","ArXiv":"1602.07261","DOI":"10.1609/aaai.v31i1.11231","CorpusId":1023605},"title":"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"},{"paperId":"b4929ef46d86b92753362bdd1aa7b6e3e03e6214","externalIds":{"MAG":"2279034837","DBLP":"journals/corr/Long0J16","ArXiv":"1602.04433","CorpusId":745350},"title":"Unsupervised Domain Adaptation with Residual Transfer Networks"},{"paperId":"2f2d8f8072e5cc9b296fad551f65f183bdbff7aa","externalIds":{"DBLP":"journals/corr/JozefowiczVSSW16","ArXiv":"1602.02410","MAG":"2259472270","CorpusId":260422},"title":"Exploring the Limits of Language Modeling"},{"paperId":"c1e3a26fb88c6720f4e84b7118e6f2df7dc8efa3","externalIds":{"MAG":"2963123301","DBLP":"journals/corr/MartinsA16","ArXiv":"1602.02068","CorpusId":16432551},"title":"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification"},{"paperId":"9ed9bff37ec952134564b3b2a022b7aba9479ff2","externalIds":{"DBLP":"journals/corr/FiratCB16","ArXiv":"1601.01073","MAG":"2229833550","ACL":"N16-1101","DOI":"10.18653/v1/N16-1101","CorpusId":6359641},"title":"Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism"},{"paperId":"759956bb98689dbcc891528636d8994e54318f85","externalIds":{"DBLP":"journals/corr/ChenGA15","MAG":"2963932686","ArXiv":"1512.04906","ACL":"P16-1186","DOI":"10.18653/v1/P16-1186","CorpusId":6035643},"title":"Strategies for Training Large Vocabulary Neural Language Models"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"4ca3b996d888d7178dbbf9855bb2ab253bdfa43d","externalIds":{"MAG":"2177847924","ArXiv":"1511.06530","DBLP":"journals/corr/KimPYCYS15","CorpusId":15602035},"title":"Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications"},{"paperId":"d76c07211479e233f7c6a6f32d5346c983c5598f","externalIds":{"MAG":"2172589779","ArXiv":"1511.06114","DBLP":"journals/corr/LuongLSVK15","CorpusId":6954272},"title":"Multi-task Sequence to Sequence Learning"},{"paperId":"97dc8df45972e4ed7423fc992a5092ba25b33411","externalIds":{"MAG":"2178237821","ArXiv":"1511.06422","DBLP":"journals/corr/MishkinM15","CorpusId":2780493},"title":"All you need is a good init"},{"paperId":"a5733ff08daff727af834345b9cfff1d0aa109ec","externalIds":{"MAG":"2949401648","DBLP":"conf/nips/CourbariauxBD15","ArXiv":"1511.00363","CorpusId":1518846},"title":"BinaryConnect: Training Deep Neural Networks with binary weights during propagations"},{"paperId":"49bc9ff4b6109a8fc35ba84602d182870bfce10d","externalIds":{"MAG":"2208150243","DBLP":"journals/corr/WangWXY15","ArXiv":"1510.05041","DOI":"10.1145/2925426.2926256","CorpusId":14691112},"title":"BLASX: A High Performance Level-3 BLAS Library for Heterogeneous Multi-GPU Computing"},{"paperId":"7e9469418f8cca348c766c801691931767f5e800","externalIds":{"DBLP":"conf/codes/ParkKKKKYY15","MAG":"2133796295","DOI":"10.1109/CODESISSS.2015.7331375","CorpusId":265339},"title":"Big/little deep neural network for ultra low power inference"},{"paperId":"642d0f49b7826adcf986616f4af77e736229990f","externalIds":{"MAG":"2119144962","DBLP":"journals/corr/HanMD15","ArXiv":"1510.00149","CorpusId":2134321},"title":"Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"},{"paperId":"1ac30af5522c7a50ec4d1ee43fd2bd8652a9bd52","externalIds":{"MAG":"2952820801","ArXiv":"1509.00685","DBLP":"journals/corr/RushCW15","ACL":"D15-1044","DOI":"10.18653/v1/D15-1044","CorpusId":1918428},"title":"A Neural Attention Model for Abstractive Sentence Summarization"},{"paperId":"1518039b5001f1836565215eb047526b3ac7f462","externalIds":{"DBLP":"conf/acl/SennrichHB16a","ACL":"P16-1162","MAG":"1816313093","ArXiv":"1508.07909","DOI":"10.18653/v1/P16-1162","CorpusId":1114678},"title":"Neural Machine Translation of Rare Words with Subword Units"},{"paperId":"891ce1687e2befddd19f54e4eef1d3f39c8dbaf7","externalIds":{"DBLP":"journals/corr/KimJSR15","ArXiv":"1508.06615","MAG":"2951559648","DOI":"10.1609/aaai.v30i1.10362","CorpusId":686481},"title":"Character-Aware Neural Language Models"},{"paperId":"b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d","externalIds":{"DBLP":"journals/corr/SrinivasB15","MAG":"992687842","ArXiv":"1507.06149","DOI":"10.5244/C.29.31","CorpusId":15647317},"title":"Data-free Parameter Pruning for Deep Neural Networks"},{"paperId":"83cf4b2f39bcc802b09fd59b69e23068447b26b7","externalIds":{"MAG":"2251743902","DBLP":"conf/acl/DongWHYW15","ACL":"P15-1166","DOI":"10.3115/v1/P15-1166","CorpusId":3666937},"title":"Multi-Task Learning for Multiple Language Translation"},{"paperId":"ea4b9f05d91c91c99a654b623c0ed87de4427ed9","externalIds":{"DBLP":"conf/acl/DuongCBC15","ACL":"P15-2139","MAG":"2251324968","DOI":"10.3115/v1/P15-2139","CorpusId":17263016},"title":"Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser"},{"paperId":"7613d67c7348f746ecaf71c6fd034fd577154050","externalIds":{"MAG":"2952822287","DBLP":"conf/cikm/MouJXL0J16","ArXiv":"1506.04488","DOI":"10.1145/2983323.2983888","CorpusId":8350200},"title":"Distilling Word Embeddings: An Encoding Approach"},{"paperId":"1ff9a37d766e3a4f39757f5e1b235a42dacf18ff","externalIds":{"DBLP":"conf/nips/HanPTD15","MAG":"2951882884","ArXiv":"1506.02626","CorpusId":2238772},"title":"Learning both Weights and Connections for Efficient Neural Network"},{"paperId":"4a6fb70a76968fbb136f370551f720e8d745698c","externalIds":{"MAG":"2140610559","DBLP":"conf/acl/FaruquiTYDS15","ACL":"P15-1144","ArXiv":"1506.02004","DOI":"10.3115/v1/P15-1144","CorpusId":9397697},"title":"Sparse Overcomplete Word Vector Representations"},{"paperId":"424561d8585ff8ebce7d5d07de8dbf7aae5e7270","externalIds":{"MAG":"2953106684","ArXiv":"1506.01497","DBLP":"journals/pami/RenHG017","DOI":"10.1109/TPAMI.2016.2577031","CorpusId":10328909,"PubMed":"27295650"},"title":"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"},{"paperId":"0c908739fbff75f03469d13d4a1a07de3414ee19","externalIds":{"ArXiv":"1503.02531","MAG":"1821462560","DBLP":"journals/corr/HintonVD15","CorpusId":7200347},"title":"Distilling the Knowledge in a Neural Network"},{"paperId":"ca5c766b2d31a1f5ce8896a0a42b40a2bff9323a","externalIds":{"ArXiv":"1502.03240","MAG":"3100332847","DBLP":"journals/corr/ZhengJRVSDHT15","DOI":"10.1109/ICCV.2015.179","CorpusId":1318262},"title":"Conditional Random Fields as Recurrent Neural Networks"},{"paperId":"995c5f5e62614fcb4d2796ad2faab969da51713e","externalIds":{"MAG":"1836465849","ArXiv":"1502.03167","DBLP":"conf/icml/IoffeS15","CorpusId":5808102},"title":"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"},{"paperId":"b7cf49e30355633af2db19f35189410c8515e91f","externalIds":{"DBLP":"journals/corr/GuptaAGN15","MAG":"2950826343","ArXiv":"1502.02551","CorpusId":2547043},"title":"Deep Learning with Limited Numerical Precision"},{"paperId":"d6f2f611da110b5b5061731be3fc4c7f45d8ee23","externalIds":{"MAG":"1677182931","DBLP":"conf/iccv/HeZRS15","ArXiv":"1502.01852","DOI":"10.1109/ICCV.2015.123","CorpusId":13740328},"title":"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification"},{"paperId":"72de1bfa528c9450a57394c900361acf1e85b8d0","externalIds":{"DBLP":"journals/corr/RamsundarKRWKP15","ArXiv":"1502.02072","MAG":"1738019091","CorpusId":2127453},"title":"Massively Multitask Networks for Drug Discovery"},{"paperId":"8250ecbaef057bdb5390ef4e4be798f1523a23f6","externalIds":{"MAG":"1723811852","ArXiv":"1412.7479","DBLP":"journals/corr/VijayanarasimhanSMY14","CorpusId":15147584},"title":"Deep Networks With Large Output Spaces"},{"paperId":"62e348e26976c3ef77909b9af9788ebc2509009a","externalIds":{"MAG":"2951296089","ArXiv":"1412.6553","DBLP":"journals/corr/LebedevGROL14","CorpusId":15002492},"title":"Speeding-up Convolutional Neural Networks Using Fine-tuned CP-Decomposition"},{"paperId":"8604f376633af8b347e31d84c6150a93b11e34c2","externalIds":{"DBLP":"journals/corr/RomeroBKCGB14","MAG":"2964118293","ArXiv":"1412.6550","CorpusId":2723173},"title":"FitNets: Hints for Thin Deep Nets"},{"paperId":"e7bf9803705f2eb608db1e59e5c7636a3f171916","externalIds":{"MAG":"1724438581","DBLP":"journals/corr/GongLYB14","ArXiv":"1412.6115","CorpusId":6251653},"title":"Compressing Deep Convolutional Networks using Vector Quantization"},{"paperId":"30ae2bdef407e7a05b83781907ad7fb257dcd7a1","externalIds":{"DBLP":"journals/corr/JinDC14","MAG":"1650736245","ArXiv":"1412.5474","CorpusId":2868054},"title":"Flattened Convolutional Neural Networks for Feedforward Acceleration"},{"paperId":"feaa7e295c7a43ec52091ed9ade1a9a1e5d9bed2","externalIds":{"DBLP":"conf/nips/SoudryHM14","MAG":"2161758346","CorpusId":14245558},"title":"Expectation Backpropagation: Parameter-Free Training of Multilayer Neural Networks with Continuous or Discrete Weights"},{"paperId":"1938624bb9b0f999536dcc8d8f519810bb4e1b3b","externalIds":{"ACL":"P15-1001","DBLP":"conf/acl/JeanCMB15","MAG":"2100664567","ArXiv":"1412.2007","DOI":"10.3115/v1/P15-1001","CorpusId":2863491},"title":"On Using Very Large Target Vocabulary for Neural Machine Translation"},{"paperId":"081651b38ff7533550a3adfc1c00da333a8fe86c","externalIds":{"DBLP":"conf/nips/YosinskiCBL14","ArXiv":"1411.1792","MAG":"2149933564","CorpusId":362467},"title":"How transferable are features in deep neural networks?"},{"paperId":"f37e1b62a767a307c046404ca96bc140b3e68cb5","externalIds":{"DBLP":"conf/emnlp/PenningtonSM14","ACL":"D14-1162","MAG":"2250539671","DOI":"10.3115/v1/D14-1162","CorpusId":1957433},"title":"GloVe: Global Vectors for Word Representation"},{"paperId":"e15cf50aa89fee8535703b9f9512fca5bfc43327","externalIds":{"DBLP":"journals/corr/SzegedyLJSRAEVR14","MAG":"2097117768","ArXiv":"1409.4842","DOI":"10.1109/CVPR.2015.7298594","CorpusId":206592484},"title":"Going deeper with convolutions"},{"paperId":"e5b21cfe616658a21679a30aad14dade8b71a1ff","externalIds":{"DBLP":"conf/eccv/FreytagRD14","MAG":"2262342046","DOI":"10.1007/978-3-319-10593-2_37","CorpusId":2013441},"title":"Selecting Influential Examples: Active Learning with Expected Model Output Changes"},{"paperId":"eb42cf88027de515750f230b23b1a057dc782108","externalIds":{"MAG":"2949429431","ArXiv":"1409.1556","DBLP":"journals/corr/SimonyanZ14a","CorpusId":14124313},"title":"Very Deep Convolutional Networks for Large-Scale Image Recognition"},{"paperId":"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5","externalIds":{"MAG":"2133564696","ArXiv":"1409.0473","DBLP":"journals/corr/BahdanauCB14","CorpusId":11212020},"title":"Neural Machine Translation by Jointly Learning to Align and Translate"},{"paperId":"c08f5fa876181fc040d76c75fe2433eee3c9b001","externalIds":{"MAG":"2161381512","DBLP":"conf/cvpr/OquabBLS14","DOI":"10.1109/CVPR.2014.222","CorpusId":206592191},"title":"Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks"},{"paperId":"0894b06cff1cd0903574acaa7fcf071b144ae775","externalIds":{"DBLP":"conf/acl/DevlinZHLSM14","MAG":"2251682575","ACL":"P14-1129","DOI":"10.3115/v1/P14-1129","CorpusId":7417943},"title":"Fast and Robust Neural Network Joint Models for Statistical Machine Translation"},{"paperId":"8b156bdce947783b8c7071f02557b414ab7b5276","externalIds":{"DBLP":"conf/acl/LiJ14","ACL":"P14-1038","MAG":"2134033474","DOI":"10.3115/v1/P14-1038","CorpusId":20744},"title":"Incremental Joint Extraction of Entity Mentions and Relations"},{"paperId":"ea9941cf31e3f9b5edf0972d8a3ae9d075c9199b","externalIds":{"DBLP":"conf/icassp/XueLYSG14","MAG":"2056738732","DOI":"10.1109/ICASSP.2014.6854828","CorpusId":12971356},"title":"Singular value decomposition based low-footprint speaker adaptation and personalization for deep neural network"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","externalIds":{"ArXiv":"1405.0312","DBLP":"conf/eccv/LinMBHPRDZ14","MAG":"2952122856","DOI":"10.1007/978-3-319-10602-1_48","CorpusId":14113767},"title":"Microsoft COCO: Common Objects in Context"},{"paperId":"f254cbfe9710de5e41589f8b7898112b06872ed2","externalIds":{"MAG":"1563795667","ArXiv":"1404.1869","DBLP":"journals/corr/IandolaMKGDK14","CorpusId":8803949},"title":"DenseNet: Implementing Efficient ConvNet Descriptor Pyramids"},{"paperId":"e5ae8ab688051931b4814f6d32b18391f8d1fa8d","externalIds":{"MAG":"2950248853","DBLP":"conf/nips/DentonZBLF14","ArXiv":"1404.0736","CorpusId":7340116},"title":"Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation"},{"paperId":"d770060812fb646b3846a7d398a3066145b5e3c8","externalIds":{"MAG":"2134797427","ArXiv":"1312.6184","DBLP":"journals/corr/BaC13","CorpusId":11536917},"title":"Do Deep Nets Really Need to be Deep?"},{"paperId":"99c970348b8f70ce23d6641e201904ea49266b6e","externalIds":{"ArXiv":"1312.6120","MAG":"2953334419","DBLP":"journals/corr/SaxeMG13","CorpusId":17272965},"title":"Exact solutions to the nonlinear dynamics of learning in deep linear neural networks"},{"paperId":"1a2a770d23b4a171fa81de62a78a3deb0588f238","externalIds":{"DBLP":"journals/corr/ZeilerF13","ArXiv":"1311.2901","MAG":"1849277567","DOI":"10.1007/978-3-319-10590-1_53","CorpusId":3960646},"title":"Visualizing and Understanding Convolutional Networks"},{"paperId":"87f40e6f3022adbc1f1905e3e506abad05a9964f","externalIds":{"ArXiv":"1310.4546","MAG":"2950133940","DBLP":"conf/nips/MikolovSCCD13","CorpusId":16447573},"title":"Distributed Representations of Words and Phrases and their Compositionality"},{"paperId":"687bac2d3320083eb4530bf18bb8f8f721477600","externalIds":{"ACL":"D13-1170","DBLP":"conf/emnlp/SocherPWCMNP13","MAG":"2251939518","DOI":"10.18653/v1/d13-1170","CorpusId":990233},"title":"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"},{"paperId":"62c76ca0b2790c34e85ba1cce09d47be317c7235","externalIds":{"ArXiv":"1308.3432","DBLP":"journals/corr/BengioLC13","MAG":"2242818861","CorpusId":18406556},"title":"Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation"},{"paperId":"5a434953b58c72fe2089531d6c4b4fc1325defcb","externalIds":{"DBLP":"conf/cvpr/RigamontiSLF13","MAG":"2121775913","DOI":"10.1109/CVPR.2013.355","CorpusId":430659},"title":"Learning Separable Filters"},{"paperId":"5cea23330c76994cb626df20bed31cc2588033df","externalIds":{"MAG":"2058641082","DBLP":"conf/icassp/SainathKSAR13","DOI":"10.1109/ICASSP.2013.6638949","CorpusId":3334366},"title":"Low-rank matrix factorization for Deep Neural Network training with high-dimensional output targets"},{"paperId":"0a7c4cec908ca18f76f5101578a2496a2dceb5e7","externalIds":{"MAG":"2025198378","DBLP":"conf/icassp/HuangLYDG13","DOI":"10.1109/ICASSP.2013.6639081","CorpusId":6828602},"title":"Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers"},{"paperId":"f6b51c8753a871dc94ff32152c00c01e94f90f09","externalIds":{"MAG":"2950577311","DBLP":"journals/corr/abs-1301-3781","ArXiv":"1301.3781","CorpusId":5959482},"title":"Efficient Estimation of Word Representations in Vector Space"},{"paperId":"abd1c342495432171beb7ca8fd9551ef13cbd0ff","externalIds":{"DBLP":"conf/nips/KrizhevskySH12","MAG":"2618530766","DOI":"10.1145/3065386","CorpusId":195908774},"title":"ImageNet classification with deep convolutional neural networks"},{"paperId":"184ac0766262312ba76bbdece4e7ffad0aa8180b","externalIds":{"DBLP":"journals/pami/BengioCV13","MAG":"2952111767","ArXiv":"1206.5538","DOI":"10.1109/TPAMI.2013.50","CorpusId":393948,"PubMed":"23787338"},"title":"Representation Learning: A Review and New Perspectives"},{"paperId":"91c3130e89d2fd37caface9047389c71de14e2a1","externalIds":{"MAG":"162171320","DBLP":"conf/naacl/HuangFG12","ACL":"N12-1015","CorpusId":367732},"title":"Structured Perceptron with Inexact Search"},{"paperId":"e2b168dbaa57736b31891451163a5c5582d84324","externalIds":{"ACL":"I11-1120","MAG":"2251201446","DBLP":"conf/ijcnlp/GhoshJRT11","CorpusId":9713133},"title":"Shallow Discourse Parsing with Conditional Random Fields"},{"paperId":"128cb6b891aee1b5df099acb48e2efecfcff689f","externalIds":{"DBLP":"conf/aaaiss/Levesque11","MAG":"2267020232","CorpusId":15710851},"title":"The Winograd Schema Challenge"},{"paperId":"bc1022b031dc6c7019696492e8116598097a8c12","externalIds":{"MAG":"2158899491","DBLP":"journals/jmlr/CollobertWBKKK11","ArXiv":"1103.0398","DOI":"10.5555/1953048.2078186","CorpusId":351666},"title":"Natural Language Processing (Almost) from Scratch"},{"paperId":"eb9c924383aca0d137c736a41271d569a12cf518","externalIds":{"MAG":"2129999749","ArXiv":"1011.4088","DBLP":"journals/ftml/SuttonM12","DOI":"10.1561/2200000013","CorpusId":342976},"title":"An Introduction to Conditional Random Fields"},{"paperId":"371bd20afe88e73eafea2298b52beca7b9b5660a","externalIds":{"ACL":"N10-1069","MAG":"2138302120","DBLP":"conf/naacl/McDonaldHM10","CorpusId":7747592},"title":"Distributed Training Strategies for the Structured Perceptron"},{"paperId":"e3ce36b9deb47aa6bb2aa19c4bfa71283b505025","externalIds":{"DBLP":"journals/jmlr/GutmannH10","MAG":"2152790380","CorpusId":15816723},"title":"Noise-contrastive estimation: A new estimation principle for unnormalized statistical models"},{"paperId":"ea9d2a2b4ce11aaf85136840c65f3bc9c03ab649","externalIds":{"MAG":"2606251538","DBLP":"journals/jmlr/GlorotB10","CorpusId":5575601},"title":"Understanding the difficulty of training deep feedforward neural networks"},{"paperId":"87e43e9eba01a4eb03436c9946bf6aa031a5d5af","externalIds":{"MAG":"2024165284","DBLP":"journals/siamrev/KoldaB09","DOI":"10.1137/07070111X","CorpusId":16074195},"title":"Tensor Decompositions and Applications"},{"paperId":"065985d4d0854c51f52ad7a7507b267d9b88ab1c","externalIds":{"DBLP":"conf/cvpr/JoshiPP09","MAG":"2124244761","DOI":"10.1109/CVPR.2009.5206627","CorpusId":6764656},"title":"Multi-class active learning for image classification"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","externalIds":{"DBLP":"conf/cvpr/DengDSLL009","MAG":"2108598243","DOI":"10.1109/CVPR.2009.5206848","CorpusId":57246310},"title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"a9fc84f8abe740cdc7ee82e69444d1d00dbe0ceb","externalIds":{"DBLP":"conf/nips/MnihH08","MAG":"2131462252","CorpusId":10097073},"title":"A Scalable Hierarchical Distributed Language Model"},{"paperId":"699d5ab38deee78b1fd17cc8ad233c74196d16e9","externalIds":{"DBLP":"journals/tnn/BengioS08","MAG":"2152808281","DOI":"10.1109/TNN.2007.912312","CorpusId":9147661,"PubMed":"18390314"},"title":"Adaptive Importance Sampling to Accelerate Training of a Neural Probabilistic Language Model"},{"paperId":"355d44f53428b1ac4fb2ab468d593c720640e5bd","externalIds":{"MAG":"2540556213","DBLP":"conf/nips/BengioLPL06","DOI":"10.7551/mitpress/7503.003.0024","CorpusId":14201947},"title":"Greedy Layer-Wise Training of Deep Networks"},{"paperId":"30c9bb327b7f2b9f1d1e5b69b9d0c97b410948d9","externalIds":{"MAG":"2294370754","DBLP":"conf/kdd/BucilaCN06","DOI":"10.1145/1150402.1150464","CorpusId":11253972},"title":"Model compression"},{"paperId":"8978cf7574ceb35f4c3096be768c7547b28a35d0","externalIds":{"DBLP":"journals/neco/HintonOT06","MAG":"2136922672","DOI":"10.1162/neco.2006.18.7.1527","CorpusId":2309950,"PubMed":"16764513"},"title":"A Fast Learning Algorithm for Deep Belief Nets"},{"paperId":"7c5bae29a266a7a67228c0a9b051961bc48ed4db","externalIds":{"MAG":"2581852757","DBLP":"conf/icml/NguyenS04","DOI":"10.1145/1015330.1015349","CorpusId":1438975},"title":"Active learning using pre-clustering"},{"paperId":"9fb7b636edeaf344394fdf37481d7b83eec75358","externalIds":{"MAG":"2107634464","DBLP":"conf/icip/LienhartM02","DOI":"10.1109/ICIP.2002.1038171","CorpusId":11554984},"title":"An extended set of Haar-like features for rapid object detection"},{"paperId":"dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63","externalIds":{"MAG":"2164598857","DBLP":"conf/cvpr/ViolaJ01","DOI":"10.1109/CVPR.2001.990517","CorpusId":2715202},"title":"Rapid object detection using a boosted cascade of simple features"},{"paperId":"8d314c440a537f9338358ef1fa3cc49664c98d8a","externalIds":{"DBLP":"conf/iccv/ViolaJ01","MAG":"2137401668","DOI":"10.1023/B:VISI.0000013087.49260.fb","CorpusId":2796017},"title":"Robust Real-Time Face Detection"},{"paperId":"838f77a43d05d53f6617edb4aa4e4cb07cf1984f","externalIds":{"DBLP":"journals/npl/SuzukiHS01","MAG":"1546630874","DOI":"10.1023/A:1009639214138","CorpusId":18223515},"title":"A Simple Neural Network Pruning Algorithm with Application to Filter Synthesis"},{"paperId":"2e9d221c206e9503ceb452302d68d10e293f2a10","externalIds":{"DBLP":"journals/neco/HochreiterS97","MAG":"2064675550","DOI":"10.1162/neco.1997.9.8.1735","CorpusId":1915014,"PubMed":"9377276"},"title":"Long Short-Term Memory"},{"paperId":"5194b668c67aa83c037e71599a087f63c98eb713","externalIds":{"MAG":"2951911250","DBLP":"conf/sigir/LewisG94","DOI":"10.1007/978-1-4471-2099-5_1","CorpusId":915058},"title":"A sequential algorithm for training text classifiers"},{"paperId":"6dc04a1b6be52df56be6581fcd6460a0fd5c5521","externalIds":{"MAG":"2140660536","DBLP":"journals/tsp/TangK93","DOI":"10.1109/78.229903","CorpusId":13085796},"title":"Multilayer feedforward neural networks with single powers-of-two weights"},{"paperId":"8c3c011e5c7c3bc8f959fbe580fe269bffe11af8","externalIds":{"MAG":"2007329174","DBLP":"journals/nn/BalzerTOK91","DOI":"10.1016/0893-6080(91)90077-I","CorpusId":7418039},"title":"Weight quantization in Boltzmann machines"},{"paperId":"843d0f89223e18f20c6d7b1e9e4cc87db1735f0a","externalIds":{"MAG":"2046542508","DOI":"10.1117/12.20700","CorpusId":62160723},"title":"Weight discretization paradigm for optical neural networks"},{"paperId":"1554887c6bd76c443a477b27dbcab35877787b27","externalIds":{"DBLP":"conf/naacl/WangXWWL21","ACL":"2021.naacl-industry.15","DOI":"10.18653/v1/2021.naacl-industry.15","CorpusId":235097440},"title":"LightSeq: A High Performance Inference Library for Transformers"},{"paperId":"b6ef401835b92bbe313c8e0740ca761028ea7860","externalIds":{"DBLP":"journals/corr/abs-2106-04570","CorpusId":235367978},"title":"Meta Learning for Knowledge Distillation"},{"paperId":"53d8b356551a2361020a948f64454a6d599af69f","externalIds":{"DBLP":"conf/acl/LiL20","ACL":"2021.acl-long.353","ArXiv":"2101.00190","DOI":"10.18653/v1/2021.acl-long.353","CorpusId":230433941},"title":"Prefix-Tuning: Optimizing Continuous Prompts for Generation"},{"paperId":"b50bd1f96e20952d7ad1bf774ea6199ce12f2fa6","externalIds":{"DBLP":"journals/corr/abs-2105-15075","CorpusId":235254787},"title":"Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length"},{"paperId":"7b37c0a4976c4d2a5a440d494fbb0f3daede2a00","externalIds":{"ACL":"2021.eacl-main.8","DBLP":"conf/eacl/XinTYL21","DOI":"10.18653/v1/2021.eacl-main.8","CorpusId":233189542},"title":"BERxiT: Early Exiting for BERT with Better Fine-Tuning and Extension to Regression"},{"paperId":"a855f3790d017d789719af0d3403a43f6920c816","externalIds":{"DBLP":"journals/corr/abs-2103-01148","CorpusId":232092159},"title":"Class Means as an Early Exit Decision Mechanism"},{"paperId":"8200994faff3bf39446839632ad41df7713ef015","externalIds":{"CorpusId":236907079},"title":"L EARNING FROM DEEP MODEL VIA EXPLORING LOCAL TARGETS"},{"paperId":"b60a16d2978b10ead102a6a6cd03dc940b1194cc","externalIds":{"ACL":"2020.aacl-main.88","DBLP":"conf/ijcnlp/NoachG20","DOI":"10.18653/v1/2020.aacl-main.88","CorpusId":227905681},"title":"Compressing Pre-trained Language Models by Matrix Decomposition"},{"paperId":"17d5884215b5afa53545cd7cb6135de5478da4ec","externalIds":{"ArXiv":"2005.12766","DBLP":"journals/corr/abs-2005-12766","MAG":"3026732421","DOI":"10.36227/techrxiv.12308378","CorpusId":218889852},"title":"CERT: Contrastive Self-supervised Learning for Language Understanding"},{"paperId":"e64bad304a6b2697d1fb01e9a0e6daa160ecdb17","externalIds":{"DBLP":"journals/corr/abs-2012-14682","CorpusId":229923648},"title":"Accelerating Pre-trained Language Models via Calibrated Cascade"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"cb22814265531c4a802407cf2dd450a924b43ebe","externalIds":{"MAG":"2889847962","DBLP":"conf/nips/WangXDLWX18","CorpusId":54056451},"title":"HitNet: Hybrid Ternary Recurrent Neural Network"},{"paperId":"d0134386fad3e9ad4ae83fc289bdb0fda9caf121","externalIds":{"MAG":"2787146684","DBLP":"conf/iclr/Yu0S018","CorpusId":3332523},"title":"Fast and Accurate Text Classification: Skimming, Rereading and Early Stopping"},{"paperId":"13ad21cdd77a07c846e315691ce47e0d12f22da8","externalIds":{"DBLP":"conf/acl/StoyanovJLY18","MAG":"2798778171","ACL":"P18-1074","DOI":"10.18653/v1/P18-1074","CorpusId":51870433},"title":"A Multi-lingual Multi-task Architecture for Low-resource Sequence Labeling"},{"paperId":"88cd4209db62a34d9cba0b9cbe9d45d1e57d21e5","externalIds":{"MAG":"2752037867","DBLP":"conf/nips/LinRLZ17","CorpusId":38486148},"title":"Runtime Neural Pruning"},{"paperId":"0c721c6afe980542bc091b3a3bff7d075fa8cd47","externalIds":{"DBLP":"conf/iccci/Rueda-PlataRG15","MAG":"2239639518","DOI":"10.1007/978-3-319-24069-5_26","CorpusId":853131},"title":"Supervised Greedy Layer-Wise Training for Deep Convolutional Networks with Small Datasets"},{"paperId":"4e18fea7edd3a49e3ed580b9eafd72d477b1975e","externalIds":{"MAG":"2295800168","ACL":"N15-1027","DBLP":"conf/naacl/AndreasK15","DOI":"10.3115/v1/N15-1027","CorpusId":289313},"title":"When and why are log-linear models self-normalizing?"},{"paperId":"fbeaa499e10e98515f7e1c4ad89165e8c0677427","externalIds":{"MAG":"587794757","CorpusId":15196840},"title":"Improving the speed of neural networks on CPUs"},{"paperId":"db8885a0037fe47d973ade79d696586453710233","externalIds":{"DBLP":"conf/tac/BentivogliCDG10","CorpusId":858065},"title":"The Sixth PASCAL Recognizing Textual Entailment Challenge"},{"paperId":"475354f10798f110d34792b6d88f31d6d5cb099e","externalIds":{"ACL":"I05-5002","DBLP":"conf/acl-iwp/DolanB05","MAG":"131533222","CorpusId":16639476},"title":"Automatically Constructing a Corpus of Sentential Paraphrases"},{"paperId":"c19fbefdeead6a4154a22a9c8551a18b1530033a","externalIds":{"DBLP":"conf/aistats/MorinB05","MAG":"36903255","CorpusId":1326925},"title":"Hierarchical Probabilistic Neural Network Language Model"},{"paperId":"6b388f0151ab37adb3d57738b8f52a3f943f86c8","externalIds":{"CorpusId":2606135},"title":"Quick Training of Probabilistic Neural Nets by Importance Sampling"},{"paperId":"b4f10bab6edf7f743a0ddfeca18d45bdcf0037fd","externalIds":{"MAG":"157619294","CorpusId":14293159},"title":"Toward Optimal Active Learning through Monte Carlo Estimation of Error Reduction"},{"paperId":"162d958ff885f1462aeda91cd72582323fd6a1f4","externalIds":{"MAG":"2112796928","DBLP":"journals/pieee/LeCunBBH98","DOI":"10.1109/5.726791","CorpusId":14542261},"title":"Gradient-based learning applied to document recognition"},{"paperId":"84959dd429f795b4e74dd0ecf79eb90394577534","externalIds":{"DBLP":"conf/nips/HassibiSW93","CorpusId":36364298},"title":"Optimal Brain Surgeon: Extensions and performance comparison"},{"paperId":"e7297db245c3feb1897720b173a59fe7e36babb7","externalIds":{"MAG":"2114766824","DBLP":"conf/nips/CunDS89","CorpusId":7785881},"title":"Optimal Brain Damage"},{"paperId":"f4ea5a6ff3ffcd11ec2e6ed7828a7d41279fb3ad","externalIds":{"MAG":"2120972216","DBLP":"conf/nips/HansonP88","CorpusId":9344018},"title":"Comparing Biases for Minimal Network Construction with Back-Propagation"},{"paperId":"3a9b175324ba11bc0e16c0633912d897b2fac4e2","externalIds":{"CorpusId":4246903},"title":"International Journal of Computer Vision manuscript No. (will be inserted by the editor) The PASCAL Visual Object Classes (VOC) Challenge"}]}