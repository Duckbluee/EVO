{"abstract":"Smartphones are equipped with a range of highly responsive sensors. From gyroscopes to accelerometers, providing mobile applications a wide variety of ways to interact with the environment. Unfortunately, some applications may be able to use these sensors to monitor their surroundings in unintended ways. Acoustic emanations are the most commonly used side channel in attacking computer keyboards, ATMs, etc. However, if multiple uncorrelated sensors are used, then the attack can be much more effective. In this paper, we explore how data from various sensors can be fused to improve the accuracy in recovering characters typed in a nearby mechanical keyboard from a smartphone. Unlike conventional approaches wherein acoustic emanations or other sensor reading are used as side-channel vectors, we combine emanations recorded from multiple sensors available in a smartphone and fuse them to achieve higher accuracy than any single sensor. Experiments reveal that the use of fusion could achieve an accuracy of 80 percent which is an improvement of over 6 percent using only audio emanations."}