{"abstract":"The attempt to concretely define the concept of explainability in terms of other vaguely described notions, is doomed to fail. We argue that a rigorous numeric measure is needed to take a significant step forward. Such a measure would allow the objective comparison of machine learning models that are explainable to varying degrees. In the longer term, a numeric measure might make it possible to compare humans and machines in terms of explanatory capacities, thereby establishing a very specific kind of Turing test.We introduce some notions and rigorous definitions related to explainability, in particular completeness and consistency. The objective of this paper is that the introduced terms can act as a concrete starting point for the construction of a mathematically expressed measure of explainability. We also show how the idea of model selection, where a model is chosen from a candidate set by optimizing the trade-off between complexity and goodness of fit, can be applied to select explainable models."}