{"references":[{"paperId":"96e8d5e1cc47d5d3cd8aad976803e640b19e9a6e","externalIds":{"DBLP":"conf/nips/SalimansMHH24","ArXiv":"2406.04103","DOI":"10.48550/arXiv.2406.04103","CorpusId":270285800},"title":"Multistep Distillation of Diffusion Models via Moment Matching"},{"paperId":"76e8218f657c77c38da44daaed5bb54ab727a8fc","externalIds":{"DBLP":"conf/nips/TianJYPW24","ArXiv":"2404.02905","DOI":"10.48550/arXiv.2404.02905","CorpusId":268876071},"title":"Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction"},{"paperId":"a52d40d89c51ea91ce4477565a963d8ab31067fc","externalIds":{"DBLP":"journals/pr/KimJLHSK24","DOI":"10.1016/j.patcog.2024.110474","CorpusId":268935536},"title":"Depth-aware guidance with self-estimated depth representations of diffusion models"},{"paperId":"d44b3f31b57cc45ce96e87c434a0766c302affcb","externalIds":{"DBLP":"conf/eccv/AhnCMJKKPJK24","ArXiv":"2403.17377","DOI":"10.48550/arXiv.2403.17377","CorpusId":268692048},"title":"Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance"},{"paperId":"c04926fbdb9476967e84fdc008b0e78e99fe8444","externalIds":{"ArXiv":"2403.13788","DBLP":"journals/corr/abs-2403-13788","DOI":"10.48550/arXiv.2403.13788","CorpusId":268537220},"title":"DepthFM: Fast Monocular Depth Estimation with Flow Matching"},{"paperId":"0c17c30c7194c2d1d6c37a0f1c2cbd0c9f89899e","externalIds":{"DBLP":"journals/corr/abs-2403-13802","ArXiv":"2403.13802","DOI":"10.48550/arXiv.2403.13802","CorpusId":268537245},"title":"ZigMa: A DiT-style Zigzag Mamba Diffusion Model"},{"paperId":"f6ab25605dc36db5e4b4f2f167d905944d5203c4","externalIds":{"DBLP":"journals/corr/abs-2403-12015","ArXiv":"2403.12015","DOI":"10.1145/3680528.3687625","CorpusId":268532573},"title":"Fast High-Resolution Image Synthesis with Latent Adversarial Diffusion Distillation"},{"paperId":"0a32e6ff6eaac83ff325bae4557a8362222979aa","externalIds":{"DBLP":"journals/ijcv/ChenHXPWCLLW26","ArXiv":"2403.09626","DOI":"10.1007/s11263-025-02597-y","CorpusId":268385114},"title":"Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding"},{"paperId":"3af7273d7ca20c0c63cbaa47e60b058840835052","externalIds":{"ArXiv":"2403.06977","DBLP":"conf/eccv/LiLWHWWQ24","DOI":"10.48550/arXiv.2403.06977","CorpusId":268363759},"title":"VideoMamba: State Space Model for Efficient Video Understanding"},{"paperId":"a5e0cf204383f10c96f7dcee832b6e1addbe094c","externalIds":{"ArXiv":"2403.06807","DBLP":"journals/corr/abs-2403-06807","DOI":"10.48550/arXiv.2403.06807","CorpusId":268363449},"title":"Multistep Consistency Models"},{"paperId":"0027446b0d8ff38f71d48d1e311fc2b13815be97","externalIds":{"DBLP":"conf/aaai/AyromlouKFA25","ArXiv":"2403.05966","DOI":"10.48550/arXiv.2403.05966","CorpusId":268357073},"title":"Can Generative Models Improve Self-Supervised Representation Learning?"},{"paperId":"bdd4670ed1f38e6dc584af93f4c8bcccbd424ca6","externalIds":{"ArXiv":"2403.00570","DBLP":"conf/wacv/AdaloglouKMK25","DOI":"10.1109/WACV61041.2025.00355","CorpusId":268230387},"title":"Rethinking Cluster-Conditioned Diffusion Models for Label-Free Image Synthesis"},{"paperId":"9761bcf49892601a3bec07d616c13c7f8bb7ac6c","externalIds":{"DBLP":"journals/corr/abs-2402-17525","ArXiv":"2402.17525","DOI":"10.1109/TPAMI.2025.3541625","CorpusId":268033671,"PubMed":"40031849"},"title":"Diffusion Model-Based Image Editing: A Survey"},{"paperId":"20a9fdf9e3b77be8d182fb04646ffc11c9708367","externalIds":{"DBLP":"conf/icml/Ben-HamuPGKSL24","ArXiv":"2402.14017","DOI":"10.48550/arXiv.2402.14017","CorpusId":267770268},"title":"D-Flow: Differentiating through Flows for Controlled Generation"},{"paperId":"7154fc93bdefcd237a0ce3902511c0b154049253","externalIds":{"DBLP":"journals/corr/abs-2402-05608","ArXiv":"2402.05608","DOI":"10.48550/arXiv.2402.05608","CorpusId":267548062},"title":"Scalable Diffusion Models with State Space Backbone"},{"paperId":"d51e87b2cb750d8f2c3f7cfeb0943a3b2c7ecb01","externalIds":{"ArXiv":"2401.11430","DBLP":"conf/iclr/Yue0S0CZ24","DOI":"10.48550/arXiv.2401.11430","CorpusId":267069216},"title":"Exploring Diffusion Time-steps for Unsupervised Representation Learning"},{"paperId":"66271ddc2e2e4279f57b8308ccedfd22f06ca4f1","externalIds":{"ArXiv":"2401.00110","DBLP":"journals/corr/abs-2401-00110","DOI":"10.48550/arXiv.2401.00110","CorpusId":266693789},"title":"Diffusion Model with Perceptual Loss"},{"paperId":"840f737832915aff853911bc681c1468168c6a86","externalIds":{"DBLP":"journals/corr/abs-2312-13216","ArXiv":"2312.13216","DOI":"10.1109/CVPR52733.2024.01846","CorpusId":266375158},"title":"Improving Semantic Correspondence with Viewpoint-Guided Spherical Maps"},{"paperId":"ca743e75ce090bbf686307e41bd8747661768fbe","externalIds":{"ArXiv":"2312.10825","DBLP":"conf/aaai/HuZTMZS24","DOI":"10.48550/arXiv.2312.10825","CorpusId":264552917},"title":"Latent Space Editing in Transformer-Based Flow Matching"},{"paperId":"c231418d40fa0eb67ee6a1901add09e9af433a4f","externalIds":{"ArXiv":"2312.08825","DBLP":"journals/corr/abs-2312-08825","DOI":"10.48550/arXiv.2312.08825","CorpusId":266210467},"title":"Guided Diffusion from Self-Supervised Diffusion Features"},{"paperId":"b6b49a33a1ee2afea884dc947e124ee36a303117","externalIds":{"ArXiv":"2312.08895","DBLP":"journals/corr/abs-2312-08895","DOI":"10.48550/arXiv.2312.08895","CorpusId":266209926},"title":"Motion Flow Matching for Human Motion Synthesis and Editing"},{"paperId":"527bc1af6f644a49f503d63a7d8c188665229400","externalIds":{"ArXiv":"2312.07360","DBLP":"conf/eccv/SchusterbauerGMSBHO24","DOI":"10.1007/978-3-031-73030-6_19","CorpusId":266174732},"title":"Boosting Latent Diffusion with Flow Matching"},{"paperId":"3333fa6dc9d39cad3d5cd87da9ae39e5a6aefe27","externalIds":{"ArXiv":"2312.04410","DBLP":"conf/cvpr/GuoXPNWVSHS24","DOI":"10.1109/CVPR52733.2024.00721","CorpusId":266054322},"title":"Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models"},{"paperId":"58bafe15b75f2f9803344270d82a61b5c576c051","externalIds":{"ArXiv":"2312.03701","DBLP":"conf/nips/LiKH24","DOI":"10.52202/079017-3985","CorpusId":265664611},"title":"Return of Unconditional Generation: A Self-supervised Representation Generation Method"},{"paperId":"b31295b45c5c44377eeeaa1d0cf9523926cc115b","externalIds":{"DBLP":"conf/cvpr/LuoDWGH24","ArXiv":"2312.02150","DOI":"10.1109/CVPR52733.2024.00785","CorpusId":265608773},"title":"Readout Guidance: Learning Control from Diffusion Features"},{"paperId":"7ee5d6fd4d2bbd0fed6f3dde583618a88d557424","externalIds":{"DBLP":"conf/cvpr/Pandey0GHSM24","ArXiv":"2312.02190","DOI":"10.1109/CVPR52733.2024.00735","CorpusId":265659119},"title":"Diffusion Handles Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D"},{"paperId":"7bbc7595196a0606a07506c4fb1473e5e87f6082","externalIds":{"ArXiv":"2312.00752","DBLP":"journals/corr/abs-2312-00752","CorpusId":265551773},"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces"},{"paperId":"31245344a6eb6cd897a71928dc4b174ab75e4070","externalIds":{"DBLP":"conf/cvpr/YanGR24","ArXiv":"2311.18257","DOI":"10.1109/CVPR52733.2024.00787","CorpusId":265506646},"title":"Diffusion Models Without Attention"},{"paperId":"51f864c81edce7f0472993f7bfdf299ebd770ebe","externalIds":{"ArXiv":"2311.17921","DBLP":"conf/eccv/MukhopadhyayGYAPSZOS24","DOI":"10.48550/arXiv.2311.17921","CorpusId":265498931},"title":"Do text-free diffusion models learn discriminative visual representations?"},{"paperId":"3852b468bd6c5a22e1c13a425fdd7604b5bcb7e2","externalIds":{"ArXiv":"2311.17901","DBLP":"conf/cvpr/HudsonZMLJMMHL24","DOI":"10.1109/CVPR52733.2024.02181","CorpusId":265498761},"title":"SODA: Bottleneck Diffusion Models for Representation Learning"},{"paperId":"a04377b3e6b0061e3742a1605665df99c723cc1d","externalIds":{"DBLP":"conf/cvpr/0004HHCJS024","ArXiv":"2311.17034","DOI":"10.1109/CVPR52733.2024.00297","CorpusId":265466276},"title":"Telling Left from Right: Identifying Geometry-Aware Semantic Correspondence"},{"paperId":"9eb476cd15becf02163d6f3dab75d207eed52214","externalIds":{"DBLP":"conf/fat/LuccioniJS24","ArXiv":"2311.16863","DOI":"10.1145/3630106.3658542","CorpusId":265466268},"title":"Power Hungry Processing: Watts Driving the Cost of AI Deployment?"},{"paperId":"070c827308bec794584b5ca38de57f8e1f5ce191","externalIds":{"ArXiv":"2311.17009","DBLP":"conf/cvpr/YatimFBKD24","DOI":"10.1109/CVPR52733.2024.00809","CorpusId":265466643},"title":"Space-Time Diffusion Features for Zero-Shot Text-Driven Motion Transfer"},{"paperId":"88f4b8d1662473a6ad75e2e65aea41ea86b41765","externalIds":{"DBLP":"conf/cvpr/LiL0P24","ArXiv":"2310.17569","DOI":"10.1109/CVPR52733.2024.02602","CorpusId":264490858},"title":"SD4Match: Learning to Prompt Stable Diffusion Model for Semantic Matching"},{"paperId":"6487ec82f6d8082a5b402a5416ea03009acb1679","externalIds":{"DBLP":"journals/cgf/PoYGABBCDHKLLMNOTWW24","ArXiv":"2310.07204","DOI":"10.1111/cgf.15063","CorpusId":263835355},"title":"State of the Art on Diffusion Models for Visual Computing"},{"paperId":"02ad9f3fefe33cb9ca546591bec65dbdf7766c80","externalIds":{"ArXiv":"2310.01889","DBLP":"conf/iclr/0055ZA24","DOI":"10.48550/arXiv.2310.01889","CorpusId":263608461},"title":"Ring Attention with Blockwise Transformers for Near-Infinite Context"},{"paperId":"6deb76b8ac8d35dded7dd76d768a245bb69ffe91","externalIds":{"DBLP":"journals/corr/abs-2309-04372","ArXiv":"2309.04372","DOI":"10.48550/arXiv.2309.04372","CorpusId":261660692},"title":"MoEController: Instruction-based Arbitrary Image Manipulation with Mixture-of-Expert Controllers"},{"paperId":"75ca0ce6493c94bb48766b042243023a5439beeb","externalIds":{"ArXiv":"2309.03895","DBLP":"conf/cvpr/GengYHLGZBZLHCG24","DOI":"10.1109/CVPR52733.2024.01208","CorpusId":261582721},"title":"InstructDiffusion: A Generalist Modeling Interface for Vision Tasks"},{"paperId":"72de731e88f7a6d983729d0dfafea1b41be5ac8f","externalIds":{"DBLP":"journals/corr/abs-2308-05695","ArXiv":"2308.05695","DOI":"10.48550/arXiv.2308.05695","CorpusId":260775966},"title":"Masked Diffusion as Self-supervised Representation Learner"},{"paperId":"4761f173965195798cd3046ef4af608a83504e4d","externalIds":{"DBLP":"conf/iclr/GeyerBBD24","ArXiv":"2307.10373","DOI":"10.48550/arXiv.2307.10373","CorpusId":259991741},"title":"TokenFlow: Consistent Diffusion Features for Consistent Video Editing"},{"paperId":"e93e3e71fb1b065f2514a456a32853b01992de0e","externalIds":{"ArXiv":"2307.08702","DBLP":"journals/corr/abs-2307-08702","DOI":"10.48550/arXiv.2307.08702","CorpusId":259937835},"title":"Diffusion Models Beat GANs on Image Classification"},{"paperId":"512fdb53eb341bc56769728274615c9bbe5bc23d","externalIds":{"ArXiv":"2307.08698","DBLP":"journals/corr/abs-2307-08698","DOI":"10.48550/arXiv.2307.08698","CorpusId":259936788},"title":"Flow Matching in Latent Space"},{"paperId":"d69528899cb26687fae460ac3729eaef99ca0561","externalIds":{"DBLP":"conf/iccv/LiLKA0K0F23","ArXiv":"2307.07487","DOI":"10.1109/ICCV51070.2023.01531","CorpusId":259924740},"title":"DreamTeacher: Pretraining Image Backbones with Deep Generative Models"},{"paperId":"a9e00c216ce69325a15fd139da0624978e54058a","externalIds":{"ArXiv":"2306.15687","DBLP":"journals/corr/abs-2306-15687","DOI":"10.48550/arXiv.2306.15687","CorpusId":259275061},"title":"Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale"},{"paperId":"cac34b51cfbeb84a3789a409c36977c49e499e94","externalIds":{"DBLP":"conf/icml/WangSGPWSK23","ArXiv":"2306.08757","DOI":"10.48550/arXiv.2306.08757","CorpusId":259165151},"title":"InfoDiffusion: Representation Learning Using Information Maximizing Diffusion Models"},{"paperId":"94749e66f5d91df6f23b13dcc7bb02127a6a2137","externalIds":{"DBLP":"conf/iclr/TianTD0LL00HZ24","ArXiv":"2306.05423","DOI":"10.48550/arXiv.2306.05423","CorpusId":259108646},"title":"ADDP: Learning General Representations for Image Recognition and Generation with Alternating Denoising Diffusion Process"},{"paperId":"05d6db8f4727c0cb4fd7bb63cd98de25b2888016","externalIds":{"DBLP":"journals/corr/abs-2306-04542","ArXiv":"2306.04542","DOI":"10.48550/arXiv.2306.04542","CorpusId":259095911},"title":"On the Design Fundamentals of Diffusion Models: A Survey"},{"paperId":"f421b314aaff48e463507034691cfdd3f93cd4c2","externalIds":{"ArXiv":"2306.03881","DBLP":"journals/corr/abs-2306-03881","DOI":"10.48550/arXiv.2306.03881","CorpusId":259089017},"title":"Emergent Correspondence from Image Diffusion"},{"paperId":"9ecda80a94213c4d8322ccfb34ff6e1bfc4a9390","externalIds":{"ArXiv":"2306.00966","DBLP":"conf/iclr/CheferLGPSIMW24","DOI":"10.48550/arXiv.2306.00966","CorpusId":258999763},"title":"The Hidden Language of Diffusion Models"},{"paperId":"fbebb1a5d72aec2a6b13fc909f781f6ba9b04925","externalIds":{"DBLP":"conf/nips/EpsteinJPEH23","ArXiv":"2306.00986","DOI":"10.48550/arXiv.2306.00986","CorpusId":258999106},"title":"Diffusion Self-Guidance for Controllable Image Generation"},{"paperId":"946fa1978b570407e082c61ed8334822f3da1740","externalIds":{"DBLP":"conf/nips/LuoHZSLZ23","ArXiv":"2305.18455","DOI":"10.48550/arXiv.2305.18455","CorpusId":258967550},"title":"Diff-Instruct: A Universal Approach for Transferring Knowledge From Pre-trained Diffusion Models"},{"paperId":"3ad0899e9fa71cc6c294db4e8061ff6bc9e22225","externalIds":{"DBLP":"conf/nips/ZhangHHCJS023","ArXiv":"2305.15347","DOI":"10.48550/arXiv.2305.15347","CorpusId":258865497},"title":"A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence"},{"paperId":"e49b1b6227afbe16f01174a72dbf2868915f5aac","externalIds":{"DBLP":"conf/nips/HedlinSMIKTY23","ArXiv":"2305.15581","DOI":"10.48550/arXiv.2305.15581","CorpusId":258887715},"title":"Unsupervised Semantic Correspondence Using Stable Diffusion"},{"paperId":"c267f83a5d0fb0e4ed4c5c1174998ab6efd457aa","externalIds":{"DBLP":"conf/nips/LuoDPHD23","ArXiv":"2305.14334","DOI":"10.48550/arXiv.2305.14334","CorpusId":258841218},"title":"Diffusion Hyperfeatures: Searching Through Time and Space for Semantic Correspondence"},{"paperId":"d1f974089f205d24517634c98df92fc1b0e4ad69","externalIds":{"DBLP":"conf/iclr/MardaniSKV24","ArXiv":"2305.04391","DOI":"10.48550/arXiv.2305.04391","CorpusId":258557287},"title":"A Variational Perspective on Solving Inverse Problems with Diffusion Models"},{"paperId":"42f967ba1691740ebf1268d4c1e24af79249c648","externalIds":{"ArXiv":"2305.03935","DBLP":"conf/icml/Zheng00023","DOI":"10.48550/arXiv.2305.03935","CorpusId":258557324},"title":"Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs"},{"paperId":"7882ea0a51470963dbdba34de188692125b08491","externalIds":{"DBLP":"journals/corr/abs-2305-02385","ArXiv":"2305.02385","DOI":"10.48550/arXiv.2305.02385","CorpusId":258479803},"title":"SimSC: A Simple Framework for Semantic Correspondence with Temperature Learning"},{"paperId":"241536d067624791d590af8b94f3f80a99328233","externalIds":{"DBLP":"conf/aaai/SamuelBRDC24","ArXiv":"2304.14530","DOI":"10.1609/aaai.v38i5.28270","CorpusId":258418154},"title":"Generating Images of Rare Concepts Using Pre-trained Diffusion Models"},{"paperId":"5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891","externalIds":{"DBLP":"journals/corr/abs-2304-07193","ArXiv":"2304.07193","DOI":"10.48550/arXiv.2304.07193","CorpusId":258170077},"title":"DINOv2: Learning Robust Visual Features without Supervision"},{"paperId":"b032f324a0d4a24fd917551345bd100dc368e41a","externalIds":{"DBLP":"conf/iccv/0005M0L00WXYF23","ArXiv":"2304.03283","DOI":"10.1109/ICCV51070.2023.01492","CorpusId":257985028},"title":"Diffusion Models as Masked Autoencoders"},{"paperId":"2782acfdf745bcc5abe2743a94472f64fc83cd7e","externalIds":{"DBLP":"conf/bmvc/AdaloglouMKK23","ArXiv":"2303.17896","DOI":"10.48550/arXiv.2303.17896","CorpusId":257900818},"title":"Exploring the Limits of Deep Image Clustering using Pretrained Models"},{"paperId":"4702d5a163477c734a54f3ed2d171dca1504eaae","externalIds":{"DBLP":"conf/iccv/LiPDBP23","ArXiv":"2303.16203","DOI":"10.1109/ICCV51070.2023.00210","CorpusId":257771787},"title":"Your Diffusion Model is Secretly a Zero-Shot Classifier"},{"paperId":"352f26798b07160bf10d87cf0fd67187c5a0c432","externalIds":{"ArXiv":"2303.13703","DBLP":"journals/corr/abs-2303-13703","DOI":"10.1109/ICCV51070.2023.00669","CorpusId":257757144},"title":"End-to-End Diffusion Latent Optimization Improves Classifier Guidance"},{"paperId":"df4b6713abfe226d06099d7749f8b47903ac087b","externalIds":{"DBLP":"conf/iccv/XiangY0W23","ArXiv":"2303.09769","DOI":"10.1109/ICCV51070.2023.01448","CorpusId":257623083},"title":"Denoising Diffusion Autoencoders are Unified Self-supervised Learners"},{"paperId":"ce06533ecc98ba221a4db427738884c6a6af6eee","externalIds":{"DBLP":"journals/corr/abs-2303-09833","ArXiv":"2303.09833","DOI":"10.1109/ICCV51070.2023.02118","CorpusId":257622962},"title":"FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model"},{"paperId":"eaa3a21fe70d7c2e4de3c92274daa4a8eca7b277","externalIds":{"DBLP":"journals/corr/abs-2303-06555","ArXiv":"2303.06555","DOI":"10.48550/arXiv.2303.06555","CorpusId":257496235},"title":"One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale"},{"paperId":"323400245885e08ad498cd108e30e18020662278","externalIds":{"DBLP":"conf/cvpr/XuLVBWM23","ArXiv":"2303.04803","DOI":"10.1109/CVPR52729.2023.00289","CorpusId":257405338},"title":"Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion Models"},{"paperId":"c09ca9da1fce13b1560f45c38321c7bb971f13fc","externalIds":{"ArXiv":"2303.02153","DBLP":"journals/corr/abs-2303-02153","DOI":"10.1109/ICCV51070.2023.00527","CorpusId":257353292},"title":"Unleashing Text-to-Image Diffusion Models for Visual Perception"},{"paperId":"f5324c908e840995f681ac677c40d5d6b1555622","externalIds":{"DBLP":"journals/corr/abs-2302-10586","ArXiv":"2302.10586","DOI":"10.48550/arXiv.2302.10586","CorpusId":257050467},"title":"Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels"},{"paperId":"9ced6e814457eae83f5415364e266143defc81d1","externalIds":{"DBLP":"journals/corr/abs-2302-08113","ArXiv":"2302.08113","DOI":"10.48550/arXiv.2302.08113","CorpusId":256900756},"title":"MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation"},{"paperId":"efbe97d20c4ffe356e8826c01dc550bacc405add","externalIds":{"DBLP":"journals/corr/abs-2302-05543","ArXiv":"2302.05543","DOI":"10.1109/ICCV51070.2023.00355","CorpusId":256827727},"title":"Adding Conditional Control to Text-to-Image Diffusion Models"},{"paperId":"4049d388b8487e4d6c5adafbcdaa867d5f87a1a6","externalIds":{"ArXiv":"2302.03298","DBLP":"conf/cvpr/ShipardWTXF23","DOI":"10.1109/CVPRW59228.2023.00084","CorpusId":257757078},"title":"Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion"},{"paperId":"57b9cd58e489052cc7f004fecc7e46b2cf8f76c2","externalIds":{"DBLP":"journals/corr/abs-2301-13622","ArXiv":"2301.13622","DOI":"10.48550/arXiv.2301.13622","CorpusId":256416358},"title":"Learning Data Representations with Joint Diffusion Models"},{"paperId":"6d1433f3342fbee85ad1e2809e62734aec5c3853","externalIds":{"DBLP":"journals/corr/abs-2301-12661","ArXiv":"2301.12661","DOI":"10.48550/arXiv.2301.12661","CorpusId":256390046},"title":"Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models"},{"paperId":"6e3a3b7a8a0376d867cad72eedf2f9b746f29a33","externalIds":{"DBLP":"journals/corr/abs-2301-11093","ArXiv":"2301.11093","DOI":"10.48550/arXiv.2301.11093","CorpusId":256274516},"title":"simple diffusion: End-to-end diffusion for high resolution images"},{"paperId":"57655bdf9bfaf326ca73e5843edeb3e9f2c4d315","externalIds":{"DBLP":"journals/corr/abs-2212-12990","ArXiv":"2212.12990","DOI":"10.48550/arXiv.2212.12990","CorpusId":255124924},"title":"Unsupervised Representation Learning from Pre-trained Diffusion Probabilistic Models"},{"paperId":"736973165f98105fec3729b7db414ae4d80fcbeb","externalIds":{"DBLP":"journals/corr/abs-2212-09748","ArXiv":"2212.09748","DOI":"10.1109/ICCV51070.2023.00387","CorpusId":254854389},"title":"Scalable Diffusion Models with Transformers"},{"paperId":"16de2006e2960ba410772c6b6d460b83c0a5cc4b","externalIds":{"ArXiv":"2212.07143","DBLP":"journals/corr/abs-2212-07143","DOI":"10.1109/CVPR52729.2023.00276","CorpusId":254636568},"title":"Reproducible Scaling Laws for Contrastive Language-Image Learning"},{"paperId":"583e87b70cfee68f6c160abaaaf7f53c07beb92b","externalIds":{"DBLP":"conf/iccv/DavtyanSF23","ArXiv":"2211.14575","DOI":"10.1109/ICCV51070.2023.02126","CorpusId":254044658},"title":"Efficient Video Prediction via Sparsely Conditioned Flow Matching"},{"paperId":"b000d6865db824af1563708fb7a545ddd65c6b3a","externalIds":{"DBLP":"conf/cvpr/TumanyanGBD23","ArXiv":"2211.12572","DOI":"10.1109/CVPR52729.2023.00191","CorpusId":253801961},"title":"Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation"},{"paperId":"a2d2bbe4c542173662a444b33b76c66992697830","externalIds":{"DBLP":"conf/cvpr/BrooksHE23","ArXiv":"2211.09800","DOI":"10.1109/CVPR52729.2023.01764","CorpusId":253581213},"title":"InstructPix2Pix: Learning to Follow Image Editing Instructions"},{"paperId":"2f68d3934b006fcd01732adbc1ab459b2485fc8e","externalIds":{"DBLP":"journals/corr/abs-2211-09117","ArXiv":"2211.09117","DOI":"10.1109/CVPR52729.2023.00213","CorpusId":253553243},"title":"MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis"},{"paperId":"a02313d56a6f71be9aafe43628e0f3a1d0cb858e","externalIds":{"DBLP":"journals/corr/abs-2210-10960","ArXiv":"2210.10960","DOI":"10.48550/arXiv.2210.10960","CorpusId":253018703},"title":"Diffusion Models already have a Semantic Latent Space"},{"paperId":"b798c925a4c43ea09e76a1c748491ef70067c0c6","externalIds":{"ArXiv":"2210.06462","DBLP":"conf/cvpr/HuZABS23","DOI":"10.1109/CVPR52729.2023.01766","CorpusId":252846258},"title":"Self-Guided Diffusion Models"},{"paperId":"af68f10ab5078bfc519caae377c90ee6d9c504e9","externalIds":{"ArXiv":"2210.02747","DBLP":"journals/corr/abs-2210-02747","CorpusId":252734897},"title":"Flow Matching for Generative Modeling"},{"paperId":"0eca1993fd78649aa94c49a73277546aeeb76e21","externalIds":{"ArXiv":"2210.00939","DBLP":"journals/corr/abs-2210-00939","DOI":"10.1109/ICCV51070.2023.00686","CorpusId":252683688},"title":"Improving Sample Quality of Diffusion Models Using Self-Attention Guidance"},{"paperId":"4e6244baf4236f4635e85f7dfb941a9a0a6c4a11","externalIds":{"DBLP":"conf/iclr/AlbergoV23","ArXiv":"2209.15571","DOI":"10.48550/arXiv.2209.15571","CorpusId":252668615},"title":"Building Normalizing Flows with Stochastic Interpolants"},{"paperId":"897f3bb5eacaa80359e81ff33378e1110e20ae95","externalIds":{"DBLP":"conf/cvpr/BaoNXCL0023","ArXiv":"2209.12152","DOI":"10.1109/CVPR52729.2023.02171","CorpusId":253581703},"title":"All are Worth Words: A ViT Backbone for Diffusion Models"},{"paperId":"efa1647594b236361610a20d507127f0586a379b","externalIds":{"DBLP":"journals/corr/abs-2209-04747","ArXiv":"2209.04747","DOI":"10.1109/TPAMI.2023.3261988","CorpusId":252199918,"PubMed":"37030794"},"title":"Diffusion Models in Vision: A Survey"},{"paperId":"244054a4254a2147e43a3dad9c124b9b7eb4a04a","externalIds":{"DBLP":"journals/corr/abs-2209-03003","ArXiv":"2209.03003","DOI":"10.48550/arXiv.2209.03003","CorpusId":252111177},"title":"Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow"},{"paperId":"e342165a614588878ad0f4bc9bacf3905df34d08","externalIds":{"DBLP":"journals/corr/abs-2209-00796","ArXiv":"2209.00796","DOI":"10.1145/3626235","CorpusId":252070859},"title":"Diffusion Models: A Comprehensive Survey of Methods and Applications"},{"paperId":"17d068e78e6f25e65cb08319b19b58279bb8b214","externalIds":{"DBLP":"journals/corr/abs-2208-11970","ArXiv":"2208.11970","DOI":"10.48550/arXiv.2208.11970","CorpusId":251799923},"title":"Understanding Diffusion Models: A Unified Perspective"},{"paperId":"a815b0a955db2163617baf308020c3d770da099d","externalIds":{"DBLP":"journals/corr/abs-2208-07791","ArXiv":"2208.07791","DOI":"10.48550/arXiv.2208.07791","CorpusId":251594515},"title":"Your ViT is Secretly a Hybrid Discriminative-Generative Diffusion Model"},{"paperId":"04e541391e8dce14d099d00fb2c21dbbd8afe87f","externalIds":{"DBLP":"journals/corr/abs-2208-01626","ArXiv":"2208.01626","DOI":"10.48550/arXiv.2208.01626","CorpusId":251252882},"title":"Prompt-to-Prompt Image Editing with Cross Attention Control"},{"paperId":"af9f365ed86614c800f082bd8eb14be76072ad16","externalIds":{"DBLP":"journals/corr/abs-2207-12598","ArXiv":"2207.12598","DOI":"10.48550/arXiv.2207.12598","CorpusId":249145348},"title":"Classifier-Free Diffusion Guidance"},{"paperId":"eaef083b9d661f42cc0d89d9d8156218f33a91d9","externalIds":{"DBLP":"journals/corr/abs-2206-13947","ArXiv":"2206.13947","DOI":"10.48550/arXiv.2206.13947","CorpusId":250089125},"title":"Long Range Language Modeling via Gated State Spaces"},{"paperId":"44b3fb61bec49f5e4d8a3b81ddc6082aedd771fe","externalIds":{"DBLP":"conf/nips/GraikosMJS22","ArXiv":"2206.09012","DOI":"10.48550/arXiv.2206.09012","CorpusId":249889060},"title":"Diffusion models as plug-and-play priors"},{"paperId":"2f4c451922e227cbbd4f090b74298445bbd900d0","externalIds":{"DBLP":"journals/corr/abs-2206-00364","ArXiv":"2206.00364","DOI":"10.48550/arXiv.2206.00364","CorpusId":249240415},"title":"Elucidating the Design Space of Diffusion-Based Generative Models"},{"paperId":"1386b8a11929cf02da291c56aca353e33bbc22ed","externalIds":{"DBLP":"conf/nips/LiTGLH22","ArXiv":"2205.14217","DOI":"10.48550/arXiv.2205.14217","CorpusId":249192356},"title":"Diffusion-LM Improves Controllable Text Generation"},{"paperId":"9695824d7a01fad57ba9c01d7d76a519d78d65e7","externalIds":{"DBLP":"journals/corr/abs-2205-11487","ArXiv":"2205.11487","DOI":"10.48550/arXiv.2205.11487","CorpusId":248986576},"title":"Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding"},{"paperId":"a225d5d846ba5110232ed5bb32d54ea742b1c2d4","externalIds":{"DBLP":"conf/iclr/SheyninAPSGNT23","ArXiv":"2204.02849","DOI":"10.48550/arXiv.2204.02849","CorpusId":247996596},"title":"KNN-Diffusion: Image Generation via Large-Scale Retrieval"},{"paperId":"7dbb386a617eacc954940c9540d9cb262529b8b1","externalIds":{"DBLP":"conf/icml/HoogeboomSVW22","ArXiv":"2203.17003","DOI":"10.48550/arXiv.2203.17003","CorpusId":247839510},"title":"Equivariant Diffusion for Molecule Generation in 3D"},{"paperId":"48e7f866c18f9e69f10f1fd96ad2b1d3091a8c4e","externalIds":{"DBLP":"journals/corr/abs-2203-04304","ArXiv":"2203.04304","DOI":"10.1109/CVPR52688.2022.01119","CorpusId":247318852},"title":"Dynamic Dual-Output Diffusion Models"},{"paperId":"7c597874535c1537d7ddff3b3723015b4dc79d30","externalIds":{"DBLP":"journals/corr/abs-2202-04200","ArXiv":"2202.04200","DOI":"10.1109/CVPR52688.2022.01103","CorpusId":246680316},"title":"MaskGIT: Masked Generative Image Transformer"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","externalIds":{"ArXiv":"2112.10752","DBLP":"journals/corr/abs-2112-10752","DOI":"10.1109/CVPR52688.2022.01042","CorpusId":245335280},"title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"42f2271cebb7f272b0066c1f22d33381f139ee68","externalIds":{"ArXiv":"2112.03126","DBLP":"journals/corr/abs-2112-03126","CorpusId":244908617},"title":"Label-Efficient Semantic Segmentation with Diffusion Models"},{"paperId":"b582edb16f5425642767cb6c26839111f867f4dc","externalIds":{"DBLP":"journals/corr/abs-2111-15640","ArXiv":"2111.15640","DOI":"10.1109/CVPR52688.2022.01036","CorpusId":244729224},"title":"Diffusion Autoencoders: Toward a Meaningful and Decodable Representation"},{"paperId":"6351ebb4a3287f5f3e1273464b3b91e5df5a16d7","externalIds":{"DBLP":"conf/cvpr/HeCXLDG22","ArXiv":"2111.06377","DOI":"10.1109/CVPR52688.2022.01553","CorpusId":243985980},"title":"Masked Autoencoders Are Scalable Vision Learners"},{"paperId":"6330f74d8606c269cb2a8e06182971c0d90994ca","externalIds":{"DBLP":"journals/corr/abs-2110-00473","ArXiv":"2110.00473","CorpusId":238253287},"title":"Score-Based Generative Classifiers"},{"paperId":"9bd1814af7c845e7bd46f77ac15d6bedf64e276f","externalIds":{"ArXiv":"2109.05070","DBLP":"conf/nips/CasanovaCVDR21","CorpusId":237491885},"title":"Instance-Conditioned GAN"},{"paperId":"91b32fc0a23f0af53229fceaae9cce43a0406d2e","externalIds":{"DBLP":"journals/corr/abs-2107-03006","ArXiv":"2107.03006","CorpusId":235755106},"title":"Structured Denoising Diffusion Models in Discrete State-Spaces"},{"paperId":"94bcd712aed610b8eaeccc57136d65ec988356f2","externalIds":{"DBLP":"journals/corr/abs-2107-00630","ArXiv":"2107.00630","CorpusId":235694314},"title":"Variational Diffusion Models"},{"paperId":"63d6a3cc7f2f52c9b4e224bb8b18f17b03f6de1e","externalIds":{"DBLP":"conf/nips/HuangLC21","ArXiv":"2106.02808","CorpusId":235358715},"title":"A Variational Perspective on Diffusion-Based Generative Models and Score Matching"},{"paperId":"9d6e6488bb3d1ecd55e8a50b78c2e4cbedf2f437","externalIds":{"ArXiv":"2105.14257","DBLP":"conf/icml/MittalABSM23","CorpusId":237605601},"title":"Diffusion Based Representation Learning"},{"paperId":"64ea8f180d0682e6c18d1eb688afdb2027c02794","externalIds":{"ArXiv":"2105.05233","DBLP":"journals/corr/abs-2105-05233","CorpusId":234357997},"title":"Diffusion Models Beat GANs on Image Synthesis"},{"paperId":"fe92f3f7ceec008118842d42b578dc25bcba63f9","externalIds":{"ArXiv":"2105.02446","DBLP":"conf/aaai/Liu00CZ22","DOI":"10.1609/aaai.v36i10.21350","CorpusId":235262772},"title":"DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism"},{"paperId":"ad4a0938c48e61b7827869e4ac3baffd0aefab35","externalIds":{"ArXiv":"2104.14294","DBLP":"journals/corr/abs-2104-14294","DOI":"10.1109/ICCV48922.2021.00951","CorpusId":233444273},"title":"Emerging Properties in Self-Supervised Vision Transformers"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"cc8d8dac7b5e56752c042a152fdd78ef06963701","externalIds":{"DBLP":"conf/iccv/PanJWTC21","ArXiv":"2102.09896","DOI":"10.1109/ICCV48922.2021.00732","CorpusId":231979272},"title":"Scribble-Supervised Semantic Segmentation by Uncertainty Reduction on Neural Representation and Self-Supervision on Neural Eigenspace"},{"paperId":"add5f3f820b393e7ce5ed467814253824ecc484b","externalIds":{"DBLP":"conf/nips/HoogeboomNJFW21","ArXiv":"2102.05379","CorpusId":235262511},"title":"Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions"},{"paperId":"47f7ec3d0a5e6e83b6768ece35206a94dc81919c","externalIds":{"ArXiv":"2012.09841","MAG":"3111551570","DBLP":"journals/corr/abs-2012-09841","DOI":"10.1109/CVPR46437.2021.01268","CorpusId":229297973},"title":"Taming Transformers for High-Resolution Image Synthesis"},{"paperId":"633e2fbfc0b21e959a244100937c5853afca4853","externalIds":{"DBLP":"journals/corr/abs-2011-13456","ArXiv":"2011.13456","MAG":"3110257065","CorpusId":227209335},"title":"Score-Based Generative Modeling through Stochastic Differential Equations"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"MAG":"3094502228","ArXiv":"2010.11929","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"014576b866078524286802b1d0e18628520aa886","externalIds":{"ArXiv":"2010.02502","DBLP":"journals/corr/abs-2010-02502","MAG":"3092442149","CorpusId":222140788},"title":"Denoising Diffusion Implicit Models"},{"paperId":"34bf13e58c7226d615afead0c0f679432502940e","externalIds":{"MAG":"3087665158","DBLP":"conf/iclr/KongPHZC21","ArXiv":"2009.09761","CorpusId":221818900},"title":"DiffWave: A Versatile Diffusion Model for Audio Synthesis"},{"paperId":"685af6d2bcdff7170574643b2c5ab4fbcc36f597","externalIds":{"DBLP":"conf/iclr/ChenZZWNC21","MAG":"3082563516","ArXiv":"2009.00713","CorpusId":221447287},"title":"WaveGrad: Estimating Gradients for Waveform Generation"},{"paperId":"5c126ae3421f05768d8edd97ecd44b1364e2c99a","externalIds":{"DBLP":"conf/nips/HoJA20","MAG":"3100572490","ArXiv":"2006.11239","CorpusId":219955663},"title":"Denoising Diffusion Probabilistic Models"},{"paperId":"9a75cb455b4e70c66f3b72e6bb1498d8cab72fb2","externalIds":{"MAG":"3100859887","DBLP":"journals/corr/abs-2006-10029","ArXiv":"2006.10029","CorpusId":219721239},"title":"Big Self-Supervised Models are Strong Semi-Supervised Learners"},{"paperId":"38f93092ece8eee9771e61c1edaf11b1293cae1b","externalIds":{"MAG":"3101821705","DBLP":"conf/nips/GrillSATRBDPGAP20","ArXiv":"2006.07733","CorpusId":219687798},"title":"Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning"},{"paperId":"daac0eb664f885b5728b7728f5fa7ef23cc75862","externalIds":{"ArXiv":"2006.10728","MAG":"3034523045","DBLP":"conf/cvpr/Liu0BZ020","DOI":"10.1109/cvpr42600.2020.01429","CorpusId":219632978},"title":"Diverse Image Generation via Self-Conditioned GANs"},{"paperId":"925ad2897d1b5decbea320d07e99afa9110e09b2","externalIds":{"DBLP":"journals/corr/abs-2004-05150","MAG":"3015468748","ArXiv":"2004.05150","CorpusId":215737171},"title":"Longformer: The Long-Document Transformer"},{"paperId":"7af72a461ed7cda180e7eab878efd5f35d79bbf4","externalIds":{"DBLP":"conf/icml/ChenK0H20","MAG":"3034978746","ArXiv":"2002.05709","CorpusId":211096730},"title":"A Simple Framework for Contrastive Learning of Visual Representations"},{"paperId":"7dc31d7fa8bf8caabed958173c3e220256c64af4","externalIds":{"MAG":"3034526383","DBLP":"conf/icml/VoynovB20","ArXiv":"2002.03754","CorpusId":211069212},"title":"Unsupervised Discovery of Interpretable Directions in the GAN Latent Space"},{"paperId":"add2f205338d70e10ce5e686df4a690e2851bdfc","externalIds":{"DBLP":"conf/cvpr/He0WXG20","MAG":"2987283559","ArXiv":"1911.05722","DOI":"10.1109/cvpr42600.2020.00975","CorpusId":207930212},"title":"Momentum Contrast for Unsupervised Visual Representation Learning"},{"paperId":"87045bfc6f8036d032ab6ad1ebeb0377db05da9a","externalIds":{"MAG":"2986405467","ArXiv":"1911.05371","DBLP":"conf/iclr/AsanoRV20a","CorpusId":207930156},"title":"Self-labelling via simultaneous clustering and representation learning"},{"paperId":"cb70ff3a4e51cdf8f83680b3e9105856eaf8dd3f","externalIds":{"DBLP":"journals/corr/abs-1908-10543","MAG":"2970350341","ArXiv":"1908.10543","CorpusId":201653520},"title":"SPair-71k: A Large-scale Benchmark for Semantic Correspondence"},{"paperId":"965359b3008ab50dd04e171551220ec0e7f83aba","externalIds":{"MAG":"2971034910","ArXiv":"1907.05600","DBLP":"conf/nips/SongE19","CorpusId":196470871},"title":"Generative Modeling by Estimating Gradients of the Data Distribution"},{"paperId":"cde35c87aaabbc617d38f9cfaa2721a2e166d750","externalIds":{"DBLP":"journals/corr/abs-1907-02544","ArXiv":"1907.02544","MAG":"2970241862","CorpusId":195820291},"title":"Large Scale Adversarial Representation Learning"},{"paperId":"329b84a919bfd1771be5bd14fa81e7b3f74cc961","externalIds":{"MAG":"2948978827","DBLP":"journals/corr/abs-1906-02691","ArXiv":"1906.02691","DOI":"10.1561/2200000056","CorpusId":174802445},"title":"An Introduction to Variational Autoencoders"},{"paperId":"a84906dbd4d6640f918d0b6ed2a7313dda0d55f1","externalIds":{"MAG":"2910628332","DBLP":"journals/corr/abs-1901-02446","ArXiv":"1901.02446","DOI":"10.1109/CVPR.2019.00656","CorpusId":57721164},"title":"Panoptic Feature Pyramid Networks"},{"paperId":"ceb2ebef0b41e31c1a21b28c2734123900c005e2","externalIds":{"DBLP":"journals/corr/abs-1812-04948","MAG":"2904367110","ArXiv":"1812.04948","DOI":"10.1109/CVPR.2019.00453","CorpusId":54482423},"title":"A Style-Based Generator Architecture for Generative Adversarial Networks"},{"paperId":"22aab110058ebbd198edb1f1e7b4f69fb13c0613","externalIds":{"ArXiv":"1809.11096","MAG":"2893749619","DBLP":"conf/iclr/BrockDS19","CorpusId":52889459},"title":"Large Scale GAN Training for High Fidelity Natural Image Synthesis"},{"paperId":"e65c2b0feddfe4c89e9955ca9b5ece6ef416628f","externalIds":{"DBLP":"conf/cvpr/YuCWXCLMD20","ArXiv":"1805.04687","MAG":"3016101116","DOI":"10.1109/cvpr42600.2020.00271","CorpusId":215415900},"title":"BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning"},{"paperId":"e644867bc141453d1f0387c76ff5e7f7863c5f4f","externalIds":{"DBLP":"conf/cvpr/AhnK18","MAG":"2951127649","ArXiv":"1803.10464","DOI":"10.1109/CVPR.2018.00523","CorpusId":4702470},"title":"Learning Pixel-Level Semantic Affinity with Image-Level Supervision for Weakly Supervised Semantic Segmentation"},{"paperId":"dce916351ef589afa7a63452648dd8acba931e92","externalIds":{"DBLP":"conf/cvpr/KirillovHGRD19","MAG":"2999219213","ArXiv":"1801.00868","DOI":"10.1109/CVPR.2019.00963","CorpusId":4853375},"title":"Panoptic Segmentation"},{"paperId":"9c88c2357abcd58cc330179c1965fe0a8c067ebc","externalIds":{"DBLP":"journals/corr/abs-1709-00029","ArXiv":"1709.00029","MAG":"2950939977","DOI":"10.1109/JSTARS.2019.2918242","CorpusId":11810992},"title":"EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification"},{"paperId":"f7b032a4df721d4ed2bab97f6acd33d62477b7a5","externalIds":{"MAG":"2949829435","DBLP":"journals/corr/ZagoruykoK16a","ArXiv":"1612.03928","CorpusId":829159},"title":"Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer"},{"paperId":"88512be44744615f4baa8e14f600f036db4c2433","externalIds":{"MAG":"2507296351","DBLP":"journals/corr/ZhouZPFBT16","ArXiv":"1608.05442","DOI":"10.1007/s11263-018-1140-0","CorpusId":11371972},"title":"Semantic Understanding of Scenes Through the ADE20K Dataset"},{"paperId":"97fb4e3d45bb098e27e0071448b6152217bd35a5","externalIds":{"MAG":"3037932933","ArXiv":"1607.06450","DBLP":"journals/corr/BaKH16","CorpusId":8236317},"title":"Layer Normalization"},{"paperId":"cab372bc3824780cce20d9dd1c22d4df39ed081a","externalIds":{"MAG":"2952865063","DBLP":"journals/pami/ChenPKMY18","ArXiv":"1606.00915","DOI":"10.1109/TPAMI.2017.2699184","CorpusId":3429309,"PubMed":"28463186"},"title":"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs"},{"paperId":"1c4e9156ca07705531e45960b7a919dc473abb51","externalIds":{"MAG":"2964137095","DBLP":"conf/bmvc/ZagoruykoK16","ArXiv":"1605.07146","DOI":"10.5244/C.30.87","CorpusId":15276198},"title":"Wide Residual Networks"},{"paperId":"3d1e82b69663758a1db87fbebed6525d23090146","externalIds":{"MAG":"2949375864","ArXiv":"1604.05144","DBLP":"conf/cvpr/LinDJHS16","DOI":"10.1109/CVPR.2016.344","CorpusId":3121011},"title":"ScribbleSup: Scribble-Supervised Convolutional Networks for Semantic Segmentation"},{"paperId":"8b97247d9e097c82e47b406bc6282fa4fc2c58ed","externalIds":{"MAG":"3037679600","DBLP":"conf/cvpr/HamCSP16","ArXiv":"1511.05065","DOI":"10.1109/CVPR.2016.378","CorpusId":6050505},"title":"Proposal Flow"},{"paperId":"4dcdae25a5e33682953f0853ee4cf7ca93be58a9","externalIds":{"MAG":"967544008","DBLP":"journals/corr/YuZSSX15","ArXiv":"1506.03365","CorpusId":8317437},"title":"LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop"},{"paperId":"2dcef55a07f8607a819c21fe84131ea269cc2e3c","externalIds":{"MAG":"2129069237","DBLP":"journals/corr/Sohl-DicksteinW15","ArXiv":"1503.03585","CorpusId":14888175},"title":"Deep Unsupervised Learning using Nonequilibrium Thermodynamics"},{"paperId":"0c908739fbff75f03469d13d4a1a07de3414ee19","externalIds":{"ArXiv":"1503.02531","MAG":"1821462560","DBLP":"journals/corr/HintonVD15","CorpusId":7200347},"title":"Distilling the Knowledge in a Neural Network"},{"paperId":"39ad6c911f3351a3b390130a6e4265355b4d593b","externalIds":{"DBLP":"journals/corr/ChenPKMY14","MAG":"1923697677","ArXiv":"1412.7062","CorpusId":1996665},"title":"Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs"},{"paperId":"8604f376633af8b347e31d84c6150a93b11e34c2","externalIds":{"DBLP":"journals/corr/RomeroBKCGB14","MAG":"2964118293","ArXiv":"1412.6550","CorpusId":2723173},"title":"FitNets: Hints for Thin Deep Nets"},{"paperId":"6fc6803df5f9ae505cae5b2f178ade4062c768d0","externalIds":{"DBLP":"journals/corr/ShelhamerLD16","MAG":"2952632681","ArXiv":"1411.4038","DOI":"10.1109/CVPR.2015.7298965","CorpusId":1629541},"title":"Fully convolutional networks for semantic segmentation"},{"paperId":"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c","externalIds":{"DBLP":"journals/corr/MirzaO14","ArXiv":"1411.1784","MAG":"2125389028","CorpusId":12803511},"title":"Conditional Generative Adversarial Nets"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","externalIds":{"ArXiv":"1405.0312","DBLP":"conf/eccv/LinMBHPRDZ14","MAG":"2952122856","DOI":"10.1007/978-3-319-10602-1_48","CorpusId":14113767},"title":"Microsoft COCO: Common Objects in Context"},{"paperId":"5f5dc5b9a2ba710937e2c413b37b053cd673df02","externalIds":{"DBLP":"journals/corr/KingmaW13","MAG":"2951004968","ArXiv":"1312.6114","CorpusId":216078090},"title":"Auto-Encoding Variational Bayes"},{"paperId":"d9704f8119d6ba748230b4f2ad59f0e8c64fdfb0","externalIds":{"DBLP":"conf/nips/BengioYAV13","ArXiv":"1305.6663","MAG":"2134842679","CorpusId":5554756},"title":"Generalized Denoising Auto-Encoders as Generative Models"},{"paperId":"872bae24c109f7c30e052ac218b17a8b028d08a0","externalIds":{"MAG":"2013035813","DBLP":"journals/neco/Vincent11","DOI":"10.1162/NECO_a_00142","CorpusId":5560643,"PubMed":"21492012"},"title":"A Connection Between Score Matching and Denoising Autoencoders"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","externalIds":{"DBLP":"conf/cvpr/DengDSLL009","MAG":"2108598243","DOI":"10.1109/CVPR.2009.5206848","CorpusId":57246310},"title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"843959ffdccf31c6694d135fad07425924f785b1","externalIds":{"MAG":"2025768430","DBLP":"conf/icml/VincentLBM08","DOI":"10.1145/1390156.1390294","CorpusId":207168299},"title":"Extracting and composing robust features with denoising autoencoders"},{"paperId":"79ad463104c7b7afeab11c2046fe7c18d5108ac6","externalIds":{"DOI":"10.1080/10131750485310161","CorpusId":218497666},"title":"Pattern"},{"paperId":"c7a5128b45edb4db9105ec5167210b887617ddf2","externalIds":{"MAG":"1991111872","DOI":"10.1016/0304-4149(82)90051-5","CorpusId":3897405},"title":"Reverse-time diffusion equation models"},{"paperId":"b29155a6f6ba113188b28b1351fcc694f5e67eec","externalIds":{"MAG":"1566263627","DOI":"10.1017/S0027763000022819","CorpusId":118766808},"title":"Stochastic Differential Equations in a Differentiable Manifold"},{"paperId":"1a15a59aab9fb59d66572e101fa02bd544a1ba7e","externalIds":{"DBLP":"conf/eacl/HuWAMFOS24","ACL":"2024.eacl-short.33","CorpusId":268417074},"title":"Flow Matching for Conditional Text Generation in a Few Sampling Steps"},{"paperId":"cf0f8f585c8822e3c6bcd9527d546eefc8486aea","externalIds":{"DBLP":"conf/nips/NguyenGGDSDBR22","CorpusId":260443992},"title":"S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces"},{"paperId":"33f3f31f871070f19b0c3e967a24e322bfc178f2","externalIds":{"DBLP":"conf/nips/BlattmannROMO22","DOI":"10.48550/arXiv.2204.11824","CorpusId":248377386},"title":"Retrieval-Augmented Diffusion Models"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","externalIds":{"ArXiv":"2103.14030","DBLP":"conf/iccv/LiuL00W0LG21","DOI":"10.1109/ICCV48922.2021.00986","CorpusId":232352874},"title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"},{"paperId":"c68796f833a7151f0a63d1d1608dc902b4fdc9b6","externalIds":{"CorpusId":10319744},"title":"GENERATIVE ADVERSARIAL NETS"},{"paperId":"3a9b175324ba11bc0e16c0633912d897b2fac4e2","externalIds":{"CorpusId":4246903},"title":"International Journal of Computer Vision manuscript No. (will be inserted by the editor) The PASCAL Visual Object Classes (VOC) Challenge"}]}