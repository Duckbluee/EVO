{"references":[{"paperId":"a22ed2c7a069a4325a0e0c43e6b5ba3700bc5724","externalIds":{"DBLP":"journals/corr/abs-2508-04379","ArXiv":"2508.04379","DOI":"10.48550/arXiv.2508.04379","CorpusId":280537097},"title":"VisionTS++: Cross-Modal Time Series Foundation Model with Continual Pre-trained Visual Backbones"},{"paperId":"40c54e4e3c061f00fea482b20a3dc3b2909b7e1f","externalIds":{"DBLP":"journals/corr/abs-2508-01727","ArXiv":"2508.01727","DOI":"10.48550/arXiv.2508.01727","CorpusId":280421288},"title":"OccamVTS: Distilling Vision Models to 1% Parameters for Time Series Forecasting"},{"paperId":"6e2e576c40319571eb1d7cc2c6428129ce6dfa9a","externalIds":{"DBLP":"conf/kdd/WangMC25","ArXiv":"2506.16746","DOI":"10.1145/3711896.3737005","CorpusId":279464486},"title":"Pre-training Time Series Models with Stock Data Customization"},{"paperId":"b0be0c4de776f11cc4c71a3e1326623cb80871f4","externalIds":{"ArXiv":"2506.06836","DBLP":"journals/corr/abs-2506-06836","DOI":"10.48550/arXiv.2506.06836","CorpusId":279250909},"title":"Harnessing Vision-Language Models for Time Series Anomaly Detection"},{"paperId":"d276183c9f1c7d424a2a7520772c4e93789a79cd","externalIds":{"ArXiv":"2505.24003","DBLP":"journals/corr/abs-2505-24003","DOI":"10.48550/arXiv.2505.24003","CorpusId":279071066},"title":"Multi-Modal View Enhanced Large Vision Models for Long-Term Time Series Forecasting"},{"paperId":"e7623c71255ef18d12de7e8fc7aedf5471439dce","externalIds":{"DBLP":"conf/www/HuangZYW25","DOI":"10.1145/3696410.3714793","CorpusId":277998647},"title":"Exploiting Language Power for Time Series Forecasting with Exogenous Variables"},{"paperId":"6bffbfd7047eab6396ceb04fa6540018d4acb5b4","externalIds":{"DBLP":"conf/aaai/ZhaoWWWYW25","DOI":"10.1609/aaai.v39i21.34447","CorpusId":277750938},"title":"STEM-LTS: Integrating Semantic-Temporal Dynamics in LLM-driven Time Series Analysis"},{"paperId":"b457019cad575bb1d54a7a041cdd56015d3daa3f","externalIds":{"DBLP":"journals/corr/abs-2504-04011","ArXiv":"2504.04011","DOI":"10.48550/arXiv.2504.04011","CorpusId":277621915},"title":"Foundation Models for Time Series: A Survey"},{"paperId":"8f5a0b052e3931a74fe2db0f6f6008dc16d4acb7","externalIds":{"DBLP":"conf/icml/NiuXSHXH25","ArXiv":"2503.08271","DOI":"10.48550/arXiv.2503.08271","CorpusId":276928614},"title":"LangTime: A Language-Guided Unified Model for Time Series Forecasting with Proximal Policy Optimization"},{"paperId":"db0dcdb02fd964a5981470f214268d1e64a16cce","externalIds":{"DBLP":"conf/wsdm/ChengCLLLC25","DOI":"10.1145/3701551.3703499","CorpusId":276664811},"title":"InstrucTime: Advancing Time Series Classification with Multimodal Language Modeling"},{"paperId":"bd2eb51e00392bd8a148ba2f60b2284e3dc6a93a","externalIds":{"DBLP":"journals/corr/abs-2503-02445","ArXiv":"2503.02445","DOI":"10.48550/arXiv.2503.02445","CorpusId":276773507},"title":"BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modelling"},{"paperId":"f61cc9b5583c6295d5cd756ec0f34e4c003aab29","externalIds":{"ArXiv":"2502.13923","DBLP":"journals/corr/abs-2502-13923","DOI":"10.48550/arXiv.2502.13923","CorpusId":276449796},"title":"Qwen2.5-VL Technical Report"},{"paperId":"c1b55449e740b6c806db0bf37f70043f3e6a3f13","externalIds":{"ArXiv":"2502.11418","DBLP":"journals/corr/abs-2502-11418","DOI":"10.48550/arXiv.2502.11418","CorpusId":276409254},"title":"TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents"},{"paperId":"d6b06634275ba479ab7ca9233cc7a83309c60d72","externalIds":{"ArXiv":"2502.14887","DBLP":"journals/corr/abs-2502-14887","DOI":"10.48550/arXiv.2502.14887","CorpusId":276557823},"title":"Vision-Enhanced Time Series Forecasting via Latent Diffusion Models"},{"paperId":"92b91dee9c7ed4d9af2c31e3a6eb95f3ab0152fe","externalIds":{"DBLP":"conf/kdd/0058Y00025","ArXiv":"2502.04592","DOI":"10.1145/3711896.373687","CorpusId":276235959},"title":"CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements"},{"paperId":"d9a69d44841044a12bc72df848cd94b78524ed84","externalIds":{"DBLP":"journals/corr/abs-2502-04395","ArXiv":"2502.04395","DOI":"10.48550/arXiv.2502.04395","CorpusId":276235936},"title":"Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting"},{"paperId":"280c58271770030e5d4d15ca5531f75ba2a5aba0","externalIds":{"DBLP":"journals/corr/abs-2502-00816","ArXiv":"2502.00816","DOI":"10.48550/arXiv.2502.00816","CorpusId":276094326},"title":"Sundial: A Family of Highly Capable Time Series Foundation Models"},{"paperId":"163f8f91005c6844f2617e1e33ef484b30e08f2a","externalIds":{"DBLP":"conf/iclr/0003LZYC25","ArXiv":"2501.03747","DOI":"10.48550/arXiv.2501.03747","CorpusId":275342915},"title":"Context-Alignment: Activating and Enhancing LLM Capabilities in Time Series"},{"paperId":"3c47b2290c95b4021a453e7a1b281637debf03d2","externalIds":{"ArXiv":"2412.20810","DBLP":"journals/corr/abs-2412-20810","DOI":"10.48550/arXiv.2412.20810","CorpusId":275134359},"title":"TimeRAF: Retrieval-Augmented Foundation model for Zero-shot Time Series Forecasting"},{"paperId":"b578d920f2b3e46e5f4e11ea393e85c3db17124f","externalIds":{"ArXiv":"2412.17304","DBLP":"journals/corr/abs-2412-17304","DOI":"10.48550/arXiv.2412.17304","CorpusId":274982307},"title":"On the Feasibility of Vision-Language Models for Time-Series Classification"},{"paperId":"3ff6b82155e89e553d74a4eb4be79437bb3a8052","externalIds":{"DBLP":"journals/corr/abs-2412-11376","ArXiv":"2412.11376","DOI":"10.48550/arXiv.2412.11376","CorpusId":274776648},"title":"ChatTime: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data"},{"paperId":"ad25ff526458681bc112102e3586f64bfa205bd2","externalIds":{"DBLP":"journals/corr/abs-2412-08906","ArXiv":"2412.08906","DOI":"10.48550/arXiv.2412.08906","CorpusId":274656208},"title":"Federated Foundation Models on Heterogeneous Time Series"},{"paperId":"84447fcc43ce4c9f975dbc8ec9e54e67c6453833","externalIds":{"DBLP":"conf/cvpr/ChenYWL00025","ArXiv":"2412.04424","DOI":"10.1109/CVPR52734.2025.02321","CorpusId":274514911},"title":"Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion"},{"paperId":"2899e6782bb83d23f89e2a69499c4ca78dfe71ab","externalIds":{"DBLP":"journals/corr/abs-2412-03104","ArXiv":"2412.03104","DOI":"10.14778/3742728.3742735","CorpusId":274464820},"title":"ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning"},{"paperId":"cead61ae025cc2e01c5a5f7255c8f1e5b5be2f7c","externalIds":{"DBLP":"journals/corr/abs-2411-02465","ArXiv":"2411.02465","DOI":"10.48550/arXiv.2411.02465","CorpusId":273821668},"title":"See it, Think it, Sorted: Large Multimodal Models are Few-shot Time Series Anomaly Analyzers"},{"paperId":"1216a29c0beb36a2b621b59d36877edf05afcf8c","externalIds":{"DBLP":"journals/corr/abs-2410-24087","ArXiv":"2410.24087","DOI":"10.48550/arXiv.2410.24087","CorpusId":273707576},"title":"In-Context Fine-Tuning for Time-Series Foundation Models"},{"paperId":"f491028ab69f126357a069afab903de3fad67f2f","externalIds":{"DBLP":"journals/corr/abs-2410-18686","ArXiv":"2410.18686","DOI":"10.1145/3785505","CorpusId":273549434},"title":"Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification"},{"paperId":"38485dac189ddb3a00a1dcfb863260e8e686e3fa","externalIds":{"ArXiv":"2410.17462","DBLP":"journals/corr/abs-2410-17462","DOI":"10.48550/arXiv.2410.17462","CorpusId":273532492},"title":"Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation"},{"paperId":"3478b9dda561998530e59d8fee184c848e3ade4b","externalIds":{"DBLP":"conf/cikm/0004HK24","DOI":"10.1145/3627673.3679931","CorpusId":273498253},"title":"General Time Transformer: an Encoder-only Foundation Model for Zero-Shot Multivariate Time Series Forecasting"},{"paperId":"b262573cbe92ef296544418340d577865603af49","externalIds":{"ArXiv":"2410.19818","DBLP":"journals/corr/abs-2410-19818","DOI":"10.48550/arXiv.2410.19818","CorpusId":273654875},"title":"UniMTS: Unified Pre-training for Motion Time Series"},{"paperId":"a87d911bee64f961730142670dadf9f5b8cc9210","externalIds":{"DBLP":"conf/iclr/YaoYJL0P25","ArXiv":"2410.12360","DOI":"10.48550/arXiv.2410.12360","CorpusId":273375506},"title":"Towards Neural Scaling Laws for Time Series Foundation Models"},{"paperId":"7a944dc164895d923498347894c7ed780d944066","externalIds":{"ArXiv":"2410.10469","DBLP":"journals/corr/abs-2410-10469","DOI":"10.48550/arXiv.2410.10469","CorpusId":273345306},"title":"Moirai-MoE: Empowering Time Series Foundation Models with Sparse Mixture of Experts"},{"paperId":"0673ed89899a55ca10850edc6adab0a7cb08480a","externalIds":{"ArXiv":"2409.19407","DBLP":"journals/corr/abs-2409-19407","DOI":"10.48550/arXiv.2409.19407","CorpusId":272987892},"title":"Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking"},{"paperId":"32bee919a779c601881e8257988e6dabe10383c1","externalIds":{"ArXiv":"2409.17515","DBLP":"conf/nips/WangF0G024","DOI":"10.48550/arXiv.2409.17515","CorpusId":273404602},"title":"From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection"},{"paperId":"2cb3044ef42c7ee022a988864028b80ce977072c","externalIds":{"ArXiv":"2409.16040","DBLP":"journals/corr/abs-2409-16040","DOI":"10.48550/arXiv.2409.16040","CorpusId":272832214},"title":"Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts"},{"paperId":"e2b1ba7e73ca4ce0abef8c87f2c266e502b3b7b4","externalIds":{"DBLP":"journals/corr/abs-2409-11376","ArXiv":"2409.11376","DOI":"10.48550/arXiv.2409.11376","CorpusId":272694168},"title":"Towards Time Series Reasoning with LLMs"},{"paperId":"ace7d07de33a903e1b3052479cacd2dfa7ae2bb6","externalIds":{"ArXiv":"2409.02322","DBLP":"journals/corr/abs-2409-02322","DOI":"10.48550/arXiv.2409.02322","CorpusId":272397961},"title":"TimeDiT: General-purpose Diffusion Transformers for Time Series Foundation Model"},{"paperId":"7665209f6d696321650c8d7eb1d1635406f44d0d","externalIds":{"DBLP":"journals/corr/abs-2408-17253","ArXiv":"2408.17253","DOI":"10.48550/arXiv.2408.17253","CorpusId":272310529},"title":"VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters"},{"paperId":"52902f77199e6fadef06311c20d26ad84d8bc713","externalIds":{"ArXiv":"2408.14756","DBLP":"journals/corr/abs-2408-14756","DOI":"10.48550/arXiv.2408.14756","CorpusId":271962849},"title":"Training-Free Time-Series Anomaly Detection: Leveraging Image Foundation Models"},{"paperId":"95eaa78b44b935e35d994b9d4b1605e14cb81f19","externalIds":{"DBLP":"conf/kdd/ZhangYCC024","ArXiv":"2409.00122","DOI":"10.1145/3637528.3671953","CorpusId":270619263},"title":"Brant-X: A Unified Physiological Signal Alignment Framework"},{"paperId":"206b0021c5c7a1acc85f2fdee0c419e780dbca74","externalIds":{"ArXiv":"2408.14484","DBLP":"journals/corr/abs-2408-14484","DOI":"10.48550/arXiv.2408.14484","CorpusId":271962900},"title":"Agentic Retrieval-Augmented Generation for Time Series Analysis"},{"paperId":"6ac9e9c8bdd4eebe3cf6adf7187b9ffb16ff5b64","externalIds":{"DBLP":"journals/corr/abs-2408-07773","ArXiv":"2408.07773","DOI":"10.48550/arXiv.2408.07773","CorpusId":271874655},"title":"MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis"},{"paperId":"7c229fb02f204925e5274601a7c4356d49b12c92","externalIds":{"ArXiv":"2408.08328","DBLP":"conf/kdd/0003Y0025","DOI":"10.1145/3711896.3737171","CorpusId":271892251},"title":"Unleashing The Power of Pre-Trained Language Models for Irregularly Sampled Time Series"},{"paperId":"a08b1fc4c1621dc54a57b39a4eb7f9f19abbac63","externalIds":{"DBLP":"conf/ijcai/HuangZYLYW24","DOI":"10.24963/ijcai.2024/460","CorpusId":271495614},"title":"LeRet: Language-Empowered Retentive Network for Time Series Forecasting"},{"paperId":"40e8af970329135ec95057d73e239dab805ad128","externalIds":{"ArXiv":"2407.21783","CorpusId":271571434},"title":"The Llama 3 Herd of Models"},{"paperId":"b72a95c6070d722335fae650a0e5b1dd926a66a8","externalIds":{"ArXiv":"2407.07311","DBLP":"journals/tmlr/YangWFCCZ25","CorpusId":271088840},"title":"ViTime: Foundation Model for Time Series Forecasting Powered by Vision Intelligence"},{"paperId":"df0d604b8e8e3b2947d9865d735f204c08635012","externalIds":{"DBLP":"conf/nips/TanMGAH24","ArXiv":"2406.16964","DOI":"10.48550/arXiv.2406.16964","CorpusId":270711347},"title":"Are Language Models Actually Useful for Time Series Forecasting?"},{"paperId":"57701ecb3a8c98f5e5b579baf1185c8874a44a24","externalIds":{"DOI":"10.1016/j.ijpe.2024.109319","CorpusId":270828529},"title":"BearingFM: Towards a foundation model for bearing fault diagnosis by domain knowledge and contrastive learning"},{"paperId":"e7f47e8393c697696a3fccd9ff906dfdb49fe736","externalIds":{"DBLP":"journals/corr/abs-2405-17394","ArXiv":"2405.17394","DOI":"10.52202/079017-1304","CorpusId":270063518},"title":"The Expressive Capacity of State Space Models: A Formal Language Perspective"},{"paperId":"39e0e964d6ba714584c6fd58e170fc36370da6a6","externalIds":{"DBLP":"conf/icml/0004Q000RP0G25","ArXiv":"2405.17478","CorpusId":270068010},"title":"Towards a General Time Series Forecasting Model with Unified Representation and Adaptive Transfer"},{"paperId":"37772412738d8d7af8a62b0617e07ff7a72a1893","externalIds":{"ArXiv":"2405.15317","DBLP":"journals/corr/abs-2405-15317","DOI":"10.48550/arXiv.2405.15317","CorpusId":270045901},"title":"NuwaTS: a Foundation Model Mending Every Incomplete Time Series"},{"paperId":"8e736e11a7096ae33e75da52d4f057a5113e66e2","externalIds":{"ArXiv":"2405.14755","DBLP":"journals/corr/abs-2405-14755","DOI":"10.48550/arXiv.2405.14755","CorpusId":269982782},"title":"Large language models can be zero-shot anomaly detectors for time series?"},{"paperId":"68a65925ac6d270ca27a4fe99e58cf2ed0795821","externalIds":{"DBLP":"conf/nips/LiuLLWL24","ArXiv":"2405.14252","DOI":"10.48550/arXiv.2405.14252","CorpusId":269983741},"title":"Time-FFM: Towards LM-Empowered Federated Foundation Model for Time Series Forecasting"},{"paperId":"8991a260faad1a80f4f1f73e9f1fc6a63b247b0f","externalIds":{"DBLP":"journals/corr/abs-2404-11757","ArXiv":"2404.11757","DOI":"10.48550/arXiv.2404.11757","CorpusId":269214004},"title":"Language Models Still Struggle to Zero-shot Reason about Time Series"},{"paperId":"34eedbb011e45d80045cadebaf1d01b2ddec22a1","externalIds":{"DBLP":"conf/aaai/JiaWZCL24","DOI":"10.1609/aaai.v38i21.30383","CorpusId":268695979},"title":"GPT4MTS: Prompt-based Large Language Model for Multimodal Time-series Forecasting"},{"paperId":"c30abb2ad76fcbfd4e6dc8881850b591d3434a3e","externalIds":{"DBLP":"conf/kdd/LiangWNJ0SPW24","ArXiv":"2403.14735","DOI":"10.1145/3637528.3671451","CorpusId":268667522},"title":"Foundation Models for Time Series Analysis: A Tutorial and Survey"},{"paperId":"c5af46d51668c054e00c6419a522862531eaf9cc","externalIds":{"ArXiv":"2403.07300","DBLP":"conf/aaai/LiuG0LBR0X25","DOI":"10.1609/aaai.v39i18.34082","CorpusId":268363471},"title":"CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning"},{"paperId":"02fa77e4f355198cb4270f6d4a07517bf09c46dd","externalIds":{"DBLP":"journals/tmlr/AnsariSTZMSSRPK24","ArXiv":"2403.07815","DOI":"10.48550/arXiv.2403.07815","CorpusId":268363551},"title":"Chronos: Learning the Language of Time Series"},{"paperId":"de7acd08ad9727d044c3562711e95e581d1d793f","externalIds":{"ArXiv":"2403.06659","DBLP":"journals/corr/abs-2403-06659","DOI":"10.48550/arXiv.2403.06659","CorpusId":268356633},"title":"Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement"},{"paperId":"ff1f1cf9df8c413ec7345da7604ba28597da5b90","externalIds":{"DBLP":"conf/nips/GaoKQHTZ24","ArXiv":"2403.00131","DOI":"10.52202/079017-4463","CorpusId":268201715},"title":"UniTS: A Unified Multi-Task Time Series Model"},{"paperId":"f9f09c782155ca4f2ae4b6ffcf28514b439226cd","externalIds":{"DBLP":"journals/tmlr/TalukderYG24","ArXiv":"2402.16412","DOI":"10.48550/arXiv.2402.16412","CorpusId":268032971},"title":"TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis"},{"paperId":"8cbb814f7f064aa84650614376094e563b532490","externalIds":{"ArXiv":"2403.00813","DBLP":"journals/corr/abs-2403-00813","DOI":"10.1145/3637528.3671578","CorpusId":268230972},"title":"UrbanGPT: Spatio-Temporal Large Language Models"},{"paperId":"bbf272d92b76cc5f1e6f793dcfeb5edd4abed7ef","externalIds":{"ArXiv":"2402.16132","DBLP":"journals/corr/abs-2402-16132","DOI":"10.48550/arXiv.2402.16132","CorpusId":267938863},"title":"LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting"},{"paperId":"c3c810d723214e8f608f7ac64f7444999468fb80","externalIds":{"DBLP":"journals/corr/abs-2402-11838","ArXiv":"2402.11838","DOI":"10.1145/3637528.3671662","CorpusId":267750515},"title":"UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction"},{"paperId":"aabfdbd9db5ce9b1d598eae44e0d6250e7f0fc00","externalIds":{"ArXiv":"2402.03885","DBLP":"conf/icml/GoswamiSCCLD24","DOI":"10.48550/arXiv.2402.03885","CorpusId":267500205},"title":"MOMENT: A Family of Open Time-series Foundation Models"},{"paperId":"d622d8b2d5adc4b638a73b105686840e264dfb8f","externalIds":{"DBLP":"conf/icml/0005ZCZL0WPW24","ArXiv":"2402.02713","CorpusId":270213739},"title":"Position: What Can Large Language Models Tell Us about Time Series Analysis"},{"paperId":"44f6cea2aa05620fef00d8dc9e566918dc6771c9","externalIds":{"DBLP":"journals/corr/abs-2402-03182","ArXiv":"2402.03182","DOI":"10.48550/arXiv.2402.03182","CorpusId":267412144},"title":"Empowering Time Series Analysis with Large Language Models: A Survey"},{"paperId":"4a111f7a3b56d0468f13104999844885157ef17d","externalIds":{"DBLP":"journals/corr/abs-2402-02592","ArXiv":"2402.02592","DOI":"10.48550/arXiv.2402.02592","CorpusId":267411817},"title":"Unified Training of Universal Time Series Forecasting Transformers"},{"paperId":"73f58b90697f957832f5090946894480849dea3a","externalIds":{"ArXiv":"2402.02368","DBLP":"conf/icml/LiuZLH0L24","CorpusId":267412273},"title":"Timer: Generative Pre-trained Transformers Are Large Time Series Models"},{"paperId":"d488445bb2bf6719bc48a4d39bd906116274abda","externalIds":{"DBLP":"journals/corr/abs-2402-02370","ArXiv":"2402.02370","DOI":"10.48550/arXiv.2402.02370","CorpusId":267412001},"title":"AutoTimes: Autoregressive Time Series Forecasters via Large Language Models"},{"paperId":"13df472c3fe81bf1b615238fbd7884c8b45d8d1c","externalIds":{"DBLP":"conf/ijcai/0001C0S24","ArXiv":"2402.01801","DOI":"10.48550/arXiv.2402.01801","CorpusId":267411923},"title":"Large Language Models for Time Series: A Survey"},{"paperId":"3827ec14b1b6a1152f1b54c2339d98953dfcfae9","externalIds":{"ArXiv":"2401.15123","DBLP":"journals/corr/abs-2401-15123","DOI":"10.48550/arXiv.2401.15123","CorpusId":267311589},"title":"Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection"},{"paperId":"2be319e4ac88c29b4d212bc6efa244321d350498","externalIds":{"ArXiv":"2401.14192","DBLP":"journals/corr/abs-2401-14192","DOI":"10.48550/arXiv.2401.14192","CorpusId":267211621},"title":"How Can Large Language Models Understand Spatial-Temporal Data?"},{"paperId":"142961786632e880c05e0b72097427553568e282","externalIds":{"ArXiv":"2401.13912","DBLP":"journals/corr/abs-2401-13912","DOI":"10.48550/arXiv.2401.13912","CorpusId":267212125},"title":"A Survey of Deep Learning and Foundation Models for Time Series Forecasting"},{"paperId":"50728717946ac1e3bf71b917db80bab6aa306bab","externalIds":{"ArXiv":"2401.10134","DBLP":"journals/corr/abs-2401-10134","DOI":"10.1109/MDM61037.2024.00025","CorpusId":267035019},"title":"Spatial-Temporal Large Language Model for Traffic Prediction"},{"paperId":"e2e1f1b8e6c1b7f4f166e15b7c674945856a51b6","externalIds":{"DBLP":"journals/corr/abs-2401-03955","ArXiv":"2401.03955","DOI":"10.48550/arXiv.2401.03955","CorpusId":266844130},"title":"Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series"},{"paperId":"72f38d513a8ab095a3d4f459958cbb31b1f7cdc4","externalIds":{"DBLP":"journals/corr/abs-2401-03717","ArXiv":"2401.03717","DOI":"10.48550/arXiv.2401.03717","CorpusId":266844836},"title":"Universal Time-Series Representation Learning: A Survey"},{"paperId":"2fb8c64bd14f62d2f65377ee3835555a748a8ada","externalIds":{"DBLP":"journals/tkdd/ChenE24","DOI":"10.1145/3638534","CorpusId":266469873},"title":"Graph Time-series Modeling in Deep Learning: A Survey"},{"paperId":"4a89f69277735d3254ea9d734256637ebccbe2ce","externalIds":{"ArXiv":"2311.14332","DBLP":"journals/corr/abs-2311-14332","DOI":"10.48550/arXiv.2311.14332","CorpusId":265444946},"title":"GATGPT: A Pre-trained Large Language Model with Graph Attention Network for Spatiotemporal Imputation"},{"paperId":"d8140a17dfc21b1e3300158cb0676600136f14b1","externalIds":{"DBLP":"journals/corr/abs-2311-11413","ArXiv":"2311.11413","DOI":"10.48550/arXiv.2311.11413","CorpusId":265295118},"title":"Large Pre-trained time series models for cross-domain Time series analysis tasks"},{"paperId":"2d2bfb068e3441aaa9743043603d00f860dd0308","externalIds":{"DBLP":"conf/nips/DooleyKMNW23","ArXiv":"2311.01933","DOI":"10.48550/arXiv.2311.01933","CorpusId":265019400},"title":"ForecastPFN: Synthetically-Trained Zero-Shot Forecasting"},{"paperId":"5b038c1a93967072cc76689fd805e756f804cc42","externalIds":{"DBLP":"journals/corr/abs-2310-10196","ArXiv":"2310.10196","DOI":"10.48550/arXiv.2310.10196","CorpusId":264146957},"title":"Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook"},{"paperId":"b8e57155bbcc1ce8a112482c85b3a3bb25f3fe52","externalIds":{"DBLP":"journals/corr/abs-2310-09751","ArXiv":"2310.09751","DOI":"10.1145/3589334.3645434","CorpusId":264146377},"title":"UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting"},{"paperId":"f45f85fa1beaa795c24c4ff86f1f2deece72252f","externalIds":{"DBLP":"journals/corr/abs-2310-10688","ArXiv":"2310.10688","DOI":"10.48550/arXiv.2310.10688","CorpusId":264172792},"title":"A decoder-only foundation model for time-series forecasting"},{"paperId":"123acfbccca0460171b6b06a4012dbb991cde55b","externalIds":{"ArXiv":"2310.07820","DBLP":"conf/nips/GruverFQW23","DOI":"10.48550/arXiv.2310.07820","CorpusId":263908782},"title":"Large Language Models Are Zero-Shot Time Series Forecasters"},{"paperId":"83ac79bb8e8695fb3c3c024be74790d862adea74","externalIds":{"ArXiv":"2310.04948","DBLP":"journals/corr/abs-2310-04948","DOI":"10.48550/arXiv.2310.04948","CorpusId":263829348},"title":"TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting"},{"paperId":"0efc09978d45bfd35cb6ef60ac88d11a443ba2e1","externalIds":{"ArXiv":"2310.04942","DBLP":"journals/corr/abs-2310-04942","DOI":"10.1145/3681765.3698467","CorpusId":263830923},"title":"Large Language Models for Spatial Trajectory Patterns Mining"},{"paperId":"e8f1d35d56ee04dbf6ba2ac6d42e8e85f4424ca6","externalIds":{"DBLP":"journals/corr/abs-2310-03916","ArXiv":"2310.03916","DOI":"10.1145/3583780.3615155","CorpusId":263830106},"title":"Toward a Foundation Model for Time Series Data"},{"paperId":"16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277","externalIds":{"DBLP":"journals/corr/abs-2310-01728","ArXiv":"2310.01728","DOI":"10.48550/arXiv.2310.01728","CorpusId":263609325},"title":"Time-LLM: Time Series Forecasting by Reprogramming Large Language Models"},{"paperId":"0b778079946764292de3771a489d5ce9e1868a8b","externalIds":{"DBLP":"journals/jamia/SpathisK24","ArXiv":"2309.06236","DOI":"10.48550/arXiv.2309.06236","CorpusId":261697232,"PubMed":"38950417"},"title":"The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models"},{"paperId":"f4eea3bda63af47bd6ddc0b5a34ab04c558f0da2","externalIds":{"ArXiv":"2308.15197","DBLP":"journals/corr/abs-2308-15197","DOI":"10.48550/arXiv.2308.15197","CorpusId":261276812},"title":"Where Would I Go Next? Large Language Models as Human Mobility Predictors"},{"paperId":"d84cf745c534c010b8e55e5a4a04878906848dc3","externalIds":{"DBLP":"conf/iclr/Sun0LH24","ArXiv":"2308.08241","DOI":"10.48550/arXiv.2308.08241","CorpusId":260926650},"title":"TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series"},{"paperId":"1f1899907a1121e9c224a0cd01676e8ac7c03ff2","externalIds":{"DBLP":"journals/fi/KontopoulouPKM23","DOI":"10.3390/fi15080255","CorpusId":260364140},"title":"A Review of ARIMA vs. Machine Learning Approaches for Time Series Forecasting in Data Driven Networks"},{"paperId":"d0475e16e14ac7a9bfaded88a0166d0559962eb3","externalIds":{"DOI":"10.1016/j.aej.2023.05.019","CorpusId":258769682},"title":"A unique Markov chain Monte Carlo method for forecasting wind power utilizing time series model"},{"paperId":"d3ba770fa1f48458b7ccbc88307b942cfb751a36","externalIds":{"DBLP":"journals/corr/abs-2306-03763","ArXiv":"2306.03763","DOI":"10.2139/ssrn.4464002","CorpusId":259006192},"title":"ChatGPT Informed Graph Neural Network for Stock Movement Prediction"},{"paperId":"6dd44624ac912fb50c21c691806ee52d27e73abb","externalIds":{"ArXiv":"2305.15525","DBLP":"journals/corr/abs-2305-15525","DOI":"10.48550/arXiv.2305.15525","CorpusId":258888248},"title":"Large Language Models are Few-Shot Health Learners"},{"paperId":"c2a5073564be916b900ed4c610b3be06805df598","externalIds":{"DBLP":"journals/corr/abs-2305-00624","ArXiv":"2305.00624","DOI":"10.1631/FITEE.2300310","CorpusId":258427023},"title":"Diffusion models for time-series applications: a survey"},{"paperId":"a5036f31f0e629dc661f120b8c3b1f374d479ab8","externalIds":{"DBLP":"journals/corr/abs-2304-08485","ArXiv":"2304.08485","DOI":"10.48550/arXiv.2304.08485","CorpusId":258179774},"title":"Visual Instruction Tuning"},{"paperId":"d26c55bee1ac6856a20862b0f7b4ff38fa39af50","externalIds":{"DBLP":"journals/corr/abs-2304-07619","ArXiv":"2304.07619","DOI":"10.2139/ssrn.4412788","CorpusId":258071542},"title":"Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models"},{"paperId":"ef4cb88b1635b34af15059567dfdf134f79797aa","externalIds":{"ArXiv":"2304.05351","DBLP":"journals/corr/abs-2304-05351","DOI":"10.48550/arXiv.2304.05351","CorpusId":258059831},"title":"The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges"},{"paperId":"45dd0fd5a3e40bd722db2df055405576cf084720","externalIds":{"DBLP":"journals/corr/abs-2303-12311","ArXiv":"2303.12311","DOI":"10.48550/arXiv.2303.12311","CorpusId":257663871},"title":"Frozen Language Model Helps ECG Zero-Shot Learning"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"3f4bd6e35eca865b0226f1bc0da9fc5f0dc948a8","externalIds":{"ArXiv":"2303.12799","DBLP":"conf/nips/0008LY23","DOI":"10.48550/arXiv.2303.12799","CorpusId":257687717},"title":"Time Series as Images: Vision Transformer for Irregularly Sampled Time Series"},{"paperId":"fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c","externalIds":{"ArXiv":"2302.14045","DBLP":"conf/nips/Huang0WHSML0MPL23","DOI":"10.48550/arXiv.2302.14045","CorpusId":257219775},"title":"Language Is Not All You Need: Aligning Perception with Language Models"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"5b7f5488c380cf5085a5dd93e993ad293b225eee","externalIds":{"ArXiv":"2302.11939","DBLP":"conf/nips/ZhouNW0023","CorpusId":258741419},"title":"One Fits All: Power General Time Series Analysis by Pretrained LM"},{"paperId":"874deb5f06f35e52ae13a921b23611eec4abd1da","externalIds":{"DBLP":"journals/corr/abs-2301-10343","ArXiv":"2301.10343","DOI":"10.48550/arXiv.2301.10343","CorpusId":256231457},"title":"ClimaX: A foundation model for weather and climate"},{"paperId":"dad15404d372a23b4b3bf9a63b3124693df3c85e","externalIds":{"ArXiv":"2211.14730","DBLP":"journals/corr/abs-2211-14730","DOI":"10.48550/arXiv.2211.14730","CorpusId":254044221},"title":"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers"},{"paperId":"47696145b3f88c4cc3f3c22035286b5d7ebce09d","externalIds":{"DBLP":"conf/iclr/WuHLZ0L23","ArXiv":"2210.02186","DOI":"10.48550/arXiv.2210.02186","CorpusId":252715491},"title":"TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis"},{"paperId":"863171ed35ca0035074f73bb202b153cc346f2f3","externalIds":{"DBLP":"journals/tkde/XueS24","ArXiv":"2210.08964","DOI":"10.1109/TKDE.2023.3342137","CorpusId":253254774},"title":"PromptCast: A New Prompt-Based Learning Paradigm for Time Series Forecasting"},{"paperId":"c55407cb2fd2fff0c8298090e0f8c99a005d057b","externalIds":{"ArXiv":"2209.05479","DBLP":"journals/corr/abs-2209-05479","DOI":"10.1145/3557915.3561026","CorpusId":252212309},"title":"Leveraging language foundation models for human mobility forecasting"},{"paperId":"dac3a172b504f4e33c029655e9befb3386e5f63a","externalIds":{"DBLP":"journals/corr/abs-2206-07682","ArXiv":"2206.07682","DOI":"10.48550/arXiv.2206.07682","CorpusId":249674500},"title":"Emergent Abilities of Large Language Models"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"ed4087f6e8d77452810979f58246c5b2ad846cf8","externalIds":{"DBLP":"journals/corr/abs-2202-07125","ArXiv":"2202.07125","DOI":"10.24963/ijcai.2023/759","CorpusId":246863823},"title":"Transformers in Time Series: A Survey"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","externalIds":{"ArXiv":"2201.11903","DBLP":"conf/nips/Wei0SBIXCLZ22","CorpusId":246411621},"title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"a3b42a83669998f65df60d7c065a70d07ca95e99","externalIds":{"DBLP":"journals/corr/abs-2201-12086","ArXiv":"2201.12086","CorpusId":246411402},"title":"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"},{"paperId":"6351ebb4a3287f5f3e1273464b3b91e5df5a16d7","externalIds":{"DBLP":"conf/cvpr/HeCXLDG22","ArXiv":"2111.06377","DOI":"10.1109/CVPR52688.2022.01553","CorpusId":243985980},"title":"Masked Autoencoders Are Scalable Vision Learners"},{"paperId":"76e9e2ec3de437ffb30d8b7b629f7fe3e61de5c2","externalIds":{"DBLP":"journals/corr/abs-2108-07258","ArXiv":"2108.07258","CorpusId":237091588},"title":"On the Opportunities and Risks of Foundation Models"},{"paperId":"a8ca46b171467ceb2d7652fbfb67fe701ad86092","externalIds":{"DBLP":"conf/iclr/HuSWALWWC22","ArXiv":"2106.09685","CorpusId":235458009},"title":"LoRA: Low-Rank Adaptation of Large Language Models"},{"paperId":"722ad6ac92286507437b31486f47987d6ece05c9","externalIds":{"DBLP":"conf/iclr/Bao0PW22","ArXiv":"2106.08254","CorpusId":235436185},"title":"BEiT: BERT Pre-Training of Image Transformers"},{"paperId":"e3288a7c7f2a7e272392f10491ed85d178d80089","externalIds":{"DBLP":"conf/nips/GodahewaBWHM21","ArXiv":"2105.06643","CorpusId":234681550},"title":"Monash Time Series Forecasting Archive"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"0839722fb5369c0abaff8515bfc08299efc790a1","externalIds":{"ArXiv":"2102.03334","DBLP":"journals/corr/abs-2102-03334","CorpusId":231839613},"title":"ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"},{"paperId":"0600a8982abb5ce087efd6ded007c19e4bfcad5d","externalIds":{"MAG":"3109365969","DBLP":"journals/bigdata/TorresHSMT21","DOI":"10.1089/big.2020.0159","CorpusId":227298097,"PubMed":"33275484"},"title":"Deep Learning for Time Series Forecasting: A Survey"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"MAG":"3094502228","ArXiv":"2010.11929","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"814a4f680b9ba6baba23b93499f4b48af1a27678","externalIds":{"ArXiv":"2009.03300","DBLP":"journals/corr/abs-2009-03300","MAG":"3083410900","CorpusId":221516475},"title":"Measuring Massive Multitask Language Understanding"},{"paperId":"90abbc2cf38462b954ae1b772fac9532e2ccd8b0","externalIds":{"ArXiv":"2005.14165","DBLP":"conf/nips/BrownMRSKDNSSAA20","MAG":"3030163527","CorpusId":218971783},"title":"Language Models are Few-Shot Learners"},{"paperId":"7af72a461ed7cda180e7eab878efd5f35d79bbf4","externalIds":{"DBLP":"conf/icml/ChenK0H20","MAG":"3034978746","ArXiv":"2002.05709","CorpusId":211096730},"title":"A Simple Framework for Contrastive Learning of Visual Representations"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"dbabab9bf5955558f73a37644f4bb626106a6d73","externalIds":{"MAG":"2802508687","DBLP":"journals/tits/ZhuYWNT19","DOI":"10.1109/TITS.2018.2815678","CorpusId":56717443},"title":"Big Data Analytics in Intelligent Transportation Systems: A Survey"},{"paperId":"d8abb8206b913d185b4bd406880131c13759a6ff","externalIds":{"DBLP":"journals/corr/abs-1811-00075","ArXiv":"1811.00075","MAG":"2898647012","CorpusId":53166683},"title":"The UEA multivariate time series classification archive, 2018"},{"paperId":"4543360d6b6133d143121eda079cd4b7667d2277","externalIds":{"DBLP":"journals/ieeejas/DauBKYZGRK19","ArXiv":"1810.07758","MAG":"2897997001","DOI":"10.1109/JAS.2019.1911747","CorpusId":53019704},"title":"The UCR time series archive"},{"paperId":"474de4adfce86e14a59d02ccce59cf158fdc4c36","externalIds":{"DBLP":"journals/fgcs/GeBB18","MAG":"2802878531","DOI":"10.1016/j.future.2018.04.053","CorpusId":49645129},"title":"Big Data for Internet of Things: A Survey"},{"paperId":"1c2efb418f79b5d29913e014a1dfd78865221c39","externalIds":{"DBLP":"journals/datamine/FawazFWIM19","MAG":"3102970590","ArXiv":"1809.04356","DOI":"10.1007/s10618-019-00619-1","CorpusId":52195012},"title":"Deep learning for time series classification: a review"},{"paperId":"d3229d6cf3738b31ee23e815e2a8c799df5c82dd","externalIds":{"DBLP":"conf/icaisc/ZebikKAS17","MAG":"2616935361","DOI":"10.1007/978-3-319-59060-8_57","CorpusId":13354751},"title":"Convolutional Neural Networks for Time Series Classification"},{"paperId":"3eb25255a46bb99c8fb2dd10fa547f1bc19810bb","externalIds":{"DBLP":"journals/electronicmarkets/AkterW16","MAG":"2304640842","DOI":"10.1007/s12525-016-0219-0","CorpusId":31492959},"title":"Big data analytics in E-commerce: a systematic review and agenda for future research"},{"paperId":"c0883f5930a232a9c1ad601c978caede29155979","externalIds":{"DBLP":"conf/naacl/Ribeiro0G16","MAG":"2516809705","ArXiv":"1602.04938","ACL":"N16-3020","DOI":"10.1145/2939672.2939778","CorpusId":13029170},"title":"“Why Should I Trust You?”: Explaining the Predictions of Any Classifier"},{"paperId":"de6046f58a05a769b5aa526d95a09c5fa5e5b42c","externalIds":{"MAG":"2074812030","DOI":"10.2307/1912559","CorpusId":12579598},"title":"A New Approach to the Economic Analysis of Nonstationary Time Series and the Business Cycle"},{"paperId":"2ee6cb87fc81ecd78d161c4a92c9dfce00c8961c","externalIds":{"MAG":"2304348607","DOI":"10.2307/1912773","CorpusId":18673159},"title":"Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation"},{"paperId":"bc580318bcd411bd8087e86e7d79edef4365ab97","externalIds":{"DBLP":"conf/iclr/DarlowDHASJBS24","CorpusId":271745883},"title":"DAM: Towards a Foundation Model for Forecasting"},{"paperId":"ba8400cd7b94f04f91cf3c2d8c1e1fa5ef83e8d3","externalIds":{"DBLP":"conf/iclr/Cheng024","CorpusId":271532829},"title":"SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series"},{"paperId":"aaf4e88f7a5e4129c6fc50b904c600f62d173083","externalIds":{"DBLP":"journals/corr/abs-2411-15737","DOI":"10.48550/arXiv.2411.15737","CorpusId":274234882},"title":"TableTime: Reformulating Time Series Classification as Zero-Shot Table Understanding via Large Language Models"},{"paperId":"b4e10d3e6d08d8c52b31adee3b808fab21d32d19","externalIds":{"DBLP":"journals/access/LiuZ24","DOI":"10.1109/ACCESS.2024.3415349","CorpusId":270573482},"title":"Combining Seasonal and Trend Decomposition Using LOESS With a Gated Recurrent Unit for Climate Time Series Forecasting"},{"paperId":"2fafad06b457cdc7f132b78c06e5fbfb68bd16eb","externalIds":{"DBLP":"conf/icml/BianJLXC024","CorpusId":272330590},"title":"Multi-Patch Prediction: Adapting Language Models for Time Series Representation Learning"},{"paperId":"41576f3a627c0db8815fe8eb9328e13d09fc2eff","externalIds":{"DBLP":"journals/corr/abs-2308-08469","DOI":"10.48550/arXiv.2308.08469","CorpusId":272980553},"title":"LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs"},{"paperId":"f005889b7d85558f978d40506196e9a853b5ed15","externalIds":{"DBLP":"journals/corr/abs-2310-08278","DOI":"10.48550/arXiv.2310.08278","CorpusId":269766909},"title":"Lag-Llama: Towards Foundation Models for Time Series Forecasting"},{"paperId":"fdbd1c11a0cd390309ad147d0273b5d8721def12","externalIds":{"DBLP":"conf/nips/ZhangY0CWL23","CorpusId":265160406},"title":"Brant: Foundation Model for Intracranial Neural Signal"},{"paperId":"59ff5490b905c1253d7fcd285c15925681ee6eb0","externalIds":{"DBLP":"conf/emnlp/YuCL23","DOI":"10.18653/v1/2023.emnlp-industry.69","CorpusId":265817515},"title":"Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting"},{"paperId":"0e95008a8c49a4c2538aed62ff61977ff7b47ca5","externalIds":{"DBLP":"conf/iclr/KimKTPCC22","CorpusId":251647808},"title":"Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift"},{"paperId":"9c909cffe92d4e076d19cb07593360fd99fbcebe","externalIds":{"DBLP":"journals/pr/ChengYXL22","DOI":"10.1016/j.patcog.2021.108218","CorpusId":238232840},"title":"Financial time series forecasting with multi-modality graph neural network"},{"paperId":"9302b13c194a955371c56b977088859c5cc3aeef","externalIds":{"DBLP":"conf/eacl/SawhneyWAS21","ACL":"2021.eacl-main.185","DOI":"10.18653/v1/2021.eacl-main.185","CorpusId":233189608},"title":"FAST: Financial News and Tweet Based Time Aware Network for Stock Trading"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"783b14ab10a95f3dc7a74073886313a256f05de7","externalIds":{"MAG":"2735895797","DBLP":"conf/ccbd/ChenCHHC16","DOI":"10.1109/CCBD.2016.027","CorpusId":28791934},"title":"Financial Time-Series Data Analysis Using Deep Convolutional Neural Networks"},{"paperId":"18821afd89bfa319a683243f10a89399bbedeabb","externalIds":{"MAG":"1861848143","DOI":"10.1007/978-3-319-29854-2_8","CorpusId":118330637},"title":"Multivariate Time Series"}]}