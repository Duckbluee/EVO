{"abstract":"Machine learning models are increasingly adopted for facilitating clinical decision-making. However, recent research has shown that techniques may result in unintentional biases towards gender, race, and/or ethnicity. Such bias can lead to unexpected social implications, especially detrimental effects on the health and well-being of disadvantaged groups such as racial-ethnic minorities. In recent years, extensive studies on such algorithmic fairness have been conducted in machine learning in general. Yet, the understanding of how algorithmic bias will impact medicine and how to mitigate such bias still remains limited. The goal of this survey is to fill in this gap by providing a comprehensive review of algorithmic fairness within the scope of computational medicine, which aims at improving medicine with computational approaches. We first overview the three types of computational bias: data bias, measurement bias, and model bias. Then we summarize the fairness quantification metrics that are used in various literature. Finally, we present two types of bias mitigation methods, namely, data-based and model-based ones. We also summarize the popular software libraries and tools for bias evaluation and mitigation, followed by open questions and future directions."}