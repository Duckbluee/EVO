{"abstract":"Large language models (LLMs) hold immense potential for personalized AI, but effectively incorporating user history for personalized responses remains challenging. Existing methods often convert user timelines into lengthy text descriptions, leading to high computational cost and potential loss of nuanced information. Inspired by the successful integration of LLMs with other modalities, such as images, we introduce USER-LLM, a novel framework that treats user timelines as a distinct modality and leverages user embeddings for efficient LLM contextualization. User embeddings, generated by a pretrained user encoder, capture latent user behaviors and interests from diverse interaction data. By integrating these embeddings with LLMs through cross-attention, USER-LLM enables LLMs to dynamically adapt their responses to individual user history. Our evaluation on three diverse datasets (MovieLens, Amazon Review, and Google Local Review) demonstrates that User-LLM achieves substantial computation reduction (up to 78.1X) compared to text-prompt-based methods, without sacrificing performance. Importantly, User-LLM maintains or even improves performance on tasks requiring deep user understanding, particularly with long user histories, highlighting its effectiveness in efficiently capturing and leveraging user information for personalized responses."}