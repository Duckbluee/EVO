{"abstract":"Forecasting traffic accidents at a fine-grained spatial scale is essential to provide effective precautions and improve traffic safety in smart urban sensing applications. Current solutions primarily rely on complete historical traffic accident records and/or accurate real-time traffic sensor data for traffic risk prediction. These solutions are prone to various limitations (e.g., facility availability, privacy and legal constraints). In this paper, we address those limitations by exploring two types of widely available and complementary data sources: social media sensing and remote sensing. However, three important technical challenges exist: i) the social media data and remote sensing data often have different data modalities and characteristics, which makes it difficult to effectively fuse them for traffic risk forecasting; ii) the social media data is often noisy, providing fuzzy evidence to capture the spatial-temporal dynamics of traffic accident occurrences; iii) the remote sensing data often contains complex visual features, making it a non-trivial task to explore the accident occurrence correlation between different locations. To address the above challenges, we propose GraphCast, a multi-modal graph neural network framework to accurately forecast the traffic risks in a city by jointly exploring the social media sensing and remote sensing paradigms. The evaluation results on a real-world case study in New York City show that our GraphCast scheme significantly outperforms the state-of-the-art conventional and deep learning baselines in accurately forecasting the traffic risks in a city."}