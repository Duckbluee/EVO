{"paperId":"71bc0c97c20fffce796a355b16bd202987260029","externalIds":{"ArXiv":"2309.05922","DBLP":"journals/corr/abs-2309-05922","DOI":"10.48550/arXiv.2309.05922","CorpusId":261696947},"title":"A Survey of Hallucination in Large Foundation Models","openAccessPdf":{"url":"https://arxiv.org/pdf/2309.05922","status":"CLOSED","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2309.05922, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"9460529","name":"Vipula Rawte"},{"authorId":"144463965","name":"A. Sheth"},{"authorId":"48806891","name":"Amitava Das"}],"abstract":"Hallucination in a foundation model (FM) refers to the generation of content that strays from factual reality or includes fabricated information. This survey paper provides an extensive overview of recent efforts that aim to identify, elucidate, and tackle the problem of hallucination, with a particular focus on ``Large'' Foundation Models (LFMs). The paper classifies various types of hallucination phenomena that are specific to LFMs and establishes evaluation criteria for assessing the extent of hallucination. It also examines existing strategies for mitigating hallucination in LFMs and discusses potential directions for future research in this area. Essentially, the paper offers a comprehensive examination of the challenges and solutions related to hallucination in LFMs."}