{"abstract":"Misinformation has become a pressing issue. Fake media, in both visual and textual forms, is widespread on the web. While various DeepFake detection and text fake news detection methods have been proposed, they are only designed for single-modality forgery based on binary classification, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we highlight a new research problem for multi-modal fake media, namely <bold>D</bold>etecting and <bold>G</bold>rounding <bold>M</bold>ulti-<bold>M</bold>odal <bold>M</bold>edia <bold>M</bold>anipulation (<bold>DGM<inline-formula><tex-math notation=\"LaTeX\">$^{4}$</tex-math><alternatives><mml:math><mml:msup><mml:mrow/><mml:mn>4</mml:mn></mml:msup></mml:math><inline-graphic xlink:href=\"shao-ieq1-3367749.gif\"/></alternatives></inline-formula></bold>). <bold>DGM<inline-formula><tex-math notation=\"LaTeX\">$^{4}$</tex-math><alternatives><mml:math><mml:msup><mml:mrow/><mml:mn>4</mml:mn></mml:msup></mml:math><inline-graphic xlink:href=\"shao-ieq2-3367749.gif\"/></alternatives></inline-formula></bold> aims to not only detect the authenticity of multi-modal media, but also ground the manipulated content (i.e., image bounding boxes and text tokens), which requires deeper reasoning of multi-modal media manipulation. To support a large-scale investigation, we construct the first <bold>DGM<inline-formula><tex-math notation=\"LaTeX\">$^{4}$</tex-math><alternatives><mml:math><mml:msup><mml:mrow/><mml:mn>4</mml:mn></mml:msup></mml:math><inline-graphic xlink:href=\"shao-ieq3-3367749.gif\"/></alternatives></inline-formula></bold> dataset, where image-text pairs are manipulated by various approaches, with rich annotation of diverse manipulations. Moreover, we propose a novel <bold>H</bold>ier<bold>A</bold>rchical <bold>M</bold>ulti-modal <bold>M</bold>anipulation r<bold>E</bold>asoning t<bold>R</bold>ansformer (<bold>HAMMER</bold>) to fully capture the fine-grained interaction between different modalities. <bold>HAMMER</bold> performs: 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated manipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. To exploit more fine-grained contrastive learning for cross-modal semantic alignment, we further integrate Manipulation-Aware Contrastive Loss with Local View and construct a more advanced model <bold>HAMMER++</bold>. Finally, we build an extensive benchmark and set up rigorous evaluation metrics for this new research problem. Comprehensive experiments demonstrate the superiority of <bold>HAMMER</bold> and <bold>HAMMER++</bold>; several valuable observations are also revealed to facilitate future research in multi-modal media manipulation."}