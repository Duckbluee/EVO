{"references":[{"paperId":"30a3eee5e9302108416f6234d739373dde68d373","externalIds":{"MAG":"2951637687","DBLP":"journals/corr/abs-1802-05766","ArXiv":"1802.05766","CorpusId":3358859},"title":"Learning to Count Objects in Natural Images for Visual Question Answering"},{"paperId":"0605a012aeeee9bef773812a533c4f3cb7fa5a5f","externalIds":{"DBLP":"conf/iclr/TrottXS18","MAG":"2950966281","ArXiv":"1712.08697","CorpusId":3538627},"title":"Interpretable Counting for Visual Question Answering"},{"paperId":"799537fa855caf53a6a3a7cf20301a81e90da127","externalIds":{"MAG":"2950045970","DBLP":"conf/nips/SchwartzSH17","ArXiv":"1711.04323","CorpusId":26356195},"title":"High-Order Attention Models for Visual Question Answering"},{"paperId":"33998aff64ce51df8dee45989cdca4b6b1329ec4","externalIds":{"DBLP":"journals/corr/abs-1710-10903","ArXiv":"1710.10903","MAG":"2766453196","DOI":"10.17863/CAM.48429","CorpusId":3292002},"title":"Graph Attention Networks"},{"paperId":"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81","externalIds":{"DBLP":"journals/corr/abs-1708-02711","ArXiv":"1708.02711","MAG":"2745132836","DOI":"10.1109/CVPR.2018.00444","CorpusId":12288917},"title":"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge"},{"paperId":"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8","externalIds":{"MAG":"2745461083","DBLP":"conf/cvpr/00010BT0GZ18","ArXiv":"1707.07998","DOI":"10.1109/CVPR.2018.00636","CorpusId":3753452},"title":"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"},{"paperId":"34b73c1aa158b892bbe41705b4ae5bf01ecaea86","externalIds":{"ArXiv":"1701.02426","DBLP":"journals/corr/XuZCF17","MAG":"2579549467","DOI":"10.1109/CVPR.2017.330","CorpusId":1780254},"title":"Scene Graph Generation by Iterative Message Passing"},{"paperId":"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e","externalIds":{"MAG":"3016211260","DBLP":"conf/cvpr/GoyalKSBP17","ArXiv":"1612.00837","DOI":"10.1007/s11263-018-1116-0","CorpusId":8081284},"title":"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"},{"paperId":"f09f7888aa5aeaf88a2a44aea768d9a8747e97d2","externalIds":{"MAG":"2949755136","DBLP":"conf/cvpr/MontiBMRSB17","ArXiv":"1611.08402","DOI":"10.1109/CVPR.2017.576","CorpusId":301319},"title":"Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs"},{"paperId":"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede","externalIds":{"ArXiv":"1610.01465","DBLP":"journals/corr/KafleK16","MAG":"2529436507","DOI":"10.1016/j.cviu.2017.06.005","CorpusId":207061473},"title":"Visual question answering: Datasets, algorithms, and future challenges"},{"paperId":"c7d007ba376faddf0046930ea7375ed59600cee9","externalIds":{"ArXiv":"1609.05600","DBLP":"journals/corr/TeneyLH16","MAG":"2950243881","DOI":"10.1109/CVPR.2017.344","CorpusId":206595534},"title":"Graph-Structured Representations for Visual Question Answering"},{"paperId":"36eff562f65125511b5dfab68ce7f7a943c27478","externalIds":{"ArXiv":"1609.02907","MAG":"2519887557","DBLP":"journals/corr/KipfW16","CorpusId":3144218},"title":"Semi-Supervised Classification with Graph Convolutional Networks"},{"paperId":"88c307c51594c6d802080a0780d0d654e2e2891f","externalIds":{"MAG":"2964138343","DBLP":"journals/cviu/WuTWSDH17","ArXiv":"1607.05910","DOI":"10.1016/j.cviu.2017.05.001","CorpusId":11746788},"title":"Visual question answering: A survey of methods and datasets"},{"paperId":"c41eb895616e453dcba1a70c9b942c5063cc656c","externalIds":{"MAG":"2468907370","ArXiv":"1606.09375","DBLP":"conf/nips/DefferrardBV16","CorpusId":3016223},"title":"Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering"},{"paperId":"12f7de07f9b00315418e381b2bd797d21f12b419","externalIds":{"DBLP":"conf/emnlp/FukuiPYRDR16","ACL":"D16-1044","ArXiv":"1606.01847","MAG":"2412400526","DOI":"10.18653/v1/D16-1044","CorpusId":2840197},"title":"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding"},{"paperId":"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b","externalIds":{"MAG":"2963668159","ArXiv":"1606.00061","DBLP":"journals/corr/LuYBP16","CorpusId":868693},"title":"Hierarchical Question-Image Co-Attention for Visual Question Answering"},{"paperId":"ba8d37f2e98d70f917d0d3a49c387cef6867e65e","externalIds":{"MAG":"2950242896","DBLP":"journals/corr/BoscainiMRB16","ArXiv":"1605.06437","CorpusId":15425191},"title":"Learning shape correspondence with anisotropic convolutional neural networks"},{"paperId":"492f57ee9ceb61fb5a47ad7aebfec1121887a175","externalIds":{"MAG":"2244807774","ArXiv":"1511.05493","DBLP":"journals/corr/LiTBZ15","CorpusId":8393918},"title":"Gated Graph Sequence Neural Networks"},{"paperId":"a6cb366736791bcccc5c8639de5a8f9636bf87e8","externalIds":{"MAG":"2964121744","DBLP":"journals/corr/KingmaB14","ArXiv":"1412.6980","CorpusId":6628106},"title":"Adam: A Method for Stochastic Optimization"},{"paperId":"f37e1b62a767a307c046404ca96bc140b3e68cb5","externalIds":{"DBLP":"conf/emnlp/PenningtonSM14","ACL":"D14-1162","MAG":"2250539671","DOI":"10.3115/v1/D14-1162","CorpusId":1957433},"title":"GloVe: Global Vectors for Word Representation"},{"paperId":"0b544dfe355a5070b60986319a3f51fb45d1348e","externalIds":{"MAG":"2950635152","DBLP":"conf/emnlp/ChoMGBBSB14","ACL":"D14-1179","ArXiv":"1406.1078","DOI":"10.3115/v1/D14-1179","CorpusId":5590763},"title":"Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation"},{"paperId":"39e223e6b5a6f8727e9f60b8b7c7720dc40a5dbc","externalIds":{"MAG":"3106171566","DBLP":"journals/spm/ShumanNFOV13","ArXiv":"1211.0053","DOI":"10.1109/MSP.2012.2235192","CorpusId":1594725},"title":"The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains"},{"paperId":"eb4fc76dc335f89d258f38676ea6e92c9ddf66c6","externalIds":{"MAG":"2753474648","DBLP":"conf/nips/IlievskiF17","CorpusId":20016955},"title":"Multimodal Learning and Reasoning for Visual Question Answering"}]}