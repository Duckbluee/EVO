{"references":[{"paperId":"2296629527ebbd6f8c897df7cf5cdbac3f0cc15b","externalIds":{"DBLP":"conf/acl/UstunAYKDOBSOKV24","ArXiv":"2402.07827","DOI":"10.48550/arXiv.2402.07827","CorpusId":267627803},"title":"Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model"},{"paperId":"3287f11b060dc720d8b6a71a3404679d5bd76f56","externalIds":{"DBLP":"conf/aaai/WangZGWG25","ArXiv":"2402.05813","DOI":"10.48550/arXiv.2402.05813","CorpusId":267547751},"title":"Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models"},{"paperId":"4a2a1a107964c19a8b4a523a7fcd78e166e85f21","externalIds":{"DBLP":"journals/corr/abs-2402-01981","ArXiv":"2402.01981","DOI":"10.48550/arXiv.2402.01981","CorpusId":267411833},"title":"Self-Debiasing Large Language Models: Zero-Shot Recognition and Reduction of Stereotypes"},{"paperId":"46fb63b449a468600c4274823bbffb37b8a21d87","externalIds":{"ArXiv":"2312.07420","DBLP":"journals/corr/abs-2312-07420","DOI":"10.48550/arXiv.2312.07420","CorpusId":266174259},"title":"FairSISA: Ensemble Post-Processing to Improve Fairness of Unlearning in LLMs"},{"paperId":"fc7ee1828030a818f52518022a39f6a3ada60222","externalIds":{"ArXiv":"2311.17035","DBLP":"journals/corr/abs-2311-17035","DOI":"10.48550/arXiv.2311.17035","CorpusId":265466445},"title":"Scalable Extraction of Training Data from (Production) Language Models"},{"paperId":"e0b3cdd6639cc702e106f708bd3ba934e646ffba","externalIds":{"DBLP":"journals/corr/abs-2311-08011","ArXiv":"2311.08011","DOI":"10.48550/arXiv.2311.08011","CorpusId":265158175},"title":"Forgetting before Learning: Utilizing Parametric Arithmetic for Knowledge Updating in Large Language Models"},{"paperId":"0399533de2d1d21f456663d1bd5355c8b3c32a58","externalIds":{"DBLP":"journals/corr/abs-2310-20150","ArXiv":"2310.20150","DOI":"10.48550/arXiv.2310.20150","CorpusId":264828972},"title":"Unlearn What You Want to Forget: Efficient Unlearning for LLMs"},{"paperId":"41a3c41ba1912e1384849e6898c241af89cc4a11","externalIds":{"DBLP":"journals/corr/abs-2310-20138","ArXiv":"2310.20138","DOI":"10.48550/arXiv.2310.20138","CorpusId":264816202},"title":"DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models"},{"paperId":"3422d5e0cdfdc935d6a84a1e3d3f96659265fe3a","externalIds":{"DBLP":"conf/iclr/ShiAXHLB0Z24","ArXiv":"2310.16789","DOI":"10.48550/arXiv.2310.16789","CorpusId":264451585},"title":"Detecting Pretraining Data from Large Language Models"},{"paperId":"8fd11c6f3eb1d0aeb915369f3c4f0b1bb24cab0c","externalIds":{"DBLP":"conf/nips/YaoXL24","ArXiv":"2310.10683","DOI":"10.48550/arXiv.2310.10683","CorpusId":264172840},"title":"Large Language Model Unlearning"},{"paperId":"a1fd0cbdeae7fe6f44698139e240d9498fb74cbb","externalIds":{"ArXiv":"2310.09573","DBLP":"conf/emnlp/LeongCWWL23","DOI":"10.48550/arXiv.2310.09573","CorpusId":264146935},"title":"Self-Detoxifying Language Models via Toxification Reversal"},{"paperId":"40a7c44d1cfaa9faf1f731a6f93a889fab5426da","externalIds":{"ArXiv":"2310.02238","DBLP":"journals/corr/abs-2310-02238","CorpusId":263608437},"title":"Who's Harry Potter? Approximate Unlearning in LLMs"},{"paperId":"46eea7d651420e60f9b1393e3f5eda14cbff7a2a","externalIds":{"DBLP":"conf/iclr/PatilHB24","ArXiv":"2309.17410","DOI":"10.48550/arXiv.2309.17410","CorpusId":263311025},"title":"Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks"},{"paperId":"2379523160f357a4041f5be51c67ad5e759e03d2","externalIds":{"DBLP":"conf/icassp/0011K24","ArXiv":"2309.16082","DOI":"10.1109/ICASSP48485.2024.10446299","CorpusId":263141263},"title":"Forgetting Private Textual Sequences in Language Models Via Leave-One-Out Ensemble"},{"paperId":"fec455cd5798dfcb70e741d76c88326d20d2536a","externalIds":{"DBLP":"journals/corr/abs-2310-01424","ArXiv":"2310.01424","DOI":"10.48550/arXiv.2310.01424","CorpusId":263608702},"title":"Identifying and Mitigating Privacy Risks Stemming from Language Models: A Survey"},{"paperId":"e26888285436bc7998e5c95102a9beb60144be5e","externalIds":{"DBLP":"journals/corr/abs-2309-05463","ArXiv":"2309.05463","DOI":"10.48550/arXiv.2309.05463","CorpusId":261696657},"title":"Textbooks Are All You Need II: phi-1.5 technical report"},{"paperId":"104b0bb1da562d53cbda87aec79ef6a2827d191a","externalIds":{"ArXiv":"2307.09288","DBLP":"journals/corr/abs-2307-09288","CorpusId":259950998},"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models"},{"paperId":"35b7f5c369c78d36f83d5e8cf844432735bc7819","externalIds":{"ACL":"2023.acl-short.74","DBLP":"journals/corr/abs-2306-07052","ArXiv":"2306.07052","DOI":"10.48550/arXiv.2306.07052","CorpusId":259138312},"title":"Gradient Ascent Post-training Enhances Language Model Generalization"},{"paperId":"22ae20f20d0b4e6451ae41cc76e58a9221e90df9","externalIds":{"DBLP":"journals/corr/abs-2306-03819","ArXiv":"2306.03819","DOI":"10.48550/arXiv.2306.03819","CorpusId":259088549},"title":"LEACE: Perfect linear concept erasure in closed form"},{"paperId":"e0384ba36555232c587d4a80d527895a095a9001","externalIds":{"DBLP":"journals/corr/abs-2305-11747","ArXiv":"2305.11747","DOI":"10.48550/arXiv.2305.11747","CorpusId":258832847},"title":"HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models"},{"paperId":"cf8f4e762e0758f4f648eafc16c74f7a72a9a13c","externalIds":{"ArXiv":"2305.06535","DBLP":"conf/acl/WangCYZWY23","ACL":"2023.acl-long.740","DOI":"10.48550/arXiv.2305.06535","CorpusId":258615571},"title":"KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment"},{"paperId":"be55e8ec4213868db08f2c3168ae666001bea4b8","externalIds":{"DBLP":"conf/icml/BidermanSABOHKP23","ArXiv":"2304.01373","DOI":"10.48550/arXiv.2304.01373","CorpusId":257921893},"title":"Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling"},{"paperId":"68f0695aad787fdfbce4ec3992fea78641b91552","externalIds":{"DBLP":"conf/naacl/DaheimDSGP24","ArXiv":"2303.17574","ACL":"2024.naacl-long.393","DOI":"10.48550/arXiv.2303.17574","CorpusId":257834065},"title":"Elastic Weight Removal for Faithful and Abstractive Dialogue Generation"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"1bc061b249420116fafeb0dee488ba64540c5388","externalIds":{"MAG":"3157562165","DBLP":"journals/tkde/HassanSD23","DOI":"10.1109/TKDE.2021.3076632","CorpusId":235869640},"title":"Utility-Preserving Privacy Protection of Textual Documents via Word Embeddings"},{"paperId":"ccbb76dc7996f370043b34e32844b1b18a586227","externalIds":{"DBLP":"journals/corr/abs-2212-09573","ArXiv":"2212.09573","DOI":"10.48550/arXiv.2212.09573","CorpusId":254854347},"title":"Privacy Adhering Machine Un-learning in NLP"},{"paperId":"71ba5f845bd22d42003675b7cea970ca9e590bcc","externalIds":{"ArXiv":"2212.04089","DBLP":"conf/iclr/IlharcoRWSHF23","DOI":"10.48550/arXiv.2212.04089","CorpusId":254408495},"title":"Editing Models with Task Arithmetic"},{"paperId":"7d645a3fd276918374fd9483fd675c28e46506d1","externalIds":{"DBLP":"journals/corr/abs-2211-09085","ArXiv":"2211.09085","CorpusId":253553203},"title":"Galactica: A Large Language Model for Science"},{"paperId":"964bd39b546f0f6625ff3b9ef1083f797807ef2e","externalIds":{"DBLP":"journals/corr/abs-2211-05100","ArXiv":"2211.05100","DOI":"10.48550/arXiv.2211.05100","CorpusId":253420279},"title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"},{"paperId":"91fb2254c5942048425e642c8a6c8d400006150e","externalIds":{"DBLP":"journals/corr/abs-2210-01504","ACL":"2023.acl-long.805","ArXiv":"2210.01504","DOI":"10.48550/arXiv.2210.01504","CorpusId":252693065},"title":"Knowledge Unlearning for Mitigating Privacy Risks in Language Models"},{"paperId":"8b64c094a4b637189e3a7fb6fed649562bf78f7e","externalIds":{"ArXiv":"2206.10744","ACL":"2022.gebnlp-1.3","DBLP":"journals/corr/abs-2206-10744","DOI":"10.48550/arXiv.2206.10744","CorpusId":248980783},"title":"Don’t Forget About Pronouns: Removing Gender Bias in Language Models Without Losing Factual Gender Information"},{"paperId":"1d650f1afd45c59ff907396fe8b678595dcb85ea","externalIds":{"DBLP":"conf/icml/MitchellLBMF22","ArXiv":"2206.06520","CorpusId":249642147},"title":"Memory-Based Model Editing at Scale"},{"paperId":"023edab4738690444e3924e224c2641017a0d794","externalIds":{"ArXiv":"2205.13636","DBLP":"journals/corr/abs-2205-13636","DOI":"10.48550/arXiv.2205.13636","CorpusId":249152301},"title":"Quark: Controllable Text Generation with Reinforced Unlearning"},{"paperId":"55c36748f2a7c060c3313349c730b053ed03fbf7","externalIds":{"DBLP":"journals/corr/abs-2202-06539","ArXiv":"2202.06539","CorpusId":246823128},"title":"Deduplicating Training Data Mitigates Privacy Risks in Language Models"},{"paperId":"1b32b77718be22ca31c2a0dba709c815e19d4672","externalIds":{"DOI":"10.1017/9781108936040.022","CorpusId":244427297},"title":"Ethics Guidelines for Trustworthy AI"},{"paperId":"77d956cdab4508d569ae5741549b78e715fd0749","externalIds":{"DBLP":"journals/corr/abs-2109-07958","ACL":"2022.acl-long.229","ArXiv":"2109.07958","DOI":"10.18653/v1/2022.acl-long.229","CorpusId":237532606},"title":"TruthfulQA: Measuring How Models Mimic Human Falsehoods"},{"paperId":"28692beece311a90f5fa1ca2ec9d0c2ce293d069","externalIds":{"DBLP":"journals/csur/LiuYFJHN23","ArXiv":"2107.13586","DOI":"10.1145/3560815","CorpusId":236493269},"title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"},{"paperId":"de549c1592a62c129b8d49c8c0137aa6859b103f","externalIds":{"DBLP":"journals/corr/abs-2107-07566","ACL":"2022.acl-long.579","ArXiv":"2107.07566","DOI":"10.18653/v1/2022.acl-long.579","CorpusId":236034557},"title":"Internet-Augmented Dialogue Generation"},{"paperId":"7e5008713c404445dd8786753526f1a45b93de12","externalIds":{"MAG":"3212496002","DOI":"10.5281/ZENODO.5297715","CorpusId":245758737},"title":"GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"},{"paperId":"db1afe3b3cd4cd90e41fbba65d3075dd5aebb61e","externalIds":{"DBLP":"journals/corr/abs-2101-00027","ArXiv":"2101.00027","CorpusId":230435736},"title":"The Pile: An 800GB Dataset of Diverse Text for Language Modeling"},{"paperId":"df7d26339adf4eb0c07160947b9d2973c24911ba","externalIds":{"DBLP":"journals/corr/abs-2012-07805","MAG":"3112689365","ArXiv":"2012.07805","CorpusId":229156229},"title":"Extracting Training Data from Large Language Models"},{"paperId":"645bd6eadc247989abc5e0b0aa0be79ec8b11ea6","externalIds":{"MAG":"3089430725","DBLP":"journals/corr/abs-2010-00133","ArXiv":"2010.00133","ACL":"2020.emnlp-main.154","DOI":"10.18653/v1/2020.emnlp-main.154","CorpusId":222090785},"title":"CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models"},{"paperId":"399e7d8129c60818ee208f236c8dda17e876d21f","externalIds":{"MAG":"3088599783","ACL":"2020.findings-emnlp.301","DBLP":"journals/corr/abs-2009-11462","ArXiv":"2009.11462","DOI":"10.18653/v1/2020.findings-emnlp.301","CorpusId":221878771},"title":"RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models"},{"paperId":"e28a5d2dc2847f8bc5a40ee062a8fe101aefa28b","externalIds":{"MAG":"3032232719","ACL":"2020.lrec-1.155","DBLP":"conf/lrec/TuggenerDPC20","DOI":"10.21256/ZHAW-20087","CorpusId":218974409},"title":"LEDGAR: A Large-Scale Multi-label Corpus for Text Classification of Legal Provisions in Contracts"},{"paperId":"b805693c17961af2cc7f859c1a54320b26036f46","externalIds":{"MAG":"3031245789","ArXiv":"2004.10643","ACL":"2020.lrec-1.497","DBLP":"journals/corr/abs-2004-10643","CorpusId":216056404},"title":"Universal Dependencies v2: An Evergrowing Multilingual Treebank Collection"},{"paperId":"babeda48b10a4d638252118f2238d05a06f4ec55","externalIds":{"ACL":"2021.acl-long.416","DBLP":"journals/corr/abs-2004-09456","MAG":"3019416653","ArXiv":"2004.09456","DOI":"10.18653/v1/2021.acl-long.416","CorpusId":215828184},"title":"StereoSet: Measuring stereotypical bias in pretrained language models"},{"paperId":"71017cc6d270d28d9edcd47550450dc05edd65f4","externalIds":{"DBLP":"conf/acl/SmithWSWB20","MAG":"3034600233","ArXiv":"2004.08449","ACL":"2020.acl-main.183","DOI":"10.18653/v1/2020.acl-main.183","CorpusId":215827653},"title":"Can You Put it All Together: Evaluating Conversational Agents’ Ability to Blend Skills"},{"paperId":"e969aa3422a49152c22f3faf734e4561a2a3cf42","externalIds":{"DBLP":"conf/acl/RavfogelEGTG20","ArXiv":"2004.07667","ACL":"2020.acl-main.647","MAG":"3035241006","DOI":"10.18653/v1/2020.acl-main.647","CorpusId":215786522},"title":"Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection"},{"paperId":"4ae52766028e69186052ea8f33a137fbbbdb986a","externalIds":{"MAG":"3035252911","ArXiv":"2004.04696","DBLP":"conf/acl/SellamDP20","ACL":"2020.acl-main.704","DOI":"10.18653/v1/2020.acl-main.704","CorpusId":215548699},"title":"BLEURT: Learning Robust Metrics for Text Generation"},{"paperId":"8e58dc63817a2a26e5a2ddad38d8b1d19d1c3795","externalIds":{"ArXiv":"1912.03817","DBLP":"journals/corr/abs-1912-03817","DOI":"10.1109/SP40001.2021.00019","CorpusId":208909851},"title":"Machine Unlearning"},{"paperId":"f9700e31a1d0ae34d4571ab056dfb268c1543349","externalIds":{"MAG":"2989743967","ACL":"D19-5409","DBLP":"journals/corr/abs-1911-12237","ArXiv":"1911.12237","DOI":"10.18653/v1/D19-5409","CorpusId":208010268},"title":"SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization"},{"paperId":"04f4e55e14150b7c48b0287ba77c7443df76ed45","externalIds":{"DBLP":"conf/aaai/BiskZLGC20","MAG":"2998617917","ArXiv":"1911.11641","DOI":"10.1609/AAAI.V34I05.6239","CorpusId":208290939},"title":"PIQA: Reasoning about Physical Commonsense in Natural Language"},{"paperId":"6c4b76232bb72897685d19b3d264c6ee3005bc2b","externalIds":{"MAG":"2981852735","DBLP":"journals/corr/abs-1910-10683","ArXiv":"1910.10683","CorpusId":204838007},"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"a54b56af24bb4873ed0163b77df63b92bd018ddc","externalIds":{"DBLP":"journals/corr/abs-1910-01108","ArXiv":"1910.01108","MAG":"2978017171","CorpusId":203626972},"title":"DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"},{"paperId":"7a064df1aeada7e69e5173f7d4c8606f4470365b","externalIds":{"MAG":"2996428491","DBLP":"journals/corr/abs-1909-11942","ArXiv":"1909.11942","CorpusId":202888986},"title":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"},{"paperId":"0c3c4c88c7b07596221ac640c7b7102686e3eae3","externalIds":{"MAG":"2972522091","DBLP":"conf/emnlp/JinDLCL19","ArXiv":"1909.06146","ACL":"D19-1259","DOI":"10.18653/v1/D19-1259","CorpusId":202572622},"title":"PubMedQA: A Dataset for Biomedical Research Question Answering"},{"paperId":"3fb2d2a28f26c82febe37c632315073ccbc5863c","externalIds":{"DBLP":"conf/trustcom/Hassan0SD19","MAG":"2982673177","DOI":"10.1109/TrustCom/BigDataSE.2019.00055","CorpusId":207829529},"title":"Automatic Anonymization of Textual Documents: Detecting Sensitive Information via Word Embeddings"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","externalIds":{"DBLP":"journals/corr/abs-1907-11692","ArXiv":"1907.11692","MAG":"2965373594","CorpusId":198953378},"title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"1670a07b70f90cc4ddba71343e6a7ee4b5198595","externalIds":{"ACL":"P19-1164","MAG":"2947599143","DBLP":"conf/acl/StanovskySZ19","ArXiv":"1906.00591","DOI":"10.18653/v1/P19-1164","CorpusId":173991101},"title":"Evaluating Gender Bias in Machine Translation"},{"paperId":"eef7cfe8267954adbb4675576072a1d80ca7a3a8","externalIds":{"ArXiv":"1905.13319","MAG":"2945720633","DBLP":"journals/corr/abs-1905-13319","ACL":"N19-1245","DOI":"10.18653/v1/N19-1245","CorpusId":173188048},"title":"MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms"},{"paperId":"8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad","externalIds":{"MAG":"2946609015","DBLP":"journals/corr/abs-1905-07830","ACL":"P19-1472","ArXiv":"1905.07830","DOI":"10.18653/v1/P19-1472","CorpusId":159041722},"title":"HellaSwag: Can a Machine Really Finish Your Sentence?"},{"paperId":"bf8eb31f2918f0a54eff8de3e6c4bf012bfe7a5d","externalIds":{"DOI":"10.1007/springerreference_21883","CorpusId":118938089},"title":"Prediction"},{"paperId":"b611a8095630557229dc5fb6b07c272f1cd614da","externalIds":{"MAG":"2920807444","DBLP":"conf/www/BorkanDSTV19","ArXiv":"1903.04561","DOI":"10.1145/3308560.3317593","CorpusId":75135222},"title":"Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification"},{"paperId":"29ddc1f43f28af7c846515e32cc167bc66886d0c","externalIds":{"DBLP":"journals/corr/abs-1902-00751","ArXiv":"1902.00751","MAG":"2964303773","CorpusId":59599816},"title":"Parameter-Efficient Transfer Learning for NLP"},{"paperId":"c4afa2b3eda95a1194313394901e0e96e24cefaa","externalIds":{"DBLP":"conf/fat/De-ArteagaRWCBC19","MAG":"3105536512","ArXiv":"1901.09451","DOI":"10.1145/3287560.3287572","CorpusId":58006082},"title":"Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting"},{"paperId":"a33a06ddc762fb855b6954c08d5aca603080b011","externalIds":{"MAG":"2951583236","DBLP":"conf/acl/RashkinSLB19","ACL":"P19-1534","DOI":"10.18653/v1/P19-1534","CorpusId":195069365},"title":"Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset"},{"paperId":"227458886343b86bd15adf58c769be326b4b058a","externalIds":{"MAG":"2898875342","DBLP":"conf/iclr/DinanRSFAW19","ArXiv":"1811.01241","CorpusId":53218829},"title":"Wizard of Wikipedia: Knowledge-Powered Conversational agents"},{"paperId":"a68fccc152d238f62848de1be8522ccd71137ac0","externalIds":{"MAG":"2963378725","ArXiv":"1806.01246","DBLP":"journals/corr/abs-1806-01246","DOI":"10.14722/NDSS.2019.23119","CorpusId":46933970},"title":"ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models"},{"paperId":"29de7c0fb3c09eaf55b20619bceaeafe72fd87a6","externalIds":{"MAG":"2963096510","DBLP":"conf/acl/LewisDF18","ArXiv":"1805.04833","ACL":"P18-1082","DOI":"10.18653/v1/P18-1082","CorpusId":44134226},"title":"Hierarchical Neural Story Generation"},{"paperId":"9967cb4fd949039c6f04dd9f2f4c3331dbebe6f7","externalIds":{"MAG":"2963457723","DBLP":"conf/naacl/RudingerNLD18","ArXiv":"1804.09301","ACL":"N18-2002","DOI":"10.18653/v1/N18-2002","CorpusId":13756572},"title":"Gender Bias in Coreference Resolution"},{"paperId":"0be19fd9896e5d40222c690cc3ff553adc7c0e27","externalIds":{"MAG":"2963526187","DBLP":"conf/naacl/ZhaoWYOC18","ACL":"N18-2003","ArXiv":"1804.06876","DOI":"10.18653/v1/N18-2003","CorpusId":4952494},"title":"Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods"},{"paperId":"88bb0a28bb58d847183ec505dda89b63771bb495","externalIds":{"ArXiv":"1803.05457","DBLP":"journals/corr/abs-1803-05457","MAG":"2794325560","CorpusId":3922816},"title":"Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"},{"paperId":"6c7046195f64cccac1ed3275d88d77655534b5a4","externalIds":{"DBLP":"conf/acl/KielaWZDUS18","ACL":"P18-1205","ArXiv":"1801.07243","MAG":"2963825865","DOI":"10.18653/v1/P18-1205","CorpusId":6869582},"title":"Personalizing Dialogue Agents: I have a dog, do you have pets too?"},{"paperId":"873cb93ddf7963b3fb92cbda58fc016cd1ba5a8f","externalIds":{"MAG":"2970343513","DOI":"10.4324/9781351278881-7","CorpusId":147100920},"title":"The Universal Declaration of Human Rights"},{"paperId":"c8f216f663660ff3bc195ecd3a8ad61f0ed1d9d7","externalIds":{"MAG":"2795435272","DBLP":"conf/csfw/YeomGFJ18","DOI":"10.1109/CSF.2018.00027","CorpusId":2656445},"title":"Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting"},{"paperId":"fa025e5d117929361bcf798437957762eb5bb6d4","externalIds":{"DBLP":"conf/conll/LevySCZ17","MAG":"2962881743","ACL":"K17-1034","ArXiv":"1706.04115","DOI":"10.18653/v1/K17-1034","CorpusId":793385},"title":"Zero-Shot Relation Extraction via Reading Comprehension"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"f302e136c41db5de1d624412f68c9174cf7ae8be","externalIds":{"MAG":"2949197630","DBLP":"conf/icml/SundararajanTY17","ArXiv":"1703.01365","CorpusId":16747630},"title":"Axiomatic Attribution for Deep Networks"},{"paperId":"5a8e3eb9206995f070d0d990c054ce7a4b4a47bd","externalIds":{"ArXiv":"1701.00436","DBLP":"journals/corr/0001B17","MAG":"2562898622","DOI":"10.1016/j.engappai.2016.12.013","CorpusId":7931159},"title":"Toward sensitive document release with privacy guarantees"},{"paperId":"f0dcc9aa31dc9b31b836bcac1b140c8c94a2982d","externalIds":{"ArXiv":"1610.05820","DBLP":"journals/corr/ShokriSS16","MAG":"2535690855","DOI":"10.1109/SP.2017.41","CorpusId":10488675},"title":"Membership Inference Attacks Against Machine Learning Models"},{"paperId":"efbd381493bb9636f489b965a2034d529cd56bcd","externalIds":{"ArXiv":"1609.07843","MAG":"2525332836","DBLP":"journals/corr/MerityXBS16","CorpusId":16299141},"title":"Pointer Sentinel Mixture Models"},{"paperId":"e9a986c8ff6c2f381d026fe014f6aaa865f34da7","externalIds":{"MAG":"3098586851","ArXiv":"1607.00133","DBLP":"conf/ccs/AbadiCGMMT016","DOI":"10.1145/2976749.2978318","CorpusId":207241585},"title":"Deep Learning with Differential Privacy"},{"paperId":"5ed791f810da580c78df6a052c6b9f2e258f6b0a","externalIds":{"MAG":"2952915793","ArXiv":"1606.06031","DBLP":"conf/acl/PapernoKLPBPBBF16","ACL":"P16-1144","DOI":"10.18653/v1/P16-1144","CorpusId":2381275},"title":"The LAMBADA dataset: Word prediction requiring a broad discourse context"},{"paperId":"51a55df1f023571a7e07e338ee45a3e3d66ef73e","externalIds":{"DBLP":"journals/corr/ZhangZL15","MAG":"2963012544","ArXiv":"1509.01626","CorpusId":368182},"title":"Character-level Convolutional Networks for Text Classification"},{"paperId":"b7fe00e7e3b9266d9ae65dad3f093ddf48d0d0cc","externalIds":{"MAG":"1690606251","ArXiv":"1406.4285","DBLP":"journals/jasis/0001B16","DOI":"10.1002/asi.23363","CorpusId":7247801},"title":"C‐sanitized: A privacy model for document redaction and sanitization"},{"paperId":"687bac2d3320083eb4530bf18bb8f8f721477600","externalIds":{"ACL":"D13-1170","DBLP":"conf/emnlp/SocherPWCMNP13","MAG":"2251939518","DOI":"10.18653/v1/d13-1170","CorpusId":990233},"title":"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"},{"paperId":"1c61f9ef06fe74505775a833ff849185757199e7","externalIds":{"MAG":"2113459411","ACL":"P11-1015","DBLP":"conf/acl/MaasDPHNP11","CorpusId":1428702},"title":"Learning Word Vectors for Sentiment Analysis"},{"paperId":"5cfbbf3cdff0f905874589bcd21b2646340a5447","externalIds":{"MAG":"2145755360","DBLP":"conf/aaaiss/RoemmeleBG11","CorpusId":434646},"title":"Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning"},{"paperId":"31548c5bb163895211f9b8813c494840bfce4a65","externalIds":{"DOI":"10.32873/uno.dc.jrf.06.01.12","CorpusId":271282726},"title":"Harry Potter and the Sorcerer's Stone"},{"paperId":"a662a25c195d27df933e7236b583b0151ce54045","externalIds":{"DOI":"10.1007/978-94-009-5452-6_5","CorpusId":146938764},"title":"European Parliament"},{"paperId":"c373c792bcf5d0add8de812425d384ff101ef070","externalIds":{"DBLP":"conf/acl/YuJKYJ23","DOI":"10.18653/v1/2023.findings-acl.375","CorpusId":259859034},"title":"Unlearning Bias in Language Models by Partitioning Gradients"},{"paperId":"bfff56fc9080f94ec5bba5bc2bb8cf060f890c76","externalIds":{"DBLP":"journals/corr/abs-2305-07512","DOI":"10.48550/arXiv.2305.07512","CorpusId":258676147},"title":"Learn to Unlearn: A Survey on Machine Unlearning"},{"paperId":"3360d8d78e04579f5778b988506a0439115ceece","externalIds":{"CorpusId":279987025},"title":"Exploring the Landscape of Machine Unlearning: A Survey and Taxonomy"},{"paperId":"448e1493034dafe35699ae054ff4480b31dcf64a","externalIds":{"DBLP":"conf/emnlp/MadaanTCY22","DOI":"10.18653/v1/2022.emnlp-main.183","CorpusId":246016194},"title":"Memory-assisted prompt editing to improve GPT-3 after deployment"},{"paperId":"8c23e7627896b7571648896b7d61b6ef76ece982","externalIds":{"DBLP":"journals/corr/abs-2202-05262","CorpusId":249282155},"title":"Locating and Editing Factual Knowledge in GPT"},{"paperId":"9262b3fdd11e1fa73bc96cf4db4de6bfb5f6f6a2","externalIds":{"DBLP":"conf/acl/LisonPSBO20","ACL":"2021.acl-long.323","DOI":"10.18653/v1/2021.acl-long.323","CorpusId":236460282},"title":"Anonymisation Models for Text Data: State of the art, Challenges and Future Directions"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"92e121c6e114fe3cfb89370df03847c66a9b4e28","externalIds":{"CorpusId":199370376},"title":"An Adversarial Winograd Schema Challenge at Scale"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","externalIds":{"MAG":"2955855238","CorpusId":160025533},"title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","externalIds":{"MAG":"2965425874","CorpusId":49313245},"title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":"82cf69e48ede65b9d1f419da786c0349342d449d","externalIds":{"ACL":"L14-1067","MAG":"2250263931","DBLP":"conf/lrec/SilveiraDMBCBM14","CorpusId":2339260},"title":"A Gold Standard Dependency Corpus for English"},{"paperId":"81aace0e90c6a962059b117c24db0d856f340f41","externalIds":{"ACL":"2014.iwslt-evaluation.1","DBLP":"conf/iwslt/CettoloNSBF14","CorpusId":21661214},"title":"Report on the 11th IWSLT evaluation campaign"},{"paperId":"135d89a35623359aa3af7ce6f95b0078c6acc43a","externalIds":{"DBLP":"conf/ceas/KlimtY04","MAG":"155995321","CorpusId":44854032},"title":"Introducing the Enron Corpus"}]}