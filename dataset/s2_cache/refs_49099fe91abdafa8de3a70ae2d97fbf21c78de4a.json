{"references":[{"paperId":"31753c7ef35309c028694af685221fb6b13c2b63","externalIds":{"ArXiv":"2112.12545","DBLP":"journals/corr/abs-2112-12545","DOI":"10.1016/j.trc.2022.103981","CorpusId":245424852},"title":"A Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drone"},{"paperId":"56b9777dd9dded2a2dad99e2c0e586b4dcbd0ec5","externalIds":{"ArXiv":"2110.13987","DBLP":"conf/nips/KimPK21","CorpusId":239998492},"title":"Learning Collaborative Policies to Solve NP-hard Routing Problems"},{"paperId":"db4c9a6804fcc784bedbb9c3831f1c5921bcd089","externalIds":{"ArXiv":"2110.07983","DBLP":"journals/corr/abs-2110-07983","CorpusId":239009619},"title":"NeuroLKH: Combining Deep Learning Model with Lin-Kernighan-Helsgaun Heuristic for Solving the Traveling Salesman Problem"},{"paperId":"87e879c2465b2414a58dd3a1184f8b346d48f3e7","externalIds":{"ArXiv":"2110.02544","DBLP":"journals/corr/abs-2110-02544","CorpusId":238407851},"title":"Learning to Iteratively Solve Routing Problems with Dual-Aspect Collaborative Transformer"},{"paperId":"15eafc1bd1797b0bb632ecf9beb3c22b99d17d1b","externalIds":{"ArXiv":"2109.13983","DBLP":"journals/orl/AccorsiLV22","DOI":"10.1016/j.orl.2022.01.018","CorpusId":238215507},"title":"Guidelines for the Computational Testing of Machine Learning approaches to Vehicle Routing Problems"},{"paperId":"1629a168adb4095c78c4dc3d590a1214a4919149","externalIds":{"ArXiv":"2110.02629","DBLP":"journals/corr/abs-2110-02629","DOI":"10.1109/TCYB.2021.3111082","CorpusId":237616034,"PubMed":"34554923"},"title":"Deep Reinforcement Learning for Solving the Heterogeneous Capacitated Vehicle Routing Problem"},{"paperId":"0d0207f5cb0ddc5a0d2738234ff81271370ee7fb","externalIds":{"DBLP":"journals/sncs/CostaRZAK21","DOI":"10.1007/s42979-021-00779-2","CorpusId":237156231},"title":"Learning 2-Opt Heuristics for Routing Problems via Deep Reinforcement Learning"},{"paperId":"6652233cc6a6f89eacb13f7a755ea49be5b65fee","externalIds":{"DBLP":"journals/tcyb/XuFCXDZ22","DOI":"10.1109/TCYB.2021.3089179","CorpusId":235778179,"PubMed":"34236983"},"title":"Reinforcement Learning With Multiple Relational Attention for Solving Vehicle Routing Problems"},{"paperId":"e2f0250a349ac515865aef47bfcd3e92f19c172c","externalIds":{"ArXiv":"2107.04139","DBLP":"conf/nips/LiYW21","CorpusId":235790288},"title":"Learning to Delegate for Large-scale Vehicle Routing"},{"paperId":"e3f453ee3d2e084cb0f24769ead763844dbc0661","externalIds":{"DBLP":"journals/corr/abs-2106-05126","ArXiv":"2106.05126","CorpusId":235376887},"title":"Efficient Active Search for Combinatorial Optimization Problems"},{"paperId":"902d70fb673a1af053e0113bb5bd09fd56682112","externalIds":{"DBLP":"journals/candie/QinZHH21","MAG":"3136908367","DOI":"10.1016/J.CIE.2021.107252","CorpusId":233713365},"title":"A novel reinforcement learning-based hyper-heuristic for heterogeneous vehicle routing problem"},{"paperId":"d596ac251729fc3647b08b51c5208fdf5414c7c1","externalIds":{"DBLP":"journals/corr/abs-2102-09544","ArXiv":"2102.09544","DOI":"10.24963/ijcai.2021/595","CorpusId":231951618},"title":"Combinatorial optimization and reasoning with graph neural networks"},{"paperId":"73a6f2a35fbe417e525efcc9da25eb978e6028e9","externalIds":{"DBLP":"journals/tcyb/LiZWWHW22","ArXiv":"2102.05875","DOI":"10.1109/TCYB.2021.3103811","CorpusId":231879679,"PubMed":"34437087"},"title":"Deep Reinforcement Learning for Combinatorial Optimization: Covering Salesman Problems"},{"paperId":"59ee86187388b4e4b5770ab3c87c4e6bd19ad83d","externalIds":{"MAG":"3133471011","DBLP":"journals/tits/LiXCLSZ22","ArXiv":"2110.02634","DOI":"10.1109/TITS.2021.3056120","CorpusId":233941716},"title":"Heterogeneous Attentions for Solving Pickup and Delivery Problem via Deep Reinforcement Learning"},{"paperId":"f2edfaa6cbbd3ca06e9bbdea6294e27345230789","externalIds":{"MAG":"3080752678","DOI":"10.1016/j.ijpe.2020.107899","CorpusId":225236786},"title":"Green vehicle routing problem: A state-of-the-art review"},{"paperId":"50eec8da1acc52a7c4a0a2c527d7696a41bbdc22","externalIds":{"DBLP":"journals/corr/abs-2012-10658","ArXiv":"2012.10658","DOI":"10.1609/aaai.v35i8.16916","CorpusId":229340173},"title":"Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances"},{"paperId":"de741d317507e21d3f7d3f8107d5b685db455aff","externalIds":{"DBLP":"journals/corr/abs-2012-10638","ArXiv":"2012.10638","DOI":"10.1609/aaai.v35i13.17430","CorpusId":229340513},"title":"Multi-Decoder Attention Model with Embedding Glimpse for Solving Vehicle Routing Problems"},{"paperId":"aa18319831e143371ef41974977314d9ab2ec210","externalIds":{"DBLP":"journals/itor/BogyrbayevaTCK21","MAG":"3101064119","DOI":"10.1111/itor.12903","CorpusId":228885381},"title":"An iterative combinatorial auction design for fractional ownership of autonomous vehicles"},{"paperId":"246a68fcf2bcd1db8f0184129b63123d1f98eaa3","externalIds":{"MAG":"3098134815","DBLP":"conf/nips/KwonCKYGM20","ArXiv":"2010.16011","CorpusId":226222332},"title":"POMO: Policy Optimization with Multiple Optima for Reinforcement Learning"},{"paperId":"c7f0bac65336214c042920a378b7ecd511a10ce5","externalIds":{"MAG":"3094001213","DBLP":"conf/nips/DelarueAT20","ArXiv":"2010.12001","CorpusId":225062173},"title":"Reinforcement Learning with Combinatorial Actions: An Application to Vehicle Routing"},{"paperId":"c19e862bb59e252dc02bc61004ec79ac8db390e4","externalIds":{"DBLP":"journals/tii/XinSCZ21","MAG":"3109714359","DOI":"10.1109/TII.2020.3031409","CorpusId":229516324},"title":"Step-Wise Deep Learning Models for Solving Routing Problems"},{"paperId":"1c5709f6d1e82b144fbb8c01b7b4c8b926daed9b","externalIds":{"MAG":"3092574910","DBLP":"journals/tits/BogyrbayevaJ0JK22","ArXiv":"2010.02369","DOI":"10.1109/tits.2021.3085217","CorpusId":222141803},"title":"A Reinforcement Learning Approach for Rebalancing Electric Vehicle Sharing Systems"},{"paperId":"05b919f0ff46a9c3828d0899275a003bdcb1039d","externalIds":{"DBLP":"journals/corr/abs-2010-02068","ArXiv":"2010.02068","MAG":"3090234698","DOI":"10.1109/TITS.2021.3105232","CorpusId":222133968},"title":"Deep Reinforcement Learning for the Electric Vehicle Routing Problem With Time Windows"},{"paperId":"22569a6fe90a75792bb3cae513156f7438adf9e8","externalIds":{"DBLP":"journals/itor/TakallooBCK21","MAG":"3081962134","DOI":"10.1111/itor.12868","CorpusId":221837715},"title":"Solving the winner determination problem in combinatorial auctions for fractional ownership of autonomous vehicles"},{"paperId":"be260cb66bc1935d720252670973ce52af14aaf2","externalIds":{"DBLP":"journals/tits/BonoDSMP21","MAG":"3045710730","DOI":"10.1109/tits.2020.3009289","CorpusId":225495807},"title":"Solving Multi-Agent Routing Problems Using Deep Attention Mechanisms"},{"paperId":"7d0d883c57419164cc5bb29611e381db73aa691e","externalIds":{"DBLP":"journals/tits/ZhaoMZZ21","MAG":"3043239066","DOI":"10.1109/tits.2020.3003163","CorpusId":226569672},"title":"A Hybrid of Deep Reinforcement Learning and Local Search for the Vehicle Routing Problems"},{"paperId":"718d40b26cd53da0d7a4bf4c5557545516b5eddc","externalIds":{"MAG":"3041833837","DBLP":"conf/icml/SykoraRU20","ArXiv":"2007.05096","CorpusId":220486803},"title":"Multi-Agent Routing Value Iteration Network"},{"paperId":"cec75e884ae26c65c7dce83a5b2a8608776415c2","externalIds":{"MAG":"3080626793","DBLP":"conf/kdd/DuanZHGWZX20","DOI":"10.1145/3394486.3403356","CorpusId":221191399},"title":"Efficiently Solving the Practical Vehicle Routing Problem: A Novel Joint Learning Approach"},{"paperId":"9ae7c96289e59f87a02d66d9cb23bf2b70a7b79c","externalIds":{"MAG":"3091755028","DBLP":"conf/ijcnn/ZhangPD20","DOI":"10.1109/IJCNN48605.2020.9207026","CorpusId":221585193},"title":"Deep Reinforcement Learning for Traveling Salesman Problem with Time Windows and Rejections"},{"paperId":"21a5465adf036a3a5b6644753ecc3a7da301ceb8","externalIds":{"MAG":"3040363661","DBLP":"journals/networks/CorberanEHPS21","DOI":"10.1002/net.21965","CorpusId":225803039},"title":"Arc routing problems: A review of the past, present, and future"},{"paperId":"734c3554a2452622afeeb0d43b3804c5a14918d4","externalIds":{"MAG":"3034975643","ArXiv":"2006.09100","DBLP":"journals/corr/abs-2006-09100","CorpusId":219708177},"title":"Learning to Solve Vehicle Routing Problems with Time Windows through Joint Attention"},{"paperId":"9d7846b1c38f280370c7b841859a1d416ed07e6a","externalIds":{"MAG":"3034214690","DBLP":"journals/corr/abs-2006-07054","CorpusId":219636211},"title":"Learning TSP Requires Rethinking Generalization"},{"paperId":"05d2f64c3588e7f230957b75580b427ca4e144f3","externalIds":{"MAG":"3112654960","ArXiv":"2009.10520","DBLP":"conf/icphys/KnippenbergHM20","DOI":"10.1109/ICPS48405.2020.9274782","CorpusId":221836292},"title":"Complex Vehicle Routing with Memory Augmented Neural Networks"},{"paperId":"3a41c499e5ddd5cb4975f36c513ce6a3882bcfde","externalIds":{"MAG":"3033107996","ArXiv":"2006.03750","DBLP":"journals/corr/abs-2006-03750","DOI":"10.1109/ICMLA51294.2020.00013","CorpusId":219530437},"title":"Learning to Solve Combinatorial Optimization Problems on Real-World Graphs in Linear Time"},{"paperId":"6eaeb3687648b8fc8fd23667fa4a66bf49fdba2f","externalIds":{"MAG":"3033044509","DBLP":"journals/corr/abs-2006-01610","ArXiv":"2006.01610","DOI":"10.1609/aaai.v35i5.16484","CorpusId":219179778},"title":"Combining Reinforcement Learning and Constraint Programming for Combinatorial Optimization"},{"paperId":"145fb8670ffb498d6cb5dc42d009a7002a859094","externalIds":{"MAG":"3037428092","DBLP":"conf/aips/JoeL20","DOI":"10.1609/icaps.v30i1.6685","CorpusId":219320873},"title":"Deep Reinforcement Learning Approach to Solve Dynamic Vehicle Routing Problem with Stochastic Customers"},{"paperId":"89139a394ccdc8784ddbdf7d76d56e3d242cf557","externalIds":{"MAG":"3027146252","ArXiv":"2005.11081","DBLP":"journals/corr/abs-2005-11081","DOI":"10.1109/ACCESS.2020.3004964","CorpusId":218862921},"title":"Learning Combinatorial Optimization on Graphs: A Survey With Applications to Networking"},{"paperId":"89998030721e58ade6349b9426cc8c8d81103028","externalIds":{"MAG":"3016108562","DOI":"10.1007/s40745-020-00253-5","CorpusId":216263993},"title":"A Comprehensive Survey of Loss Functions in Machine Learning"},{"paperId":"e7551f9a243e67802af8cf5d2ab9d26b833f4279","externalIds":{"DBLP":"conf/aaai/XuPKL20","MAG":"2997596630","DOI":"10.1609/AAAI.V34I02.5531","CorpusId":212764875},"title":"Deep Neural Network Approximated Dynamic Programming for Combinatorial Optimization"},{"paperId":"1dd0b56776ae37608d64770e732d03683c586058","externalIds":{"DBLP":"journals/corr/abs-2004-01608","MAG":"3014847873","ArXiv":"2004.01608","CorpusId":214795270},"title":"Learning 2-opt Heuristics for the Traveling Salesman Problem via Deep Reinforcement Learning"},{"paperId":"5646b7e555fc7768db1e3e9a792b59a6553b1d7e","externalIds":{"MAG":"3009304813","DBLP":"journals/corr/abs-2003-03600","ArXiv":"2003.03600","DOI":"10.1016/j.cor.2021.105400","CorpusId":212633747},"title":"Reinforcement Learning for Combinatorial Optimization: A Survey"},{"paperId":"ec6fe650b6a32567c060b4cfaa62ac8098756113","externalIds":{"ArXiv":"2002.08539","MAG":"3008858828","DBLP":"journals/corr/abs-2002-08539","CorpusId":211204777},"title":"Learn to Design the Heuristics for Vehicle Routing Problem"},{"paperId":"1f124992fbe1f7d96e7431ca89d9316f74b8ccf2","externalIds":{"MAG":"3109386843","DBLP":"journals/corr/abs-2002-05513","ArXiv":"2002.05513","DOI":"10.1016/j.trc.2020.102861","CorpusId":211096615},"title":"Multi-Vehicle Routing Problems with Soft Time Windows: A Multi-Agent Reinforcement Learning Approach"},{"paperId":"e462b40789ef904e5b6d8bc4f3201e6fb93320d9","externalIds":{"DBLP":"journals/corr/abs-2002-03282","MAG":"3097400948","ArXiv":"2002.03282","DOI":"10.1007/978-981-15-5577-0_51","CorpusId":211069726},"title":"A Deep Reinforcement Learning Algorithm Using Dynamic Attention Model for Vehicle Routing Problems"},{"paperId":"c48fdbbd2c671c8fc9495799c063091eba5e20d6","externalIds":{"DBLP":"journals/tnn/WuSCZL22","ArXiv":"1912.05784","MAG":"3021435853","DOI":"10.1109/TNNLS.2021.3068828","CorpusId":219150860,"PubMed":"33793405"},"title":"Learning Improvement Heuristics for Solving Routing Problems"},{"paperId":"54d4a221db5a91a2487b1610374843fafff5a23d","externalIds":{"MAG":"2991046523","ArXiv":"1911.10635","DBLP":"journals/corr/abs-1911-10635","DOI":"10.1007/978-3-030-60990-0_12","CorpusId":208268127},"title":"Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms"},{"paperId":"901bad1d73e36d0dbd7f03438013d4acbbddf7b1","externalIds":{"MAG":"2987288550","ArXiv":"1911.04936","DBLP":"journals/corr/abs-1911-04936","CorpusId":207863294},"title":"Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning"},{"paperId":"04636d0edc2c6822af5119bef83efdc63b65dc14","externalIds":{"DBLP":"journals/corr/abs-1911-09539","MAG":"3090479233","ArXiv":"1911.09539","DOI":"10.3233/FAIA200124","CorpusId":208201905},"title":"Neural Large Neighborhood Search for the Capacitated Vehicle Routing Problem"},{"paperId":"33abd91d35ad8150b06ddb7bba1e064358251152","externalIds":{"DBLP":"conf/lacci/VeraA19","MAG":"3011810733","ArXiv":"1912.03341","DOI":"10.1109/LA-CCI47412.2019.9037042","CorpusId":208921299},"title":"Deep Reinforcement Learning for Routing a Heterogeneous Fleet of Vehicles"},{"paperId":"2972dfd9d6769cc0483bc9fa2af4362807ed8d2e","externalIds":{"MAG":"3174474790","ArXiv":"1910.11901","DBLP":"journals/eor/ChenUT22","DOI":"10.1016/j.ejor.2021.06.021","CorpusId":237825967},"title":"Deep Q-learning for same-day delivery with vehicles and drones"},{"paperId":"c0cf45edd530abec7ff993fd4c5bb55ab8d26143","externalIds":{"ArXiv":"1910.07210","DBLP":"journals/corr/abs-1910-07210","MAG":"2980930344","CorpusId":204734350},"title":"On Learning Paradigms for the Travelling Salesman Problem"},{"paperId":"470f2f54801226c63d4154a5bae1de6e9122d0b7","externalIds":{"DBLP":"journals/eswa/SilvaSSB19","MAG":"2940740707","DOI":"10.1016/J.ESWA.2019.04.056","CorpusId":150329435},"title":"A reinforcement learning-based multi-agent framework applied for solving routing and scheduling problems"},{"paperId":"72ea8908491fefdf2b217c505abd64135a42d22f","externalIds":{"MAG":"2995180159","CorpusId":213586397},"title":"Targeted sampling of enlarged neighborhood via Monte Carlo tree search for TSP"},{"paperId":"7ac9bd4906de4412d123c4a4f43dc1e458b23da9","externalIds":{"MAG":"2970336486","DBLP":"conf/epia/AliAKB19","DOI":"10.1007/978-3-030-30241-2_49","CorpusId":201711026},"title":"Neural Network Based Large Neighborhood Search Algorithm for Ride Hailing Services"},{"paperId":"ab376f85d36f3af1778e5560421c6cb6c2fefd1b","externalIds":{"MAG":"2948175577","DBLP":"journals/corr/abs-1906-02386","ArXiv":"1906.02386","DOI":"10.1109/TCYB.2020.2977661","CorpusId":174802898,"PubMed":"32191907"},"title":"Deep Reinforcement Learning for Multiobjective Optimization"},{"paperId":"f598a8afec169c435e48ad19356c3b768f8ce7a7","externalIds":{"ArXiv":"1906.01227","DBLP":"journals/corr/abs-1906-01227","MAG":"2948433391","CorpusId":174798181},"title":"An Efficient Graph Convolutional Network Technique for the Travelling Salesman Problem"},{"paperId":"a161cfb4e0239683335a5147799963745dd2bb6c","externalIds":{"MAG":"2958811696","DBLP":"conf/icra/SunGRJ19","DOI":"10.1109/ICRA.2019.8793834","CorpusId":199089828},"title":"Feasible coordination of multiple homogeneous or heterogeneous mobile vehicles with various constraints"},{"paperId":"509d72bdf4bfb9e510b4f56ba8db0e2ca9306ea4","externalIds":{"MAG":"2938157874","DBLP":"journals/tits/YuYG19","DOI":"10.1109/TITS.2019.2909109","CorpusId":146077590},"title":"Online Vehicle Routing With Neural Combinatorial Optimization and Deep Reinforcement Learning"},{"paperId":"db5b9d9c089fd32a44ca43e09ea56d733e55fd6d","externalIds":{"MAG":"2898032212","DBLP":"journals/eswa/Gutierrez-Rodriguez19","DOI":"10.1016/J.ESWA.2018.10.036","CorpusId":54444466},"title":"Selecting meta-heuristics for solving vehicle routing problems with time windows via meta-learning"},{"paperId":"bfc628f21ee904972a43de61ea701c3cc7a13b06","externalIds":{"MAG":"2797064164","DBLP":"journals/transci/UlmerGMH19","DOI":"10.1287/TRSC.2017.0767","CorpusId":32214820},"title":"Offline-Online Approximate Dynamic Programming for Dynamic Vehicle Routing with Stochastic Requests"},{"paperId":"3f13a5148f7caa51ea946193d261d4f8ed32d81a","externalIds":{"MAG":"2900896126","ArXiv":"1811.06128","DBLP":"journals/corr/abs-1811-06128","DOI":"10.1016/j.ejor.2020.07.063","CorpusId":53427953},"title":"Machine Learning for Combinatorial Optimization: a Methodological Tour d'Horizon"},{"paperId":"ba73fe5e00212289dea15c642a2bd0e1db3b9b6c","externalIds":{"MAG":"2901816197","DBLP":"journals/corr/abs-1811-08359","ArXiv":"1811.08359","DOI":"10.1007/s10107-020-01474-5","CorpusId":53760231},"title":"Strong mixed-integer programming formulations for trained neural networks"},{"paperId":"ae51014149d2b0b1032e200cc122f1dba82aab49","externalIds":{"MAG":"2911259909","DBLP":"conf/acml/YangJLSZ18","CorpusId":53618766},"title":"Boosting Dynamic Programming with Neural Networks for Solving NP-hard Problems"},{"paperId":"3f43f08611cbcfba62bb9e0c5339c2a8f0cc3e4b","externalIds":{"DBLP":"journals/corr/abs-1810-05587","MAG":"2981038142","ArXiv":"1810.05587","DOI":"10.1007/s10458-019-09421-1","CorpusId":202540003},"title":"A survey and critique of multiagent deep reinforcement learning"},{"paperId":"f2b840c3c14b9f05106589c1be0a2dd4a494c0ba","externalIds":{"ArXiv":"1810.00337","MAG":"2944956154","DBLP":"conf/nips/ChenT19","CorpusId":165163853},"title":"Learning to Perform Local Rewriting for Combinatorial Optimization"},{"paperId":"960d80dfff5cddf7ad16edcc95027ac9ddec2166","externalIds":{"MAG":"2963382544","DBLP":"conf/aaai/PratesALLV19","ArXiv":"1809.02721","DOI":"10.1609/aaai.v33i01.33014731","CorpusId":52181727},"title":"Learning to Solve NP-Complete Problems - A Graph Neural Network for the Decision TSP"},{"paperId":"4db4f1af1b94fbd5defa0fa0010fdc449dd1e96c","externalIds":{"DBLP":"conf/cpaior/DeudonCLAR18","MAG":"2805798351","DOI":"10.1007/978-3-319-93031-2_12","CorpusId":47017706},"title":"Learning Heuristics for the TSP by Policy Gradient"},{"paperId":"96b99a91617b9b560576ae781f78f569586ce9fd","externalIds":{"MAG":"2991302404","CorpusId":216927954},"title":"The last mile delivery problem"},{"paperId":"9e9644761e7fa4c438477ef44eed216c218d6105","externalIds":{"MAG":"2803151174","DBLP":"journals/corr/abs-1805-07010","ArXiv":"1805.07010","CorpusId":29151261},"title":"Learning Permutations with Sinkhorn Policy Gradient"},{"paperId":"ce4f001c1d8ddb9a95cf54e14240ef02c44bd329","externalIds":{"MAG":"2951846985","ArXiv":"1803.08475","DBLP":"conf/iclr/KoolHW19","CorpusId":59608816},"title":"Attention, Learn to Solve Routing Problems!"},{"paperId":"332327c6d00a776fdcf77637be481effa86e6de0","externalIds":{"MAG":"2962764167","DBLP":"conf/kdd/LinZXZ18","DOI":"10.1145/3219819.3219993","CorpusId":3334421},"title":"Efficient Large-Scale Fleet Management via Multi-Agent Deep Reinforcement Learning"},{"paperId":"0366b6396610708a77540564050a90a761a28937","externalIds":{"MAG":"2949922211","ArXiv":"1802.04240","DBLP":"conf/nips/NazariOST18","CorpusId":46892983},"title":"Reinforcement Learning for Solving the Vehicle Routing Problem"},{"paperId":"0f450869083f8c285b62e5e8ce18af35068686a1","externalIds":{"MAG":"2784910652","CorpusId":57634432},"title":"An Extension of the Lin-Kernighan-Helsgaun TSP Solver for Constrained Traveling Salesman and Vehicle Routing Problems: Technical report"},{"paperId":"dce6f9d4017b1785979e7520fd0834ef8cf02f4b","externalIds":{"MAG":"2736601468","DBLP":"journals/corr/SchulmanWDRK17","ArXiv":"1707.06347","CorpusId":28695052},"title":"Proximal Policy Optimization Algorithms"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"7c3ece1ba41c415d7e81cfa5ca33a8de66efd434","externalIds":{"DBLP":"conf/nips/LoweWTHAM17","MAG":"2623431351","ArXiv":"1706.02275","CorpusId":26419660},"title":"Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"},{"paperId":"ce982006b55f98850a3d8ac7128ae519eb125cf8","externalIds":{"MAG":"2607817513","DBLP":"conf/cec/TyasnuritaOJ17","DOI":"10.1109/CEC.2017.7969477","CorpusId":5959987},"title":"Learning heuristic selection using a Time Delay Neural Network for Open Vehicle Routing"},{"paperId":"2b292ff89d808fba10579871591a22f1649cd039","externalIds":{"ArXiv":"1705.08926","DBLP":"journals/corr/FoersterFANW17","MAG":"2617547828","DOI":"10.1609/aaai.v32i1.11794","CorpusId":19141434},"title":"Counterfactual Multi-Agent Policy Gradients"},{"paperId":"1e819f533ef2bf5ca50a6b2008d96eaea2a2706e","externalIds":{"ArXiv":"1704.01665","DBLP":"journals/corr/DaiKZDS17","MAG":"2607264901","CorpusId":3486660},"title":"Learning Combinatorial Optimization Algorithms over Graphs"},{"paperId":"399f08588ee8d040c3cc0c3d6d58dbab4ffb13b7","externalIds":{"MAG":"2597664555","DBLP":"journals/transci/UlmerMK18","DOI":"10.1287/trsc.2016.0719","CorpusId":3590721},"title":"Budgeting Time for Dynamic Vehicle Routing with Stochastic Customer Requests"},{"paperId":"b68673a166f9c620e13152f63d358fb8fce7850d","externalIds":{"DBLP":"journals/corr/OmidshafieiPAHV17","MAG":"2951896791","ArXiv":"1703.06182","CorpusId":8894704},"title":"Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability"},{"paperId":"b91db36495defb794899ffeae9f2fd4268997489","externalIds":{"MAG":"2509755532","DBLP":"journals/eor/UchoaPPPVS17","DOI":"10.1016/j.ejor.2016.08.012","CorpusId":2749712},"title":"New benchmark instances for the Capacitated Vehicle Routing Problem"},{"paperId":"053ad56377eb143d25203e07c7ee9e14bfdf745c","externalIds":{"MAG":"2591182809","DBLP":"journals/nca/AlipourRFB18","DOI":"10.1007/s00521-017-2880-4","CorpusId":18278494},"title":"A hybrid algorithm using a genetic algorithm and multiagent reinforcement learning heuristic to solve the traveling salesman problem"},{"paperId":"c0ce6c60727808bdadcd7b2be0cf0de34eb36aba","externalIds":{"DBLP":"conf/aaai/MilanRGD017","MAG":"2604308046","DOI":"10.1609/aaai.v31i1.10750","CorpusId":12331764},"title":"Data-Driven Approximations to NP-Hard Problems"},{"paperId":"1a0acc9dd2d23d81b1342d843355daf47a78bbcc","externalIds":{"DBLP":"conf/aaai/NijsWWS17","MAG":"2604677816","DOI":"10.1609/aaai.v31i1.11037","CorpusId":3520745},"title":"Bounding the Probability of Resource Constraint Violations in Multi-Agent MDPs"},{"paperId":"19a7040e38130fbc69772209894a814d80cd5b2e","externalIds":{"MAG":"2560684347","DOI":"10.2507/IJSIMM15(4)CO19","CorpusId":114472586},"title":"Vehicle Routing Problem with Time Windows Using Multi-Objective Co-Evolutionary Approach"},{"paperId":"d7878c2044fb699e0ce0cad83e411824b1499dc8","externalIds":{"DBLP":"journals/corr/BelloPLNB16","ArXiv":"1611.09940","MAG":"2952332632","CorpusId":3649804},"title":"Neural Combinatorial Optimization with Reinforcement Learning"},{"paperId":"69e76e16740ed69f4dc55361a3d319ac2f1293dd","externalIds":{"MAG":"2964043796","DBLP":"journals/corr/MnihBMGLHSK16","ArXiv":"1602.01783","CorpusId":6875312},"title":"Asynchronous Methods for Deep Reinforcement Learning"},{"paperId":"5e08e1cf9ca7c04103b56a579447e753ec766ff1","externalIds":{"MAG":"1510850782","DOI":"10.1080/00207543.2015.1043403","CorpusId":53761338},"title":"A survey on dynamic and stochastic vehicle routing problems"},{"paperId":"c6170fa90d3b2efede5a2e1660cb23e1c824f2ca","externalIds":{"MAG":"2963477884","DBLP":"journals/corr/SchaulQAS15","ArXiv":"1511.05952","CorpusId":13022595},"title":"Prioritized Experience Replay"},{"paperId":"4dcf4cf2af9b466dc48ce2fe174bad8a5099c8ee","externalIds":{"MAG":"2009003336","DBLP":"journals/cor/QiHLHL15","DOI":"10.1016/j.cor.2015.04.009","CorpusId":4854486},"title":"A decomposition based memetic algorithm for multi-objective vehicle routing problem with time windows"},{"paperId":"3b9732bb07dc99bde5e1f9f75251c6ea5039373e","externalIds":{"MAG":"2155968351","DBLP":"conf/aaai/HasseltGS16","ArXiv":"1509.06461","DOI":"10.1609/aaai.v30i1.10295","CorpusId":6208256},"title":"Deep Reinforcement Learning with Double Q-Learning"},{"paperId":"024006d4c2a89f7acacc6e4438d156525b60a98f","externalIds":{"MAG":"2173248099","DBLP":"journals/corr/LillicrapHPHETS15","ArXiv":"1509.02971","CorpusId":16326763},"title":"Continuous control with deep reinforcement learning"},{"paperId":"340f48901f72278f6bf78a04ee5b01df208cc508","externalIds":{"DBLP":"journals/nature/MnihKSRVBGRFOPB15","MAG":"2145339207","DOI":"10.1038/nature14236","CorpusId":205242740,"PubMed":"25719670"},"title":"Human-level control through deep reinforcement learning"},{"paperId":"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5","externalIds":{"MAG":"2133564696","ArXiv":"1409.0473","DBLP":"journals/corr/BahdanauCB14","CorpusId":11212020},"title":"Neural Machine Translation by Jointly Learning to Align and Translate"},{"paperId":"4d23db55e6671a82c95dacec33b2967a4b8b677d","externalIds":{"MAG":"2055312318","DBLP":"conf/pldi/Ragan-KelleyBAPDA13","DOI":"10.1145/2491956.2462176","CorpusId":5885207},"title":"Halide: a language and compiler for optimizing parallelism, locality, and recomputation in image processing pipelines"},{"paperId":"a543a406040eb691372cd9665b70ab8393052a52","externalIds":{"MAG":"1527499860","DBLP":"conf/hm/DoernerS10","DOI":"10.1007/978-3-642-16054-7_15","CorpusId":31324397},"title":"Survey: Matheuristics for Rich Vehicle Routing Problems"},{"paperId":"a4af320294ae7099de61910f432c5260272ecc4f","externalIds":{"DBLP":"conf/smc/FernandesSSBR09","MAG":"2135011173","DOI":"10.1109/ICSMC.2009.5345934","CorpusId":1721684},"title":"A multiagent architecture for solving combinatorial optimization problems through metaheuristics"},{"paperId":"c3aed30ac1573c3b4b9d06db2d059d510bb82977","externalIds":{"DBLP":"journals/eswa/LiuZ09","MAG":"2015164669","DOI":"10.1016/j.eswa.2008.08.026","CorpusId":38465202},"title":"Study of genetic algorithm with reinforcement learning to solve the TSP"},{"paperId":"a8ebee54efc8a5f986692205e7c1ee0070b40524","externalIds":{"MAG":"2110567623","DOI":"10.18637/JSS.V023.I02","CorpusId":215754715},"title":"TSPInfrastructure for the Traveling Salesperson Problem"},{"paperId":"28797767d25fbfe58fcbee618ad183f87eb04441","externalIds":{"DBLP":"journals/swarm/RizzoliMLG07","MAG":"2133343168","DOI":"10.1007/s11721-007-0005-x","CorpusId":2520372},"title":"Ant colony optimization for real-world vehicle routing problems"},{"paperId":"155bca8385eba80126ab4c482a1840b22262f943","externalIds":{"DBLP":"journals/apin/OmbukiRH06","MAG":"2070637511","DOI":"10.1007/s10489-006-6926-z","CorpusId":2645688},"title":"Multi-Objective Genetic Algorithms for Vehicle Routing Problem with Time Windows"},{"paperId":"282001869bd502c7917db8b32b75593addfbbc68","externalIds":{"MAG":"166862392","DBLP":"conf/ecml/Riedmiller05","DOI":"10.1007/11564096_32","CorpusId":6921329},"title":"Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method"},{"paperId":"1e31ab25fb008af395fdc2deb7b4e809f5c21026","externalIds":{"MAG":"1532651649","DBLP":"conf/smc/TanLCL03","DOI":"10.1109/ICSMC.2003.1243842","CorpusId":154338},"title":"A multiobjective evolutionary algorithm for solving vehicle routing problem with time windows"},{"paperId":"a20f0ce0616def7cc9a87446c228906cd5da093b","externalIds":{"DBLP":"conf/nips/SuttonMSM99","MAG":"2155027007","CorpusId":1211821},"title":"Policy Gradient Methods for Reinforcement Learning with Function Approximation"},{"paperId":"cb4368eab957ded0ce8c587c4fda165a26bc5a22","externalIds":{"MAG":"2154929945","DBLP":"journals/tec/DorigoG97","DOI":"10.1109/4235.585892","CorpusId":14074696},"title":"Ant colony system: a cooperative learning approach to the traveling salesman problem"},{"paperId":"b66d590193b5662b5c68400818ce7fa87fcf47fc","externalIds":{"DBLP":"conf/icml/GambardellaD95","MAG":"1566652554","DOI":"10.1016/b978-1-55860-377-6.50039-6","CorpusId":6197270},"title":"Ant-Q: A Reinforcement Learning Approach to the Traveling Salesman Problem"},{"paperId":"bd680d5708297eb76513611919c1145694db77e4","externalIds":{"MAG":"2029681015","DOI":"10.1016/0377-2217(92)90192-C","CorpusId":2671944},"title":"The vehicle routing problem: An overview of exact and approximate algorithms"},{"paperId":"03b7e51c52084ac1db5118342a00b5fbcfc587aa","externalIds":{"MAG":"2625787351","DBLP":"journals/ml/WatkinsD92","DOI":"10.1007/BF00992698","CorpusId":208910339},"title":"Q-learning"},{"paperId":"6dd4c69048d8dad7e42c4293cb8a43f474f02108","externalIds":{"MAG":"2163428398","DBLP":"journals/informs/Reinelt91","DOI":"10.1287/ijoc.3.4.376","CorpusId":207225504},"title":"TSPLIB - A Traveling Salesman Problem Library"},{"paperId":"d35f1e533b72370683d8fa2dabff5f0fc16490cc","externalIds":{"DBLP":"journals/nn/Hornik91","MAG":"1988115241","DOI":"10.1016/0893-6080(91)90009-T","CorpusId":7343126},"title":"Approximation capabilities of multilayer feedforward networks"},{"paperId":"8da1dda34ecc96263102181448c94ec7d645d085","externalIds":{"DBLP":"journals/mcss/Cybenko89","MAG":"2103496339","DOI":"10.1007/BF02551274","CorpusId":3958369},"title":"Approximation by superpositions of a sigmoidal function"},{"paperId":"586d63ddc8b328337966f15296ecc203ff05d9bd","externalIds":{"DBLP":"journals/ior/Solomon87","MAG":"2005521117","DOI":"10.1287/opre.35.2.254","CorpusId":15346313},"title":"Algorithms for the Vehicle Routing and Scheduling Problems with Time Window Constraints"},{"paperId":"8d9b83d213b172582fcdb930ebe3d33ada3c5a8e","externalIds":{"DBLP":"journals/networks/LenstraK81","MAG":"2146870367","DOI":"10.1002/net.3230110211","CorpusId":206312678},"title":"Complexity of vehicle routing and scheduling problems"},{"paperId":"bb35380cbe7d447edd3dc168bddb1f5357abfd59","externalIds":{"DBLP":"conf/acm/HeldK61","MAG":"1982687611","DOI":"10.1145/800029.808532","CorpusId":1542174},"title":"A dynamic programming approach to sequencing problems"},{"paperId":"168526097c6c1e8a2010ce9d2ec434319a5fb948","externalIds":{"DBLP":"conf/iclr/HottungBT21","CorpusId":235613398},"title":"Learning a Latent Search Space for Routing Problems using Variational Autoencoders"},{"paperId":"d79139d3564fe1bf9a301543343a121df971e7ea","externalIds":{"DBLP":"journals/access/XingT20","MAG":"2998057994","DOI":"10.1109/ACCESS.2020.3000236","CorpusId":209475033},"title":"A Graph Neural Network Assisted Monte Carlo Tree Search Approach to Traveling Salesman Problem"},{"paperId":"4c915c1eecb217c123a36dc6d3ce52d12c742614","externalIds":{"DOI":"10.1023/A:1022672621406","CorpusId":2332513},"title":"Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning"},{"paperId":"8f442b0015f4dc9299f5e9256d5e8bf86fe5b218","externalIds":{"CorpusId":232013570},"title":"UvA-DARE (Digital Academic Repository) Deep Policy Dynamic Programming for Vehicle Routing Problems"}]}