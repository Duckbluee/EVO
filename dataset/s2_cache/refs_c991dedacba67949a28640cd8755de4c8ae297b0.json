{"references":[{"paperId":"acbce5ebf3f254188d10f6ba7de1ba716db89774","externalIds":{"DBLP":"conf/icml/GhoshEKSAJDM24","ArXiv":"2402.05119","DOI":"10.48550/arXiv.2402.05119","CorpusId":267548105},"title":"A Closer Look at the Limitations of Instruction Tuning"},{"paperId":"41113411e1748a34bb80f12c761b7af1ed6dbb90","externalIds":{"ArXiv":"2312.15685","DBLP":"conf/iclr/0131Z00H24","DOI":"10.48550/arXiv.2312.15685","CorpusId":266551413},"title":"What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning"},{"paperId":"7a31971b0af439dec6fc484cca20df57f440b644","externalIds":{"DBLP":"journals/corr/abs-2312-10302","ArXiv":"2312.10302","DOI":"10.48550/arXiv.2312.10302","CorpusId":266348323},"title":"One Shot Learning as Instruction Data Prospector for Large Language Models"},{"paperId":"83d12fa58743015f8abe4097fb58088f2d13c7f0","externalIds":{"DBLP":"journals/corr/abs-2312-11508","ArXiv":"2312.11508","DOI":"10.48550/arXiv.2312.11508","CorpusId":266362177},"title":"Rethinking the Instruction Quality: LIFT is What You Need"},{"paperId":"e3f7ad05b1652c6ada78cffbe405bceb723bc70c","externalIds":{"ArXiv":"2311.15653","DBLP":"journals/corr/abs-2311-15653","DOI":"10.48550/arXiv.2311.15653","CorpusId":265457248},"title":"MoDS: Model-oriented Data Selection for Instruction Tuning"},{"paperId":"91e8ce403704a38bee8a5df90d99979a796d1741","externalIds":{"ArXiv":"2311.08182","DBLP":"journals/corr/abs-2311-08182","DOI":"10.48550/arXiv.2311.08182","CorpusId":265157588},"title":"Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning"},{"paperId":"590954e15e247cc343710ee97e396ad99f52970f","externalIds":{"ArXiv":"2311.00288","DBLP":"conf/emnlp/KungY0CP23","DOI":"10.48550/arXiv.2311.00288","CorpusId":264832712},"title":"Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks"},{"paperId":"e3052ebca5eeae6a8a73e44517903d39746f5f3a","externalIds":{"ArXiv":"2308.12032","ACL":"2024.naacl-long.421","DBLP":"journals/corr/abs-2308-12032","DOI":"10.18653/v1/2024.naacl-long.421","CorpusId":261076515},"title":"From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning"},{"paperId":"d7e92d03dfa5427c0c5ef2b59de54733e0589606","externalIds":{"ArXiv":"2308.12067","DBLP":"journals/corr/abs-2308-12067","DOI":"10.48550/arXiv.2308.12067","CorpusId":261075922},"title":"InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4"},{"paperId":"f0950a3f27c0fefffba60ae1c9a8ee360d5eb55f","externalIds":{"ArXiv":"2308.10792","DBLP":"journals/corr/abs-2308-10792","DOI":"10.1145/3777411","CorpusId":261049152},"title":"Instruction Tuning for Large Language Models: A Survey"},{"paperId":"51ef336bb1bb9875d715abb78be93b58f952cb5c","externalIds":{"DBLP":"conf/iccv/ZhouWGPLZYF23","ArXiv":"2308.10524","DOI":"10.1109/ICCV51070.2023.01578","CorpusId":261049434},"title":"Dataset Quantization"},{"paperId":"dd3fb89d1201d46fa80b6a9519114599c01c11ac","externalIds":{"ArXiv":"2308.07074","DBLP":"conf/iclr/LuY0LLTZZ24","DOI":"10.48550/arXiv.2308.07074","CorpusId":260887200},"title":"#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models"},{"paperId":"f2ba9e7d9624bd94a786ea5e3161a9425a21a475","externalIds":{"DBLP":"conf/iclr/LiYZSLZWL24","ArXiv":"2308.06259","DOI":"10.48550/arXiv.2308.06259","CorpusId":260866107},"title":"Self-Alignment with Instruction Backtranslation"},{"paperId":"c74a13b251b6af6dfce49eeb128b1c0e2ddf955d","externalIds":{"DBLP":"conf/coling/Zhao0HYLHZL24","ACL":"2024.lrec-main.1460","ArXiv":"2308.05696","DOI":"10.48550/arXiv.2308.05696","CorpusId":260775760},"title":"Tree-Instruct: A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment"},{"paperId":"546d0624adfc6e18fb87d8cc77e7705bb9ea7445","externalIds":{"ArXiv":"2305.11206","DBLP":"conf/nips/ZhouLX0SMMEYYZG23","CorpusId":258822910},"title":"LIMA: Less Is More for Alignment"},{"paperId":"5c7aaee5651221893ea0e67c363cab4c4be53b83","externalIds":{"ArXiv":"2305.09246","DBLP":"journals/corr/abs-2305-09246","DOI":"10.48550/arXiv.2305.09246","CorpusId":258715090},"title":"Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning"},{"paperId":"ca6a2bc279be5a3349a22bfd6866ed633d18734b","externalIds":{"ArXiv":"2304.10592","DBLP":"conf/iclr/Zhu0SLE24","DOI":"10.48550/arXiv.2304.10592","CorpusId":258291930},"title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"57e849d0de13ed5f91d086936296721d4ff75a75","externalIds":{"DBLP":"journals/corr/abs-2302-13971","ArXiv":"2302.13971","CorpusId":257219404},"title":"LLaMA: Open and Efficient Foundation Language Models"},{"paperId":"f2b0017ddd77fa38760a18145e63553105a1a236","externalIds":{"DBLP":"journals/corr/abs-2301-13688","ArXiv":"2301.13688","DOI":"10.48550/arXiv.2301.13688","CorpusId":256415991},"title":"The Flan Collection: Designing Data and Methods for Effective Instruction Tuning"},{"paperId":"e65b346d442e9962a4276dc1c1af2956d9d5f1eb","externalIds":{"DBLP":"journals/corr/abs-2212-10560","ArXiv":"2212.10560","ACL":"2023.acl-long.754","DOI":"10.48550/arXiv.2212.10560","CorpusId":254877310},"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","externalIds":{"ArXiv":"2204.02311","DBLP":"journals/corr/abs-2204-02311","CorpusId":247951931},"title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","externalIds":{"ArXiv":"2203.02155","DBLP":"journals/corr/abs-2203-02155","CorpusId":246426909},"title":"Training language models to follow instructions with human feedback"},{"paperId":"17dd3555fd1ccf1141cf984347fa1b3fd6b009ca","externalIds":{"ArXiv":"2110.08207","DBLP":"journals/corr/abs-2110-08207","CorpusId":239009562},"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization"},{"paperId":"ff0b2681d7b05e16c46dfb71d980cc2f605907cd","externalIds":{"DBLP":"journals/corr/abs-2109-01652","ArXiv":"2109.01652","CorpusId":237416585},"title":"Finetuned Language Models Are Zero-Shot Learners"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"93d63ec754f29fa22572615320afe0521f7ec66d","externalIds":{"DBLP":"journals/corr/abs-1908-10084","MAG":"2970641574","ArXiv":"1908.10084","ACL":"D19-1410","DOI":"10.18653/v1/D19-1410","CorpusId":201646309},"title":"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"},{"paperId":"c342c71cb23199f112d0bc644fcce56a7306bf94","externalIds":{"MAG":"2774918944","DBLP":"conf/iclr/SenerS18","CorpusId":3383786},"title":"Active Learning for Convolutional Neural Networks: A Core-Set Approach"},{"paperId":"f17c6e164ccc7ec1ad91b3fbbafe8f84664e9803","externalIds":{"MAG":"2110026675","DBLP":"conf/www/DongCL11","DOI":"10.1145/1963405.1963487","CorpusId":207186093},"title":"Efficient k-nearest neighbor graph construction for generic similarity measures"},{"paperId":"362cae35fb65710af8230a4ee8e1aad1f275a4e7","externalIds":{"DBLP":"journals/corr/abs-2312-14187","DOI":"10.48550/arXiv.2312.14187","CorpusId":266521384},"title":"WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation"},{"paperId":"ac4ffaab10f6b6ad83e79ca5691f338abf5cff82","externalIds":{"DBLP":"journals/corr/abs-2307-06290","DOI":"10.48550/arXiv.2307.06290","CorpusId":259837472},"title":"Instruction Mining: High-Quality Instruction Data Selection for Large Language Models"},{"paperId":"fe0825f9ddb1cccb545f4249da55b6b55e577bbd","externalIds":{"DBLP":"conf/iclr/SanhWRBSACSRDBX22","CorpusId":276421109},"title":"Multitask Prompted Training Enables Zero-Shot Task Generalization"}]}