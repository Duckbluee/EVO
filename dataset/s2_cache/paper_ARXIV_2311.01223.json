{"paperId":"c95244ea3ec82de5adc96fd3b96c0f59f5d1b1b2","externalIds":{"ArXiv":"2311.01223","DBLP":"journals/corr/abs-2311-01223","DOI":"10.48550/arXiv.2311.01223","CorpusId":264935559},"title":"Diffusion Models for Reinforcement Learning: A Survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2311.01223, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"1999326708","name":"Zhengbang Zhu"},{"authorId":"1490744375","name":"Hanye Zhao"},{"authorId":"2212792017","name":"Haoran He"},{"authorId":"2265389783","name":"Yichao Zhong"},{"authorId":"2265021355","name":"Shenyu Zhang"},{"authorId":"2237958078","name":"Yong Yu"},{"authorId":"2240768092","name":"Weinan Zhang"}],"abstract":"Diffusion models surpass previous generative models in sample quality and training stability. Recent works have shown the advantages of diffusion models in improving reinforcement learning (RL) solutions. This survey aims to provide an overview of this emerging field and hopes to inspire new avenues of research. First, we examine several challenges encountered by RL algorithms. Then, we present a taxonomy of existing methods based on the roles of diffusion models in RL and explore how the preceding challenges are addressed. We further outline successful applications of diffusion models in various RL-related tasks. Finally, we conclude the survey and offer insights into future research directions. We are actively maintaining a GitHub repository for papers and other related resources in utilizing diffusion models in RL: https://github.com/apexrl/Diff4RLSurvey."}