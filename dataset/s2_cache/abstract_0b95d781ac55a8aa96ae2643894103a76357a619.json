{"abstract":"Detection of out-of-distribution (OOD) samples is cru-cial for safe real-world deployment of machine learning models. Recent advances in vision language foundation models have made them capable of detecting OOD sam-ples without requiring in-distribution (ID) images. How-ever, these zero-shot methods often underperform as they do not adequately consider ID class likelihoods in their detection confidence scoring. Hence, we introduce CLIPScope, a zero-shot OOD detection approach that normalizes the confidence score of a sample by class likelihoods, akin to a Bayesian posterior update. Furthermore, CLIPScope incor-porates a novel strategy to mine OOD classes from a large lexical database. It selects class labels that are farthest and nearest to ID classes in terms of CLIP embedding distance to maximize coverage of OOD samples. We conduct ex-tensive ablation studies and empirical evaluations, demon-strating state of the art performance of CLIPScope across various OOD detection benchmarks. Code is available at https://github.com/ful001hao/CLIPScope."}