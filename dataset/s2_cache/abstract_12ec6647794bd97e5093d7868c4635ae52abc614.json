{"abstract":"The Algorithmic Accountability Act of 2019, sponsored by Senators Cory Booker (D-NJ) and Ron Wyden (D-OR), with a House equivalent sponsored by Rep. Yvette Clarke (D-NY), requires companies to assess their automatic decision systems for risks to “privacy and security of personal information” and risks of “inaccurate, unfair, biased, or discriminatory decisions.” They must also “reasonably address” the results of their assessments. The bill empowers the Federal Trade Commission (FTC) to resolve by regulation the crucial details of these requirements. It is not likely to pass Congress on its own, but it might become part of a new national privacy law currently under consideration in Congress. If passed, it would apply to the AI systems that platforms increasingly deploy to detect and counter hate speech, terrorist material and disinformation campaigns and would require the platforms to conduct fairness assessments of these AI systems and fix issues of bias uncovered in these studies. Even without a legislative mandate, however, platforms should rigorously review algorithmic content moderation systems for fairness and accuracy and should establish and maintain effective, easy-to-use complaint mechanisms whereby people wrongly labeled as purveyors of harmful material can obtain redress."}