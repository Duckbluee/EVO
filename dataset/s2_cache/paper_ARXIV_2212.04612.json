{"paperId":"c164ec3b73eb108f861fcd60df73b62d2482c3a6","externalIds":{"DBLP":"journals/corr/abs-2212-04612","ArXiv":"2212.04612","DOI":"10.1007/s10994-023-06495-7","CorpusId":254535627},"title":"Training data influence analysis and estimation: a survey","openAccessPdf":{"url":"https://link.springer.com/content/pdf/10.1007/s10994-023-06495-7.pdf","status":"HYBRID","license":"CCBY","disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2212.04612, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"37882247","name":"Zayd Hammoudeh"},{"authorId":"3021654","name":"Daniel Lowd"}],"abstract":"Good models require good training data. For overparameterized deep models, the causal relationship between training data and model predictions is increasingly opaque and poorly understood. Influence analysis partially demystifies training’s underlying interactions by quantifying the amount each training instance alters the final model. Measuring the training data’s influence exactly can be provably hard in the worst case; this has led to the development and use of influence estimators, which only approximate the true influence. This paper provides the first comprehensive survey of training data influence analysis and estimation. We begin by formalizing the various, and in places orthogonal, definitions of training data influence. We then organize state-of-the-art influence analysis methods into a taxonomy; we describe each of these methods in detail and compare their underlying assumptions, asymptotic complexities, and overall strengths and weaknesses. Finally, we propose future research directions to make influence analysis more useful in practice as well as more theoretically and empirically sound."}