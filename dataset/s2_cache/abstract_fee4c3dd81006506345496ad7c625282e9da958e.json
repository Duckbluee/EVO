{"abstract":"Deep learning (DL) has demonstrated several successes in a variety of fields, particularly in the era of big data. The process of training a deep learning model entails selecting the ideal learning parameters such as the number of hidden layers and neurons. Particle Swarm Optimization (PSO) is one useful nature-inspired algorithm to set those two influential learning parameters. In this study, two different datasets are used to study and evaluate the particle swarm optimizer with deep learning on datasets of different concentrations of poisoning attack, where some adversarial samples were crafted by attackers to ruin the learning process. The results showed that particle swarm optimization could find settings for deep learning with the existence of poisoned data that maximizes the model accuracy on the unseen testing dataset, and could also offer better recommendations compared to those recommended on all benign samples. This may introduce a concern that optimizers might conceal the existence of data poisoning, which may lead to unreliable learning in the advanced stages of upgrading the model on updated datasets."}