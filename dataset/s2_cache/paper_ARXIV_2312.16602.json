{"paperId":"1e1230ef1de1ba9c4f6cb4789184a295133afac0","externalIds":{"ArXiv":"2312.16602","DBLP":"journals/corr/abs-2312-16602","DOI":"10.48550/arXiv.2312.16602","CorpusId":266573642},"title":"Visual Instruction Tuning towards General-Purpose Multimodal Model: A Survey","openAccessPdf":{"url":"","status":null,"license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2312.16602, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2115941903","name":"Jiaxing Huang"},{"authorId":"2276743977","name":"Jingyi Zhang"},{"authorId":"2276609830","name":"Kai Jiang"},{"authorId":"49660254","name":"Han Qiu"},{"authorId":"2237947102","name":"Shijian Lu"}],"abstract":"Traditional computer vision generally solves each single task independently by a dedicated model with the task instruction implicitly designed in the model architecture, arising two limitations: (1) it leads to task-specific models, which require multiple models for different tasks and restrict the potential synergies from diverse tasks; (2) it leads to a pre-defined and fixed model interface that has limited interactivity and adaptability in following user' task instructions. To address them, Visual Instruction Tuning (VIT) has been intensively studied recently, which finetunes a large vision model with language as task instructions, aiming to learn from a wide range of vision tasks described by language instructions a general-purpose multimodal model that can follow arbitrary instructions and thus solve arbitrary tasks specified by the user. This work aims to provide a systematic review of visual instruction tuning, covering (1) the background that presents computer vision task paradigms and the development of VIT; (2) the foundations of VIT that introduce commonly used network architectures, visual instruction tuning frameworks and objectives, and evaluation setups and tasks; (3) the commonly used datasets in visual instruction tuning and evaluation; (4) the review of existing VIT methods that categorizes them with a taxonomy according to both the studied vision task and the method design and highlights the major contributions, strengths, and shortcomings of them; (5) the comparison and discussion of VIT methods over various instruction-following benchmarks; (6) several challenges, open directions and possible future works in visual instruction tuning research."}