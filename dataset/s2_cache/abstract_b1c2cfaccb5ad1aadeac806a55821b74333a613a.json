{"abstract":"Discriminative correlation filters (DCFs) have drawn increasing interest in visual tracking. In particular, a few recent works treat DCFs as a special layer and adding it into a Siamese network for visual tracking. However, they adopt shallow networks to learn target representations, which lack robust semantic information in deeper layers and make these works fail to handle significant appearance changes. In this paper, we design a novel network to fuse multi-level convolutional features, each level of which characterize target from different perspectives. Then we integrate our network with the DCF layer to construct an end-to-end deep architecture for visual tracking. The overall architecture is trained end-to-end offline to adaptively learn target representations, which are not only enabled to encode high-level semantic features and low-level spatial detail features, but also closely related to correlation filters. Experiments show that our proposed tracker achieves superior performance against state-of the-art trackers."}