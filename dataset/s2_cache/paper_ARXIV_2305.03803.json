{"paperId":"a460e787c2e68d66ad98d5029fe788085ecb0d14","externalIds":{"ArXiv":"2305.03803","DBLP":"journals/corr/abs-2305-03803","DOI":"10.48550/arXiv.2305.03803","CorpusId":258557500},"title":"A Survey of Trojans in Neural Models of Source Code: Taxonomy and Techniques","openAccessPdf":{"url":"http://arxiv.org/pdf/2305.03803","status":"GREEN","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2305.03803, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2082388485","name":"Aftab Hussain"},{"authorId":"9392397","name":"Md Rafiqul Islam Rabin"},{"authorId":"3432275","name":"Toufique Ahmed"},{"authorId":"2203459","name":"Bowen Xu"},{"authorId":"114875459","name":"Prem Devanbu"},{"authorId":"50532331","name":"Mohammad Amin Alipour"}],"abstract":"In this work, we study literature in Explainable AI and Safe AI to understand poisoning of neural models of code. In order to do so, we first establish a novel taxonomy for Trojan AI for code, and present a new aspect-based classification of triggers in neural models of code. Next, we highlight recent works that help us deepen our conception of how these models understand software code. Then we pick some of the recent, state-of-art poisoning strategies that can be used to manipulate such models. The insights we draw can potentially help to foster future research in the area of Trojan AI for code."}