{"abstract":"Summary Traditionally, to improve the segmentation performance of models, most approaches prefer to use more complex modules. This is not suitable for the medical field, especially for mobile medical devices, where computationally loaded models are not suitable for real clinical environments due to computational resource constraints. Recently, state-space models, represented by Mamba, have become a strong competitor to traditional convolutional neural networks and transformers. In this paper, we deeply explore the key elements of parameter influence in Mamba and propose an UltraLight Vision Mamba UNet (UltraLight VM-UNet) based on this. Specifically, we propose a method for processing features in parallel Vision Mamba, named the PVM Layer, which achieves competitive performance with the lowest computational complexity while keeping the overall number of processing channels constant. We conducted segmentation experiments on three public datasets of skin lesions and showed that UltraLight VM-UNet exhibits competitive performance with only 0.049M parameters and 0.060 GFLOPs."}