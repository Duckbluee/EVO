{"references":[{"paperId":"d3ee2e639751cbe75683537aa0d6841bd9a7341f","externalIds":{"DBLP":"journals/corr/abs-2405-02670","ArXiv":"2405.02670","DOI":"10.48550/arXiv.2405.02670","CorpusId":269604749},"title":"From Generalization Analysis to Optimization Designs for State Space Models"},{"paperId":"67b1ca32e081c1237b1c3f428bbd8adbf83d9c58","externalIds":{"DBLP":"journals/corr/abs-2404-11117","ArXiv":"2404.11117","DOI":"10.48550/arXiv.2404.11117","CorpusId":269187649},"title":"Variational quantization for state space models"},{"paperId":"81b06f31535024f39a01e70c6920fe2621812514","externalIds":{"DBLP":"journals/corr/abs-2404-07645","ArXiv":"2404.07645","DOI":"10.48550/arXiv.2404.07645","CorpusId":269043007},"title":"Simba: Mamba augmented U-ShiftGCN for Skeletal Action Recognition in Videos"},{"paperId":"eed646c62b0665316218a1bae5dc55d333ebe100","externalIds":{"DBLP":"conf/mm/Long0LLY0MY24","ArXiv":"2404.07794","DOI":"10.1145/3664647.3681247","CorpusId":269043035},"title":"DGMamba: Domain Generalization via Generalized State Space Model"},{"paperId":"2a006743e7e88294d81609d86b89c2b4c462df25","externalIds":{"DBLP":"journals/corr/abs-2404-07705","ArXiv":"2404.07705","DOI":"10.48550/arXiv.2404.07705","CorpusId":269043330},"title":"ViM-UNet: Vision Mamba for Biomedical Segmentation"},{"paperId":"a9a44c4180f115a974757f239eb915615bb9cd12","externalIds":{"DBLP":"journals/corr/abs-2404-07106","ArXiv":"2404.07106","DOI":"10.48550/arXiv.2404.07106","CorpusId":269033257},"title":"3DMambaComplete: Exploring Structured State Space Model for Point Cloud Completion"},{"paperId":"e29a34d17dc41422fb16c6d8c258dfa7ff949b47","externalIds":{"DBLP":"conf/nips/HeBZHCGWLT024","ArXiv":"2404.06564","DOI":"10.48550/arXiv.2404.06564","CorpusId":269033047},"title":"MambaAD: Exploring State Space Models for Multi-class Unsupervised Anomaly Detection"},{"paperId":"a29fd41812deb68aa6ee1c28b1221e3cabf3ac5c","externalIds":{"DBLP":"conf/aaai/ZhouYFXZLL025","ArXiv":"2404.05522","DOI":"10.48550/arXiv.2404.05522","CorpusId":269004872},"title":"3DMambaIPF: A State Space Model for Iterative Point Cloud Filtering via Differentiable Rendering"},{"paperId":"4d84441e7f296d42d6493bb5a7b16d36e479b354","externalIds":{"ArXiv":"2404.04478","DBLP":"journals/corr/abs-2404-04478","DOI":"10.48550/arXiv.2404.04478","CorpusId":269005284},"title":"Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models"},{"paperId":"a06ad946578d92baac73735726a00b5f7f446c98","externalIds":{"DBLP":"conf/wacv/WanZWYSSX25","ArXiv":"2404.04256","DOI":"10.1109/WACV61041.2025.00176","CorpusId":268987521},"title":"Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation"},{"paperId":"541bcf94bd09f17c25d8ed7cd10e69c8f91331d0","externalIds":{"ArXiv":"2404.03425","DBLP":"journals/corr/abs-2404-03425","DOI":"10.1109/TGRS.2024.3417253","CorpusId":268889712},"title":"ChangeMamba: Remote Sensing Change Detection With Spatiotemporal State Space Model"},{"paperId":"5664f7f52264ff656faa3671d83e2009f4f390fd","externalIds":{"ArXiv":"2404.03646","DBLP":"journals/corr/abs-2404-03646","DOI":"10.48550/arXiv.2404.03646","CorpusId":268889738},"title":"Locating and Editing Factual Associations in Mamba"},{"paperId":"31700a32d5d48f787170cd0ecd3ba0e5eb37d371","externalIds":{"ArXiv":"2404.02457","DBLP":"journals/lgrs/MaZP24","DOI":"10.1109/LGRS.2024.3414293","CorpusId":268876327},"title":"RS3Mamba: Visual State Space Model for Remote Sensing Image Semantic Segmentation"},{"paperId":"2833716cabbd7c709f4b266832b8b3fa3e37d2c6","externalIds":{"DBLP":"journals/tgrs/ZhaoCZXBO24","ArXiv":"2404.02668","DOI":"10.1109/TGRS.2024.3425540","CorpusId":268875757},"title":"RS-Mamba for Large Remote Sensing Image Dense Prediction"},{"paperId":"ed228d3ad968eb1aa38baea5471bcb1d698f196a","externalIds":{"ArXiv":"2404.01705","PubMedCentral":"11466675","DBLP":"journals/corr/abs-2404-01705","DOI":"10.1016/j.heliyon.2024.e38495","CorpusId":268856763,"PubMed":"39398081"},"title":"Samba: Semantic segmentation of remotely sensed images with state space model"},{"paperId":"db521cd814b2c0ea6c5e89c34e192c7077ffe7eb","externalIds":{"ArXiv":"2404.01871","DBLP":"journals/corr/abs-2404-01871","DOI":"10.48550/arXiv.2404.01871","CorpusId":268856836},"title":"On the reduction of Linear Parameter-Varying State-Space models"},{"paperId":"609b7d5bf1ad35b20073152245da65855aa25942","externalIds":{"ArXiv":"2404.01065","CorpusId":268819833},"title":"T-Mamba: A unified framework with Long-Range Dependency in dual-domain for 2D&3D Tooth Segmentation"},{"paperId":"bb6afe666ffd07d9059ec94cac551c2b1f33f096","externalIds":{"ArXiv":"2404.01174","DBLP":"journals/corr/abs-2404-01174","DOI":"10.48550/arXiv.2404.01174","CorpusId":268819945},"title":"SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video Grounding"},{"paperId":"8664fdad23646b7fea29a2eacc333b26c3eba800","externalIds":{"ArXiv":"2404.00272","DBLP":"journals/corr/abs-2404-00272","DOI":"10.48550/arXiv.2404.00272","CorpusId":268819175},"title":"HSIMamba: Hyperpsectral Imaging Efficient Feature Learning with Bidirectional State Space for Classification"},{"paperId":"ac5fff2daec30a29bd36bd7577da6c0e6570b9ac","externalIds":{"DBLP":"journals/iotj/LiZDCNNW25","ArXiv":"2403.20183","DOI":"10.1109/JIOT.2024.3463405","CorpusId":268793513},"title":"HARMamba: Efficient and Lightweight Wearable Sensor Human Activity Recognition Based on Bidirectional Mamba"},{"paperId":"21ffa380d4cfceeaaeed4fafc8fe76c669e2e4ef","externalIds":{"ArXiv":"2403.20035","DBLP":"journals/corr/abs-2403-20035","PubMedCentral":"12664954","DOI":"10.1016/j.patter.2025.101298","CorpusId":268793860,"PubMed":"41328156"},"title":"UltraLight VM-UNet: Parallel Vision Mamba significantly reduces parameters for skin lesion segmentation"},{"paperId":"9b8130a2a5d3398f4993f540ddd01d440d99d62e","externalIds":{"ArXiv":"2403.19925","DBLP":"journals/corr/abs-2403-19925","DOI":"10.48550/arXiv.2403.19925","CorpusId":268793600},"title":"Decision Mamba: Reinforcement Learning via Sequence Modeling with Selective State Spaces"},{"paperId":"3e4ed3b3790980efbb537d381c7bc020eefed53f","externalIds":{"DBLP":"journals/corr/abs-2403-19888","ArXiv":"2403.19888","DOI":"10.48550/arXiv.2403.19888","CorpusId":268793643},"title":"MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection"},{"paperId":"cbaf689fd9ea9bc939510019d90535d6249b3367","externalIds":{"DBLP":"journals/corr/abs-2403-19887","ArXiv":"2403.19887","DOI":"10.48550/arXiv.2403.19887","CorpusId":268793596},"title":"Jamba: A Hybrid Transformer-Mamba Language Model"},{"paperId":"69fa358ca1680ff2779477bdab2f42851c2499ca","externalIds":{"ArXiv":"2403.18795","DBLP":"journals/corr/abs-2403-18795","DOI":"10.48550/arXiv.2403.18795","CorpusId":268724060,"PubMed":"40388288"},"title":"Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction"},{"paperId":"da9178eae82d1ca5492aaecd0151ba49481cb8b1","externalIds":{"DBLP":"journals/corr/abs-2403-18257","ArXiv":"2403.18257","DOI":"10.1109/ICASSP49660.2025.10888514","CorpusId":268723673},"title":"Dual-path Mamba: Short and Long-term Bidirectional Selective Structured State Space Models for Speech Separation"},{"paperId":"6acbc413e8cf3c5c52d37c2aeefe80334ec0fccf","externalIds":{"ArXiv":"2403.18276","CorpusId":268723594},"title":"RankMamba: Benchmarking Mamba's Document Ranking Performance in the Era of Transformers"},{"paperId":"62ac3ef81e54e1d1930fb5980b236345ee2e4f32","externalIds":{"ArXiv":"2403.17695","DBLP":"conf/bmvc/YangCEEWLC24","DOI":"10.48550/arXiv.2403.17695","CorpusId":268692121},"title":"PlainMamba: Improving Non-Hierarchical Mamba in Visual Recognition"},{"paperId":"df0e715f15ba81be07663aae51339072d972faaf","externalIds":{"ArXiv":"2403.17701","DBLP":"journals/corr/abs-2403-17701","DOI":"10.48550/arXiv.2403.17701","CorpusId":268692226},"title":"Rotate to Scan: UNet-like Mamba with Triplet SSM Module for Medical Image Segmentation"},{"paperId":"7bdf826221e4f833e224a581bc143f67052f6af8","externalIds":{"ArXiv":"2403.17902","DBLP":"journals/corr/abs-2403-17902","DOI":"10.48550/arXiv.2403.17902","CorpusId":268691791},"title":"Serpent: Scalable and Efficient Image Restoration via Multi-scale Structured State Space Models"},{"paperId":"9bd60a0b1b5e70c9e6ccfde513f8fdea61d8b503","externalIds":{"DBLP":"journals/corr/abs-2403-17839","ArXiv":"2403.17839","DOI":"10.48550/arXiv.2403.17839","CorpusId":268691384},"title":"ReMamber: Referring Image Segmentation with Mamba Twister"},{"paperId":"05c1dc502ed51162580ccd320d5668d2fec94a7a","externalIds":{"DBLP":"journals/corr/abs-2403-17844","ArXiv":"2403.17844","DOI":"10.48550/arXiv.2403.17844","CorpusId":268691910},"title":"Mechanistic Design and Scaling of Hybrid Architectures"},{"paperId":"b8a1829a42b11dc4bd4ce03c22e07298398d0405","externalIds":{"DBLP":"journals/corr/abs-2403-17432","ArXiv":"2403.17432","DOI":"10.48550/arXiv.2403.17432","CorpusId":268692069},"title":"Integrating Mamba Sequence Model and Hierarchical Upsampling Network for Accurate Semantic Segmentation of Multiple Sclerosis Legion"},{"paperId":"2a53d07a399c47151a7b440dacfb3673b9c4e753","externalIds":{"ArXiv":"2403.16899","DBLP":"journals/corr/abs-2403-16899","DOI":"10.23919/ACC63710.2025.11107969","CorpusId":268681121},"title":"State Space Models as Foundation Models: A Control Theoretic Overview"},{"paperId":"61c828689915505ad9eb250d6494657319e3d7b3","externalIds":{"ArXiv":"2403.16877","DBLP":"conf/iros/LaRocqueGDGP24","DOI":"10.1109/IROS58592.2024.10801407","CorpusId":268681377},"title":"Proprioception Is All You Need: Terrain Classification for Boreal Forests"},{"paperId":"7381d645f6ad239aaef2d42899515f21ece650d3","externalIds":{"DBLP":"conf/cvpr/TangDT0022","ArXiv":"2403.16536","DOI":"10.1109/CVPRW63382.2024.00575","CorpusId":268681179},"title":"VMRNN: Integrating Vision Mamba and LSTM for Efficient and Accurate Spatiotemporal Forecasting"},{"paperId":"278c122ff695a0ded29af43a719a76b97763161c","externalIds":{"ArXiv":"2403.16520","DBLP":"journals/corr/abs-2403-16520","DOI":"10.48550/arXiv.2403.16520","CorpusId":268681125},"title":"CMViM: Contrastive Masked Vim Autoencoder for 3D Multi-modal Representation Learning for AD classification"},{"paperId":"d38c7612e5efad88b8cc11ad7f0e69d20089bc84","externalIds":{"ArXiv":"2403.16371","DBLP":"journals/corr/abs-2403-16371","DOI":"10.48550/arXiv.2403.16371","CorpusId":268680696},"title":"Uncovering Selective State Space Model's Capabilities in Lifelong Sequential Recommendation"},{"paperId":"c70fef3d235ffedeaab2b2a6a2bfa2abfd59019e","externalIds":{"ArXiv":"2403.16331","DBLP":"journals/corr/abs-2403-16331","DOI":"10.48550/arXiv.2403.16331","CorpusId":268681437},"title":"Modeling Analog Dynamic Range Compressors using Deep Learning and State-space Models"},{"paperId":"491ef7fb89a958f1c615292c4ec8f3bd1d12f59d","externalIds":{"DBLP":"journals/corr/abs-2403-15569","ArXiv":"2403.15569","DOI":"10.48550/arXiv.2403.15569","CorpusId":268681708},"title":"Music to Dance as Language Translation using Sequence Models"},{"paperId":"fea8a3096391a418cb9ef724e0ff9754e5a467fd","externalIds":{"ArXiv":"2403.15360","DBLP":"journals/corr/abs-2403-15360","DOI":"10.48550/arXiv.2403.15360","CorpusId":268666944},"title":"SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series"},{"paperId":"40e996a7c3e914a67c708704fa9b4c54ea70f36e","externalIds":{"DBLP":"conf/aaai/0008ZZDHW25","ArXiv":"2403.14520","DOI":"10.48550/arXiv.2403.14520","CorpusId":268553791},"title":"Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference"},{"paperId":"b541371f45ddda342f254b0c397af73499762464","externalIds":{"ArXiv":"2403.14833","DBLP":"conf/cdc/ForgioneMP24","DOI":"10.1109/CDC56724.2024.10886865","CorpusId":268666904},"title":"Model order reduction of deep structured state-space models: A system-theoretic approach"},{"paperId":"206974b54e00c1145157d6bc4229b9a2b77ea929","externalIds":{"ArXiv":"2403.13642","DBLP":"journals/ijon/WuLLC25","DOI":"10.1016/j.neucom.2025.129447","CorpusId":268537116},"title":"H-vmunet: High-order Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"0c17c30c7194c2d1d6c37a0f1c2cbd0c9f89899e","externalIds":{"DBLP":"journals/corr/abs-2403-13802","ArXiv":"2403.13802","DOI":"10.48550/arXiv.2403.13802","CorpusId":268537245},"title":"ZigMa: A DiT-style Zigzag Mamba Diffusion Model"},{"paperId":"904563400562d35226618839fd7f3c3de23179bf","externalIds":{"ArXiv":"2403.13660","DBLP":"journals/corr/abs-2403-13660","DOI":"10.48550/arXiv.2403.13660","CorpusId":268536910},"title":"ProMamba: Prompt-Mamba for polyp segmentation"},{"paperId":"6d49ed0ea24b9c218f5ec6731cd261ce618df2ac","externalIds":{"DBLP":"journals/corr/abs-2403-13600","ArXiv":"2403.13600","DOI":"10.48550/arXiv.2403.13600","CorpusId":268537285},"title":"VL-Mamba: Exploring State Space Models for Multimodal Learning"},{"paperId":"46f33203f6f50bbd38d2e3e3eb1aa4f3eb66715d","externalIds":{"ArXiv":"2403.12418","DBLP":"journals/corr/abs-2403-12418","DOI":"10.48550/arXiv.2403.12418","CorpusId":268532293},"title":"STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model"},{"paperId":"f67d6126c8436cf91a9cc2ef97c347a41dbf05d4","externalIds":{"DBLP":"journals/corr/abs-2403-11423","ArXiv":"2403.11423","DOI":"10.1109/TCSVT.2025.3530090","CorpusId":268512896},"title":"VmambaIR: Visual State Space Model for Image Restoration"},{"paperId":"dba88f9a59ad816ce14d93b2c8bfda5917adc196","externalIds":{"DBLP":"journals/ijon/WangKFWYZWZ25","ArXiv":"2403.11144","DOI":"10.48550/arXiv.2403.11144","CorpusId":268513477},"title":"Is Mamba Effective for Time Series Forecasting?"},{"paperId":"746bd3631c83c56dca4ab6a130fc8303a629e8e1","externalIds":{"ArXiv":"2403.10935","DBLP":"journals/corr/abs-2403-10935","DOI":"10.48550/arXiv.2403.10935","CorpusId":268513323},"title":"Understanding Robustness of Visual State Space Models for Image Classification"},{"paperId":"9f1dc0ebf06841f988d7a1d12d1d2206c0707b53","externalIds":{"ArXiv":"2403.09977","DBLP":"journals/corr/abs-2403-09977","DOI":"10.48550/arXiv.2403.09977","CorpusId":268510293},"title":"EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba"},{"paperId":"fd7313602c94a0e8282a38684192fe5120415b96","externalIds":{"DBLP":"conf/fusion/ZhangLSYF24","ArXiv":"2403.10123","DOI":"10.23919/FUSION59988.2024.10706515","CorpusId":268510302},"title":"Regularization-Based Efficient Continual Learning in Deep State-Space Models"},{"paperId":"0a32e6ff6eaac83ff325bae4557a8362222979aa","externalIds":{"DBLP":"journals/ijcv/ChenHXPWCLLW26","ArXiv":"2403.09626","DOI":"10.1007/s11263-025-02597-y","CorpusId":268385114},"title":"Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding"},{"paperId":"5867382590f9f0ff8caf15804d20bde10845b2d2","externalIds":{"DBLP":"conf/eccv/HuangPYWQX24","ArXiv":"2403.09338","DOI":"10.48550/arXiv.2403.09338","CorpusId":268385283},"title":"LocalMamba: Visual State Space Model with Windowed Selective Scan"},{"paperId":"66a5f11bdd88a2586d5fa83fca33153fcd2440b8","externalIds":{"ArXiv":"2403.09157","DBLP":"journals/corr/abs-2403-09157","DOI":"10.48550/arXiv.2403.09157","CorpusId":268385505},"title":"VM-UNET-V2 Rethinking Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"3a0c5026f7ea965dc4475c8d857fc3b6df27ae05","externalIds":{"PubMedCentral":"11767608","DBLP":"journals/corr/abs-2403-09898","ArXiv":"2403.09898","DOI":"10.3233/faia240677","CorpusId":268510628,"PubMed":"39866204"},"title":"TimeMachine: A Time Series is Worth 4 Mambas for Long-Term Forecasting"},{"paperId":"97388c71be60282e149c2c3d00db7c0eb2c946e4","externalIds":{"DBLP":"journals/corr/abs-2403-09471","ArXiv":"2403.09471","DOI":"10.48550/arXiv.2403.09471","CorpusId":268384773},"title":"MambaTalk: Efficient Holistic Gesture Synthesis with Selective State Space Models"},{"paperId":"03226803be2fc4dee589883dcb76f28858192e14","externalIds":{"ArXiv":"2403.08330","DBLP":"journals/corr/abs-2403-08330","DOI":"10.48550/arXiv.2403.08330","CorpusId":268379672},"title":"Activating Wider Areas in Image Super-Resolution"},{"paperId":"319762c8841f8e1e413642bc551ed748add4777b","externalIds":{"DBLP":"journals/spl/QuanL24","ArXiv":"2403.07675","DOI":"10.1109/LSP.2024.3418714","CorpusId":268363750},"title":"Multichannel Long-Term Streaming Neural Speech Enhancement for Static and Moving Speakers"},{"paperId":"4e03f7bb27b8ce6a7a0f22bd07dad65f4a45ca3f","externalIds":{"ArXiv":"2403.07332","CorpusId":268364247},"title":"LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"3af7273d7ca20c0c63cbaa47e60b058840835052","externalIds":{"ArXiv":"2403.06977","DBLP":"conf/eccv/LiLWHWWQ24","DOI":"10.48550/arXiv.2403.06977","CorpusId":268363759},"title":"VideoMamba: State Space Model for Efficient Video Understanding"},{"paperId":"a01e1138600499f65462ed3d51c3e76af1aad18c","externalIds":{"ArXiv":"2403.06963","DBLP":"conf/icml/BachmannN24","DOI":"10.48550/arXiv.2403.06963","CorpusId":268364153},"title":"The pitfalls of next-token prediction"},{"paperId":"46fb606d4059611d95ffc534bef6ad593c2281a3","externalIds":{"ArXiv":"2403.06467","DBLP":"journals/corr/abs-2403-06467","DOI":"10.48550/arXiv.2403.06467","CorpusId":268349001},"title":"Point Mamba: A Novel Point Cloud Backbone Based on State Space Model with Octree-Based Ordering Strategy"},{"paperId":"4b00522f10c08efaef7980a4f0ae145b40536986","externalIds":{"ArXiv":"2403.06800","DBLP":"conf/miccai/YangWC24","DOI":"10.48550/arXiv.2403.06800","CorpusId":268358302},"title":"MambaMIL: Enhancing Long Sequence Modeling with Sequence Reordering in Computational Pathology"},{"paperId":"c6da4673a7d75ba9c62df6ab1e57214a4aacd87b","externalIds":{"DBLP":"journals/corr/abs-2403-07201","ArXiv":"2403.07201","DOI":"10.48550/arXiv.2403.07201","CorpusId":268363821},"title":"A multi-cohort study on prediction of acute brain dysfunction states using selective state space models"},{"paperId":"a25be4db3b13f1a83a77c045fe4211e2f79717f1","externalIds":{"DBLP":"conf/acl-clinicalnlp/YangMKY24","ACL":"2024.clinicalnlp-1.5","ArXiv":"2403.05795","DOI":"10.48550/arXiv.2403.05795","CorpusId":268356404},"title":"ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes"},{"paperId":"4f96a57d87b810dd71141d5cf9782b5c920bbe6c","externalIds":{"ArXiv":"2403.05839","CorpusId":268358052},"title":"Long-Term Visual Object Tracking with Event Cameras: An Associative Memory Augmented Tracker and A Benchmark Dataset"},{"paperId":"05cbfca98309d5b558f20ef11479a0e3e21aa04e","externalIds":{"DBLP":"conf/icra/ZhangYLFXQTC25","ArXiv":"2403.05146","DOI":"10.1109/ICRA55743.2025.11127574","CorpusId":268296963},"title":"Motion-Guided Dual-Camera Tracker for Endoscope Tracking and Motion Analysis in a Mechanical Gastric Simulator"},{"paperId":"a7b6c089f50aeed1361582338610587b0e76d0a4","externalIds":{"ArXiv":"2403.05246","DBLP":"journals/corr/abs-2403-05246","DOI":"10.48550/arXiv.2403.05246","CorpusId":268297157},"title":"LightM-UNet: Mamba Assists in Lightweight UNet for Medical Image Segmentation"},{"paperId":"78283dfdc78654b8e785e4bcb8ee889a66c63a25","externalIds":{"DBLP":"conf/bibm/FangWZWZJZ24","ArXiv":"2403.05160","DOI":"10.1109/BIBM62325.2024.10822552","CorpusId":268297294},"title":"MamMIL: Multiple Instance Learning for Whole Slide Images with State Space Models"},{"paperId":"e34868427f607bd35f11576963c36b95673e5a75","externalIds":{"DBLP":"conf/iclr/SamsamiZRC24","ArXiv":"2403.04253","DOI":"10.48550/arXiv.2403.04253","CorpusId":268264561},"title":"Mastering Memory Tasks with World Models"},{"paperId":"bb44bd0a303902ebf5caa91a7a7094b6bdab26a7","externalIds":{"ArXiv":"2403.03900","DBLP":"journals/corr/abs-2403-03900","DOI":"10.48550/arXiv.2403.03900","CorpusId":268253535},"title":"Mamba4Rec: Towards Efficient Sequential Recommendation with Selective State Space Models"},{"paperId":"9463ef5f893e4ade0363242894be081f7684350f","externalIds":{"DBLP":"journals/corr/abs-2403-03849","ArXiv":"2403.03849","DOI":"10.48550/arXiv.2403.03849","CorpusId":268253450},"title":"MedMamba: Vision Mamba for Medical Image Classification"},{"paperId":"6c1578d9eff8f9d25ddf0398a77ffcc888a4593b","externalIds":{"DBLP":"conf/icml/SchiffKGDGK24","ArXiv":"2403.03234","CorpusId":268253280,"PubMed":"40567809"},"title":"Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling"},{"paperId":"51f38bd957fa863022feb5878fa1ba3bea6657cf","externalIds":{"DBLP":"conf/iclr/DuanWCZLLQ0DW25","ArXiv":"2403.02308","DOI":"10.48550/arXiv.2403.02308","CorpusId":268248528},"title":"Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures"},{"paperId":"375128c5000b08dd6aa1818ae42287f200aaa3c6","externalIds":{"DBLP":"journals/corr/abs-2403-02148","ArXiv":"2403.02148","DOI":"10.1109/TGRS.2024.3485721","CorpusId":268247869},"title":"MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small-Target Detection"},{"paperId":"26e6cd121c5fdb147df83cb848e4813c926737c8","externalIds":{"ArXiv":"2403.01590","DBLP":"conf/acl/AliZW25","DOI":"10.48550/arXiv.2403.01590","CorpusId":268248520},"title":"The Hidden Attention of Mamba Models"},{"paperId":"f8d89b497cb6f1333e7035fd520885464c067a33","externalIds":{"DBLP":"conf/aaai/ZhangYQZ0JYL25","ArXiv":"2403.00762","DOI":"10.48550/arXiv.2403.00762","CorpusId":268230692},"title":"Point Cloud Mamba: Point Cloud Learning via State Space Model"},{"paperId":"dbb4f95a489b43ed0604b210a6efc4189a095b98","externalIds":{"ArXiv":"2402.18959","DBLP":"journals/corr/abs-2402-18959","DOI":"10.48550/arXiv.2402.18959","CorpusId":268063723},"title":"MambaStock: Selective state space model for stock prediction"},{"paperId":"917096f28209ef90c9e6363cf49438341120af5e","externalIds":{"DBLP":"journals/corr/abs-2402-19047","ArXiv":"2402.19047","DOI":"10.48550/arXiv.2402.19047","CorpusId":268063708},"title":"Theoretical Foundations of Deep Selective State-Space Models"},{"paperId":"8acdb7e54d76e9629887209ad15b92c3d87d3c6b","externalIds":{"DBLP":"journals/corr/abs-2402-18451","ArXiv":"2402.18451","DOI":"10.48550/arXiv.2402.18451","CorpusId":268041453},"title":"MambaMIR: An Arbitrary-Masked Mamba for Joint Medical Image Reconstruction and Uncertainty Estimation"},{"paperId":"7351898febca53d01453283c9b1a541b662e1ed3","externalIds":{"DBLP":"journals/corr/abs-2403-00818","ArXiv":"2403.00818","DOI":"10.48550/arXiv.2403.00818","CorpusId":268230534},"title":"DenseMamba: State Space Models with Dense Hidden Connection for Efficient Large Language Models"},{"paperId":"f97440c1eacd628453da4c66030f303ad19f1c80","externalIds":{"DBLP":"journals/corr/abs-2402-15761","ArXiv":"2402.15761","DOI":"10.48550/arXiv.2402.15761","CorpusId":267938348},"title":"Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning"},{"paperId":"e730beb44042499763d36214c0498434e470dfd5","externalIds":{"ArXiv":"2402.15648","DBLP":"journals/corr/abs-2402-15648","DOI":"10.48550/arXiv.2402.15648","CorpusId":267938238},"title":"MambaIR: A Simple Baseline for Image Restoration with State-Space Model"},{"paperId":"c264e98dcf3d9ee5365b87a882445a7aacbb0e70","externalIds":{"ArXiv":"2402.15584","DBLP":"conf/cvpr/ZubicG024","DOI":"10.1109/CVPR52733.2024.00556","CorpusId":267938402},"title":"State Space Models for Event Cameras"},{"paperId":"efb7af4ae6943f298449416529c288e9559c991b","externalIds":{"ArXiv":"2402.12192","DBLP":"journals/corr/abs-2402-12192","DOI":"10.48550/arXiv.2402.12192","CorpusId":267751105},"title":"Pan-Mamba: Effective pan-sharpening with State Space Model"},{"paperId":"3fa58a65b4e7eb60c078e6135c46f38258d278d9","externalIds":{"DBLP":"journals/npl/ZhuSJ24","DOI":"10.1007/s11063-024-11540-0","CorpusId":267949483},"title":"TLS-RWKV: Real-Time Online Action Detection with Temporal Label Smoothing"},{"paperId":"0682771fd5f611bce2a536bf83587532469a83df","externalIds":{"ArXiv":"2402.10887","DBLP":"journals/corr/abs-2402-10887","DOI":"10.48550/arXiv.2402.10887","CorpusId":267740717},"title":"Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation"},{"paperId":"21ddc4fc3551619b8a64db6ae124acc72aaae2c2","externalIds":{"DBLP":"conf/nips/LiangZXZZYTB24","ArXiv":"2402.10739","DOI":"10.48550/arXiv.2402.10739","CorpusId":267740688},"title":"PointMamba: A Simple State Space Model for Point Cloud Analysis"},{"paperId":"a0b8309c31731e9f7c3368247e73ca843d001d94","externalIds":{"ArXiv":"2402.10211","DBLP":"conf/icml/BhirangiWPM0HP24","DOI":"10.48550/arXiv.2402.10211","CorpusId":267681866},"title":"Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling"},{"paperId":"2dda6da7375bf5e8bcf60f87b17ba10757f3bc57","externalIds":{"DBLP":"journals/corr/abs-2402-08678","ArXiv":"2402.08678","DOI":"10.1145/3637528.3672044","CorpusId":267636928},"title":"Graph Mamba: Towards Learning on Graphs with State Space Models"},{"paperId":"fe54abaf7a3973202158ed73cc8ec1bb5643782a","externalIds":{"ArXiv":"2402.08506","DBLP":"journals/corr/abs-2402-08506","DOI":"10.48550/arXiv.2402.08506","CorpusId":267636614},"title":"P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation"},{"paperId":"1498e54ace1140cdb73aef51b44b7a573101c623","externalIds":{"DBLP":"journals/corr/abs-2402-06378","ArXiv":"2402.06378","DOI":"10.48550/arXiv.2402.06378","CorpusId":267616867},"title":"FD-Vision Mamba for Endoscopic Exposure Correction"},{"paperId":"906d0688e1c683d5fec70e88e71ea1291c666b78","externalIds":{"DBLP":"conf/eccv/LiSG24","ArXiv":"2402.05892","DOI":"10.48550/arXiv.2402.05892","CorpusId":267547860},"title":"Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data"},{"paperId":"7154fc93bdefcd237a0ce3902511c0b154049253","externalIds":{"DBLP":"journals/corr/abs-2402-05608","ArXiv":"2402.05608","DOI":"10.48550/arXiv.2402.05608","CorpusId":267548062},"title":"Scalable Diffusion Models with State Space Backbone"},{"paperId":"08b30038fe938fb8460dff3085bda9ff6503e4c5","externalIds":{"DBLP":"journals/corr/abs-2402-05079","ArXiv":"2402.05079","DOI":"10.48550/arXiv.2402.05079","CorpusId":267523307},"title":"Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation"},{"paperId":"9da427202cc48370fd66359f5d72ff5ff3bc8b57","externalIds":{"DBLP":"journals/corr/abs-2402-04248","ArXiv":"2402.04248","DOI":"10.48550/arXiv.2402.04248","CorpusId":267499935},"title":"Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks"},{"paperId":"9ed5300327d7a45e408ff418334382fe9ca460a3","externalIds":{"DBLP":"conf/isbi/GongK0WWWL25","ArXiv":"2402.03526","DOI":"10.1109/ISBI60581.2025.10980694","CorpusId":267499913},"title":"Nnmamba: 3D Biomedical Image Segmentation, Classification and Landmark Detection with State Space Model"},{"paperId":"98a7444a221e27f51c89c58fa29a8a1e168c6d69","externalIds":{"ArXiv":"2402.03302","DBLP":"conf/miccai/LiuYZXYLLSYZZW24","DOI":"10.48550/arXiv.2402.03302","CorpusId":267413236},"title":"Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining"},{"paperId":"57a6c75ebb987ea29a1f904de23f72451e095032","externalIds":{"ArXiv":"2402.03170","DBLP":"conf/automl/GrazziSSBH24","DOI":"10.48550/arXiv.2402.03170","CorpusId":267412719},"title":"Is Mamba Capable of In-Context Learning?"},{"paperId":"ffaa66e698655d4b2dee1ab61448d5cc1a743a63","externalIds":{"DBLP":"journals/corr/abs-2402-02491","ArXiv":"2402.02491","DOI":"10.1145/3767748","CorpusId":267413263},"title":"VM-UNet: Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"1df04f33a8ef313cc2067147dbb79c3ca7c5c99f","externalIds":{"DBLP":"journals/corr/abs-2402-00789","ArXiv":"2402.00789","DOI":"10.48550/arXiv.2402.00789","CorpusId":267364853},"title":"Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces"},{"paperId":"99621f3ce8caf5d99f2b350d53ec8e6c57695bc2","externalIds":{"DBLP":"conf/eacl/BronnecDRACGLSG24","ArXiv":"2401.17919","ACL":"2024.eacl-long.69","DOI":"10.48550/arXiv.2401.17919","CorpusId":267334813},"title":"LOCOST: State-Space Models for Long Document Abstractive Summarization"},{"paperId":"7c50c5dd5226953cd3620db5cd51ffe9fe2411b0","externalIds":{"ArXiv":"2401.14168","CorpusId":267211763},"title":"Vivim: a Video Vision Mamba for Medical Video Segmentation"},{"paperId":"5358b0e98934f1bbe8f6123a529bbb91dd36d662","externalIds":{"DBLP":"conf/miccai/XingYYLZ24","ArXiv":"2401.13560","DOI":"10.48550/arXiv.2401.13560","CorpusId":267199804},"title":"SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation"},{"paperId":"b24e899ec0f77eef2fc87a9b8e50516367aa1f97","externalIds":{"DBLP":"conf/nips/LiuTZYX0YJ024","ArXiv":"2401.10166","DOI":"10.48550/arXiv.2401.10166","CorpusId":267035250},"title":"VMamba: Visual State Space Model"},{"paperId":"38c48a1cd296d16dc9c56717495d6e44cc354444","externalIds":{"DBLP":"conf/icml/ZhuL0W0W24","ArXiv":"2401.09417","DOI":"10.48550/arXiv.2401.09417","CorpusId":267028142},"title":"Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"},{"paperId":"cfca60d4d957d70d5f0722080b42bfa0316619c8","externalIds":{"ArXiv":"2401.09093","DBLP":"journals/corr/abs-2401-09093","DOI":"10.48550/arXiv.2401.09093","CorpusId":267027925},"title":"RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series Tasks"},{"paperId":"c1a04730c83967d0bb904b02263b17893cb50bad","externalIds":{"DBLP":"journals/corr/abs-2401-04722","ArXiv":"2401.04722","DOI":"10.48550/arXiv.2401.04722","CorpusId":266899624},"title":"U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation"},{"paperId":"411114f989a3d1083d90afd265103132fee94ebe","externalIds":{"DBLP":"journals/corr/abs-2401-04088","ArXiv":"2401.04088","DOI":"10.48550/arXiv.2401.04088","CorpusId":266844877},"title":"Mixtral of Experts"},{"paperId":"745594bd0dc3e9dc86f74e100cd2c98ed36256c0","externalIds":{"DBLP":"journals/corr/abs-2401-04081","ArXiv":"2401.04081","DOI":"10.48550/arXiv.2401.04081","CorpusId":266844147},"title":"MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts"},{"paperId":"470a130474ac89801fb775d9ebd5c00e54cde197","externalIds":{"DBLP":"journals/tcsv/WangJLTZW25","ArXiv":"2312.10692","DOI":"10.1109/TCSVT.2024.3454366","CorpusId":266359451},"title":"Pedestrian Attribute Recognition via CLIP-Based Prompt Vision-Language Fusion"},{"paperId":"6b204642e9a231932b9e72b2e401d7a5bc17a51e","externalIds":{"DBLP":"conf/aaai/WangWLZCST24","ArXiv":"2312.09812","DOI":"10.48550/arXiv.2312.09812","CorpusId":266335414},"title":"Structural Information Guided Multimodal Pre-training for Vehicle-centric Perception"},{"paperId":"51634c1b3fc55fe14def159b2c212f78c7496ad9","externalIds":{"DBLP":"journals/corr/abs-2312-06211","ArXiv":"2312.06211","DOI":"10.48550/arXiv.2312.06211","CorpusId":266164317},"title":"Structured state-space models are deep Wiener models"},{"paperId":"62b18cc55dcc7ffe52c28e1086aee893b7bc4334","externalIds":{"DBLP":"conf/icml/YangWSPK24","ArXiv":"2312.06635","DOI":"10.48550/arXiv.2312.06635","CorpusId":266162792},"title":"Gated Linear Attention Transformers with Hardware-Efficient Training"},{"paperId":"7bb51177bddf2c6ca1194f36a07d6a6ba75e293c","externalIds":{"DBLP":"journals/corr/abs-2312-06837","ArXiv":"2312.06837","DOI":"10.48550/arXiv.2312.06837","CorpusId":266174725},"title":"Spectral State Space Models"},{"paperId":"d3dbe1447d68a8cd3536a420cc4a6c5058934edb","externalIds":{"ArXiv":"2312.01640","DBLP":"journals/pr/JinWLLHZT26","DOI":"10.48550/arXiv.2312.01640","CorpusId":265609973},"title":"SequencePAR: Understanding Pedestrian Attributes via A Sequence Generation Paradigm"},{"paperId":"92f38084de7ed74305ce7b9c3a3a3f845182fd82","externalIds":{"ArXiv":"2312.01538","DBLP":"conf/icml/DingOHH24","CorpusId":265608925},"title":"Recurrent Distance Filtering for Graph Representation Learning"},{"paperId":"7bbc7595196a0606a07506c4fb1473e5e87f6082","externalIds":{"ArXiv":"2312.00752","DBLP":"journals/corr/abs-2312-00752","CorpusId":265551773},"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces"},{"paperId":"31245344a6eb6cd897a71928dc4b174ab75e4070","externalIds":{"DBLP":"conf/cvpr/YanGR24","ArXiv":"2311.18257","DOI":"10.1109/CVPR52733.2024.00787","CorpusId":265506646},"title":"Diffusion Models Without Attention"},{"paperId":"9c5062743eaace5c1ff822bba819031f05cd3106","externalIds":{"DBLP":"conf/icml/WangL24","ArXiv":"2311.14495","DOI":"10.48550/arXiv.2311.14495","CorpusId":265445725},"title":"StableSSM: Alleviating the Curse of Memory in State-space Models through Stable Reparameterization"},{"paperId":"5c104f905fcacf390270f619f232a2ba4eb873f2","externalIds":{"ArXiv":"2311.05908","DBLP":"conf/iclr/FuKNR24","DOI":"10.48550/arXiv.2311.05908","CorpusId":265128849},"title":"FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores"},{"paperId":"d7f64f2bdd80ea15f21ef7d867e102ac9ecdc797","externalIds":{"DBLP":"journals/corr/abs-2311-01927","ArXiv":"2311.01927","DOI":"10.48550/arXiv.2311.01927","CorpusId":265018962},"title":"GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling"},{"paperId":"5ad84fe07a569b6cc339d77cd2c265c1b79d644d","externalIds":{"DBLP":"conf/nips/SmithMKLB23","ArXiv":"2310.19694","DOI":"10.48550/arXiv.2310.19694","CorpusId":264796737},"title":"Convolutional State Space Models for Long-Range Spatiotemporal Modeling"},{"paperId":"cb0ac335adda4ceef9987cbcbca9129e71c37f0a","externalIds":{"DBLP":"journals/corr/abs-2310-18780","ArXiv":"2310.18780","DOI":"10.48550/arXiv.2310.18780","CorpusId":264590326},"title":"Laughing Hyena Distillery: Extracting Compact Recurrences From Convolutions"},{"paperId":"bb247435f722a689c0568760e73a9544d5c20933","externalIds":{"DBLP":"conf/icml/MattesSH24","ArXiv":"2310.05167","DOI":"10.48550/arXiv.2310.05167","CorpusId":263830117},"title":"Hieros: Hierarchical Imagination on Structured State Space Sequence World Models"},{"paperId":"77fde89a0f28cae77fd488ee3b641dee716e9c77","externalIds":{"ArXiv":"2310.02980","DBLP":"conf/iclr/AmosB024","DOI":"10.48550/arXiv.2310.02980","CorpusId":263620655},"title":"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"},{"paperId":"db916693bc6f0b858b290b5963c8f012f8e8bccd","externalIds":{"DBLP":"journals/corr/abs-2310-01698","ArXiv":"2310.01698","DOI":"10.48550/arXiv.2310.01698","CorpusId":263609190},"title":"Robustifying State-space Models for Long Sequences via Approximate Diagonalization"},{"paperId":"722028431d78dfbeb94020d4983250430359f39d","externalIds":{"DBLP":"conf/cvpr/WangWTZJ0024","ArXiv":"2309.14611","DOI":"10.1109/CVPR52733.2024.01821","CorpusId":262822525},"title":"Event Stream-Based Visual Object Tracking: A High-Resolution Benchmark Dataset and A Novel Baseline"},{"paperId":"b3caabbae4b7c3b842086b21940ce9d5b25d476f","externalIds":{"DBLP":"journals/corr/abs-2309-13414","ArXiv":"2309.13414","DOI":"10.48550/arXiv.2309.13414","CorpusId":262466374},"title":"State-space Models with Layer-wise Nonlinearity are Universal Approximators with Exponential Decaying Memory"},{"paperId":"b85c31c9a63d1645ed1cc6f2c6765eee60871444","externalIds":{"ArXiv":"2309.03641","DBLP":"conf/icassp/DuLC24","DOI":"10.1109/ICASSP48485.2024.10448152","CorpusId":261582629},"title":"Spiking Structured State Space Model for Monaural Speech Enhancement"},{"paperId":"e29abe559e5d7521afe37e9bd1b5de1b4e1af98a","externalIds":{"ArXiv":"2309.01775","DBLP":"journals/corr/abs-2309-01775","DOI":"10.48550/arXiv.2309.01775","CorpusId":261530777},"title":"Gated recurrent neural networks discover attention"},{"paperId":"131ba9932572c92155874db93626cf299659254e","externalIds":{"ArXiv":"2308.00442","DBLP":"journals/corr/abs-2308-00442","DOI":"10.1109/ICCV51070.2023.00548","CorpusId":260351423},"title":"FLatten Transformer: Vision Transformer using Focused Linear Attention"},{"paperId":"240103933ffe3dac2179cc160a2bd91299357a53","externalIds":{"DBLP":"journals/corr/abs-2307-08621","ArXiv":"2307.08621","CorpusId":259937453},"title":"Retentive Network: A Successor to Transformer for Large Language Models"},{"paperId":"026b3396a63ed5772329708b7580d633bb86bec9","externalIds":{"DBLP":"conf/emnlp/PengAAAABCCCDDG23","ArXiv":"2305.13048","DOI":"10.18653/v1/2023.findings-emnlp.936","CorpusId":258832459},"title":"RWKV: Reinventing RNNs for the Transformer Era"},{"paperId":"983d8b87693e909eb8b2f2fe74a6244dd65b61ee","externalIds":{"DBLP":"conf/cvpr/WangZWYLOH23","ArXiv":"2303.14526","DOI":"10.1109/CVPR52729.2023.00618","CorpusId":257766807},"title":"Selective Structured State-Spaces for Long-Form Video Understanding"},{"paperId":"5e9af370994f023b26396e1a0dc9416d73a089af","externalIds":{"ArXiv":"2303.10323","DBLP":"conf/cvpr/0006LCLLC23","DOI":"10.1109/CVPR52729.2023.00325","CorpusId":257631847},"title":"Dynamic Graph Enhanced Contrastive Learning for Chest X-Ray Report Generation"},{"paperId":"163b4d6a79a5b19af88b8585456363340d9efd04","externalIds":{"ArXiv":"2303.08774","CorpusId":257532815},"title":"GPT-4 Technical Report"},{"paperId":"f393aff1593c2d370ec0ae004910d18e40524967","externalIds":{"ArXiv":"2303.06349","DBLP":"journals/corr/abs-2303-06349","CorpusId":257496654},"title":"Resurrecting Recurrent Neural Networks for Long Sequences"},{"paperId":"d98b5c1d0f9a4e39dc79ea7a3f74e54789df5e13","externalIds":{"DBLP":"conf/nips/0001SGPF0B23","ArXiv":"2303.03982","DOI":"10.48550/arXiv.2303.03982","CorpusId":257378507},"title":"Structured State Space Models for In-Context Reinforcement Learning"},{"paperId":"746bb45433f6b24d3ae64d6cd51c4e9d00a0ffa7","externalIds":{"DBLP":"journals/corr/abs-2302-10035","ArXiv":"2302.10035","DOI":"10.1007/s11633-022-1410-8","CorpusId":257038341},"title":"Large-scale Multi-modal Pre-trained Models: A Comprehensive Survey"},{"paperId":"f2d952a183dfb0a1e031b8a3f535d9f8423d7a6e","externalIds":{"DBLP":"journals/corr/abs-2301-04104","ArXiv":"2301.04104","DOI":"10.48550/arXiv.2301.04104","CorpusId":255569874},"title":"Mastering Diverse Domains through World Models"},{"paperId":"5a77b508302771fc083bf24e0bcda8553c9b5421","externalIds":{"DBLP":"journals/corr/abs-2212-14052","ArXiv":"2212.14052","DOI":"10.48550/arXiv.2212.14052","CorpusId":255340454},"title":"Hungry Hungry Hippos: Towards Language Modeling with State Space Models"},{"paperId":"a128b1c47e6842605fb95bceae930d2135fc38fc","externalIds":{"DBLP":"conf/emnlp/WangYGR23","ArXiv":"2212.10544","DOI":"10.48550/arXiv.2212.10544","CorpusId":254877218},"title":"Pretraining Without Attention"},{"paperId":"661e8d555c4424b5953f17434f2ba910bfcf3afe","externalIds":{"ArXiv":"2212.08136","DBLP":"journals/corr/abs-2212-08136","DOI":"10.48550/arXiv.2212.08136","CorpusId":254823526},"title":"Efficient Long Sequence Modeling via State Space Augmented Transformer"},{"paperId":"117b24e06d3d82103dc011626e4d63b8a592d72a","externalIds":{"DBLP":"journals/pr/TangWHJZCZWT26","ArXiv":"2211.11010","DOI":"10.48550/arXiv.2211.11010","CorpusId":253734908},"title":"Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric"},{"paperId":"eb5a29b616a9a9a2517f885332894997c58f82ce","externalIds":{"DBLP":"journals/tcsv/ChengJWZ22","DOI":"10.1109/TCSVT.2022.3178144","CorpusId":249111908},"title":"A Simple Visual-Textual Baseline for Pedestrian Attribute Recognition"},{"paperId":"70e91e16eb321067d9402710e14a40cf28311f73","externalIds":{"DBLP":"conf/iclr/MaZKHGNMZ23","ArXiv":"2209.10655","DOI":"10.48550/arXiv.2209.10655","CorpusId":252439127},"title":"Mega: Moving Average Equipped Gated Attention"},{"paperId":"f29f1a4aae0ddff13da539b9e4f54c0a15d43bfb","externalIds":{"ArXiv":"2209.03952","DBLP":"journals/corr/abs-2209-03952","DOI":"10.1109/ICASSP49357.2023.10094992","CorpusId":252118865},"title":"TF-GRIDNET: Making Time-Frequency Domain Models Great Again for Monaural Speaker Separation"},{"paperId":"6d7d141c75af752ffc0d8a6184cca3f9323d6c74","externalIds":{"DBLP":"conf/iclr/SmithWL23","ArXiv":"2208.04933","DOI":"10.48550/arXiv.2208.04933","CorpusId":251442769},"title":"Simplified State Space Layers for Sequence Modeling"},{"paperId":"827f07e79dad0c1c77c68fa69bc4f098634d3d58","externalIds":{"DBLP":"journals/corr/abs-2207-09603","ArXiv":"2207.09603","DOI":"10.48550/arXiv.2207.09603","CorpusId":250698711},"title":"AiATrack: Attention in Attention for Transformer Visual Tracking"},{"paperId":"c0b7cdd0e2249f9bc90b4d0218839f36c3965453","externalIds":{"DBLP":"conf/aaai/JiaGHCH22","DOI":"10.1609/aaai.v36i1.19991","CorpusId":250290850},"title":"Learning Disentangled Attribute Representations for Robust Pedestrian Attribute Recognition"},{"paperId":"eaef083b9d661f42cc0d89d9d8156218f33a91d9","externalIds":{"DBLP":"journals/corr/abs-2206-13947","ArXiv":"2206.13947","DOI":"10.48550/arXiv.2206.13947","CorpusId":250089125},"title":"Long Range Language Modeling via Gated State Spaces"},{"paperId":"a30ac45ac5b7bd2148d3fb80ee7f3c29724e3170","externalIds":{"DBLP":"journals/corr/abs-2206-12037","ArXiv":"2206.12037","DOI":"10.48550/arXiv.2206.12037","CorpusId":250048824},"title":"How to Train Your HiPPO: State Space Models with Generalized Orthogonal Basis Projections"},{"paperId":"a816733a342b68b75957cdda927424ff9cb04d42","externalIds":{"ACL":"2021.acl-long.234","DBLP":"journals/corr/abs-2206-14579","ArXiv":"2206.14579","DOI":"10.18653/v1/2021.acl-long.234","CorpusId":236460239},"title":"Competence-based Multimodal Curriculum Learning for Medical Report Generation"},{"paperId":"ca444821352a4bd91884413d8070446e2960715a","externalIds":{"DBLP":"journals/corr/abs-2206-11893","ArXiv":"2206.11893","DOI":"10.48550/arXiv.2206.11893","CorpusId":249953875},"title":"On the Parameterization and Initialization of Diagonal State Space Models"},{"paperId":"0731410c624e73d548932ef572a8161b2c215dcf","externalIds":{"DBLP":"journals/nca/ChenSZS22","DOI":"10.1007/s00521-022-07300-7","CorpusId":249386415},"title":"MCFL: multi-label contrastive focal loss for deep imbalanced pedestrian attribute recognition"},{"paperId":"52129ae5ac7f68dcdce93c691720e46a678278d2","externalIds":{"DBLP":"journals/pr/WuHGHZD22","DOI":"10.1016/j.patcog.2022.108865","CorpusId":249861960},"title":"Inter-Attribute awareness for pedestrian attribute recognition"},{"paperId":"43ea97fab6f6e99008f69da3b723479a0e406125","externalIds":{"DBLP":"journals/ijon/TangH22","DOI":"10.1016/j.neucom.2022.05.028","CorpusId":248646662},"title":"DRFormer: Learning dual relations using Transformer for pedestrian attribute recognition"},{"paperId":"9226ae23b95b3f6891461e086d910ffeb7ac448a","externalIds":{"DBLP":"conf/eccv/IslamB22","ArXiv":"2204.01692","DOI":"10.48550/arXiv.2204.01692","CorpusId":247940203},"title":"Long Movie Clip Classification with State-Space Video Models"},{"paperId":"71e15a9a52dcafca57bff5f310b95e2c7d0cfc87","externalIds":{"DBLP":"conf/nips/0001GB22","ArXiv":"2203.14343","CorpusId":247762199},"title":"Diagonal State Spaces are as Effective as Structured State Spaces"},{"paperId":"c1329f91cfa11011712227c8765fbbe38b9f2b7e","externalIds":{"DBLP":"conf/eccv/YeCMSC22","ArXiv":"2203.11991","DOI":"10.48550/arXiv.2203.11991","CorpusId":247618649},"title":"Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework"},{"paperId":"b6eaec7917439d79ce840fa97bc371552e9b6685","externalIds":{"DBLP":"conf/cvpr/CuiJ0W22","ArXiv":"2203.11082","DOI":"10.1109/CVPR52688.2022.01324","CorpusId":247595120},"title":"MixFormer: End-to-End Tracking with Iterative Mixed Attention"},{"paperId":"dc47b17250b639d3a89a716c7216ef69b33f9e33","externalIds":{"DBLP":"conf/cvpr/0007DBPPYG22","ArXiv":"2203.11192","DOI":"10.1109/CVPR52688.2022.00853","CorpusId":247593790},"title":"Transforming Model Prediction for Tracking"},{"paperId":"04ea6fc31a1196264a15fa9912b1ff06d6f70220","externalIds":{"ArXiv":"2203.05328","DBLP":"journals/corr/abs-2203-05328","DOI":"10.48550/arXiv.2203.05328","CorpusId":247362510},"title":"Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking"},{"paperId":"0e679523fc2cf6d8812345c9167afcb8f072b9d6","externalIds":{"DBLP":"journals/ijcv/GuoFW22","DOI":"10.1007/s11263-022-01591-y","CorpusId":247285399},"title":"Visual Attention Consistency for Human Attribute Recognition"},{"paperId":"b55ee75940d24934a54d7f1acfde06e9cb45ac44","externalIds":{"ArXiv":"2202.09729","DBLP":"journals/corr/abs-2202-09729","CorpusId":247011489},"title":"It's Raw! Audio Generation with State-Space Models"},{"paperId":"60c9d70ba8b481656f4bf63b80c5a6952da2285c","externalIds":{"ArXiv":"2112.15009","DBLP":"journals/mia/YangWGZX22","DOI":"10.1016/j.media.2022.102510","CorpusId":249557147,"PubMed":"35716558"},"title":"Knowledge matters: Chest radiology report generation with general and specific knowledge"},{"paperId":"6351ebb4a3287f5f3e1273464b3b91e5df5a16d7","externalIds":{"DBLP":"conf/cvpr/HeCXLDG22","ArXiv":"2111.06377","DOI":"10.1109/CVPR52688.2022.01553","CorpusId":243985980},"title":"Masked Autoencoders Are Scalable Vision Learners"},{"paperId":"c23d9d44e8bc68408cea9f305d1f24d915bc0d0d","externalIds":{"ArXiv":"2111.01243","DBLP":"journals/corr/abs-2111-01243","DOI":"10.1145/3605943","CorpusId":240420063},"title":"Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey"},{"paperId":"ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51","externalIds":{"DBLP":"conf/iclr/GuGR22","ArXiv":"2111.00396","CorpusId":240354066},"title":"Efficiently Modeling Long Sequences with Structured State Spaces"},{"paperId":"ca9047c78d48b606c4e4f0c456b1dda550de28b2","externalIds":{"DBLP":"conf/nips/GuJGSDRR21","ArXiv":"2110.13985","CorpusId":239998472},"title":"Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"},{"paperId":"932116a0706b9a4864f0de0eb6de5a2f15c4881b","externalIds":{"DBLP":"journals/corr/abs-2109-05686","ArXiv":"2109.05686","DOI":"10.1109/ICCV48922.2021.00100","CorpusId":237494664},"title":"Spatial and Semantic Consistency Regularizations for Pedestrian Attribute Recognition"},{"paperId":"bad3f7549ac97ae3e7d2becc9fabbff94e058dd0","externalIds":{"DBLP":"journals/ijcv/YangTTPWLGL21","MAG":"3184927044","DOI":"10.1007/s11263-021-01499-z","CorpusId":237646804},"title":"Cascaded Split-and-Aggregate Learning with Feature Recombination for Pedestrian Attribute Recognition"},{"paperId":"5d032bd2632b6f5847767f39ce247098c6bbc563","externalIds":{"DBLP":"conf/nips/RenDDYLSD21","ArXiv":"2107.05768","CorpusId":235829099},"title":"Combiner: Full Attention Transformer with Sparse Computation Cost"},{"paperId":"319b84be7a843250bc81d7086f79a4126d550277","externalIds":{"DBLP":"journals/corr/abs-2107-02137","ArXiv":"2107.02137","CorpusId":235731579},"title":"ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"},{"paperId":"9bd6a206cc91a574faa346f57d8a954fa410126b","externalIds":{"ACL":"2021.findings-acl.23","ArXiv":"2106.06965","DBLP":"conf/acl/LiuYWGZS21","DOI":"10.18653/v1/2021.findings-acl.23","CorpusId":235422047},"title":"Contrastive Attention for Automatic Chest X-ray Report Generation"},{"paperId":"c1ad5f9b32d80f1c65d67894e5b8c2fdf0ae4500","externalIds":{"DBLP":"journals/corr/abs-2106-01345","MAG":"3169291081","ArXiv":"2106.01345","CorpusId":235294299},"title":"Decision Transformer: Reinforcement Learning via Sequence Modeling"},{"paperId":"279925dbe2ebe4e38d6cfa646f726aa8d6d9a122","externalIds":{"DBLP":"conf/cvpr/LiuWG0Z21","ArXiv":"2106.06963","DOI":"10.1109/CVPR46437.2021.01354","CorpusId":235421693},"title":"Exploring and Distilling Posterior and Prior Knowledge for Radiology Report Generation"},{"paperId":"465455f3842b24a4f0bf53a4887279e8552860b3","externalIds":{"DBLP":"journals/corr/abs-2105-15076","ArXiv":"2105.15076","DOI":"10.1109/TCSVT.2021.3128214","CorpusId":235254514},"title":"Large-Scale Spatio-Temporal Person Re-Identification: Algorithms and Benchmark"},{"paperId":"d5e999aae76d5270ef272076979c809817458212","externalIds":{"DBLP":"journals/corr/abs-2105-14103","ArXiv":"2105.14103","CorpusId":235254329},"title":"An Attention Free Transformer"},{"paperId":"ea7cfe7f2340584cbe653da6077ee7c213e49b92","externalIds":{"ArXiv":"2105.05537","DBLP":"journals/corr/abs-2105-05537","DOI":"10.1007/978-3-031-25066-8_9","CorpusId":234469981},"title":"Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation"},{"paperId":"75284d5e4dfe1cd8a9ce69085210319e14fcfa3d","externalIds":{"DBLP":"journals/corr/abs-2103-11681","ArXiv":"2103.11681","DOI":"10.1109/CVPR46437.2021.00162","CorpusId":232307380},"title":"Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","externalIds":{"DBLP":"conf/icml/RadfordKHRGASAM21","ArXiv":"2103.00020","CorpusId":231591445},"title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"b4ce7f92a8b987b5e76d580bf5076e2495f06883","externalIds":{"ArXiv":"2102.04378","DBLP":"conf/iccv/He0WW0021","DOI":"10.1109/ICCV48922.2021.01474","CorpusId":231846818},"title":"TransReID: Transformer-based Object Re-Identification"},{"paperId":"ad7ddcc14984caae308c397f1a589aae75d4ab71","externalIds":{"ArXiv":"2012.12877","DBLP":"journals/corr/abs-2012-12877","CorpusId":229363322},"title":"Training data-efficient image transformers & distillation through attention"},{"paperId":"19adf1af8daa9551328226fc6c0140e955bf5689","externalIds":{"ACL":"2020.emnlp-main.112","MAG":"3096799362","DBLP":"conf/emnlp/ChenSCW20","ArXiv":"2010.16056","DOI":"10.18653/v1/2020.emnlp-main.112","CorpusId":226222210},"title":"Generating Radiology Reports via Memory-driven Transformer"},{"paperId":"51c9d4d2f50ac5707c1f889aa97f08350d549132","externalIds":{"DBLP":"journals/corr/abs-2010-13154","ArXiv":"2010.13154","MAG":"3094280184","DOI":"10.1109/ICASSP39728.2021.9413901","CorpusId":225068152},"title":"Attention Is All You Need In Speech Separation"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"ArXiv":"2010.11929","MAG":"3119786062","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"f1a83d466239c5607c7ba3920c5effbcf7ca7641","externalIds":{"DBLP":"conf/mm/SunNXY20","MAG":"3092949934","DOI":"10.1145/3394171.3413541","CorpusId":222278145},"title":"CFVMNet: A Multi-branch Network for Vehicle Re-identification Based on Common Field of View"},{"paperId":"3db110ac6a419cfa95662eb51bff6c52e6f671f2","externalIds":{"ArXiv":"2008.11423","DBLP":"journals/corr/abs-2008-11423","MAG":"3081127035","DOI":"10.1007/978-3-030-58536-5_20","CorpusId":221319661},"title":"Orientation-aware Vehicle Re-identification with Semantics-guided Part Attention Network"},{"paperId":"0964490205fdc38c2f0980c9d778069089ca92e3","externalIds":{"ArXiv":"2008.07669","MAG":"3099512283","DBLP":"conf/nips/GuDERR20","CorpusId":221150566},"title":"HiPPO: Recurrent Memory with Optimal Polynomial Projections"},{"paperId":"267ebbabf19e7f67aae6359be42ee2e12479ba17","externalIds":{"DBLP":"conf/eccv/ZhuGLTW20","MAG":"3045817950","ArXiv":"2007.13467","DOI":"10.1007/978-3-030-58580-8_21","CorpusId":220793215},"title":"Identity-Guided Human Semantic Parsing for Person Re-Identification"},{"paperId":"6f68e1bb253925d8431588555d3010419f322e04","externalIds":{"DBLP":"conf/icml/KatharopoulosV020","MAG":"3037798801","ArXiv":"2006.16236","CorpusId":220250819},"title":"Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention"},{"paperId":"a4189f837906cbc8acc84aa5f740222196034ab0","externalIds":{"DBLP":"conf/cvpr/ChenFZZSJY20","MAG":"3035186652","DOI":"10.1109/cvpr42600.2020.00336","CorpusId":219630295},"title":"Salience-Guided Cascaded Suppression Network for Person Re-Identification"},{"paperId":"7bba8759784a0d982362d73834784b02fe62d536","externalIds":{"ArXiv":"2004.06271","DBLP":"conf/eccv/KhorramshahiPCC20","MAG":"3109976024","DOI":"10.1007/978-3-030-58568-6_22","CorpusId":215754526},"title":"The Devil is in the Details: Self-Supervised Attention for Vehicle Re-Identification"},{"paperId":"4b3e12624654d505733b33b156c72235f4fcebfa","externalIds":{"MAG":"3035645942","DBLP":"conf/cvpr/MengLLLYZGWH20","ArXiv":"2004.05021","DOI":"10.1109/CVPR42600.2020.00713","CorpusId":215737119},"title":"Parsing-Based View-Aware Embedding Network for Vehicle Re-Identification"},{"paperId":"bed372546622ebe975e2c26dd34cf9304c720a14","externalIds":{"MAG":"2998496429","DBLP":"conf/aaai/Tan00GL20","DOI":"10.1609/AAAI.V34I07.6883","CorpusId":212856067},"title":"Relation-Aware Pedestrian Attribute Recognition with Graph Convolutional Networks"},{"paperId":"6b6d31b022b7984a25fa9ee7fef64086ce7c464d","externalIds":{"MAG":"3013266062","DBLP":"journals/corr/abs-2003-12565","ArXiv":"2003.12565","DOI":"10.1109/cvpr42600.2020.00721","CorpusId":214693026},"title":"Probabilistic Regression for Visual Tracking"},{"paperId":"d1e61fa7824709cae37fb59483dd0772e3101c08","externalIds":{"MAG":"3014030918","ArXiv":"2003.11014","DBLP":"conf/eccv/BhatDGT20","DOI":"10.1007/978-3-030-58592-1_13","CorpusId":214623106},"title":"Know Your Surroundings: Exploiting Scene Information for Object Tracking"},{"paperId":"8bc4d395f685140c0d7583effdfa84571e8050d8","externalIds":{"DBLP":"journals/tcsv/WuLJQRLW20","MAG":"3013799809","DOI":"10.1109/TCSVT.2020.2982962","CorpusId":216200174},"title":"Person Attribute Recognition by Sequence Contextual Relation Learning"},{"paperId":"5fffb5d73616b3f9ae698470feb2f516fd561dd0","externalIds":{"ArXiv":"2003.08177","MAG":"3035539956","DBLP":"journals/corr/abs-2003-08177","DOI":"10.1109/CVPR42600.2020.00648","CorpusId":212747636},"title":"High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Identification"},{"paperId":"ed80ce5bca11c841f900bb26b1bb89ca5585d4ac","externalIds":{"DOI":"10.1109/mc.2020.2974641","CorpusId":243252046},"title":"IEEE Transactions"},{"paperId":"5fa82dfbf469a793d7c98804a63a8acf7d9e4a5f","externalIds":{"MAG":"2997704374","DBLP":"journals/corr/abs-2002-08277","ArXiv":"2002.08277","DOI":"10.1609/AAAI.V34I07.6989","CorpusId":211171529},"title":"When Radiology Report Generation Meets Knowledge Graph"},{"paperId":"e76d71cb341bd9ef509fab4cb51b748ac7469ba8","externalIds":{"DBLP":"journals/corr/abs-2002-02256","ArXiv":"2002.02256","MAG":"3004918942","CorpusId":211043643},"title":"Looking GLAMORous: Vehicle Re-Id in Heterogeneous Cameras Networks with Global and Local Attention"},{"paperId":"dd1d8a403f83d35bb5225e9802ea1d39665af65f","externalIds":{"DBLP":"conf/eccv/ZhuangWXZZWAT20","MAG":"3096285474","DOI":"10.1007/978-3-030-58610-2_9","CorpusId":214728118},"title":"Rethinking the Distribution Gap of Person Re-identification with Camera-Based Batch Normalization"},{"paperId":"eb47a8f5d9dc2020fc7312f07dce4346b128be53","externalIds":{"MAG":"2997351135","DBLP":"conf/aaai/JinLZ020","ArXiv":"2001.05197","DOI":"10.1609/AAAI.V34I07.6774","CorpusId":210700928},"title":"Uncertainty-Aware Multi-Shot Knowledge Distillation for Image-Based Object Re-Identification"},{"paperId":"395de0bd3837fdf4b4b5e5f04835bcc69c279481","externalIds":{"MAG":"2982399380","ACL":"2020.acl-main.703","DBLP":"journals/corr/abs-1910-13461","ArXiv":"1910.13461","DOI":"10.18653/v1/2020.acl-main.703","CorpusId":204960716},"title":"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"},{"paperId":"401dc8dc49a4e6e507da7979bcd979f389937b3d","externalIds":{"DBLP":"journals/corr/abs-1910-05549","ArXiv":"1910.05549","MAG":"2980046511","DOI":"10.1088/1361-6501/ab8b81","CorpusId":204512251},"title":"Stripe-based and attribute-aware network: a two-branch deep model for vehicle re-identification"},{"paperId":"0e6beea0b90b7072c96fd6acd6c7186bd8aeadd1","externalIds":{"MAG":"2981393440","DBLP":"conf/iccv/MiaoWLD019","DOI":"10.1109/ICCV.2019.00063","CorpusId":207985433},"title":"Pose-Guided Feature Alignment for Occluded Person Re-Identification"},{"paperId":"6baed11611fecaaef97806d029097efbabd5d166","externalIds":{"MAG":"2979990497","DBLP":"conf/iccv/ChuSLLZW19","ArXiv":"1910.04104","DOI":"10.1109/ICCV.2019.00837","CorpusId":203951329},"title":"Vehicle Re-Identification With Viewpoint-Aware Metric Learning"},{"paperId":"d1b91dec543acc856561edc8993f36b18a8c8f56","externalIds":{"MAG":"2973183043","DBLP":"journals/corr/abs-1909-06023","ArXiv":"1909.06023","CorpusId":202573035},"title":"Part-Guided Attention Learning for Vehicle Re-Identification"},{"paperId":"17adb315d1fdc0757dae5d72db4a66143102d1c3","externalIds":{"MAG":"2990827756","ArXiv":"1908.01114","DBLP":"conf/iccv/ChenDXYCYRW19","DOI":"10.1109/ICCV.2019.00844","CorpusId":199442462},"title":"ABD-Net: Attentive but Diverse Person Re-Identification"},{"paperId":"8902babf787a1acfc6f45be544b78fd46c05dd04","externalIds":{"MAG":"2955854238","DBLP":"conf/cvpr/HeLZT19","DOI":"10.1109/CVPR.2019.00412","CorpusId":173174872},"title":"Part-Regularized Near-Duplicate Vehicle Re-Identification"},{"paperId":"6eef1856310619d03e65ac1753b039c44bf97bd0","externalIds":{"MAG":"2997987796","ArXiv":"1905.13143","DBLP":"conf/aaai/JinLZW020","DOI":"10.1609/AAAI.V34I07.6775","CorpusId":170079285},"title":"Semantics-Aligned Representation Learning for Person Re-identification"},{"paperId":"45f4294a9ca31ca77a3393ba4e9499096d3eacc9","externalIds":{"MAG":"2984145721","ArXiv":"1905.00953","DBLP":"conf/iccv/ZhouYCX19","DOI":"10.1109/ICCV.2019.00380","CorpusId":145050804},"title":"Omni-Scale Feature Learning for Person Re-Identification"},{"paperId":"2c8315ae713b3e27c6e9f291a158134d9c516166","externalIds":{"MAG":"3001584168","ArXiv":"1904.07220","DBLP":"journals/corr/abs-1904-07220","DOI":"10.1109/ICCV.2019.00628","CorpusId":118637813},"title":"Learning Discriminative Model Prediction for Tracking"},{"paperId":"8043113812dae0f95f68677ba7ce986321401dd6","externalIds":{"DBLP":"conf/cvpr/ZhangLZJ020","MAG":"3010766832","ArXiv":"1904.02998","DOI":"10.1109/CVPR42600.2020.00325","CorpusId":216639682},"title":"Relation-Aware Global Attention for Person Re-Identification"},{"paperId":"adc998ac4fa71bdab19537c50e3d84bf982974c1","externalIds":{"MAG":"2949197560","ArXiv":"1903.10122","DBLP":"journals/corr/abs-1903-10122","DOI":"10.1609/AAAI.V33I01.33016666","CorpusId":59276384},"title":"Knowledge-driven Encode, Retrieve, Paraphrase for Medical Image Report Generation"},{"paperId":"1e7ff66f484e9c7b235b4335103619c8796af419","externalIds":{"ArXiv":"1903.07071","DBLP":"journals/corr/abs-1903-07071","MAG":"2922510913","DOI":"10.1109/CVPRW.2019.00190","CorpusId":85517477},"title":"Bag of Tricks and a Strong Baseline for Deep Person Re-Identification"},{"paperId":"229319b01e298811a548646f8f0bfc95908511a4","externalIds":{"MAG":"2913900874","ArXiv":"1901.07474","DBLP":"journals/corr/abs-1901-07474","DOI":"10.1016/j.patcog.2021.108220","CorpusId":58981448},"title":"Pedestrian Attribute Recognition: A Survey"},{"paperId":"d74169a8fd2f90a06480d1d583d0ae5e980ea951","externalIds":{"DBLP":"journals/corr/abs-1811-07628","MAG":"2901751835","ArXiv":"1811.07628","DOI":"10.1109/CVPR.2019.00479","CorpusId":53712235},"title":"ATOM: Accurate Tracking by Overlap Maximization"},{"paperId":"e2a2818ec251d947acd9c74c2040337e656946bc","externalIds":{"MAG":"2964195337","DBLP":"conf/nips/LiLHX18","ArXiv":"1805.08298","CorpusId":44234294},"title":"Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation"},{"paperId":"927ec8dde9eb0e3bc5bf0b1a0ae57f9cf745fd9c","externalIds":{"MAG":"2795758732","DBLP":"conf/mm/WangYCLZ18","ArXiv":"1804.01438","DOI":"10.1145/3240508.3240552","CorpusId":4591954},"title":"Learning Discriminative Features with Multiple Granularities for Person Re-Identification"},{"paperId":"10c20cf47d61063032dce4af73a4b8e350bf1128","externalIds":{"MAG":"2779160359","ArXiv":"1712.09531","DBLP":"journals/corr/abs-1712-09531","CorpusId":6322767},"title":"Multi-Target, Multi-Camera Tracking by Hierarchical Clustering: Recent Progress on DukeMTMC Project"},{"paperId":"7002d8c61be9f1ea210f88059df6955c88db62b7","externalIds":{"DBLP":"conf/cvpr/WeiZ0018","MAG":"2951257857","ArXiv":"1711.08565","DOI":"10.1109/CVPR.2018.00016","CorpusId":6258614},"title":"Person Transfer GAN to Bridge Domain Gap for Person Re-identification"},{"paperId":"33998aff64ce51df8dee45989cdca4b6b1329ec4","externalIds":{"DBLP":"journals/corr/abs-1710-10903","ArXiv":"1710.10903","MAG":"2766453196","DOI":"10.17863/CAM.48429","CorpusId":3292002},"title":"Graph Attention Networks"},{"paperId":"f41c7bb02fc97d5fb9cadd7a49c3e558a1c58a44","externalIds":{"ArXiv":"1709.09930","MAG":"2950468170","DBLP":"journals/corr/abs-1709-09930","DOI":"10.1109/ICCV.2017.46","CorpusId":6523475},"title":"HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","externalIds":{"DBLP":"journals/corr/VaswaniSPUJGKP17","MAG":"2963403868","ArXiv":"1706.03762","CorpusId":13756489},"title":"Attention is All you Need"},{"paperId":"abc8638968909ab0fdfbf1049009082df554a49e","externalIds":{"DBLP":"conf/icmcs/LiuLMF16","MAG":"2512434173","DOI":"10.1109/ICME.2016.7553002","CorpusId":662727},"title":"Large-scale vehicle re-identification in urban surveillance videos"},{"paperId":"713aad1bd525cd1a28e340b366f78f81386f32de","externalIds":{"DBLP":"conf/cvpr/LiuTWPH16","MAG":"2470322391","DOI":"10.1109/CVPR.2016.238","CorpusId":3885908},"title":"Deep Relative Distance Learning: Tell the Difference between Similar Vehicles"},{"paperId":"846aedd869a00c09b40f1f1f35673cb22bc87490","externalIds":{"DBLP":"journals/nature/SilverHMGSDSAPL16","MAG":"2257979135","DOI":"10.1038/nature16961","CorpusId":515925,"PubMed":"26819042"},"title":"Mastering the game of Go with deep neural networks and tree search"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"e24c261f5cfcd58a595efb7ca684aedcb2a2f22c","externalIds":{"DBLP":"conf/iccv/ZhengSTWWT15","MAG":"2204750386","DOI":"10.1109/ICCV.2015.133","CorpusId":14991802},"title":"Scalable Person Re-identification: A Benchmark"},{"paperId":"04b9e4192eca063b95ca65db901e1cccfb0ecd6f","externalIds":{"MAG":"2152772232","DBLP":"journals/jamia/Demner-FushmanK16","DOI":"10.1093/jamia/ocv080","CorpusId":16941525,"PubMed":"26133894"},"title":"Preparing a collection of radiology examinations for distribution and retrieval"},{"paperId":"c32cefb0c917bc0fa48f5ec2e914361a9f85b85f","externalIds":{"DBLP":"conf/mm/DENGLLT14","MAG":"2111025459","DOI":"10.1145/2647868.2654966","CorpusId":5106906},"title":"Pedestrian Attribute Recognition At Far Distance"},{"paperId":"e15cf50aa89fee8535703b9f9512fca5bfc43327","externalIds":{"DBLP":"journals/corr/SzegedyLJSRAEVR14","MAG":"2097117768","ArXiv":"1409.4842","DOI":"10.1109/CVPR.2015.7298594","CorpusId":206592484},"title":"Going deeper with convolutions"},{"paperId":"0b544dfe355a5070b60986319a3f51fb45d1348e","externalIds":{"MAG":"2950635152","DBLP":"conf/emnlp/ChoMGBBSB14","ACL":"D14-1179","ArXiv":"1406.1078","DOI":"10.3115/v1/D14-1179","CorpusId":5590763},"title":"Learning Phrase Representations using RNN EncoderDecoder for Statistical Machine Translation"},{"paperId":"5e83ab70d0cbc003471e87ec306d27d9c80ecb16","externalIds":{"ArXiv":"1312.4400","MAG":"1799366690","DBLP":"journals/corr/LinCY13","CorpusId":16636683},"title":"Network In Network"},{"paperId":"abd1c342495432171beb7ca8fd9551ef13cbd0ff","externalIds":{"DBLP":"conf/nips/KrizhevskySH12","MAG":"2618530766","DOI":"10.1145/3065386","CorpusId":195908774},"title":"ImageNet classification with deep convolutional neural networks"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","externalIds":{"DBLP":"conf/cvpr/DengDSLL009","MAG":"2108598243","DOI":"10.1109/CVPR.2009.5206848","CorpusId":57246310},"title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"2e9d221c206e9503ceb452302d68d10e293f2a10","externalIds":{"DBLP":"journals/neco/HochreiterS97","MAG":"2064675550","DOI":"10.1162/neco.1997.9.8.1735","CorpusId":1915014,"PubMed":"9377276"},"title":"Long Short-Term Memory"},{"paperId":"b8fc4baba24647e59c6b48234c4f68e28c986a6c","externalIds":{"DBLP":"journals/corr/abs-2404-06483","DOI":"10.48550/arXiv.2404.06483","CorpusId":269009998},"title":"RhythmMamba: Fast Remote Physiological Measurement with Arbitrary Length Videos"},{"paperId":"d985e46330dcb76e3e7700e84693d4080061a3e8","externalIds":{"DBLP":"journals/corr/abs-2404-02063","DOI":"10.48550/arXiv.2404.02063","CorpusId":268856709},"title":"SPMamba: State-space model is all you need in speech separation"},{"paperId":"0f2fbed561e37da842c98633faf8fe1de9e2e174","externalIds":{"DBLP":"journals/corr/abs-2402-02242","DOI":"10.48550/arXiv.2402.02242","CorpusId":267412110},"title":"Parameter-Efficient Fine-Tuning for Pre-Trained Vision Models: A Survey"},{"paperId":"5dc783a45ade5124fcd828a5a9b25e723ae9d37b","externalIds":{"DBLP":"journals/corr/abs-2402-07245","DOI":"10.48550/arXiv.2402.07245","CorpusId":267627037},"title":"Semi-Mamba-UNet: Pixel-Level Contrastive Cross-Supervised Visual Mamba-based UNet for Semi-Supervised Medical Image Segmentation"},{"paperId":"e1ed7615b4918ead3d693ad3dc42e45e5742d2e2","externalIds":{"DBLP":"journals/corr/abs-2404-07932","DOI":"10.48550/arXiv.2404.07932","CorpusId":269042827},"title":"FusionMamba: Efficient Image Fusion with State Space Model"},{"paperId":"13c0b6fcf702fcfe0c8dd9c85130477f53430021","externalIds":{"DBLP":"journals/corr/abs-2401-13934","DOI":"10.48550/arXiv.2401.13934","CorpusId":267211855},"title":"MambaMorph: a Mamba-based Backbone with Contrastive Feature Learning for Deformable MR-CT Registration"},{"paperId":"7e087f842281182474ed96712febca0828469c1c","externalIds":{"DBLP":"conf/iclr/0002ZW24","CorpusId":271746253},"title":"A 2-Dimensional State Space Layer for Spatial Inductive Bias"},{"paperId":"cf0f8f585c8822e3c6bcd9527d546eefc8486aea","externalIds":{"DBLP":"conf/nips/NguyenGGDSDBR22","CorpusId":260443992},"title":"S4ND: Modeling Images and Videos as Multidimensional Signals with State Spaces"},{"paperId":"b90ba72b8368e011d31a4d2df4d10edd9e675170","externalIds":{"DBLP":"journals/tmm/FanHLLP22","MAG":"3112567928","DOI":"10.1109/tmm.2020.3045286","CorpusId":235053965},"title":"Correlation Graph Convolutional Network for Pedestrian Attribute Recognition"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","externalIds":{"ArXiv":"2103.14030","DBLP":"conf/iccv/LiuL00W0LG21","DOI":"10.1109/ICCV48922.2021.00986","CorpusId":232352874},"title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","externalIds":{"MAG":"2951055169","ACL":"N19-1423","DBLP":"journals/corr/abs-1810-04805","ArXiv":"1810.04805","DOI":"10.18653/v1/N19-1423","CorpusId":52967399},"title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"81a4fd3004df0eb05d6c1cef96ad33d5407820df","externalIds":{"DBLP":"journals/tnn/WuPCLZY21","MAG":"2907492528","ArXiv":"1901.00596","DOI":"10.1109/TNNLS.2020.2978386","CorpusId":57375753,"PubMed":"32217482"},"title":"A Comprehensive Survey on Graph Neural Networks"},{"paperId":"255a77422b1da74da05d1714b7875356187385bd","externalIds":{"CorpusId":1242324},"title":"A New Approach to Linear Filtering and Prediction Problems"}]}