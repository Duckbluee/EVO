{"paperId":"df7210b2a205030583e6ee4271270548fb645b59","externalIds":{"DBLP":"journals/corr/abs-2302-09051","ArXiv":"2302.09051","DOI":"10.48550/arXiv.2302.09051","CorpusId":257019916},"title":"Complex QA and language models hybrid architectures, Survey","openAccessPdf":{"url":"http://arxiv.org/pdf/2302.09051","status":"GREEN","license":null,"disclaimer":"Notice: Paper or abstract available at https://arxiv.org/abs/2302.09051, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."},"authors":[{"authorId":"2207712664","name":"Xavier Daull"},{"authorId":"1794810","name":"P. Bellot"},{"authorId":"24239598","name":"Emmanuel Bruno"},{"authorId":"2052553796","name":"Vincent Martin"},{"authorId":"2542690","name":"Elisabeth Murisasco"}],"abstract":"This paper reviews the state-of-the-art of large language models (LLM) architectures and strategies for\"complex\"question-answering with a focus on hybrid architectures. LLM based chatbot services have allowed anyone to grasp the potential of LLM to solve many common problems, but soon discovered their limitations for complex questions. Addressing more specific, complex questions (e.g.,\"What is the best mix of power-generation methods to reduce climate change ?\") often requires specialized architectures, domain knowledge, new skills, decomposition and multi-step resolution, deep reasoning, sensitive data protection, explainability, and human-in-the-loop processes. Therefore, we review: (1) necessary skills and tasks for handling complex questions and common LLM limits to overcome; (2) dataset, cost functions and evaluation metrics for measuring and improving (e.g. accuracy, explainability, fairness, robustness, groundedness, faithfulness, toxicity...); (3) family of solutions to overcome LLM limitations by (a) training and reinforcement (b) hybridization, (c) prompting, (d) agentic-architectures (agents, tools) and extended reasoning."}