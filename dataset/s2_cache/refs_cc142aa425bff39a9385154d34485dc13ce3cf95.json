{"references":[{"paperId":"fe4b8ab42b28fdf23f069fe8b3c9030f518e636c","externalIds":{"DBLP":"journals/corr/abs-2405-03673","ArXiv":"2405.03673","DOI":"10.48550/arXiv.2405.03673","CorpusId":269605955},"title":"MemoryMamba: Memory-Augmented State Space Model for Defect Recognition"},{"paperId":"1f790b4cb07824dbba80fdf96e07de16c0688021","externalIds":{"DBLP":"conf/iconip/BaiYHLZ24","ArXiv":"2405.03349","DOI":"10.48550/arXiv.2405.03349","CorpusId":269604860},"title":"Retinexmamba: Retinex-based Mamba for Low-light Image Enhancement"},{"paperId":"95fa89d968216b7c31e5993bd9bc08dfd9a81c20","externalIds":{"DBLP":"journals/corr/abs-2405-03025","ArXiv":"2405.03025","DOI":"10.48550/arXiv.2405.03025","CorpusId":269604707},"title":"Matten: Video Generation with Mamba-Attention"},{"paperId":"47741d9e57f7a986a350f5cb20de287b1b1b8ff8","externalIds":{"ArXiv":"2404.18861","CorpusId":269449094},"title":"Visual Mamba: A Survey and New Outlooks"},{"paperId":"efb0b124c222f4a73ab307f0c0d2b17c3c4c0c95","externalIds":{"DBLP":"journals/corr/abs-2404-18401","ArXiv":"2404.18401","DOI":"10.3390/rs16132449","CorpusId":269448985},"title":"Spectral-Spatial Mamba for Hyperspectral Image Classification"},{"paperId":"6cb7615c04f915fae8c6dd6bcad623db25787a8f","externalIds":{"DBLP":"journals/lgrs/LiuCCZZS24","ArXiv":"2404.18895","DOI":"10.1109/LGRS.2024.3404604","CorpusId":269449228},"title":"RSCaMa: Remote Sensing Image Change Captioning With State Space Model"},{"paperId":"b22a8a676c9052c647925204cf34d79f81f0c06a","externalIds":{"DBLP":"journals/corr/abs-2404-18213","ArXiv":"2404.18213","DOI":"10.1109/TGRS.2025.3530993","CorpusId":269449670},"title":"S2Mamba: A Spatialâ€“Spectral State Space Model for Hyperspectral Image Classification"},{"paperId":"490c256f9840de52455e2909c9095bd243c80c4e","externalIds":{"DBLP":"journals/corr/abs-2404-18174","ArXiv":"2404.18174","DOI":"10.48550/arXiv.2404.18174","CorpusId":269449497},"title":"Mamba-FETrack: Frame-Event Tracking via State Space Model"},{"paperId":"ba4c5a116d07b37dea1046b6d16a60cb2d01cd47","externalIds":{"DBLP":"journals/corr/abs-2404-16112","ArXiv":"2404.16112","DOI":"10.48550/arXiv.2404.16112","CorpusId":269362649},"title":"Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges"},{"paperId":"f5cea4651c32d2ba95171fb264cc6680262c17d7","externalIds":{"ArXiv":"2404.15956","DBLP":"journals/corr/abs-2404-15956","DOI":"10.48550/arXiv.2404.15956","CorpusId":269362942},"title":"A Survey on Visual Mamba"},{"paperId":"46ac9f54189e233a189035f35f850f90128f6465","externalIds":{"ArXiv":"2404.11778","DBLP":"conf/mipr/DengG24","DOI":"10.1109/MIPR62202.2024.00059","CorpusId":269214068},"title":"CU-Mamba: Selective State Space Models with Channel Learning for Image Restoration"},{"paperId":"02d3afd9c306ce0a0d39e211d60468732c591f8f","externalIds":{"DBLP":"journals/corr/abs-2404-09516","ArXiv":"2404.09516","DOI":"10.48550/arXiv.2404.09516","CorpusId":269148958},"title":"State Space Model for New-Generation Network Alternative to Transformers: A Survey"},{"paperId":"69bdcdfa8742d516bd1a7700b6f2f7861476bd8e","externalIds":{"DBLP":"conf/mm/ZouYHZ24","ArXiv":"2404.09476","DOI":"10.1145/3664647.3680862","CorpusId":269149600},"title":"FreqMamba: Viewing Mamba from a Frequency Perspective for Image Deraining"},{"paperId":"a6b7d8c5cebf7515e4bbdf6e2a13f245d8eb9366","externalIds":{"ArXiv":"2404.09498","DBLP":"journals/visintelligence/XieCTZY24","DOI":"10.1007/s44267-024-00072-9","CorpusId":269148750},"title":"FusionMamba: dynamic feature enhancement for multimodal image fusion with Mamba"},{"paperId":"9b54e80ab60632213cfd0a90d2f10f62619e0eb4","externalIds":{"DBLP":"journals/tmm/DongZLLSGZ25","ArXiv":"2404.09146","DOI":"10.1109/TMM.2025.3599020","CorpusId":269148408},"title":"Fusion-Mamba for Cross-Modality Object Detection"},{"paperId":"c2679d0d07801c48fb31edc89b0cc33b84b837e4","externalIds":{"DBLP":"conf/mm/CaoWDZ24","ArXiv":"2404.09293","DOI":"10.1145/3664647.3680905","CorpusId":269148465},"title":"A Novel State Space Model with Local Enhancement and State Sharing for Image Fusion"},{"paperId":"d8c9307e15c02d693b81135a376f3ee8d270b7f9","externalIds":{"DBLP":"journals/corr/abs-2404-08406","ArXiv":"2404.08406","DOI":"10.48550/arXiv.2404.08406","CorpusId":269137516},"title":"MambaDFuse: A Mamba-based Dual-phase Model for Multi-modality Image Fusion"},{"paperId":"f442d39e6cba53bc67c53e07759c0a90deda8ac9","externalIds":{"ArXiv":"2404.08489","DBLP":"journals/corr/abs-2404-08489","DOI":"10.48550/arXiv.2404.08489","CorpusId":269137481},"title":"SpectralMamba: Efficient Mamba for Hyperspectral Image Classification"},{"paperId":"b11b6a0edf07bb1d14ee8ed721d7fbce29b62c08","externalIds":{"ArXiv":"2404.08027","DBLP":"journals/corr/abs-2404-08027","DOI":"10.1109/BIBM66473.2025.11356727","CorpusId":269137256},"title":"SurvMamba: State Space Model with Multi-Grained Multi-Modal Interaction for Survival Prediction"},{"paperId":"eed646c62b0665316218a1bae5dc55d333ebe100","externalIds":{"DBLP":"conf/mm/Long0LLY0MY24","ArXiv":"2404.07794","DOI":"10.1145/3664647.3681247","CorpusId":269043035},"title":"DGMamba: Domain Generalization via Generalized State Space Model"},{"paperId":"a9a44c4180f115a974757f239eb915615bb9cd12","externalIds":{"DBLP":"journals/corr/abs-2404-07106","ArXiv":"2404.07106","DOI":"10.48550/arXiv.2404.07106","CorpusId":269033257},"title":"3DMambaComplete: Exploring Structured State Space Model for Point Cloud Completion"},{"paperId":"e29a34d17dc41422fb16c6d8c258dfa7ff949b47","externalIds":{"DBLP":"conf/nips/HeBZHCGWLT024","ArXiv":"2404.06564","DOI":"10.48550/arXiv.2404.06564","CorpusId":269033047},"title":"MambaAD: Exploring State Space Models for Multi-class Unsupervised Anomaly Detection"},{"paperId":"8eeab702e8cf4bedb8cba951bf1483bda02eda1f","externalIds":{"DBLP":"journals/corr/abs-2404-05105","ArXiv":"2404.05105","DOI":"10.48550/arXiv.2404.05105","CorpusId":269004567},"title":"VMambaMorph: a Multi-Modality Deformable Image Registration Framework based on Visual State Space Model with Cross-Scan Module"},{"paperId":"a06ad946578d92baac73735726a00b5f7f446c98","externalIds":{"DBLP":"conf/wacv/WanZWYSSX25","ArXiv":"2404.04256","DOI":"10.1109/WACV61041.2025.00176","CorpusId":268987521},"title":"Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation"},{"paperId":"541bcf94bd09f17c25d8ed7cd10e69c8f91331d0","externalIds":{"ArXiv":"2404.03425","DBLP":"journals/corr/abs-2404-03425","DOI":"10.1109/TGRS.2024.3417253","CorpusId":268889712},"title":"ChangeMamba: Remote Sensing Change Detection With Spatiotemporal State Space Model"},{"paperId":"a70974e64bfa510ee9c969f0d22bbfaba305d6bb","externalIds":{"DBLP":"journals/corr/abs-2404-03611","ArXiv":"2404.03611","DOI":"10.48550/arXiv.2404.03611","CorpusId":268889683},"title":"InsectMamba: Insect Pest Classification with State Space Model"},{"paperId":"31700a32d5d48f787170cd0ecd3ba0e5eb37d371","externalIds":{"ArXiv":"2404.02457","DBLP":"journals/lgrs/MaZP24","DOI":"10.1109/LGRS.2024.3414293","CorpusId":268876327},"title":"RS3Mamba: Visual State Space Model for Remote Sensing Image Semantic Segmentation"},{"paperId":"2833716cabbd7c709f4b266832b8b3fa3e37d2c6","externalIds":{"DBLP":"journals/tgrs/ZhaoCZXBO24","ArXiv":"2404.02668","DOI":"10.1109/TGRS.2024.3425540","CorpusId":268875757},"title":"RS-Mamba for Large Remote Sensing Image Dense Prediction"},{"paperId":"ed228d3ad968eb1aa38baea5471bcb1d698f196a","externalIds":{"ArXiv":"2404.01705","PubMedCentral":"11466675","DBLP":"journals/corr/abs-2404-01705","DOI":"10.1016/j.heliyon.2024.e38495","CorpusId":268856763,"PubMed":"39398081"},"title":"Samba: Semantic segmentation of remotely sensed images with state space model"},{"paperId":"609b7d5bf1ad35b20073152245da65855aa25942","externalIds":{"ArXiv":"2404.01065","CorpusId":268819833},"title":"T-Mamba: A unified framework with Long-Range Dependency in dual-domain for 2D&3D Tooth Segmentation"},{"paperId":"bb6afe666ffd07d9059ec94cac551c2b1f33f096","externalIds":{"ArXiv":"2404.01174","DBLP":"journals/corr/abs-2404-01174","DOI":"10.48550/arXiv.2404.01174","CorpusId":268819945},"title":"SpikeMba: Multi-Modal Spiking Saliency Mamba for Temporal Video Grounding"},{"paperId":"21ffa380d4cfceeaaeed4fafc8fe76c669e2e4ef","externalIds":{"ArXiv":"2403.20035","DBLP":"journals/corr/abs-2403-20035","PubMedCentral":"12664954","DOI":"10.1016/j.patter.2025.101298","CorpusId":268793860,"PubMed":"41328156"},"title":"UltraLight VM-UNet: Parallel Vision Mamba significantly reduces parameters for skin lesion segmentation"},{"paperId":"5f07ef98b64b2ab47105018cbda158527f903b28","externalIds":{"DBLP":"journals/lgrs/ChenCLLZS24","ArXiv":"2403.19654","DOI":"10.1109/LGRS.2024.3407111","CorpusId":268733376},"title":"RSMamba: Remote Sensing Image Classification With State Space Model"},{"paperId":"69fa358ca1680ff2779477bdab2f42851c2499ca","externalIds":{"ArXiv":"2403.18795","DBLP":"journals/corr/abs-2403-18795","DOI":"10.48550/arXiv.2403.18795","CorpusId":268724060,"PubMed":"40388288"},"title":"Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction"},{"paperId":"62ac3ef81e54e1d1930fb5980b236345ee2e4f32","externalIds":{"ArXiv":"2403.17695","DBLP":"conf/bmvc/YangCEEWLC24","DOI":"10.48550/arXiv.2403.17695","CorpusId":268692121},"title":"PlainMamba: Improving Non-Hierarchical Mamba in Visual Recognition"},{"paperId":"df0e715f15ba81be07663aae51339072d972faaf","externalIds":{"ArXiv":"2403.17701","DBLP":"journals/corr/abs-2403-17701","DOI":"10.48550/arXiv.2403.17701","CorpusId":268692226},"title":"Rotate to Scan: UNet-like Mamba with Triplet SSM Module for Medical Image Segmentation"},{"paperId":"9bd60a0b1b5e70c9e6ccfde513f8fdea61d8b503","externalIds":{"DBLP":"journals/corr/abs-2403-17839","ArXiv":"2403.17839","DOI":"10.48550/arXiv.2403.17839","CorpusId":268691384},"title":"ReMamber: Referring Image Segmentation with Mamba Twister"},{"paperId":"b8a1829a42b11dc4bd4ce03c22e07298398d0405","externalIds":{"DBLP":"journals/corr/abs-2403-17432","ArXiv":"2403.17432","DOI":"10.48550/arXiv.2403.17432","CorpusId":268692069},"title":"Integrating Mamba Sequence Model and Hierarchical Upsampling Network for Accurate Semantic Segmentation of Multiple Sclerosis Legion"},{"paperId":"278c122ff695a0ded29af43a719a76b97763161c","externalIds":{"ArXiv":"2403.16520","DBLP":"journals/corr/abs-2403-16520","DOI":"10.48550/arXiv.2403.16520","CorpusId":268681125},"title":"CMViM: Contrastive Masked Vim Autoencoder for 3D Multi-modal Representation Learning for AD classification"},{"paperId":"fea8a3096391a418cb9ef724e0ff9754e5a467fd","externalIds":{"ArXiv":"2403.15360","DBLP":"journals/corr/abs-2403-15360","DOI":"10.48550/arXiv.2403.15360","CorpusId":268666944},"title":"SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series"},{"paperId":"40e996a7c3e914a67c708704fa9b4c54ea70f36e","externalIds":{"DBLP":"conf/aaai/0008ZZDHW25","ArXiv":"2403.14520","DOI":"10.48550/arXiv.2403.14520","CorpusId":268553791},"title":"Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference"},{"paperId":"206974b54e00c1145157d6bc4229b9a2b77ea929","externalIds":{"ArXiv":"2403.13642","DBLP":"journals/ijon/WuLLC25","DOI":"10.1016/j.neucom.2025.129447","CorpusId":268537116},"title":"H-vmunet: High-order Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"904563400562d35226618839fd7f3c3de23179bf","externalIds":{"ArXiv":"2403.13660","DBLP":"journals/corr/abs-2403-13660","DOI":"10.48550/arXiv.2403.13660","CorpusId":268536910},"title":"ProMamba: Prompt-Mamba for polyp segmentation"},{"paperId":"6d49ed0ea24b9c218f5ec6731cd261ce618df2ac","externalIds":{"DBLP":"journals/corr/abs-2403-13600","ArXiv":"2403.13600","DOI":"10.48550/arXiv.2403.13600","CorpusId":268537285},"title":"VL-Mamba: Exploring State Space Models for Multimodal Learning"},{"paperId":"f67d6126c8436cf91a9cc2ef97c347a41dbf05d4","externalIds":{"DBLP":"journals/corr/abs-2403-11423","ArXiv":"2403.11423","DOI":"10.1109/TCSVT.2025.3530090","CorpusId":268512896},"title":"VmambaIR: Visual State Space Model for Image Restoration"},{"paperId":"9f1dc0ebf06841f988d7a1d12d1d2206c0707b53","externalIds":{"ArXiv":"2403.09977","DBLP":"journals/corr/abs-2403-09977","DOI":"10.48550/arXiv.2403.09977","CorpusId":268510293},"title":"EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba"},{"paperId":"67cfddf7e4cc909029360331d5f62d0477eab39b","externalIds":{"ArXiv":"2403.10696","DBLP":"journals/corr/abs-2403-10696","DOI":"10.48550/arXiv.2403.10696","CorpusId":268513189},"title":"On the low-shot transferability of [V]-Mamba"},{"paperId":"0a32e6ff6eaac83ff325bae4557a8362222979aa","externalIds":{"DBLP":"journals/ijcv/ChenHXPWCLLW26","ArXiv":"2403.09626","DOI":"10.1007/s11263-025-02597-y","CorpusId":268385114},"title":"Video Mamba Suite: State Space Model as a Versatile Alternative for Video Understanding"},{"paperId":"5867382590f9f0ff8caf15804d20bde10845b2d2","externalIds":{"DBLP":"conf/eccv/HuangPYWQX24","ArXiv":"2403.09338","DOI":"10.48550/arXiv.2403.09338","CorpusId":268385283},"title":"LocalMamba: Visual State Space Model with Windowed Selective Scan"},{"paperId":"66a5f11bdd88a2586d5fa83fca33153fcd2440b8","externalIds":{"ArXiv":"2403.09157","DBLP":"journals/corr/abs-2403-09157","DOI":"10.48550/arXiv.2403.09157","CorpusId":268385505},"title":"VM-UNET-V2 Rethinking Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"97388c71be60282e149c2c3d00db7c0eb2c946e4","externalIds":{"DBLP":"journals/corr/abs-2403-09471","ArXiv":"2403.09471","DOI":"10.48550/arXiv.2403.09471","CorpusId":268384773},"title":"MambaTalk: Efficient Holistic Gesture Synthesis with Selective State Space Models"},{"paperId":"03226803be2fc4dee589883dcb76f28858192e14","externalIds":{"ArXiv":"2403.08330","DBLP":"journals/corr/abs-2403-08330","DOI":"10.48550/arXiv.2403.08330","CorpusId":268379672},"title":"Activating Wider Areas in Image Super-Resolution"},{"paperId":"1321a2e1881caf0e1e330a7cb492ae5f58db5611","externalIds":{"ArXiv":"2403.08479","DBLP":"conf/bibm/FuLCWSY24","DOI":"10.1109/BIBM62325.2024.10822581","CorpusId":268378972},"title":"MD-Dose: A diffusion model based on the Mamba for radiation dose prediction"},{"paperId":"4e03f7bb27b8ce6a7a0f22bd07dad65f4a45ca3f","externalIds":{"ArXiv":"2403.07332","CorpusId":268364247},"title":"LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"b9646f057887825d7471ec01664494b0b7ca5a83","externalIds":{"ArXiv":"2403.07487","DBLP":"journals/corr/abs-2403-07487","DOI":"10.48550/arXiv.2403.07487","CorpusId":268364256},"title":"Motion Mamba: Efficient and Long Sequence Motion Generation with Hierarchical and Bidirectional Selective SSM"},{"paperId":"3af7273d7ca20c0c63cbaa47e60b058840835052","externalIds":{"ArXiv":"2403.06977","DBLP":"conf/eccv/LiLWHWWQ24","DOI":"10.48550/arXiv.2403.06977","CorpusId":268363759},"title":"VideoMamba: State Space Model for Efficient Video Understanding"},{"paperId":"46fb606d4059611d95ffc534bef6ad593c2281a3","externalIds":{"ArXiv":"2403.06467","DBLP":"journals/corr/abs-2403-06467","DOI":"10.48550/arXiv.2403.06467","CorpusId":268349001},"title":"Point Mamba: A Novel Point Cloud Backbone Based on State Space Model with Octree-Based Ordering Strategy"},{"paperId":"4b00522f10c08efaef7980a4f0ae145b40536986","externalIds":{"ArXiv":"2403.06800","DBLP":"conf/miccai/YangWC24","DOI":"10.48550/arXiv.2403.06800","CorpusId":268358302},"title":"MambaMIL: Enhancing Long Sequence Modeling with Sequence Reordering in Computational Pathology"},{"paperId":"05cbfca98309d5b558f20ef11479a0e3e21aa04e","externalIds":{"DBLP":"conf/icra/ZhangYLFXQTC25","ArXiv":"2403.05146","DOI":"10.1109/ICRA55743.2025.11127574","CorpusId":268296963},"title":"Motion-Guided Dual-Camera Tracker for Endoscope Tracking and Motion Analysis in a Mechanical Gastric Simulator"},{"paperId":"a7b6c089f50aeed1361582338610587b0e76d0a4","externalIds":{"ArXiv":"2403.05246","DBLP":"journals/corr/abs-2403-05246","DOI":"10.48550/arXiv.2403.05246","CorpusId":268297157},"title":"LightM-UNet: Mamba Assists in Lightweight UNet for Medical Image Segmentation"},{"paperId":"78283dfdc78654b8e785e4bcb8ee889a66c63a25","externalIds":{"DBLP":"conf/bibm/FangWZWZJZ24","ArXiv":"2403.05160","DOI":"10.1109/BIBM62325.2024.10822552","CorpusId":268297294},"title":"MamMIL: Multiple Instance Learning for Whole Slide Images with State Space Models"},{"paperId":"9463ef5f893e4ade0363242894be081f7684350f","externalIds":{"DBLP":"journals/corr/abs-2403-03849","ArXiv":"2403.03849","DOI":"10.48550/arXiv.2403.03849","CorpusId":268253450},"title":"MedMamba: Vision Mamba for Medical Image Classification"},{"paperId":"375128c5000b08dd6aa1818ae42287f200aaa3c6","externalIds":{"DBLP":"journals/corr/abs-2403-02148","ArXiv":"2403.02148","DOI":"10.1109/TGRS.2024.3485721","CorpusId":268247869},"title":"MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small-Target Detection"},{"paperId":"f8d89b497cb6f1333e7035fd520885464c067a33","externalIds":{"DBLP":"conf/aaai/ZhangYQZ0JYL25","ArXiv":"2403.00762","DOI":"10.48550/arXiv.2403.00762","CorpusId":268230692},"title":"Point Cloud Mamba: Point Cloud Learning via State Space Model"},{"paperId":"8acdb7e54d76e9629887209ad15b92c3d87d3c6b","externalIds":{"DBLP":"journals/corr/abs-2402-18451","ArXiv":"2402.18451","DOI":"10.48550/arXiv.2402.18451","CorpusId":268041453},"title":"MambaMIR: An Arbitrary-Masked Mamba for Joint Medical Image Reconstruction and Uncertainty Estimation"},{"paperId":"f97440c1eacd628453da4c66030f303ad19f1c80","externalIds":{"DBLP":"journals/corr/abs-2402-15761","ArXiv":"2402.15761","DOI":"10.48550/arXiv.2402.15761","CorpusId":267938348},"title":"Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning"},{"paperId":"e730beb44042499763d36214c0498434e470dfd5","externalIds":{"ArXiv":"2402.15648","DBLP":"journals/corr/abs-2402-15648","DOI":"10.48550/arXiv.2402.15648","CorpusId":267938238},"title":"MambaIR: A Simple Baseline for Image Restoration with State-Space Model"},{"paperId":"efb7af4ae6943f298449416529c288e9559c991b","externalIds":{"ArXiv":"2402.12192","DBLP":"journals/corr/abs-2402-12192","DOI":"10.48550/arXiv.2402.12192","CorpusId":267751105},"title":"Pan-Mamba: Effective pan-sharpening with State Space Model"},{"paperId":"0682771fd5f611bce2a536bf83587532469a83df","externalIds":{"ArXiv":"2402.10887","DBLP":"journals/corr/abs-2402-10887","DOI":"10.48550/arXiv.2402.10887","CorpusId":267740717},"title":"Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation"},{"paperId":"21ddc4fc3551619b8a64db6ae124acc72aaae2c2","externalIds":{"DBLP":"conf/nips/LiangZXZZYTB24","ArXiv":"2402.10739","DOI":"10.48550/arXiv.2402.10739","CorpusId":267740688},"title":"PointMamba: A Simple State Space Model for Point Cloud Analysis"},{"paperId":"fe54abaf7a3973202158ed73cc8ec1bb5643782a","externalIds":{"ArXiv":"2402.08506","DBLP":"journals/corr/abs-2402-08506","DOI":"10.48550/arXiv.2402.08506","CorpusId":267636614},"title":"P-Mamba: Marrying Perona Malik Diffusion with Mamba for Efficient Pediatric Echocardiographic Left Ventricular Segmentation"},{"paperId":"dce45c9fcbae7943a19fcdec6e78772185a86abb","externalIds":{"DBLP":"journals/kbs/MaW24","ArXiv":"2402.07245","DOI":"10.1016/j.knosys.2024.112203","CorpusId":268819029},"title":"Semi-Mamba-UNet: Pixel-level contrastive and cross-supervised visual Mamba-based UNet for semi-supervised medical image segmentation"},{"paperId":"1498e54ace1140cdb73aef51b44b7a573101c623","externalIds":{"DBLP":"journals/corr/abs-2402-06378","ArXiv":"2402.06378","DOI":"10.48550/arXiv.2402.06378","CorpusId":267616867},"title":"FD-Vision Mamba for Endoscopic Exposure Correction"},{"paperId":"906d0688e1c683d5fec70e88e71ea1291c666b78","externalIds":{"DBLP":"conf/eccv/LiSG24","ArXiv":"2402.05892","DOI":"10.48550/arXiv.2402.05892","CorpusId":267547860},"title":"Mamba-ND: Selective State Space Modeling for Multi-Dimensional Data"},{"paperId":"08b30038fe938fb8460dff3085bda9ff6503e4c5","externalIds":{"DBLP":"journals/corr/abs-2402-05079","ArXiv":"2402.05079","DOI":"10.48550/arXiv.2402.05079","CorpusId":267523307},"title":"Mamba-UNet: UNet-Like Pure Visual Mamba for Medical Image Segmentation"},{"paperId":"00e88fb1fb1ac4d83be8ee064f4d6399e438cbe5","externalIds":{"DBLP":"journals/corr/abs-2402-04139","ArXiv":"2402.04139","DOI":"10.48550/arXiv.2402.04139","CorpusId":267500036},"title":"U-shaped Vision Mamba for Single Image Dehazing"},{"paperId":"9ed5300327d7a45e408ff418334382fe9ca460a3","externalIds":{"DBLP":"conf/isbi/GongK0WWWL25","ArXiv":"2402.03526","DOI":"10.1109/ISBI60581.2025.10980694","CorpusId":267499913},"title":"Nnmamba: 3D Biomedical Image Segmentation, Classification and Landmark Detection with State Space Model"},{"paperId":"98a7444a221e27f51c89c58fa29a8a1e168c6d69","externalIds":{"ArXiv":"2402.03302","DBLP":"conf/miccai/LiuYZXYLLSYZZW24","DOI":"10.48550/arXiv.2402.03302","CorpusId":267413236},"title":"Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining"},{"paperId":"ffaa66e698655d4b2dee1ab61448d5cc1a743a63","externalIds":{"DBLP":"journals/corr/abs-2402-02491","ArXiv":"2402.02491","DOI":"10.1145/3767748","CorpusId":267413263},"title":"VM-UNet: Vision Mamba UNet for Medical Image Segmentation"},{"paperId":"7c50c5dd5226953cd3620db5cd51ffe9fe2411b0","externalIds":{"ArXiv":"2401.14168","CorpusId":267211763},"title":"Vivim: a Video Vision Mamba for Medical Video Segmentation"},{"paperId":"5358b0e98934f1bbe8f6123a529bbb91dd36d662","externalIds":{"DBLP":"conf/miccai/XingYYLZ24","ArXiv":"2401.13560","DOI":"10.48550/arXiv.2401.13560","CorpusId":267199804},"title":"SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation"},{"paperId":"866318ea410b30b998c00f9fc1a1356ce95404ca","externalIds":{"ArXiv":"2401.13934","CorpusId":268041636},"title":"MambaMorph: a Mamba-based Framework for Medical MR-CT Deformable Registration"},{"paperId":"b24e899ec0f77eef2fc87a9b8e50516367aa1f97","externalIds":{"DBLP":"conf/nips/LiuTZYX0YJ024","ArXiv":"2401.10166","DOI":"10.48550/arXiv.2401.10166","CorpusId":267035250},"title":"VMamba: Visual State Space Model"},{"paperId":"38c48a1cd296d16dc9c56717495d6e44cc354444","externalIds":{"DBLP":"conf/icml/ZhuL0W0W24","ArXiv":"2401.09417","DOI":"10.48550/arXiv.2401.09417","CorpusId":267028142},"title":"Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model"},{"paperId":"c1a04730c83967d0bb904b02263b17893cb50bad","externalIds":{"DBLP":"journals/corr/abs-2401-04722","ArXiv":"2401.04722","DOI":"10.48550/arXiv.2401.04722","CorpusId":266899624},"title":"U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation"},{"paperId":"7bbc7595196a0606a07506c4fb1473e5e87f6082","externalIds":{"ArXiv":"2312.00752","DBLP":"journals/corr/abs-2312-00752","CorpusId":265551773},"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces"},{"paperId":"84dc81dca3ea81c637fb902d4cd26606bbd1bc01","externalIds":{"DBLP":"journals/corr/abs-2308-05864","ArXiv":"2308.05864","DOI":"10.1038/s41592-024-02233-6","CorpusId":260866072,"PubMed":"38532015"},"title":"The multimodality cell segmentation challenge: toward universal solutions"},{"paperId":"a5036f31f0e629dc661f120b8c3b1f374d479ab8","externalIds":{"DBLP":"journals/corr/abs-2304-08485","ArXiv":"2304.08485","DOI":"10.48550/arXiv.2304.08485","CorpusId":258179774},"title":"Visual Instruction Tuning"},{"paperId":"5a9cb1b3dc4655218b3deeaf4a2417a9a8cd0891","externalIds":{"DBLP":"journals/corr/abs-2304-07193","ArXiv":"2304.07193","DOI":"10.48550/arXiv.2304.07193","CorpusId":258170077},"title":"DINOv2: Learning Robust Visual Features without Supervision"},{"paperId":"42754ad2b7b2193b4d8e3d067808cea8913869c4","externalIds":{"DBLP":"conf/iccv/CaiBLWTZ23","ArXiv":"2303.06705","DOI":"10.1109/ICCV51070.2023.01149","CorpusId":257496232},"title":"Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement"},{"paperId":"f393aff1593c2d370ec0ae004910d18e40524967","externalIds":{"ArXiv":"2303.06349","DBLP":"journals/corr/abs-2303-06349","CorpusId":257496654},"title":"Resurrecting Recurrent Neural Networks for Long Sequences"},{"paperId":"bb6644a9f5920abfc1fa008f366a9ff48468e063","externalIds":{"ArXiv":"2212.14427","DBLP":"journals/corr/abs-2212-14427","DOI":"10.1109/CVPR52729.2023.01798","CorpusId":255340494},"title":"Efficient Movie Scene Detection using State-Space Transformers"},{"paperId":"13fe5d02155f6691a685a1d72707f86bd637f9a2","externalIds":{"DBLP":"journals/corr/abs-2211-01784","ArXiv":"2211.01784","DOI":"10.1109/BIBM55620.2022.9995040","CorpusId":253265130},"title":"MALUNet: A Multi-Attention and Light-weight UNet for Skin Lesion Segmentation"},{"paperId":"240300b1da360f22bf0b82c6817eacebba6deed4","externalIds":{"DBLP":"conf/iclr/LiCZCD23","ArXiv":"2210.09298","DOI":"10.48550/arXiv.2210.09298","CorpusId":252917984},"title":"What Makes Convolutional Models Great on Long Sequence Modeling?"},{"paperId":"27d5abc68c2e5555bca47a3aff3f074b01f35b8c","externalIds":{"DBLP":"conf/nips/JiBGYZZLZMW022","ArXiv":"2206.08023","DOI":"10.48550/arXiv.2206.08023","CorpusId":249712481},"title":"AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation"},{"paperId":"71e15a9a52dcafca57bff5f310b95e2c7d0cfc87","externalIds":{"DBLP":"conf/nips/0001GB22","ArXiv":"2203.14343","CorpusId":247762199},"title":"Diagonal State Spaces are as Effective as Structured State Spaces"},{"paperId":"177e957f5cd93229c9794ea652c646d2557b4a69","externalIds":{"ArXiv":"2201.03545","DBLP":"journals/corr/abs-2201-03545","DOI":"10.1109/CVPR52688.2022.01167","CorpusId":245837420},"title":"A ConvNet for the 2020s"},{"paperId":"f7410f535bda5b5a9888512fb954193245c1d0b2","externalIds":{"DBLP":"journals/corr/abs-2201-01266","ArXiv":"2201.01266","DOI":"10.1007/978-3-031-08999-2_22","CorpusId":245668780},"title":"Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images"},{"paperId":"57150ca7d793d6f784cf82da1c349edf7beb6bc2","externalIds":{"DBLP":"conf/cvpr/YuLZSZWFY22","ArXiv":"2111.11418","DOI":"10.1109/CVPR52688.2022.01055","CorpusId":244478080},"title":"MetaFormer is Actually What You Need for Vision"},{"paperId":"ac2618b2ce5cdcf86f9371bcca98bc5e37e46f51","externalIds":{"DBLP":"conf/iclr/GuGR22","ArXiv":"2111.00396","CorpusId":240354066},"title":"Efficiently Modeling Long Sequences with Structured State Spaces"},{"paperId":"ca9047c78d48b606c4e4f0c456b1dda550de28b2","externalIds":{"DBLP":"conf/nips/GuJGSDRR21","ArXiv":"2110.13985","CorpusId":239998472},"title":"Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers"},{"paperId":"bd9ab344da99022cbbbfd3f5c9c82a0b21c60ad9","externalIds":{"ArXiv":"2109.03201","DBLP":"journals/tip/ZhouGZHYWY23","DOI":"10.1109/TIP.2023.3293771","CorpusId":237431181,"PubMed":"37440404"},"title":"nnFormer: Volumetric Medical Image Segmentation via a 3D Transformer"},{"paperId":"67040b931c1a384426c44ae73f9553e97f08cf6a","externalIds":{"ArXiv":"2106.13797","DBLP":"journals/cvm/WangXLFSLLLS22","DOI":"10.1007/s41095-022-0274-8","CorpusId":235652212},"title":"PVT v2: Improved baselines with Pyramid Vision Transformer"},{"paperId":"ea7cfe7f2340584cbe653da6077ee7c213e49b92","externalIds":{"ArXiv":"2105.05537","DBLP":"journals/corr/abs-2105-05537","DOI":"10.1007/978-3-031-25066-8_9","CorpusId":234469981},"title":"Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation"},{"paperId":"b6382a7351c0c595f91472ac71d3b2d87b3c4844","externalIds":{"DBLP":"journals/corr/abs-2103-15691","ArXiv":"2103.15691","DOI":"10.1109/ICCV48922.2021.00676","CorpusId":232417054},"title":"ViViT: A Video Vision Transformer"},{"paperId":"eb20e67ee20cd4122f3812b695b79a3220f2fe4a","externalIds":{"DBLP":"conf/miccai/ZhangLH21","ArXiv":"2102.08005","DOI":"10.1007/978-3-030-87193-2_2","CorpusId":231933932},"title":"TransFuse: Fusing Transformers and CNNs for Medical Image Segmentation"},{"paperId":"fa08b41ccdfc5d8771adfbc34c176fa237d4646c","externalIds":{"DBLP":"conf/icml/BertasiusWT21","ArXiv":"2102.05095","CorpusId":231861462},"title":"Is Space-Time Attention All You Need for Video Understanding?"},{"paperId":"ad7ddcc14984caae308c397f1a589aae75d4ab71","externalIds":{"ArXiv":"2012.12877","DBLP":"journals/corr/abs-2012-12877","CorpusId":229363322},"title":"Training data-efficient image transformers & distillation through attention"},{"paperId":"f28e387d4229c5f690ce4570a391c0f47e7155c7","externalIds":{"MAG":"3112701542","DOI":"10.1038/s41592-020-01008-z","CorpusId":227947847,"PubMed":"33288961"},"title":"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","externalIds":{"ArXiv":"2010.11929","MAG":"3119786062","DBLP":"conf/iclr/DosovitskiyB0WZ21","CorpusId":225039882},"title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"0964490205fdc38c2f0980c9d778069089ca92e3","externalIds":{"ArXiv":"2008.07669","MAG":"3099512283","DBLP":"conf/nips/GuDERR20","CorpusId":221150566},"title":"HiPPO: Recurrent Memory with Optimal Polynomial Projections"},{"paperId":"2709167f1c3a03fa5b970a665ea48ed243aab582","externalIds":{"ArXiv":"2003.13678","DBLP":"conf/cvpr/RadosavovicKGHD20","MAG":"3016265891","DOI":"10.1109/cvpr42600.2020.01044","CorpusId":214714446},"title":"Designing Network Design Spaces"},{"paperId":"4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9","externalIds":{"DBLP":"conf/icml/TanL19","MAG":"2946948417","ArXiv":"1905.11946","CorpusId":167217261},"title":"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"},{"paperId":"e705aeaa9440744c8341b14c7404f6a91e694571","externalIds":{"ArXiv":"1902.06426","DBLP":"journals/corr/abs-1902-06426","MAG":"2913444875","CorpusId":67787647},"title":"2017 Robotic Instrument Segmentation Challenge"},{"paperId":"1f3ff6ca41574a7136f5fe4925b7bc54189837fb","externalIds":{"ArXiv":"1902.03368","DBLP":"journals/corr/abs-1902-03368","MAG":"2932083555","CorpusId":60440592},"title":"Skin Lesion Analysis Toward Melanoma Detection 2018: A Challenge Hosted by the International Skin Imaging Collaboration (ISIC)"},{"paperId":"37a18be8c599b781cc28b6a62d8f11e8a6a75169","externalIds":{"DBLP":"conf/miccai/Myronenko18","MAG":"2963046541","ArXiv":"1810.11654","DOI":"10.1007/978-3-030-11726-9_28","CorpusId":53104235},"title":"3D MRI brain tumor segmentation using autoencoder regularization"},{"paperId":"aaab0bd4d79d4f19109bab0fbcdb05070fb0edd1","externalIds":{"ArXiv":"1807.10221","MAG":"2953120679","DBLP":"conf/eccv/XiaoLZJS18","DOI":"10.1007/978-3-030-01228-1_26","CorpusId":50781105},"title":"Unified Perceptual Parsing for Scene Understanding"},{"paperId":"c1f457e31b611da727f9aef76c283a18157dfa83","externalIds":{"DBLP":"journals/corr/abs-1806-09055","MAG":"2810075754","ArXiv":"1806.09055","CorpusId":49411844},"title":"DARTS: Differentiable Architecture Search"},{"paperId":"9406246f6972c03e5bfaac4df4676648dc4ac935","externalIds":{"MAG":"2804047627","DBLP":"journals/tmi/BernardLZCYHCLC18","DOI":"10.1109/TMI.2018.2837502","CorpusId":51610194,"PubMed":"29994302"},"title":"Deep Learning Techniques for Automatic MRI Cardiac Multi-Structures Segmentation and Diagnosis: Is the Problem Solved?"},{"paperId":"fb37561499573109fc2cebb6a7b08f44917267dd","externalIds":{"MAG":"2963420686","DBLP":"journals/corr/abs-1709-01507","ArXiv":"1709.01507","DOI":"10.1109/CVPR.2018.00745","CorpusId":140309863},"title":"Squeeze-and-Excitation Networks"},{"paperId":"7dc4f387ae9e6111b929d7a4bc6ec8cb58d41a64","externalIds":{"MAG":"2594873583","ArXiv":"1703.00523","DBLP":"journals/corr/Berseth17","CorpusId":39244443},"title":"ISIC 2017 - Skin Lesion Analysis Towards Melanoma Detection"},{"paperId":"d997beefc0922d97202789d2ac307c55c2c52fba","externalIds":{"MAG":"2950642167","DBLP":"conf/cvpr/QiSMG17","ArXiv":"1612.00593","DOI":"10.1109/CVPR.2017.16","CorpusId":5115938},"title":"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"},{"paperId":"5582bebed97947a41e3ddd9bd1f284b73f1648c2","externalIds":{"MAG":"2962858109","DBLP":"conf/iccv/SelvarajuCDVPB17","ArXiv":"1610.02391","DOI":"10.1007/s11263-019-01228-7","CorpusId":15019293},"title":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"},{"paperId":"88512be44744615f4baa8e14f600f036db4c2433","externalIds":{"MAG":"2507296351","DBLP":"journals/corr/ZhouZPFBT16","ArXiv":"1608.05442","DOI":"10.1007/s11263-018-1140-0","CorpusId":11371972},"title":"Semantic Understanding of Scenes Through the ADE20K Dataset"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","externalIds":{"DBLP":"conf/cvpr/HeZRS16","MAG":"2949650786","ArXiv":"1512.03385","DOI":"10.1109/cvpr.2016.90","CorpusId":206594692},"title":"Deep Residual Learning for Image Recognition"},{"paperId":"6364fdaa0a0eccd823a779fcdd489173f938e91a","externalIds":{"MAG":"1901129140","DBLP":"journals/corr/RonnebergerFB15","ArXiv":"1505.04597","DOI":"10.1007/978-3-319-24574-4_28","CorpusId":3719281},"title":"U-Net: Convolutional Networks for Biomedical Image Segmentation"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","externalIds":{"ArXiv":"1405.0312","DBLP":"conf/eccv/LinMBHPRDZ14","MAG":"2952122856","DOI":"10.1007/978-3-319-10602-1_48","CorpusId":14113767},"title":"Microsoft COCO: Common Objects in Context"},{"paperId":"abd1c342495432171beb7ca8fd9551ef13cbd0ff","externalIds":{"DBLP":"conf/nips/KrizhevskySH12","MAG":"2618530766","DOI":"10.1145/3065386","CorpusId":195908774},"title":"ImageNet classification with deep convolutional neural networks"},{"paperId":"810c971f8ebbe8786dcf3d846661f084bda77f12","externalIds":{"DBLP":"journals/corr/abs-2405-02844","DOI":"10.48550/arXiv.2405.02844","CorpusId":269605365},"title":"SMCD: High Realism Motion Style Transfer via Mamba-based Diffusion"},{"paperId":"e1ed7615b4918ead3d693ad3dc42e45e5742d2e2","externalIds":{"DBLP":"journals/corr/abs-2404-07932","DOI":"10.48550/arXiv.2404.07932","CorpusId":269042827},"title":"FusionMamba: Efficient Image Fusion with State Space Model"},{"paperId":"83cefdeb36c001550e3c0e0c45d10d4b80485229","externalIds":{"DBLP":"journals/corr/abs-2203-00131","DOI":"10.48550/arXiv.2203.00131","CorpusId":247187710},"title":"A Multi-scale Transformer for Medical Image Segmentation: Architectures, Model Efficiency, and Benchmarks"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","externalIds":{"ArXiv":"2103.14030","DBLP":"conf/iccv/LiuL00W0LG21","DOI":"10.1109/ICCV48922.2021.00986","CorpusId":232352874},"title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"}]}